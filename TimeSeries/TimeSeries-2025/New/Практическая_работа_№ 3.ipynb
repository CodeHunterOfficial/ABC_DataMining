{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOp1ei54FmfRAhbgYIOALZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/TimeSeries/TimeSeries-2025/New/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%96%E2%80%AF3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Практическая работа № 3**  \n",
        "## **Сравнительный анализ классических моделей машинного обучения для анализа и прогнозирования временных рядов (табличные данные)**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Цель и задачи работы**\n",
        "\n",
        "**Цель работы** — формирование у обучающегося системного представления о методологии сравнительного анализа классических моделей машинного обучения, применяемых к задачам прогнозирования временных рядов на основе табличных данных, при условии соблюдения строгих требований к предобработке, временной валидации, настройке гиперпараметров и интерпретации результатов. Работа направлена на освоение практических навыков трансформации временного ряда в регрессионную задачу, корректной оптимизации моделей с использованием временной кросс-валидации, диагностики остатков, статистического сравнения и публикации воспроизводимых результатов в соответствии с передовыми научно-методическими стандартами.\n",
        "\n",
        "**Основные задачи работы:**  \n",
        "1. Использовать обработанный табличный датасет из Практической работы № 1, содержащий не менее 720 последовательных наблюдений, с подтверждённой стационарностью, стабилизированной дисперсией и богатым набором инженерных признаков (лаги, скользящие окна, циклические кодировки).  \n",
        "2. Формализовать задачу прогнозирования как задачу табличной регрессии с соблюдением временного порядка и отсутствием утечки будущего.  \n",
        "3. Определить пространства гиперпараметров для всех моделей и провести их **настройку с использованием временной кросс-валидации** (`TimeSeriesSplit`) через `GridSearchCV` и `RandomizedSearchCV`.  \n",
        "4. Реализовать и сравнить три стратегии многопшагового прогнозирования: рекурсивную, прямую и гибридную — для горизонтов \\( h = 1, 7, 30 \\).  \n",
        "5. Построить и протестировать классические модели машинного обучения:  \n",
        "   - Линейные: OLS, Ridge, Lasso, ElasticNet  \n",
        "   - KNNRegressor  \n",
        "   - Decision Tree, Random Forest, Extra Trees  \n",
        "   - Градиентный бустинг: XGBoost, LightGBM, CatBoost  \n",
        "   - Support Vector Regression: SVR, NuSVR, LinearSVR  \n",
        "   - MLPRegressor (многослойный перцептрон)  \n",
        "   - Gaussian Process Regressor  \n",
        "   - Робастные регрессоры: Huber, Theil–Sen, RANSAC  \n",
        "   - А также бенчмарки: Naive, Seasonal Naive  \n",
        "6. Провести углублённую диагностику адекватности моделей: тест Льюнга–Бокса на автокорреляцию остатков, анализ гомоскедастичности, проверку нормальности распределения ошибок (Q-Q график, тест Шапиро–Уилка).  \n",
        "7. Оценить качество прогнозов по метрикам: MAE, RMSE, MAPE, MASE, SMAPE, R², RMSLE — **на независимой тестовой выборке, не участвовавшей в настройке**.  \n",
        "8. Применить тест Дикболда–Мариано для статистического сравнения точности прогнозов.  \n",
        "9. Проанализировать интерпретируемость моделей: коэффициенты линейных моделей, важность признаков, SHAP-объяснения, устойчивость выводов при разных разбиениях.  \n",
        "10. Оценить вычислительную сложность: время настройки, прогнозирования и потребление памяти.  \n",
        "11. Разработать интерактивный веб-инструмент для визуального и функционального сравнения моделей, включая отображение гиперпараметров, важности признаков и SHAP-диаграмм.  \n",
        "12. Обеспечить воспроизводимость и открытость результатов: опубликовать код, сравнительные таблицы, веб-приложение и аналитический отчёт.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Теоретические предпосылки**\n",
        "\n",
        "Модели машинного обучения не учитывают временную структуру данных по умолчанию, что делает их применение к временным рядам методологически нетривиальной задачей. Успешное использование ML-подходов требует **трансформации ряда в табличную форму** с помощью лагов, скользящих статистик и циклических кодировок, а также **строгого соблюдения временного порядка** при разделении и валидации.\n",
        "\n",
        "Ключевым условием объективного сравнения является **настройка гиперпараметров каждой модели на равных основаниях**. Использование параметров по умолчанию приводит к смещённым выводам, так как разные алгоритмы чувствительны к гиперпараметрам в разной степени. Однако для временных рядов стандартная кросс-валидация с перемешиванием (shuffle=True) недопустима — она нарушает причинно-временную структуру и приводит к утечке будущего. Единственно корректный подход — временная кросс-валидация (rolling origin, expanding window), реализуемая в scikit-learn через TimeSeriesSplit.\n",
        "\n",
        "\n",
        "\n",
        "Выбор метрики для оптимизации также критичен: предпочтение отдаётся **масштаб-инвариантным и устойчивым к выбросам метрикам**, таким как MASE или MAE, особенно при наличии аномалий.\n",
        "\n",
        "После настройки модель оценивается **только на независимой тестовой выборке**, что гарантирует объективность итоговых метрик.\n",
        "\n",
        "Интерпретируемость рассматривается как неотъемлемая часть анализа. Для линейных моделей это — коэффициенты и их статистическая значимость; для ансамблей — важность признаков и SHAP-значения. Это позволяет не только прогнозировать, но и **объяснять динамику системы**, выявлять ключевые детерминанты и проверять соответствие модели предметной области.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Порядок выполнения работы**\n",
        "\n",
        "Работа выполняется в несколько последовательных этапов, каждый из которых направлен на достижение конкретных образовательных и исследовательских результатов.\n",
        "\n",
        "#### **3.1. Использование данных из Практической работы № 1**\n",
        "\n",
        "**Задача:** Обеспечить методологическую преемственность и воспроизводимость.  \n",
        "**Требования к выполнению:**  \n",
        "– В качестве входных данных используется финальный обработанный датасет из Практической работы № 1:  \n",
        "  • Объём: не менее 720 последовательных наблюдений;  \n",
        "  • Наличие целевой переменной и не менее пяти дополнительных признаков (включая лаги \\( y_{t-1}, y_{t-7}, y_{t-30} \\), скользящие средние, циклические кодировки времени);  \n",
        "  • Подтверждённая стационарность (результаты ADF/KPSS);  \n",
        "  • Сохранённые параметры преобразований (например, \\( \\lambda \\) для Бокса–Кокса или параметры лог-трансформации).  \n",
        "– Все признаки представлены в табличной форме без пропусков на момент обучения.  \n",
        "– Обратное преобразование прогнозов осуществляется с использованием сохранённых параметров.\n",
        "\n",
        "#### **3.2. Формализация задачи и разделение данных**\n",
        "\n",
        "**Задача:** Корректно сформулировать задачу машинного обучения с учётом временной структуры.  \n",
        "**Требования к выполнению:**  \n",
        "– Целевая переменная: \\( y_t \\); признаки \\( X_t \\): все доступные лаги, статистики и экзогенные факторы.  \n",
        "– Разделение данных:  \n",
        "  • Тренировочная + валидационная часть: всё до \\( T - 90 \\);  \n",
        "  • Финальный тест: последние 90 наблюдений — **только для итоговой оценки, не участвует в настройке**.  \n",
        "– Для кросс-валидации: `TimeSeriesSplit(n_splits=5, test_size=60)` — без перемешивания, с сохранением порядка.\n",
        "\n",
        "#### **3.3. Определение пространств гиперпараметров и настройка моделей**\n",
        "\n",
        "**Задача:** Привести каждую модель к её оптимальной конфигурации с использованием временной кросс-валидации.  \n",
        "**Требования к выполнению:**  \n",
        "– Для каждой модели определяется пространство гиперпараметров на основе рекомендаций литературы:  \n",
        "  • **Линейные модели**: `alphas = np.logspace(-4, 4, 50)` для Ridge/Lasso;  \n",
        "  • **Деревья**: `max_depth ∈ [5,10,15,None]`, `n_estimators ∈ [100,200,300]`;  \n",
        "  • **XGBoost/LightGBM**: `learning_rate ∈ [0.01,0.3]`, `max_depth ∈ [3,10]`, `subsample ∈ [0.6,1.0]`;  \n",
        "  • **SVR**: `C ∈ [0.1,1,10,100]`, `gamma ∈ ['scale','auto',0.001,0.01,0.1]`;  \n",
        "  • **MLP**: `hidden_layer_sizes ∈ [(50,), (100,50), (50,50,50)]`, `alpha ∈ [1e-4,1e-2]`.  \n",
        "– Настройка:  \n",
        "  • `GridSearchCV` — для моделей с небольшим числом гиперпараметров (линейные, SVR, KNN);  \n",
        "  • `RandomizedSearchCV(n_iter=30)` — для моделей с большим пространством (бустинг, MLP);  \n",
        "  • Целевая метрика: **MASE** или **MAE** (масштаб-инвариантные);  \n",
        "  • Все процедуры выполняются **только на тренировочной части** с `cv=TimeSeriesSplit`.  \n",
        "– Фиксация: оптимальные гиперпараметры, значение метрики на валидации, время настройки.\n",
        "\n",
        "#### **3.4. Стратегии многопшагового прогнозирования**\n",
        "\n",
        "**Задача:** Реализовать и сравнить подходы к прогнозу на горизонт \\( h \\geq 7 \\).  \n",
        "**Требования к выполнению:**  \n",
        "– **Рекурсивная стратегия:** одна настроенная модель; прогноз на \\( t+1 \\) используется как вход для \\( t+2 \\);  \n",
        "– **Прямая стратегия:** отдельная настройка и обучение модели для каждого шага \\( t+1, \\dots, t+h \\);  \n",
        "– **Гибридная стратегия:** например, рекурсивная для \\( h \\leq 3 \\), прямая — для \\( h > 3 \\);  \n",
        "– Для каждой стратегии и каждого горизонта (\\( h = 1, 7, 30 \\)):  \n",
        "  • Расчёт MAE, RMSE на каждом шаге;  \n",
        "  • Фиксация общего времени вычислений (включая настройку для прямой стратегии);  \n",
        "  • Построение графика накопления ошибки и времени.\n",
        "\n",
        "#### **3.5. Построение и настройка моделей**\n",
        "\n",
        "**Задача:** Реализовать единообразный интерфейс для всех классических ML-моделей.  \n",
        "**Требования к выполнению:**  \n",
        "– **Линейные модели:**  \n",
        "  • OLS: `LinearRegression()`;  \n",
        "  • Ridge/Lasso/ElasticNet: с кросс-валидацией по α;  \n",
        "– **KNN:** `KNeighborsRegressor(n_neighbors=5, weights='distance')` с настройкой `n_neighbors` и `weights`;  \n",
        "– **Деревья:**  \n",
        "  • `DecisionTreeRegressor(max_depth=10)`;  \n",
        "  • `RandomForestRegressor(n_estimators=200)`;  \n",
        "  • `ExtraTreesRegressor(n_estimators=200)`;  \n",
        "– **Градиентный бустинг:**  \n",
        "  • `XGBRegressor(n_estimators=200, objective='reg:squarederror')`;  \n",
        "  • `LGBMRegressor(n_estimators=200)`;  \n",
        "  • `CatBoostRegressor(iterations=200, verbose=False)`;  \n",
        "– **Метод опорных векторов:**  \n",
        "  • `SVR(kernel='rbf')`, `NuSVR()`, `LinearSVR(max_iter=10000)`;  \n",
        "– **Нейросети:** `MLPRegressor(hidden_layer_sizes=(100,50), max_iter=500)`;  \n",
        "– **Гауссовские процессы:** `GaussianProcessRegressor(alpha=1e-5)`;  \n",
        "– **Робастные регрессоры:** `HuberRegressor()`, `TheilSenRegressor()`, `RANSACRegressor()`;  \n",
        "– **Бенчмарки:** Naive (\\( \\hat{y}_{t+h} = y_t \\)), Seasonal Naive (\\( \\hat{y}_{t+h} = y_{t+h-s} \\));  \n",
        "– Для всех моделей: прогноз на тесте, обратное преобразование, сохранение времени и метаданных.\n",
        "\n",
        "#### **3.6. Диагностика адекватности моделей**\n",
        "\n",
        "**Задача:** Убедиться, что модель корректно аппроксимирует динамику ряда.  \n",
        "**Требования к выполнению:**  \n",
        "– **Тест Льюнга–Бокса** на остатках с использованием `statsmodels.stats.diagnostic.acorr_ljungbox` (H₀: автокорреляция отсутствует; p > 0.05 — адекватность);  \n",
        "– **Гомоскедастичность:** визуальный анализ графика остатков \\( \\varepsilon_t \\) против прогнозов \\( \\hat{y}_t \\);  \n",
        "– **Нормальность остатков:**  \n",
        "  • Q-Q график;  \n",
        "  • Тест Шапиро–Уилка (`scipy.stats.shapiro`); p > 0.05 — нормальность не отвергается;  \n",
        "– **ACF/PACF остатков** — должны лежать в пределах доверительного интервала.  \n",
        "– Диагностика обязательна для всех линейных моделей и топ-5 моделей по метрикам.\n",
        "\n",
        "#### **3.7. Оценка качества и статистическое сравнение**\n",
        "\n",
        "**Задача:** Обоснованно сравнить модели по объективным критериям.  \n",
        "**Требования к выполнению:**  \n",
        "– Расчёт метрик **на финальной тестовой выборке** для каждого горизонта: MAE, RMSE, MAPE, MASE, SMAPE, R², RMSLE;  \n",
        "– Применение **теста Дикболда–Мариано** (`statsmodels.stats.diagnostic.dm_test`) для попарного сравнения прогнозов топ-5 моделей;  \n",
        "– Составление **сравнительных таблиц**:  \n",
        "  • Модели × стратегии × горизонты (метрики, время настройки, время прогноза);  \n",
        "  • Интерпретируемость (коэффициенты, SHAP, важность признаков);  \n",
        "  • Диагностические p-значения (Ljung–Box, Shapiro–Wilk);  \n",
        "– Ранжирование моделей по взвешенной оценке, учитывающей точность (50%), адекватность (30%) и интерпретируемость (20%).\n",
        "\n",
        "#### **3.8. Анализ интерпретируемости моделей**\n",
        "\n",
        "**Задача:** Оценить способность модели объяснять динамику системы.  \n",
        "**Требования к выполнению:**  \n",
        "– Для **линейных моделей**: анализ коэффициентов, их знаков, величин и p-значений (через `statsmodels`);  \n",
        "– Для **ансамблей деревьев**: встроенная важность признаков и **SHAP-значения** (`shap.TreeExplainer`);  \n",
        "– Для **KNN, SVR, MLP**: интерпретируемость ограничена — фиксируется как ограничение;  \n",
        "– Проведение **локальной интерпретации**: SHAP-водопадные диаграммы для отдельных точек прогноза;  \n",
        "– Анализ **устойчивости**: повторный запуск настройки с разными random_state — насколько стабильны ключевые признаки?  \n",
        "– Результаты интерпретации включаются в сравнительные таблицы и веб-интерфейс.\n",
        "\n",
        "#### **3.9. Анализ вычислительной эффективности**\n",
        "\n",
        "**Задача:** Оценить практическую применимость моделей в условиях ограниченных ресурсов.  \n",
        "**Требования к выполнению:**  \n",
        "– Фиксация времени:  \n",
        "  • Настройка (в секундах),  \n",
        "  • Прогнозирование (в миллисекундах на точку);  \n",
        "– Оценка потребления памяти (опционально, через `memory_profiler`);  \n",
        "– Сравнение `GridSearchCV` и `RandomizedSearchCV` по качеству/времени;  \n",
        "– Включение столбца «Вычислительная сложность» в сравнительные таблицы: низкая/средняя/высокая.\n",
        "\n",
        "#### **3.10. Разработка веб-интерфейса для анализа результатов**\n",
        "\n",
        "**Задача:** Создать интерактивное приложение для визуального и функционального сравнения моделей.  \n",
        "**Требования к выполнению:**  \n",
        "– Возможность загрузки пользовательского CSV или выбора встроенного датасета (из работы № 1);  \n",
        "– Выбор модели, горизонта прогноза и стратегии;  \n",
        "– Автоматическое построение:  \n",
        "  • Графика прогноза с остатками;  \n",
        "  • Важности признаков (столбчатая диаграмма);  \n",
        "  • SHAP-диаграмм (глобальных и локальных);  \n",
        "  • Таблицы метрик, гиперпараметров и времени;  \n",
        "– Экспорт прогноза и отчёта в CSV/PDF;  \n",
        "– Рекомендуемые технологии: Streamlit, Plotly, scikit-learn, shap, xgboost.\n",
        "\n",
        "#### **3.11. Публикация результатов исследования**\n",
        "\n",
        "**Задача:** Обеспечить открытость и воспроизводимость работы.  \n",
        "**Требования к выполнению:**  \n",
        "– Для кода и результатов составляется метаописание, включающее:  \n",
        "  • Список моделей и пространств гиперпараметров;  \n",
        "  • Оптимальные гиперпараметры и метрики на валидации;  \n",
        "  • Сравнительные таблицы по всем моделям, стратегиям и горизонтам;  \n",
        "  • Ключевые выводы и рекомендации;  \n",
        "  • Инструкцию по запуску веб-приложения;  \n",
        "– Все материалы публикуются в публичном репозитории (GitHub/GitLab);  \n",
        "– Веб-приложение развёртывается на Hugging Face Spaces, Render или Railway;  \n",
        "– Использование открытых лицензий: MIT (код), CC BY 4.0 (данные).\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Дополнительные исследовательские задания**\n",
        "\n",
        "1. Сравнение эффективности `GridSearchCV` и `RandomizedSearchCV` по качеству и времени настройки.  \n",
        "2. Анализ влияния масштабирования признаков (StandardScaler, RobustScaler) на качество нелинейных моделей.  \n",
        "3. Построение ансамбля из топ-3 ML-моделей по каждому горизонту (простое усреднение или стекинг).  \n",
        "4. Оценка устойчивости SHAP-значений при разных разбиениях данных.  \n",
        "5. Анализ чувствительности прогнозов к выбросам в обучающей выборке (сравнение робастных и обычных моделей).  \n",
        "6. Исследование зависимости времени настройки от длины временного ряда (масштабируемость).\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Требования к отчёту**\n",
        "\n",
        "Отчёт оформляется в соответствии с ГОСТ 7.32–2017 и должен содержать следующие разделы:  \n",
        "1. Введение — постановка задачи, актуальность ML для временных рядов, обзор литературы, указание на преемственность с Практической работой № 1.  \n",
        "2. Методология — описание данных, трансформация ряда в признаки, пространства гиперпараметров, стратегии прогнозирования, список моделей и инструментов.  \n",
        "3. Результаты экспериментов — сравнительные таблицы, графики ошибок, результаты теста Дикболда–Мариано, диагностика остатков, SHAP-визуализации.  \n",
        "4. Обсуждение — интерпретация важных признаков, анализ влияния настройки гиперпараметров, сравнение стратегий, вычислительная эффективность, соответствие выводов предметной области.  \n",
        "5. Заключение — итоговые выводы, практические рекомендации по выбору модели в продакшене, ограничения исследования.  \n",
        "6. Список использованных источников — оформлен в соответствии с ГОСТ Р 7.0.5–2008.  \n",
        "7. Приложения — фрагменты кода, скриншоты веб-интерфейса, примеры сравнительных таблиц, таблицы гиперпараметров.  \n",
        "Отчёт сопровождается ссылками на репозиторий с кодом, веб-приложение и опубликованные данные.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Критерии оценивания**\n",
        "\n",
        "| Оценка | Критерии |\n",
        "|--------|----------|\n",
        "| **Отлично** | Полное выполнение всех этапов; настройка гиперпараметров через временную кросс-валидацию для всех моделей; реализация всех трёх стратегий прогнозирования; углублённая диагностика остатков; тест Дикболда–Мариано; развёрнутый анализ интерпретируемости (SHAP, коэффициенты, устойчивость); оценка вычислительной сложности; функциональный веб-интерфейс с отображением гиперпараметров и объяснений; публикация всех материалов; отчёт, соответствующий ГОСТ. |\n",
        "| **Хорошо** | Выполнение основных этапов; настройка большинства моделей; наличие сравнительных таблиц и базовой диагностики; реализация основных моделей и стратегий; отсутствие лишь отдельных элементов (например, SHAP или анализа времени). |\n",
        "| **Удовлетворительно** | Реализованы 6–8 моделей без полной настройки; есть сравнение по метрикам; отсутствует диагностика остатков, интерпретируемость или стратегии прогнозирования. |\n",
        "| **Неудовлетворительно** | Отсутствуют ключевые компоненты работы (данные из работы № 1 не использованы, отсутствует настройка гиперпараметров, нет сравнительного анализа, отчёт не представлен). |\n"
      ],
      "metadata": {
        "id": "u0j1NLrTe5go"
      }
    }
  ]
}