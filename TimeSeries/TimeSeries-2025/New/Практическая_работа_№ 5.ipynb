{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOMoBHC0Nn/DKGbP6dQK6Xf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/TimeSeries/TimeSeries-2025/New/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%96%E2%80%AF5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Практическая работа № 5**  \n",
        "## **Глубокое обучение для табличных данных и временных рядов**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Цель и задачи работы**\n",
        "\n",
        "**Цель работы** — формирование у обучающегося системного представления о методологии сравнительного анализа моделей глубокого обучения, применяемых к задачам машинного обучения на структурированных данных, включая как стандартные табличные задачи (регрессия, классификация), так и специфические сценарии временных рядов. Работа направлена на освоение практических навыков проектирования, настройки, диагностики и интерпретации глубоких архитектур при условии соблюдения строгих требований к предобработке, корректному разделению данных, отсутствию утечки будущего и воспроизводимости результатов в соответствии с передовыми научно-методическими стандартами.\n",
        "\n",
        "**Основные задачи работы:**  \n",
        "1. Использовать два типа данных:  \n",
        "   – **Табличный датасет из Практической работы № 1**, содержащий не менее 720 последовательных наблюдений, с подтверждённой стационарностью, стабилизированной дисперсией и богатым набором инженерных признаков (лаги, скользящие окна, циклические кодировки), преобразованный в регрессионную задачу;  \n",
        "   – **Дополнительный табличный датасет без временной структуры**, содержащий смешанные типы признаков (например, California Housing для регрессии или Adult Income для классификации).  \n",
        "2. Формализовать задачу машинного обучения с учётом природы данных: для временных рядов — как задачу прогнозирования с соблюдением временного порядка; для табличных данных — как стандартную задачу регрессии или классификации.  \n",
        "3. Определить архитектуры и пространства гиперпараметров для всех моделей и провести их обучение с использованием корректной валидации: `TimeSeriesSplit` для временных рядов, стратифицированное разбиение — для табличных данных.  \n",
        "4. Реализовать и сравнить следующие архитектуры глубокого обучения:  \n",
        "   – **MLP (многослойный перцептрон)** — базовая архитектура для табличных данных;  \n",
        "   – **1D-CNN** — применённая к последовательности лагов (для временных рядов) или к эмбеддингам категориальных признаков (для табличных данных);  \n",
        "   – **RNN-семейство**: Vanilla RNN, LSTM, GRU — только для задач с временной структурой;  \n",
        "   – **Двунаправленные модели**: BiLSTM, BiGRU — для offline-анализа временных рядов;  \n",
        "   – **Encoder–Decoder** — для многопшагового прогнозирования временных рядов;  \n",
        "   – **Гибридные архитектуры**:  \n",
        "     • **Tabular + Temporal**: MLP для статических признаков + LSTM для временных;  \n",
        "     • **CNN + RNN**: извлечение локальных паттернов → моделирование динамики;  \n",
        "     • **Residual MLP/LSTM**: с skip-соединениями для стабилизации градиентов.  \n",
        "5. Обеспечить корректную предобработку: масштабирование числовых признаков, кодирование категориальных (эмбеддинги или one-hot), формирование окон без утечки будущего.  \n",
        "6. Оценить качество прогнозов/классификации по метрикам:  \n",
        "   – Для регрессии: MAE, RMSE, MASE, R²;  \n",
        "   – Для классификации: Accuracy, F1, AUC-ROC — **на независимой тестовой выборке, не участвовавшей в настройке**.  \n",
        "7. Провести углублённую диагностику обучения:  \n",
        "   – Графики train/val loss и метрик;  \n",
        "   – Анализ переобучения (разрыв между train и val);  \n",
        "   – Мониторинг градиентов и норм весов (особенно для RNN).  \n",
        "8. Проанализировать интерпретируемость моделей:  \n",
        "   – Для MLP/CNN: Saliency Maps, Integrated Gradients;  \n",
        "   – Для RNN/LSTM/GRU: анализ скрытых состояний и вентилей;  \n",
        "   – Для гибридных моделей: вклад временных и статических признаков.  \n",
        "9. Сравнить все глубокие модели между собой и с **лучшими классическими моделями** из Практической работы № 3 (LightGBM, XGBoost, Ridge и др.).  \n",
        "10. Оценить вычислительную сложность: время обучения, прогнозирования и потребление памяти.  \n",
        "11. Разработать модульный фреймворк на PyTorch или TensorFlow с единым интерфейсом для всех архитектур и типов данных.  \n",
        "12. Обеспечить воспроизводимость и открытость результатов: опубликовать код, сравнительные таблицы, веса моделей и аналитический отчёт.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Теоретические предпосылки**\n",
        "\n",
        "На протяжении десятилетий табличные данные оставались доменом классических алгоритмов — деревьев решений, ансамблей и линейных моделей. Глубокое обучение долгое время считалось неэффективным в этой области из-за отсутствия пространственной или последовательной структуры, на которой строятся CNN/RNN, высокого риска переобучения при малом объёме данных и сложности работы с разнородными типами признаков.\n",
        "\n",
        "Однако последние годы показали, что при правильной архитектуре, регуляризации и инициализации **глубокие модели могут конкурировать, а иногда и превосходить градиентный бустинг**, особенно в задачах с длинными последовательностями, сложными нелинейными взаимодействиями признаков или мультимодальными структурами.\n",
        "\n",
        "**MLP**, несмотря на простоту, остаётся сильной базовой линией для табличных данных. С добавлением dropout, batch normalization и Xavier-инициализации он демонстрирует удивительную устойчивость.\n",
        "\n",
        "**1D-CNN** находят применение двумя способами: как свёртки по временной оси для извлечения локальных паттернов в лагах и как свёртки по эмбеддингам категориальных признаков, выстроенных в искусственную «последовательность».\n",
        "\n",
        "**Рекуррентные сети (LSTM, GRU)** применимы исключительно в контексте временной или упорядоченной структуры данных. Их способность моделировать долгосрочные зависимости делает их незаменимыми в задачах прогнозирования, но бесполезными в чисто табличных задачах без порядка.\n",
        "\n",
        "**Encoder–Decoder** архитектура — естественное решение для многопшагового прогнозирования, где требуется сгенерировать последовательность выходов. В отличие от рекурсивной стратегии, она обучается end-to-end и избегает накопления ошибки.\n",
        "\n",
        "**Гибридные модели** открывают путь к объединению статического и динамического контекста: например, прогнозирование спроса с учётом как исторических продаж (LSTM), так и характеристик товара и магазина (MLP).\n",
        "\n",
        "Ключевой тезис настоящей работы: **глубокое обучение для табличных данных — это не универсальный инструмент, а контекстно-зависимый выбор, требующий понимания природы данных и задачи**.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Порядок выполнения работы**\n",
        "\n",
        "Работа выполняется в несколько последовательных этапов, каждый из которых направлен на достижение конкретных образовательных и исследовательских результатов.\n",
        "\n",
        "#### **3.1. Использование данных из Практической работы № 1 и дополнительного табличного датасета**\n",
        "\n",
        "**Задача:** Обеспечить методологическую преемственность и введение разнообразных сценариев.  \n",
        "**Требования к выполнению:**  \n",
        "– **Датасет 1 (временной ряд)**: финальная таблица из Практической работы № 1:  \n",
        "  • Объём: не менее 720 последовательных наблюдений;  \n",
        "  • Наличие целевой переменной и не менее пяти дополнительных признаков (включая лаги \\( y_{t-1}, y_{t-7}, y_{t-30} \\), скользящие средние, циклические кодировки);  \n",
        "  • Подтверждённая стационарность (результаты ADF/KPSS);  \n",
        "  • Сохранённые параметры преобразований (например, \\( \\lambda \\) для Бокса–Кокса).  \n",
        "– **Датасет 2 (табличный)**: например, `California Housing` (регрессия) или `Adult Income` (классификация):  \n",
        "  • Содержит числовые и категориальные признаки;  \n",
        "  • Объём ≥10 000 наблюдений.  \n",
        "– Все признаки представлены в табличной форме без пропусков на момент обучения.\n",
        "\n",
        "#### **3.2. Формализация задачи и разделение данных**\n",
        "\n",
        "**Задача:** Корректно сформулировать задачу машинного обучения с учётом природы данных.  \n",
        "**Требования к выполнению:**  \n",
        "– Для временных рядов:  \n",
        "  • Целевая переменная: \\( y_t \\); признаки \\( X_t \\): все доступные лаги и инженерные признаки;  \n",
        "  • Разделение: тренировочная + валидационная часть — всё до \\( T - 90 \\); финальный тест — последние 90 наблюдений (только для итоговой оценки);  \n",
        "  • Для кросс-валидации: `TimeSeriesSplit(n_splits=5, test_size=60)` — без перемешивания.  \n",
        "– Для табличных данных:  \n",
        "  • Стандартная задача регрессии/классификации;  \n",
        "  • Разделение: 80/10/10 с стратификацией по целевой переменной.\n",
        "\n",
        "#### **3.3. Определение архитектур и настройка моделей**\n",
        "\n",
        "**Задача:** Привести каждую модель к её оптимальной конфигурации с использованием корректной валидации.  \n",
        "**Требования к выполнению:**  \n",
        "– Для всех моделей определяются гиперпараметры на основе рекомендаций литературы:  \n",
        "  • **MLP**: `hidden_layers ∈ [(128,64), (256,128,64)]`, `dropout ∈ [0.2, 0.5]`;  \n",
        "  • **1D-CNN**: `kernel_size ∈ [3,5,7]`, `filters ∈ [32,64]`;  \n",
        "  • **LSTM/GRU**: `hidden_size ∈ [32,64,128]`, `num_layers ∈ [1,2]`;  \n",
        "  • **Encoder–Decoder**: `encoder_hidden=64`, `decoder_hidden=64`.  \n",
        "– Настройка:  \n",
        "  • Обучение с фиксированным seed;  \n",
        "  • Оптимизатор: Adam (lr=1e-3), ReduceLROnPlateau;  \n",
        "  • Регуляризация: dropout, weight decay, gradient clipping (для RNN);  \n",
        "  • Остановка: early stopping по val loss (patience=10).  \n",
        "– Все процедуры выполняются только на тренировочной части с корректной валидацией.  \n",
        "– Фиксация: оптимальные гиперпараметры, значение метрики на валидации, время обучения.\n",
        "\n",
        "#### **3.4. Стратегии многопшагового прогнозирования (для временных рядов)**\n",
        "\n",
        "**Задача:** Реализовать и сравнить подходы к прогнозу на горизонт \\( h \\geq 7 \\).  \n",
        "**Требования к выполнению:**  \n",
        "– **Рекурсивная стратегия**: одна настроенная модель; прогноз на \\( t+1 \\) используется как вход для \\( t+2 \\);  \n",
        "– **Прямая стратегия**: отдельная настройка и обучение модели для каждого шага \\( t+1, \\dots, t+h \\);  \n",
        "– **Encoder–Decoder**: единая модель для генерации всей последовательности;  \n",
        "– Для каждой стратегии и каждого горизонта (\\( h = 1, 7, 30 \\)):  \n",
        "  • Расчёт MAE, RMSE на каждом шаге;  \n",
        "  • Фиксация общего времени вычислений;  \n",
        "  • Построение графика накопления ошибки.\n",
        "\n",
        "#### **3.5. Построение и настройка моделей**\n",
        "\n",
        "**Задача:** Реализовать единообразный интерфейс для всех глубоких моделей.  \n",
        "**Требования к выполнению:**  \n",
        "– Все модели реализуются на PyTorch или TensorFlow с единым API:  \n",
        "  • `model.fit(X_train, y_train)`;  \n",
        "  • `model.predict(X_test)`.  \n",
        "– Поддержка GPU и CPU;  \n",
        "– Для временных рядов — вход в формате `(batch, seq_len, features)`;  \n",
        "– Для табличных — `(batch, num_features)`.  \n",
        "– Примеры архитектур:  \n",
        "  • **MLP**: `Linear → ReLU → Dropout → ... → Output`;  \n",
        "  • **1D-CNN**: `Conv1d → ReLU → AdaptiveAvgPool1d → Flatten → Linear`;  \n",
        "  • **LSTM**: `LSTM → Dropout → Linear`;  \n",
        "  • **Encoder–Decoder**: отдельные модули для кодирования и декодирования.\n",
        "\n",
        "#### **3.6. Диагностика адекватности моделей**\n",
        "\n",
        "**Задача:** Убедиться, что модель корректно обучается и не переобучается.  \n",
        "**Требования к выполнению:**  \n",
        "– **Графики обучения**: train/val loss и метрик по эпохам;  \n",
        "– **Анализ переобучения**: разрыв между train и val метриками > 20%;  \n",
        "– **Мониторинг градиентов**: норма градиентов по слоям (особенно для RNN);  \n",
        "– **Стабильность весов**: отсутствие взрывного роста или затухания.  \n",
        "– Диагностика обязательна для всех моделей и обоих типов данных.\n",
        "\n",
        "#### **3.7. Оценка качества и статистическое сравнение**\n",
        "\n",
        "**Задача:** Обоснованно сравнить модели по объективным критериям.  \n",
        "**Требования к выполнению:**  \n",
        "– Расчёт метрик **на финальной тестовой выборке** для каждого датасета и горизонта:  \n",
        "  • Регрессия: MAE, RMSE, MASE, R²;  \n",
        "  • Классификация: Accuracy, F1, AUC-ROC.  \n",
        "– Составление сравнительных таблиц:  \n",
        "  • Модели × датасеты × метрики × время обучения × время прогноза;  \n",
        "  • Интерпретируемость (Saliency, SHAP, анализ вентилей);  \n",
        "  • Диагностические показатели (переобучение, стабильность градиентов).  \n",
        "– Ранжирование моделей по взвешенной оценке, учитывающей точность (50%), адекватность обучения (30%) и интерпретируемость (20%).\n",
        "\n",
        "#### **3.8. Анализ интерпретируемости моделей**\n",
        "\n",
        "**Задача:** Оценить способность модели объяснять свои предсказания.  \n",
        "**Требования к выполнению:**  \n",
        "– Для **MLP/CNN**: вычисление Saliency Maps и Integrated Gradients;  \n",
        "– Для **LSTM/GRU**: визуализация forget/input/output gates на реальных последовательностях;  \n",
        "– Для **гипридных моделей**: анализ вклада временных и статических признаков;  \n",
        "– Проведение **локальной интерпретации**: водопадные диаграммы для отдельных прогнозов;  \n",
        "– Анализ **устойчивости**: повторный запуск с разными seed — насколько стабильны ключевые признаки?  \n",
        "– Результаты интерпретации включаются в сравнительные таблицы.\n",
        "\n",
        "#### **3.9. Анализ вычислительной эффективности**\n",
        "\n",
        "**Задача:** Оценить практическую применимость моделей в условиях ограниченных ресурсов.  \n",
        "**Требования к выполнению:**  \n",
        "– Фиксация времени:  \n",
        "  • Обучение (в секундах),  \n",
        "  • Прогнозирование (в миллисекундах на наблюдение);  \n",
        "– Оценка потребления памяти (опционально, через `memory_profiler`);  \n",
        "– Сравнение скорости сходимости: количество эпох до early stopping;  \n",
        "– Включение столбца «Вычислительная сложность» в сравнительные таблицы: низкая/средняя/высокая.\n",
        "\n",
        "#### **3.10. Разработка модульного фреймворка**\n",
        "\n",
        "**Задача:** Создать единый интерфейс для всех архитектур и типов данных.  \n",
        "**Требования к выполнению:**  \n",
        "– Единый базовый класс `BaseDeepModel` с методами `fit()`, `predict()`, `interpret()`;  \n",
        "– Поддержка переключения между задачами (табличная/временная) через конфигурацию;  \n",
        "– Автоматическая предобработка признаков (масштабирование, эмбеддинги);  \n",
        "– Экспорт/загрузка весов моделей.\n",
        "\n",
        "#### **3.11. Публикация результатов исследования**\n",
        "\n",
        "**Задача:** Обеспечить открытость и воспроизводимость работы.  \n",
        "**Требования к выполнению:**  \n",
        "– Для кода и результатов составляется метаописание, включающее:  \n",
        "  • Список моделей и пространств гиперпараметров;  \n",
        "  • Оптимальные гиперпараметры и метрики на валидации;  \n",
        "  • Сравнительные таблицы по всем моделям и датасетам;  \n",
        "  • Ключевые выводы и рекомендации;  \n",
        "  • Инструкцию по запуску фреймворка.  \n",
        "– Все материалы публикуются в публичном репозитории (GitHub/GitLab);  \n",
        "– Веса моделей и логи обучения — архивированы;  \n",
        "– Использование открытых лицензий: MIT (код), CC BY 4.0 (данные).\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Дополнительные исследовательские задания**\n",
        "\n",
        "1. Сравнение MLP с табличными специализированными архитектурами: NODE, TabNet, DCN (без реализации, через библиотеки).  \n",
        "2. Анализ влияния размера датасета: при каком количестве наблюдений DL начинает выигрывать у бустинга?  \n",
        "3. Робастность к зашумлённым признакам: сравнение устойчивости MLP, LSTM и LightGBM к добавлению шума.  \n",
        "4. Transfer learning между табличными задачами: возможно ли?  \n",
        "5. Ансамблирование DL и классических моделей: stacking MLP + LightGBM.  \n",
        "6. Исследование зависимости времени обучения от длины временного ряда (масштабируемость).\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Требования к отчёту**\n",
        "\n",
        "Отчёт оформляется в соответствии с ГОСТ 7.32–2017 и должен содержать следующие разделы:  \n",
        "1. **Введение** — постановка задачи, актуальность глубокого обучения для табличных данных, обзор литературы, указание на преемственность с Практической работой № 1.  \n",
        "2. **Методология** — описание данных, трансформация ряда в признаки, архитектуры моделей, стратегии обучения, список инструментов.  \n",
        "3. **Результаты экспериментов** — сравнительные таблицы, графики обучения, результаты диагностики, визуализации интерпретаций (Saliency, gates).  \n",
        "4. **Обсуждение** — интерпретация важных признаков, анализ влияния архитектуры на качество, сравнение с классическим ML, вычислительная эффективность.  \n",
        "5. **Заключение** — итоговые выводы, практические рекомендации по выбору архитектуры в зависимости от типа данных и задачи, ограничения исследования.  \n",
        "6. **Список использованных источников** — оформлен в соответствии с ГОСТ Р 7.0.5–2008.  \n",
        "7. **Приложения** — фрагменты кода, скриншоты визуализаций, примеры сравнительных таблиц, таблицы гиперпараметров.  \n",
        "Отчёт сопровождается ссылками на репозиторий с кодом и опубликованные данные.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Критерии оценивания**\n",
        "\n",
        "| Оценка | Критерии |\n",
        "|--------|----------|\n",
        "| **Отлично** | Полное выполнение всех этапов; обучение всех архитектур на двух типах данных; корректная валидация без утечки будущего; углублённая диагностика обучения; развёрнутый анализ интерпретируемости (Saliency, gates, устойчивость); оценка вычислительной сложности; модульный фреймворк; публикация всех материалов; отчёт, соответствующий ГОСТ. |\n",
        "| **Хорошо** | Выполнение основных этапов; обучение 6–8 моделей на обоих датасетах; наличие сравнительных таблиц и базовой диагностики; реализация основных архитектур; отсутствие лишь отдельных элементов (например, гибридных моделей или анализа градиентов). |\n",
        "| **Удовлетворительно** | Работа проведена только на одном типе данных; реализованы 3–5 моделей без полной диагностики; есть сравнение по метрикам; отсутствует интерпретация или стратегии прогнозирования. |\n",
        "| **Неудовлетворительно** | Отсутствуют ключевые компоненты работы (данные из работы № 1 не использованы, отсутствует корректное разделение данных, нет сравнительного анализа, отчёт не представлен). |\n"
      ],
      "metadata": {
        "id": "g4QIdpZuhtwO"
      }
    }
  ]
}