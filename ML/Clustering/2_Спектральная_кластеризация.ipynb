{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVjb5CHAxgjepNlofnUfxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/ML/Clustering/2_%D0%A1%D0%BF%D0%B5%D0%BA%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Спектральная кластеризация\n",
        "\n",
        "#### 1. Спектральная кластеризация\n",
        "\n",
        "Спектральная кластеризация — это метод кластеризации, основанный на графах, который использует собственные векторы лапласиана графа, построенного на основе данных, для разделения данных на кластеры. Этот метод особенно эффективен для учета геометрической структуры данных и часто превосходит традиционные методы, такие как K-средних.\n",
        "\n",
        "Алгоритм спектральной кластеризации состоит из двух основных шагов:\n",
        "\n",
        "1. **Построение неориентированного взвешенного графа** на основе данных. Для заданного набора данных $\\{x_i\\}_{i=1}^n$ с попарными сходствами $w_{ij}$ строится лапласиан графа. Ненормализованный лапласиан $L$ определяется как:\n",
        "$$\n",
        "   L = D - W\n",
        "$$\n",
        "   где $W$ — матрица сходств с элементами $w_{ij}$, а $D$ — диагональная матрица степеней, где $D_{ii} = \\sum_{j=1}^n w_{ij}$.\n",
        "\n",
        "   Альтернативно, нормализованный лапласиан $L_{\\text{sym}}$ определяется как:\n",
        "$$\n",
        "   L_{\\text{sym}} = I - D^{-1/2}WD^{-1/2}\n",
        "$$\n",
        "   где $I$ — единичная матрица.\n",
        "\n",
        "   Затем вычисляются собственные векторы $\\phi_1, \\phi_2, \\ldots, \\phi_k$, соответствующие наименьшим $k$ собственным значениям $L$ (или $L_{\\text{sym}}$), т.е.:\n",
        "$$\n",
        "   L\\phi_l = \\lambda_l \\phi_l\n",
        "$$\n",
        "   где $\\{\\phi_l\\}_{l=1}^n$ образуют ортонормированный базис в $\\mathbb{R}^n$, а собственные значения упорядочены как $\\lambda_1 \\leq \\lambda_2 \\leq \\ldots \\leq \\lambda_n$.\n",
        "\n",
        "   Пусть $\\Phi \\in \\mathbb{R}^{n \\times k}$ — матрица, столбцы которой являются собственными векторами $\\phi_1, \\phi_2, \\ldots, \\phi_k$. Каждая точка данных $x_i$ преобразуется в $k$-мерное пространство с помощью:\n",
        "$$\n",
        "   \\Phi(x_i) = (\\phi_1(x_i), \\phi_2(x_i), \\ldots, \\phi_k(x_i))^T \\in \\mathbb{R}^k\n",
        "$$\n",
        "   Это преобразование отображает исходные данные из $\\mathbb{R}^n$ в $\\mathbb{R}^k$ с использованием собственных векторов лапласиана.\n",
        "\n",
        "2. **Применение K-средних** к преобразованным данным $\\Phi$ для разделения данных на $k$ кластеров.\n",
        "\n",
        "#### 1.1 Выбор сходств $w_{ij}$\n",
        "\n",
        "Выбор сходств $w_{ij}$ (весов на ребрах между узлами $x_i$ и $x_j$) является ключевым в спектральной кластеризации. Общее правило: чем больше $w_{ij}$, тем больше сходство между $x_i$ и $x_j$. Распространенные методы определения $w_{ij}$ включают:\n",
        "\n",
        "- **Граф $\\epsilon$-окрестности**:\n",
        "$$\n",
        "  w_{ij} =\n",
        "  \\begin{cases}\n",
        "  1, & \\text{если } \\|x_i - x_j\\| \\leq \\epsilon \\\\\n",
        "  0, & \\text{иначе}\n",
        "  \\end{cases}\n",
        "$$\n",
        "  Здесь $w_{ij} = 1$, если $x_i$ и $x_j$ находятся на расстоянии не более $\\epsilon$; иначе $w_{ij} = 0$.\n",
        "\n",
        "- **Полносвязный граф**:\n",
        "$$\n",
        "  w_{ij} = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{\\sigma^2}\\right)\n",
        "$$\n",
        "  где $\\sigma$ — параметр, контролирующий ширину окрестности. Если $x_i$ и $x_j$ близки, $w_{ij}$ близко к 1. Если они далеки друг от друга (относительно $\\sigma$), $w_{ij}$ близко к 0.\n",
        "\n",
        "#### 1.2 Применение спектральной кластеризации к несвязному графу\n",
        "\n",
        "Для иллюстрации рассмотрим применение спектральной кластеризации к несвязному графу. Предположим, у нас есть неориентированный граф с весами $w_{ij}$ и $k$ связными компонентами $S_1, S_2, \\ldots, S_k$.\n",
        "\n",
        "После построения лапласиана графа $L$ и перестановки точек данных, $L$ может быть записан как блочно-диагональная матрица:\n",
        "$$\n",
        "L = \\begin{pmatrix}\n",
        "L_1 & 0 & \\cdots & 0 \\\\\n",
        "0 & L_2 & \\cdots & 0 \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "0 & 0 & \\cdots & L_k\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "где каждый $L_i \\in \\mathbb{R}^{|S_i| \\times |S_i|}$ — лапласиан для $i$-й связной компоненты.\n",
        "\n",
        "Поскольку $L_i \\mathbf{1}_{|S_i|} = 0$ для всех $1 \\leq i \\leq k$, где $\\mathbf{1}_{|S_i|}$ — вектор из единиц длины $|S_i|$, наименьшие $k$ собственных значений $L$ равны нулю. Нулевое пространство $L$ порождается $k$ индикаторными функциями:\n",
        "$$\n",
        "\\phi_1 = \\frac{1}{\\sqrt{|S_1|}} \\mathbf{1}_{S_1}, \\quad \\phi_2 = \\frac{1}{\\sqrt{|S_2|}} \\mathbf{1}_{S_2}, \\quad \\ldots, \\quad \\phi_k = \\frac{1}{\\sqrt{|S_k|}} \\mathbf{1}_{S_k}\n",
        "$$\n",
        "где $\\mathbf{1}_{S_i}$ — индикаторный вектор для $i$-й связной компоненты.\n",
        "\n",
        "Матрица $\\Phi$ тогда имеет вид:\n",
        "$$\n",
        "\\Phi = \\begin{pmatrix}\n",
        "\\frac{1}{\\sqrt{|S_1|}} \\mathbf{1}_{S_1} & 0 & \\cdots & 0 \\\\\n",
        "0 & \\frac{1}{\\sqrt{|S_2|}} \\mathbf{1}_{S_2} & \\cdots & 0 \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "0 & 0 & \\cdots & \\frac{1}{\\sqrt{|S_k|}} \\mathbf{1}_{S_k}\n",
        "\\end{pmatrix} \\in \\mathbb{R}^{n \\times k}\n",
        "$$\n",
        "Каждая строка $\\Phi$ соответствует точке данных в одной из связных компонент, и спектральное отображение преобразует все точки в $i$-й связной компоненте $S_i$ в одну точку $\\frac{1}{\\sqrt{|S_i|}} e_i$, где $\\{e_i\\}_{i=1}^k$ — канонический базис в $\\mathbb{R}^k$.\n",
        "\n",
        "#### 1.3 Графовый разрез в спектральной кластеризации\n",
        "\n",
        "Интуиция кластеризации заключается в разделении точек на группы на основе их сходства. Для данных, представленных в виде неориентированного графа с весами $W$, цель — найти разбиение, минимизирующее связи между разными группами. Это соответствует нахождению разреза на графе.\n",
        "\n",
        "Для несвязного графа с весами $W$ можно найти разбиение, при котором связь между компонентами равна нулю. Спектральная кластеризация может быть выведена из понятия разреза графа.\n",
        "\n",
        "**Определение разреза**: Для двух непересекающихся множеств вершин $S$ и $\\overline{S}$ таких, что $S \\cap \\overline{S} = \\emptyset$ и $S \\cup \\overline{S} = V$, разрез относительно $S$ определяется как:\n",
        "$$\n",
        "\\text{cut}(S) = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij}\n",
        "$$\n",
        "Это измеряет общий вес ребер, соединяющих $S$ и $\\overline{S}$. Меньшее значение $\\text{cut}(S)$ указывает на меньшее количество связей между $S$ и $\\overline{S}$.\n",
        "\n",
        "Однако минимизация $\\text{cut}(S)$ может привести к несбалансированным разбиениям, например, выделению одной вершины в отдельный кластер. Чтобы избежать этого, вводятся **нормированный разрез** и **отношение разрезов**:\n",
        "\n",
        "- **Отношение разрезов**:\n",
        "$$\n",
        "  \\text{Rcut}(S) = \\frac{\\text{cut}(S)}{|S|} + \\frac{\\text{cut}(\\overline{S})}{|\\overline{S}|}\n",
        "$$\n",
        "  \n",
        "- **Нормированный разрез**:\n",
        "$$\n",
        "  \\text{Ncut}(S) = \\frac{\\text{cut}(S)}{\\text{vol}(S)} + \\frac{\\text{cut}(\\overline{S})}{\\text{vol}(\\overline{S})}\n",
        "$$\n",
        "  где $\\text{vol}(S) = \\sum_{i \\in S} d_i = \\sum_{i \\in S} \\sum_{j \\in V} w_{ij}$ — объем множества $S$.\n",
        "\n",
        "**Преимущества и недостатки**:\n",
        "- **Преимущества**: $\\text{Rcut}(S)$ и $\\text{Ncut}(S)$ способствуют сбалансированным разбиениям, штрафуя разрезы, которые приводят к неравным размерам кластеров.\n",
        "- **Недостатки**: Минимизация $\\text{Rcut}(S)$ и $\\text{Ncut}(S)$ является NP-трудной задачей, так как требует дискретной оптимизации по всем возможным подмножествам $V$. Полный перебор невозможен для больших графов из-за экспоненциального числа возможных разбиений.\n",
        "\n",
        "На практике спектральная кластеризация предлагает релаксацию этих задач, решая непрерывную оптимизационную задачу с использованием собственных векторов лапласиана графа. Это позволяет эффективно находить приближенные решения.\n",
        "\n",
        "\n",
        "### 1.3 Релаксация отношения разрезов (Ratio Cut)\n",
        "\n",
        "Минимизация функции отношения разрезов (Ratio Cut) напрямую является сложной задачей, так как требует перебора всех возможных подмножеств $S \\subseteq V$. Однако это не означает, что мы не можем аппроксимировать выражения (1) и (2) с помощью других оптимизационных задач, которые проще решать. Мы надеемся, что решения этих альтернативных задач дадут хорошие приближения для исходных задач.\n",
        "\n",
        "В этом разделе мы покажем, что отношение разрезов (1) может быть аппроксимировано непрерывной оптимизационной задачей (задачей на собственные значения/векторы лапласиана $L$), которая точно соответствует первому шагу спектральной кластеризации. Начнем с связи отношения разрезов с квадратичной формой лапласиана $L$.\n",
        "\n",
        "#### Связь отношения разрезов с квадратичной формой лапласиана\n",
        "\n",
        "Рассмотрим функцию $f_S: V \\to \\mathbb{R}$, зависящую от множества $S$, определённую следующим образом:\n",
        "$$\n",
        "f_S(i) =\n",
        "\\begin{cases}\n",
        "\\sqrt{\\frac{|\\overline{S}|}{|V||S|}}, & \\text{если } i \\in S, \\\\\n",
        "-\\sqrt{\\frac{|S|}{|V||\\overline{S}|}}, & \\text{если } i \\in \\overline{S}.\n",
        "\\end{cases}\n",
        "$$\n",
        "Эта функция является простой ступенчатой функцией на множестве вершин $V$, и, в частности, выполняется $f_S(i) = -f_S(j)$ для $i \\in S$ и $j \\in \\overline{S}$.\n",
        "\n",
        "**Лемма 1.** Для функции $f_S$, определённой в (5), выполняется:\n",
        "$$\n",
        "f_S^T L f_S = \\text{Rcut}(S).\n",
        "$$\n",
        "\n",
        "**Доказательство:**\n",
        "Доказательство достаточно простое. Рассмотрим квадратичную форму $f_S^T L f_S$:\n",
        "$$\n",
        "f_S^T L f_S = \\frac{1}{2} \\sum_{i,j} w_{ij} (f_S(i) - f_S(j))^2.\n",
        "$$\n",
        "Разделим сумму на две части: по рёбрам внутри $S$ и $\\overline{S}$, и по рёбрам между $S$ и $\\overline{S}$. Поскольку $f_S(i) = f_S(j)$ для $i, j \\in S$ или $i, j \\in \\overline{S}$, вклад этих рёбер равен нулю. Таким образом, остаются только рёбра между $S$ и $\\overline{S}$:\n",
        "$$\n",
        "f_S^T L f_S = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} (f_S(i) - f_S(j))^2.\n",
        "$$\n",
        "Подставим значения $f_S(i)$ и $f_S(j)$:\n",
        "$$\n",
        "f_S(i) - f_S(j) = \\sqrt{\\frac{|\\overline{S}|}{|V||S|}} - \\left(-\\sqrt{\\frac{|S|}{|V||\\overline{S}|}}\\right) = \\sqrt{\\frac{|\\overline{S}|}{|V||S|}} + \\sqrt{\\frac{|S|}{|V||\\overline{S}|}}.\n",
        "$$\n",
        "Возведём в квадрат:\n",
        "$$\n",
        "(f_S(i) - f_S(j))^2 = \\left(\\sqrt{\\frac{|\\overline{S}|}{|V||S|}} + \\sqrt{\\frac{|S|}{|V||\\overline{S}|}}\\right)^2 = \\frac{|\\overline{S}|}{|V||S|} + \\frac{|S|}{|V||\\overline{S}|} + 2 \\cdot \\frac{1}{|V|}.\n",
        "$$\n",
        "Подставим это обратно в сумму:\n",
        "$$\n",
        "f_S^T L f_S = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} \\left(\\frac{|\\overline{S}|}{|V||S|} + \\frac{|S|}{|V||\\overline{S}|} + \\frac{2}{|V|}\\right).\n",
        "$$\n",
        "Упростим выражение:\n",
        "$$\n",
        "f_S^T L f_S = \\frac{1}{|V|} \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} \\left(\\frac{|\\overline{S}|}{|S|} + \\frac{|S|}{|\\overline{S}|} + 2\\right).\n",
        "$$\n",
        "Заметим, что $|V| = |S| + |\\overline{S}|$, и окончательно получаем:\n",
        "$$\n",
        "f_S^T L f_S = \\text{Rcut}(S).\n",
        "$$\n",
        "\n",
        "#### Релаксация задачи минимизации отношения разрезов\n",
        "\n",
        "До этого момента мы не упростили задачу минимизации (3), так как просто заменили выражение в (3) на $\\min_{f_S} f_S^T L f_S$. Теперь идея состоит в том, чтобы расширить множество ограничений, исследуя свойства всех функций $\\{f_S\\}_{S \\subseteq V}$.\n",
        "\n",
        "Все функции $f_S$ обладают двумя общими свойствами:\n",
        "\n",
        "**Лемма 2.** Для всех $S \\subseteq V$ и функций $f_S$, определённых в (5), выполняются следующие свойства:\n",
        "$$\n",
        "\\|f_S\\|_2 = 1, \\quad f_S^T \\mathbf{1} = 0,\n",
        "$$\n",
        "где $\\mathbf{1}$ — вектор из единиц.\n",
        "\n",
        "**Доказательство:**\n",
        "1. Норма $\\|f_S\\|_2$:\n",
        "$$\n",
        "\\|f_S\\|_2^2 = \\sum_{i \\in V} |f_S(i)|^2 = \\sum_{i \\in S} \\frac{|\\overline{S}|}{|V||S|} + \\sum_{i \\in \\overline{S}} \\frac{|S|}{|V||\\overline{S}|} = \\frac{|\\overline{S}|}{|V|} + \\frac{|S|}{|V|} = 1.\n",
        "$$\n",
        "2. Ортогональность к $\\mathbf{1}$:\n",
        "$$\n",
        "f_S^T \\mathbf{1} = \\sum_{i \\in V} f_S(i) = \\sum_{i \\in S} f_S(i) + \\sum_{i \\in \\overline{S}} f_S(i) = \\sqrt{\\frac{|\\overline{S}|}{|V||S|}} \\cdot |S| - \\sqrt{\\frac{|S|}{|V||\\overline{S}|}} \\cdot |\\overline{S}| = 0.\n",
        "$$\n",
        "\n",
        "#### Релаксация задачи\n",
        "\n",
        "Теперь мы заменяем исходную задачу (3) на следующую:\n",
        "$$\n",
        "\\min_{f} f^T L f, \\quad \\text{при условиях} \\quad \\|f\\|_2 = 1, \\quad f^T \\mathbf{1} = 0.\n",
        "$$\n",
        "Заметим, что $\\{f_S\\}_{S \\subseteq V} \\subseteq \\{f: \\|f\\|_2 = 1, f^T \\mathbf{1} = 0\\}$. Таким образом, задача (7) минимизирует $f^T L f$ на более широком множестве, чем $f_S$, и мы надеемся получить приближённое решение из этого подхода. Более того, задача (7) гораздо проще решается, так как она непосредственно соответствует задаче на собственные значения/векторы лапласиана $L$, что точно совпадает с первым шагом спектральной кластеризации. Мы называем (7) **релаксацией** задачи (3).\n",
        "\n",
        "\n",
        "### 1.4 Релаксация нормированного разреза (Normalized Cut)\n",
        "\n",
        "Как и в случае с отношением разрезов (Ratio Cut), нормированный разрез (Normalized Cut) также может быть аппроксимирован с помощью релаксации. Рассмотрим функцию $f_S: V \\to \\mathbb{R}$, определённую следующим образом:\n",
        "\n",
        "$$\n",
        "f_S(i) =\n",
        "\\begin{cases}\n",
        "\\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}}, & \\text{если } i \\in S, \\\\\n",
        "-\\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}, & \\text{если } i \\in \\overline{S}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Эта функция аналогична функции, определённой в (5), но вместо мощностей множеств $|S|$ и $|\\overline{S}|$ используются их объёмы $\\text{vol}(S)$ и $\\text{vol}(\\overline{S})$. Объём множества $S$ определяется как:\n",
        "$$\n",
        "\\text{vol}(S) = \\sum_{i \\in S} d_i,\n",
        "$$\n",
        "где $d_i = \\sum_{j \\in V} w_{ij}$ — степень вершины $i$.\n",
        "\n",
        "#### Связь нормированного разреза с квадратичной формой лапласиана\n",
        "\n",
        "Аналогично отношению разрезов, можно показать, что квадратичная форма $f_S^T L f_S$ связана с нормированным разрезом.\n",
        "\n",
        "**Лемма 3.** Для функции $f_S$, определённой в (8), выполняется:\n",
        "$$\n",
        "f_S^T L f_S = \\text{Ncut}(S).\n",
        "$$\n",
        "\n",
        "**Доказательство:**\n",
        "Доказательство аналогично доказательству для отношения разрезов. Рассмотрим квадратичную форму $f_S^T L f_S$:\n",
        "$$\n",
        "f_S^T L f_S = \\frac{1}{2} \\sum_{i,j} w_{ij} (f_S(i) - f_S(j))^2.\n",
        "$$\n",
        "Разделим сумму на две части: по рёбрам внутри $S$ и $\\overline{S}$, и по рёбрам между $S$ и $\\overline{S}$. Поскольку $f_S(i) = f_S(j)$ для $i, j \\in S$ или $i, j \\in \\overline{S}$, вклад этих рёбер равен нулю. Таким образом, остаются только рёбра между $S$ и $\\overline{S}$:\n",
        "$$\n",
        "f_S^T L f_S = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} (f_S(i) - f_S(j))^2.\n",
        "$$\n",
        "Подставим значения $f_S(i)$ и $f_S(j)$:\n",
        "$$\n",
        "f_S(i) - f_S(j) = \\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}} - \\left(-\\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}\\right) = \\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}} + \\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}.\n",
        "$$\n",
        "Возведём в квадрат:\n",
        "$$\n",
        "(f_S(i) - f_S(j))^2 = \\left(\\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}} + \\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}\\right)^2 = \\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)} + \\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})} + 2 \\cdot \\frac{1}{\\text{vol}(V)}.\n",
        "$$\n",
        "Подставим это обратно в сумму:\n",
        "$$\n",
        "f_S^T L f_S = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} \\left(\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)} + \\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})} + \\frac{2}{\\text{vol}(V)}\\right).\n",
        "$$\n",
        "Упростим выражение:\n",
        "$$\n",
        "f_S^T L f_S = \\frac{1}{\\text{vol}(V)} \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} \\left(\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(S)} + \\frac{\\text{vol}(S)}{\\text{vol}(\\overline{S})} + 2\\right).\n",
        "$$\n",
        "Заметим, что $\\text{vol}(V) = \\text{vol}(S) + \\text{vol}(\\overline{S})$, и окончательно получаем:\n",
        "$$\n",
        "f_S^T L f_S = \\text{Ncut}(S).\n",
        "$$\n",
        "\n",
        "#### Релаксация задачи минимизации нормированного разреза\n",
        "\n",
        "Аналогично отношению разрезов, мы можем заменить исходную задачу минимизации нормированного разреза на следующую:\n",
        "$$\n",
        "\\min_{f} f^T L f, \\quad \\text{при условиях} \\quad \\|f\\|_2 = 1, \\quad f^T D^{1/2} \\mathbf{1} = 0.\n",
        "$$\n",
        "Здесь $D$ — диагональная матрица степеней, а $D^{1/2}$ — её квадратный корень. Условие $f^T D^{1/2} \\mathbf{1} = 0$ гарантирует, что функция $f$ ортогональна вектору $D^{1/2} \\mathbf{1}$.\n",
        "\n",
        "#### Минимизатор задачи релаксации\n",
        "\n",
        "Минимизатором задачи (7) является собственный вектор $\\phi_2$, соответствующий второму наименьшему собственному значению $\\lambda_2$ лапласиана $L$. Другими словами, минимум задачи (7) равен $\\lambda_2$.\n",
        "\n",
        "**Доказательство:**\n",
        "Рассмотрим разложение функции $f$ по собственным векторам лапласиана $L$:\n",
        "$$\n",
        "f = \\sum_{l=1}^n \\alpha_l \\phi_l,\n",
        "$$\n",
        "где $\\{\\phi_l\\}_{l=1}^n$ — ортонормированные собственные векторы $L$, соответствующие собственным значениям $\\lambda_1 \\leq \\lambda_2 \\leq \\ldots \\leq \\lambda_n$. Тогда:\n",
        "$$\n",
        "f^T L f = \\sum_{l=1}^n \\lambda_l \\alpha_l^2.\n",
        "$$\n",
        "Поскольку $\\|f\\|_2 = 1$, выполняется $\\sum_{l=1}^n \\alpha_l^2 = 1$. Минимум $f^T L f$ достигается, когда $\\alpha_2 = 1$, а все остальные $\\alpha_l = 0$, то есть $f = \\phi_2$. Таким образом, минимум равен $\\lambda_2$.\n",
        "\n",
        "#### Сравнение с исходной задачей\n",
        "\n",
        "По сравнению с исходной задачей (3), мы знаем, что $\\{f_S\\}_{S \\subseteq V} \\subseteq \\{f: \\|f\\|_2 = 1, f^T \\mathbf{1} = 0\\}$, и, следовательно:\n",
        "$$\n",
        "\\text{Rcut}(S) \\geq \\lambda_2, \\quad \\min_{S \\subseteq V} \\text{Rcut}(S) \\geq \\lambda_2.\n",
        "$$\n",
        "\n",
        "#### Как получить кластеризацию на основе $\\phi_2$?\n",
        "\n",
        "Для получения кластеризации на основе собственного вектора $\\phi_2$ можно применить метод K-средних. Это эквивалентно установлению порога $r$, такого что:\n",
        "$$\n",
        "\\phi_2(i) > r \\implies i \\in S, \\quad \\phi_2(i) \\leq r \\implies i \\in \\overline{S}.\n",
        "$$\n",
        "Этот процесс также называется процедурой \"округления\".\n",
        "\n",
        "\n",
        " ### 1.4 Релаксация нормированного разреза (Normalized Cut)\n",
        "\n",
        "Как и в случае с отношением разрезов (Ratio Cut), нормированный разрез (Normalized Cut) также может быть аппроксимирован с помощью релаксации. Рассмотрим функцию $f_S: V \\to \\mathbb{R}$, определённую следующим образом:\n",
        "\n",
        "$$\n",
        "f_S(i) =\n",
        "\\begin{cases}\n",
        "\\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}}, & \\text{если } i \\in S, \\\\\n",
        "-\\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}, & \\text{если } i \\in \\overline{S}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Эта функция аналогична функции, определённой в (5), но вместо мощностей множеств $|S|$ и $|\\overline{S}|$ используются их объёмы $\\text{vol}(S)$ и $\\text{vol}(\\overline{S})$. Объём множества $S$ определяется как:\n",
        "$$\n",
        "\\text{vol}(S) = \\sum_{i \\in S} d_i,\n",
        "$$\n",
        "где $d_i = \\sum_{j \\in V} w_{ij}$ — степень вершины $i$.\n",
        "\n",
        "#### Связь нормированного разреза с квадратичной формой лапласиана\n",
        "\n",
        "Аналогично отношению разрезов, можно показать, что квадратичная форма $f_S^T L f_S$ связана с нормированным разрезом.\n",
        "\n",
        "**Лемма 4.** Для функции $f_S$, определённой в (8), выполняется:\n",
        "$$\n",
        "f_S^T L f_S = \\text{Ncut}(S).\n",
        "$$\n",
        "\n",
        "**Доказательство:**\n",
        "Доказательство аналогично доказательству для отношения разрезов. Рассмотрим квадратичную форму $f_S^T L f_S$:\n",
        "$$\n",
        "f_S^T L f_S = \\frac{1}{2} \\sum_{i,j} w_{ij} (f_S(i) - f_S(j))^2.\n",
        "$$\n",
        "Разделим сумму на две части: по рёбрам внутри $S$ и $\\overline{S}$, и по рёбрам между $S$ и $\\overline{S}$. Поскольку $f_S(i) = f_S(j)$ для $i, j \\in S$ или $i, j \\in \\overline{S}$, вклад этих рёбер равен нулю. Таким образом, остаются только рёбра между $S$ и $\\overline{S}$:\n",
        "$$\n",
        "f_S^T L f_S = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} (f_S(i) - f_S(j))^2.\n",
        "$$\n",
        "Подставим значения $f_S(i)$ и $f_S(j)$:\n",
        "$$\n",
        "f_S(i) - f_S(j) = \\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}} - \\left(-\\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}\\right) = \\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}} + \\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}.\n",
        "$$\n",
        "Возведём в квадрат:\n",
        "$$\n",
        "(f_S(i) - f_S(j))^2 = \\left(\\sqrt{\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)}} + \\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})}}\\right)^2 = \\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)} + \\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})} + 2 \\cdot \\frac{1}{\\text{vol}(V)}.\n",
        "$$\n",
        "Подставим это обратно в сумму:\n",
        "$$\n",
        "f_S^T L f_S = \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} \\left(\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(V) \\text{vol}(S)} + \\frac{\\text{vol}(S)}{\\text{vol}(V) \\text{vol}(\\overline{S})} + \\frac{2}{\\text{vol}(V)}\\right).\n",
        "$$\n",
        "Упростим выражение:\n",
        "$$\n",
        "f_S^T L f_S = \\frac{1}{\\text{vol}(V)} \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} \\left(\\frac{\\text{vol}(\\overline{S})}{\\text{vol}(S)} + \\frac{\\text{vol}(S)}{\\text{vol}(\\overline{S})} + 2\\right).\n",
        "$$\n",
        "Заметим, что $\\text{vol}(V) = \\text{vol}(S) + \\text{vol}(\\overline{S})$, и окончательно получаем:\n",
        "$$\n",
        "f_S^T L f_S = \\text{Ncut}(S).\n",
        "$$\n",
        "\n",
        "#### Релаксация задачи минимизации нормированного разреза\n",
        "\n",
        "Аналогично отношению разрезов, мы можем заменить исходную задачу минимизации нормированного разреза на следующую:\n",
        "$$\n",
        "\\min_{f} f^T L f, \\quad \\text{при условиях} \\quad f^T D f = 1, \\quad f^T D \\mathbf{1} = 0.\n",
        "$$\n",
        "Здесь $D$ — диагональная матрица степеней, а $\\mathbf{1}$ — вектор из единиц. Условие $f^T D \\mathbf{1} = 0$ гарантирует, что функция $f$ ортогональна вектору $D \\mathbf{1}$.\n",
        "\n",
        "#### Минимизатор задачи релаксации\n",
        "\n",
        "Минимизатором задачи (11) является собственный вектор $\\phi_2$, соответствующий второму наименьшему собственному значению $\\lambda_2$ нормализованного лапласиана $L_{\\text{sym}} = I - D^{-1/2} W D^{-1/2}$. Другими словами, минимум задачи (11) равен $\\lambda_2$.\n",
        "\n",
        "**Доказательство:**\n",
        "Рассмотрим разложение функции $f$ по собственным векторам нормализованного лапласиана $L_{\\text{sym}}$:\n",
        "$$\n",
        "f = \\sum_{l=1}^n \\alpha_l \\phi_l,\n",
        "$$\n",
        "где $\\{\\phi_l\\}_{l=1}^n$ — ортонормированные собственные векторы $L_{\\text{sym}}$, соответствующие собственным значениям $\\lambda_1 \\leq \\lambda_2 \\leq \\ldots \\leq \\lambda_n$. Тогда:\n",
        "$$\n",
        "f^T L_{\\text{sym}} f = \\sum_{l=1}^n \\lambda_l \\alpha_l^2.\n",
        "$$\n",
        "Поскольку $\\|f\\|_2 = 1$, выполняется $\\sum_{l=1}^n \\alpha_l^2 = 1$. Минимум $f^T L_{\\text{sym}} f$ достигается, когда $\\alpha_2 = 1$, а все остальные $\\alpha_l = 0$, то есть $f = \\phi_2$. Таким образом, минимум равен $\\lambda_2$.\n",
        "\n",
        "#### Сравнение с исходной задачей\n",
        "\n",
        "По сравнению с исходной задачей (4), мы знаем, что $\\{f_S\\}_{S \\subseteq V} \\subseteq \\{f: f^T D f = 1, f^T D \\mathbf{1} = 0\\}$, и, следовательно:\n",
        "$$\n",
        "\\text{Ncut}(S) \\geq \\lambda_2, \\quad \\min_{S \\subseteq V} \\text{Ncut}(S) \\geq \\lambda_2.\n",
        "$$\n",
        "\n",
        "#### Как получить кластеризацию на основе $\\phi_2$?\n",
        "\n",
        "Для получения кластеризации на основе собственного вектора $\\phi_2$ можно применить метод K-средних. Это эквивалентно установлению порога $r$, такого что:\n",
        "$$\n",
        "\\phi_2(i) > r \\implies i \\in S, \\quad \\phi_2(i) \\leq r \\implies i \\in \\overline{S}.\n",
        "$$\n",
        "Этот процесс также называется процедурой \"округления\".\n",
        "\n",
        "#### Заключение\n",
        "\n",
        "Релаксация задачи минимизации нормированного разреза позволяет свести исходную комбинаторную задачу к задаче на собственные значения, которая эффективно решается с использованием методов линейной алгебры. Это является ключевым шагом в спектральной кластеризации, так как позволяет находить приближённые решения для сложных задач кластеризации.\n",
        "\n",
        "### 1.5 Сравнение методов\n",
        "\n",
        "В заключение:\n",
        "- Релаксация отношения разрезов соответствует задаче на собственные значения и собственные векторы лапласиана $L = D - W$.\n",
        "- Релаксация нормированного разреза соответствует задаче на собственные значения и собственные векторы нормализованного лапласиана $L_{\\text{sym}} = I - D^{-1/2} W D^{-1/2}$.\n",
        "- Все эти результаты могут быть легко обобщены на случай многоклассовой кластеризации.\n",
        "\n",
        "#### Какой алгоритм лучше?\n",
        "\n",
        "Эмпирически, нормированный разрез (Ncut) является более предпочтительным выбором. Однако если граф регулярный (все степени вершин $d_i$ одинаковы), то оба метода эквивалентны.\n",
        "\n",
        "Цель кластеризации заключается не только в минимизации разреза, но и в максимизации связности внутри кластеров. Внутрикластерная связность (association) определяется как:\n",
        "$$\n",
        "\\text{assoc}(S, S) = \\sum_{i \\in S, j \\in S} w_{ij} = \\sum_{i \\in S, j \\in V} w_{ij} - \\sum_{i \\in S, j \\in \\overline{S}} w_{ij} = \\text{vol}(S) - \\text{cut}(S).\n",
        "$$\n",
        "Таким образом, мы хотим минимизировать $\\text{cut}(S)$ и максимизировать $\\text{vol}(S)$, что именно и делает нормированный разрез.\n",
        "\n",
        "\n",
        "\n",
        " Рассмотрим конкретный числовой пример спектральной кластеризации на основе описанного выше алгоритма. Мы будем использовать небольшой набор данных и шаг за шагом пройдем через процесс спектральной кластеризации.\n",
        "\n",
        "### Исходные данные\n",
        "Пусть у нас есть набор из 4 точек в двумерном пространстве:\n",
        "$$\n",
        "X = \\begin{pmatrix}\n",
        "1 & 1 \\\\\n",
        "1 & 2 \\\\\n",
        "4 & 4 \\\\\n",
        "4 & 5\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "Мы хотим разделить эти точки на 2 кластера.\n",
        "\n",
        "### Шаг 1: Построение матрицы сходства $W$\n",
        "Используем полносвязный граф с гауссовым ядром для вычисления сходства между точками. Формула для сходства:\n",
        "$$\n",
        "w_{ij} = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{\\sigma^2}\\right)\n",
        "$$\n",
        "Выберем $\\sigma = 1$ для простоты.\n",
        "\n",
        "Вычислим попарные расстояния между точками:\n",
        "$$\n",
        "\\|x_1 - x_2\\| = \\sqrt{(1-1)^2 + (1-2)^2} = 1 \\\\\n",
        "\\|x_1 - x_3\\| = \\sqrt{(1-4)^2 + (1-4)^2} = \\sqrt{18} \\approx 4.24 \\\\\n",
        "\\|x_1 - x_4\\| = \\sqrt{(1-4)^2 + (1-5)^2} = \\sqrt{25} = 5 \\\\\n",
        "\\|x_2 - x_3\\| = \\sqrt{(1-4)^2 + (2-4)^2} = \\sqrt{13} \\approx 3.61 \\\\\n",
        "\\|x_2 - x_4\\| = \\sqrt{(1-4)^2 + (2-5)^2} = \\sqrt{18} \\approx 4.24 \\\\\n",
        "\\|x_3 - x_4\\| = \\sqrt{(4-4)^2 + (4-5)^2} = 1\n",
        "$$\n",
        "\n",
        "Теперь вычислим матрицу сходства $W$:\n",
        "$$\n",
        "W = \\begin{pmatrix}\n",
        "1 & e^{-1} & e^{-18} & e^{-25} \\\\\n",
        "e^{-1} & 1 & e^{-13} & e^{-18} \\\\\n",
        "e^{-18} & e^{-13} & 1 & e^{-1} \\\\\n",
        "e^{-25} & e^{-18} & e^{-1} & 1\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "Приближенно:\n",
        "$$\n",
        "W \\approx \\begin{pmatrix}\n",
        "1 & 0.37 & 0 & 0 \\\\\n",
        "0.37 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 1 & 0.37 \\\\\n",
        "0 & 0 & 0.37 & 1\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 2: Построение матрицы степеней $D$\n",
        "Матрица степеней $D$ — это диагональная матрица, где каждый элемент $D_{ii}$ равен сумме элементов строки $i$ матрицы $W$:\n",
        "$$\n",
        "D = \\begin{pmatrix}\n",
        "1.37 & 0 & 0 & 0 \\\\\n",
        "0 & 1.37 & 0 & 0 \\\\\n",
        "0 & 0 & 1.37 & 0 \\\\\n",
        "0 & 0 & 0 & 1.37\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 3: Построение лапласиана $L$\n",
        "Ненормализованный лапласиан $L$ вычисляется как:\n",
        "$$\n",
        "L = D - W\n",
        "$$\n",
        "Подставляем значения:\n",
        "$$\n",
        "L = \\begin{pmatrix}\n",
        "1.37 & 0 & 0 & 0 \\\\\n",
        "0 & 1.37 & 0 & 0 \\\\\n",
        "0 & 0 & 1.37 & 0 \\\\\n",
        "0 & 0 & 0 & 1.37\n",
        "\\end{pmatrix} - \\begin{pmatrix}\n",
        "1 & 0.37 & 0 & 0 \\\\\n",
        "0.37 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 1 & 0.37 \\\\\n",
        "0 & 0 & 0.37 & 1\n",
        "\\end{pmatrix} = \\begin{pmatrix}\n",
        "0.37 & -0.37 & 0 & 0 \\\\\n",
        "-0.37 & 0.37 & 0 & 0 \\\\\n",
        "0 & 0 & 0.37 & -0.37 \\\\\n",
        "0 & 0 & -0.37 & 0.37\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 4: Вычисление собственных значений и собственных векторов\n",
        "Теперь найдем собственные значения и собственные векторы матрицы $L$. Собственные значения $\\lambda$ и собственные векторы $\\phi$ удовлетворяют уравнению:\n",
        "$$\n",
        "L\\phi = \\lambda\\phi\n",
        "$$\n",
        "\n",
        "Для нашей матрицы $L$ собственные значения и собственные векторы:\n",
        "$$\n",
        "\\lambda_1 = 0, \\quad \\phi_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\\\\n",
        "\\lambda_2 = 0.74, \\quad \\phi_2 = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\\\\n",
        "\\lambda_3 = 0.74, \\quad \\phi_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ -1 \\end{pmatrix} \\\\\n",
        "\\lambda_4 = 1.48, \\quad \\phi_4 = \\begin{pmatrix} 1 \\\\ 1 \\\\ -1 \\\\ -1 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 5: Преобразование данных\n",
        "Выберем первые два собственных вектора, соответствующие наименьшим ненулевым собственным значениям ($\\phi_2$ и $\\phi_3$), и построим матрицу $\\Phi$:\n",
        "$$\n",
        "\\Phi = \\begin{pmatrix}\n",
        "1 & 0 \\\\\n",
        "-1 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "0 & -1\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 6: Применение K-средних\n",
        "Теперь применим алгоритм K-средних к строкам матрицы $\\Phi$ для разделения данных на 2 кластера. В данном случае строки матрицы $\\Phi$ уже явно разделены на две группы:\n",
        "- Кластер 1: точки 1 и 2 ($\\begin{pmatrix}1 & 0\\end{pmatrix}$ и $\\begin{pmatrix}-1 & 0\\end{pmatrix}$)\n",
        "- Кластер 2: точки 3 и 4 ($\\begin{pmatrix}0 & 1\\end{pmatrix}$ и $\\begin{pmatrix}0 & -1\\end{pmatrix}$)\n",
        "\n",
        "### Результат\n",
        "Исходные данные разделены на два кластера:\n",
        "- Кластер 1: точки $(1, 1)$ и $(1, 2)$\n",
        "- Кластер 2: точки $(4, 4)$ и $(4, 5)$\n",
        "\n",
        "Этот пример демонстрирует, как спектральная кластеризация может эффективно разделить данные на кластеры, используя геометрическую структуру данных.\n",
        "\n",
        "\n",
        " Реализуем спектральную кластеризацию на Python с использованием библиотек `numpy`, `scipy`, `sklearn` и `matplotlib` для визуализации. Мы будем использовать тот же пример данных, что и в предыдущем объяснении.\n",
        "\n",
        "### Код на Python\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TREiYf-vwZQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import eigh\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Исходные данные\n",
        "X = np.array([[1, 1],\n",
        "              [1, 2],\n",
        "              [4, 4],\n",
        "              [4, 5]])\n",
        "\n",
        "# Функция для вычисления матрицы сходства (гауссово ядро)\n",
        "def compute_similarity_matrix(X, sigma=1.0):\n",
        "    n = X.shape[0]\n",
        "    W = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            W[i, j] = np.exp(-np.linalg.norm(X[i] - X[j])**2 / (2 * sigma**2))\n",
        "    return W\n",
        "\n",
        "# Функция для построения лапласиана\n",
        "def compute_laplacian(W):\n",
        "    D = np.diag(np.sum(W, axis=1))\n",
        "    L = D - W\n",
        "    return L\n",
        "\n",
        "# Вычисляем матрицу сходства\n",
        "W = compute_similarity_matrix(X, sigma=1.0)\n",
        "\n",
        "# Вычисляем лапласиан\n",
        "L = compute_laplacian(W)\n",
        "\n",
        "# Вычисляем собственные значения и собственные векторы\n",
        "eigenvalues, eigenvectors = eigh(L)\n",
        "\n",
        "# Выбираем первые k собственных векторов (k=2)\n",
        "k = 2\n",
        "phi = eigenvectors[:, :k]\n",
        "\n",
        "# Применяем K-средних к собственным векторам\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "clusters = kmeans.fit_predict(phi)\n",
        "\n",
        "# Визуализация исходных данных и кластеров\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Визуализация исходных данных\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X[:, 0], X[:, 1], c='blue', label='Исходные данные')\n",
        "plt.title('Исходные данные')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend()\n",
        "\n",
        "# Визуализация кластеров\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', label='Кластеры')\n",
        "plt.title('Спектральная кластеризация')\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "KEaDiCPkwbdr",
        "outputId": "8e159dda-00fe-417e-a70d-e8e8dc464dfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}