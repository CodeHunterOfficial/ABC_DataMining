{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8y2ySs4yY8t+KU4R1wPlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/ML/%D0%A2%D0%B5%D0%BC%D0%B0_2_Boosting_Tree_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**AdaBoost (Adaptive Boosting)**  \n",
        "\n",
        "**Краткое описание:**  \n",
        "Метод Adaptive Boosting (AdaBoost) представляет собой процесс последовательного добавления слабых базовых моделей к существующему ансамблю, с адаптивной корректировкой весов для каждой из базовых моделей, чтобы минимизировать ошибку.\n",
        "\n",
        "### Что такое пошаговое аддитивное моделирование (Forward Stagewise Additive Modeling)?  \n",
        "Рассмотрим базовую модель $b(x; r_m)$, управляемую параметром $r_m$.  \n",
        "Параметр $\\beta_m$ определяет вклад каждой слабой базовой модели в итоговый ансамбль.  \n",
        "\n",
        "Итоговая модель $f(x)$, построенная на основе $M$ слабых моделей, описывается следующим образом:  \n",
        "$$\n",
        "f(x) = \\sum_{m=1}^M \\beta_m \\cdot b(x; r_m)\n",
        "$$  \n",
        "\n",
        "Для получения классификатора используется функция знака $\\text{sign}(x)$, преобразующая значения в классы:  \n",
        "$$\n",
        "G(x) = \\text{sign}(f(x)) = \\text{sign}\\left(\\sum_{m=1}^M \\beta_m \\cdot b(x; r_m)\\right)\n",
        "$$  \n",
        "\n",
        "### Глобальная оптимизация для набора данных $D$  \n",
        "Для набора данных $D$, содержащего $N$ наблюдений, минимизация функции потерь на всем наборе определяется следующим образом:  \n",
        "$$\n",
        "\\min \\sum_{i=1}^N \\text{Loss}\\left(y_i, \\sum_{m=1}^M \\beta_m \\cdot b(x_i; r_m)\\right)\n",
        "$$  \n",
        "На каждом шаге цель алгоритма — оптимально подобрать параметры $\\beta_m$ и $r_m$ для текущей базовой модели так, чтобы приблизить решение к глобальному оптимуму:  \n",
        "$$\n",
        "\\min \\sum_{i=1}^N \\text{Loss}\\left(y_i, f_{m-1}(x_i) + \\beta_m \\cdot b(x_i; r_m)\\right)\n",
        "$$  \n",
        "\n",
        "### Алгоритм пошагового аддитивного моделирования  \n",
        "#### Входные данные:  \n",
        "- Набор данных $D = \\{(x_1, y_1), (x_2, y_2), \\dots, (x_N, y_N)\\}$  \n",
        "- Функция потерь $\\text{Loss}(y, f(x))$  \n",
        "- Набор базовых моделей $\\{b(x; r_m)\\}$  \n",
        "\n",
        "#### Выходные данные:  \n",
        "- Итоговая модель $f(x)$.  \n",
        "\n",
        "#### Шаги алгоритма:  \n",
        "1. Инициализация: начальная модель $f_0(x) = 0$.  \n",
        "2. Для каждого $m = 1, 2, \\dots, M$:  \n",
        "   - Минимизировать функцию потерь:  \n",
        "$$\n",
        "     (\\beta_m, r_m) = \\arg \\min_{\\beta, r} \\sum_{i=1}^N \\text{Loss}\\left(y_i, f_{m-1}(x_i) + \\beta \\cdot b(x_i; r)\\right)\n",
        "$$  \n",
        "   - Обновить модель:  \n",
        "$$\n",
        "     f_m(x) = f_{m-1}(x) + \\beta_m \\cdot b(x; r_m)\n",
        "$$  \n",
        "3. Итоговая модель задается следующим образом:  \n",
        "$$\n",
        "   f(x) = \\sum_{m=1}^M \\beta_m \\cdot b(x; r_m)\n",
        "$$  \n",
        "\n",
        "\n",
        "\n",
        "### b. Что такое экспоненциальная функция потерь и почему она используется в алгоритме AdaBoost\n",
        "\n",
        "Предположим, что $y$ принадлежит промежутку $(-1, 1)$, тогда экспоненциальная функция потерь имеет вид:\n",
        "\n",
        "$$\n",
        "\\text{Loss}(y, f(x)) = \\mathbb{E}(e^{-f(x)} \\mid x) = P(y = 1 \\mid x) e^{-f(x)} + P(y = -1 \\mid x) e^{f(x)}\n",
        "$$\n",
        "\n",
        "Если мы возьмем производную от этой функции потерь по $f(x)$ и приравняем её к нулю, то получим, что при минимизации экспоненциальной функции потерь на самом деле происходит подгонка к логистической регрессии для вероятности $P(y = 1 \\mid x)$:\n",
        "\n",
        "$$\n",
        "\\frac{d}{df(x)} \\mathbb{E}(e^{-f(x)}) = [-P(y = 1 \\mid x) e^{-f(x)} + P(y = -1 \\mid x) e^{f(x)}] = 0\n",
        "$$\n",
        "\n",
        "Решив это уравнение, мы получим:\n",
        "\n",
        "$$\n",
        "f(x) = \\frac{1}{2} \\log \\frac{P(y = 1 \\mid x)}{P(y = -1 \\mid x)}\n",
        "$$\n",
        "\n",
        "Таким образом, оптимальное решение для $f(x)$ соответствует оптимальной вероятности по Байесу:\n",
        "\n",
        "$$\n",
        "\\text{sign}(f(x)) = \\begin{cases}\n",
        "1, & \\text{если} \\, P(y = 1 \\mid x) > P(y = -1 \\mid x) \\\\\n",
        "-1, & \\text{если} \\, P(y = 1 \\mid x) < P(y = -1 \\mid x)\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Где:\n",
        "- $\\text{sign}(x) = 1$ при $x > 0$\n",
        "- $\\text{sign}(x) = -1$ при $x < 0$\n",
        "\n",
        "Экспоненциальная функция потерь в AdaBoost помогает эффективно повышать вес правильно классифицированных объектов, способствуя тому, чтобы модель фокусировалась на сложных примерах, постепенно уменьшая ошибку на тренировочных данных.\n",
        "\n",
        "### c. Математика за AdaBoost — как вычислить оптимальные параметры\n",
        "\n",
        "Предположим, что после $m-1$ итераций мы вычислили функцию классификации $f_{m-1}(x)$, которая имеет вид:\n",
        "\n",
        "$$\n",
        "f_{m-1}(x) = f_{m-2}(x) + \\beta_{m-1} b(x; r_{m-1}) = \\sum_{i=1}^{m-1} \\beta_i b(x_i)\n",
        "$$\n",
        "\n",
        "Теперь мы находимся на $m$-й итерации и хотим найти оптимальные параметры $\\beta_m$ и $b_m(x; r_m)$ (обозначим $b_m(x)$) для минимизации экспоненциальной функции потерь.\n",
        "\n",
        "Важно: выход $b_m(x)$ принадлежит промежутку $(-1, 1)$, а не вероятности. Целью является минимизация следующего выражения:\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^N \\arg \\min_{\\beta, b(x)} \\text{Loss}(y_i, f_{m-1}(x) + \\beta b(x))\n",
        "$$\n",
        "\n",
        "Где:\n",
        "\n",
        "$$\n",
        "\\text{Loss}(y_i, f_{m-1}(x) + \\beta b(x)) = \\exp(-y_i f_{m-1}(x_i)) \\cdot \\exp(-y_i \\beta b(x_i))\n",
        "$$\n",
        "\n",
        "Оптимизация осуществляется по $\\beta$ и $b(x)$. Мы пытаемся минимизировать экспоненциальную потерю, вычисляя оптимальные веса для каждого примера:\n",
        "\n",
        "$$\n",
        "\\min_{\\beta, b(x)} \\sum_{i=1}^N W_{mi} \\exp(-y_i f_{m-1}(x_i)) \\cdot \\exp(-y_i \\beta b(x_i))\n",
        "$$\n",
        "\n",
        "где $W_{mi} = \\exp(-y_i f_{m-1}(x_i))$ — веса для каждого примера.\n",
        "\n",
        "#### 1. Вычисление оптимального $b_m(x)$\n",
        "\n",
        "Для нахождения оптимального $b_m(x)$ мы минимизируем следующее выражение:\n",
        "\n",
        "$$\n",
        "\\arg \\min_{b(x)} \\sum_{i=1}^N W_{mi} \\exp(-y_i \\beta b(x_i))\n",
        "$$\n",
        "\n",
        "Решение для $b(x)$ даст нам значение, которое минимизирует экспоненциальную потерю для текущей итерации.\n",
        "\n",
        "#### 2. Вычисление оптимального $\\beta_m$\n",
        "\n",
        "Затем для нахождения оптимального $\\beta_m$, мы решаем:\n",
        "\n",
        "$$\n",
        "\\arg \\min_{\\beta} \\sum_{i=1}^N W_{mi} \\exp(-y_i \\beta b(x_i))\n",
        "$$\n",
        "\n",
        "Решение этого уравнения позволяет найти весовой коэффициент, который наилучшим образом сочетает информацию от предыдущих итераций с новыми классификаторами.\n",
        "\n",
        "#### 3. Обновление весов $W_{m+1, i}$\n",
        "\n",
        "После вычисления оптимальных значений $\\beta_m$ и $b_m(x)$, обновляем веса для следующей итерации. Вес $W_{m+1, i}$ вычисляется как:\n",
        "\n",
        "$$\n",
        "W_{m+1, i} = \\exp(-y_i f_m(x_i)) = \\exp(-y_i [f_{m-1}(x_i) + \\beta_m b_m(x_i)])\n",
        "$$\n",
        "\n",
        "Нормализуем веса, чтобы их сумма равнялась 1, что соответствует вероятности (аналогично функции softmax):\n",
        "\n",
        "$$\n",
        "W_{m+1, i} = \\frac{W_{m+1, i}}{Z_m}\n",
        "$$\n",
        "\n",
        "где $Z_m$ — нормализующий фактор, обеспечивающий, что сумма всех весов равна 1.\n",
        "\n",
        "Этот процесс повторяется для каждой итерации AdaBoost, с каждым разом улучшая классификацию и минимизируя ошибку.\n",
        "\n",
        "\n",
        "\n",
        "### d. Актуальный рекуррентный алгоритм для AdaBoost с использованием деревьев\n",
        "\n",
        "**Входные данные модели:**\n",
        "\n",
        "Набор данных $D = \\{(x_1, y_1), ..., (x_N, y_N)\\}$, где $y_i \\in \\{-1, 1\\}$.\n",
        "\n",
        "**Выходные данные модели:**\n",
        "\n",
        "Финальный классификатор $G(x)$.\n",
        "\n",
        "**Шаги алгоритма:**\n",
        "\n",
        "1. **Инициализация веса $T_1$:**\n",
        "\n",
        "$$\n",
        "   T_1 = (W_{11}, W_{12}, ..., W_{1N}), \\quad W_{hi} \\in \\{1, 2, 3, 4, ..., N\\}\n",
        "$$\n",
        "\n",
        "2. **Для $m = 1, 2, 3, ..., M$ (конечный классификатор состоит из $M$ слабых обучающих моделей):**\n",
        "\n",
        "   - Используем набор данных $D$ с весами $T_m$ для обучения слабого классификатора $b_m(x)$, где $b_m(x) \\in \\{-1, 1\\}$.\n",
        "\n",
        "$$\n",
        "     b_m = \\arg \\min \\sum_{i=1}^{N} W_{mi} \\cdot I(y_i \\neq b_m(x_i))\n",
        "$$\n",
        "     Здесь $I$ — индикаторная функция, которая принимает значение 1, если $y_i \\neq b_m(x_i)$, и 0 в противном случае.\n",
        "\n",
        "   - Рассчитываем ошибку $e_m$ для $b_m(x)$ на наборе данных $D$:\n",
        "\n",
        "$$\n",
        "     e_m = \\frac{\\sum_{i=1}^{N} W_{mi} \\cdot I(y_i \\neq b_m(x_i))}{\\sum_{i=1}^{N} W_{mi}}\n",
        "$$\n",
        "\n",
        "     Так как $\\sum_{i=1}^{N} W_{mi} = 1$, получаем:\n",
        "\n",
        "$$\n",
        "     e_m = \\sum_{i=1}^{N} W_{mi} \\cdot I(y_i \\neq b_m(x_i))\n",
        "$$\n",
        "\n",
        "   - Рассчитываем параметр $\\beta_m$ для слабого классификатора $b_m(x)$:\n",
        "\n",
        "$$\n",
        "     \\beta_m = \\frac{1}{2} \\log\\left(\\frac{1 - e_m}{e_m}\\right)\n",
        "$$\n",
        "\n",
        "   - Обновляем веса $W_{m+1}$ для следующего слабого классификатора:\n",
        "\n",
        "$$\n",
        "     W_{m+1,i} = W_{mi} \\cdot \\exp(-\\beta_m y_i b_m(x_i)), \\quad Z_m = \\sum_{i=1}^{N} W_{mi} \\cdot \\exp(-\\beta_m y_i b_m(x_i))\n",
        "$$\n",
        "\n",
        "3. **Построение конечного классификатора:**\n",
        "\n",
        "   Финальный классификатор $G(x)$ вычисляется как:\n",
        "\n",
        "$$\n",
        "   G(x) = \\text{sign}\\left(\\sum_{m=1}^{M} \\beta_m b_m(x)\\right)\n",
        "$$\n",
        "\n",
        "   Где $\\text{sign}$ — это функция знака, принимающая значение 1, если выражение положительно, и -1, если отрицательно.\n",
        "\n",
        "### e. Подробное рассмотрение процесса обновления весов в AdaBoost\n",
        "\n",
        "Помним, что:\n",
        "\n",
        "$$\n",
        "W_{m+1,i} = W_{mi} \\cdot \\exp(-\\beta_m y_i b_m(x_i)), \\quad Z_m = \\sum_{i=1}^{N} W_{mi} \\cdot \\exp(-\\beta_m y_i b_m(x_i))\n",
        "$$\n",
        "\n",
        "Таким образом, если $\\beta_m > 0$, то происходит следующее:\n",
        "\n",
        "- Если классификация выполнена правильно, то вес для соответствующего примера уменьшается, так как $\\exp(-\\beta_m)$ уменьшает значение веса.\n",
        "- Если классификация выполнена неправильно, то вес для этого примера увеличивается, так как $\\exp(\\beta_m)$ увеличивает значение веса.\n",
        "\n",
        "Это означает, что если классификатор правильно классифицирует пример, его вес уменьшается, что уменьшает его влияние на последующие классификации. Напротив, если классификатор ошибается, то вес примера увеличивается, что заставляет модель больше фокусироваться на этом примере в следующих итерациях.\n",
        "\n",
        "### Применение в библиотеке Scikit-learn\n",
        "\n",
        "**AdaBoostClassifier:**\n",
        "\n",
        "```python\n",
        "class sklearn.ensemble.AdaBoostClassifier(\n",
        "    base_estimator=None,\n",
        "    n_estimators=50,\n",
        "    learning_rate=1.0,\n",
        "    algorithm='SAMME.R',\n",
        "    random_state=None\n",
        ")\n",
        "```\n",
        "\n",
        "- **base_estimator**: объект (по умолчанию None) — это базовый классификатор, на основе которого строится ансамбль. По умолчанию используется классификатор DecisionTreeClassifier с глубиной максимума 1. Вы можете также использовать другие модели машинного обучения, такие как SVC.\n",
        "\n",
        "- **n_estimators**: целое число (по умолчанию 50) — максимальное количество классификаторов, при котором обучение будет завершено. Это соответствует $M$ в формуле.\n",
        "\n",
        "- **learning_rate**: вещественное число (по умолчанию 1.0) — коэффициент обучения, который уменьшает вклад каждого классификатора. Например, если предсказание на предыдущем шаге было $f_{m-1} = 1$, коэффициент обучения $\\text{learning_rate} = 0.1$, а коррекция для следующего дерева $= 0.5$, то обновленное предсказание будет равно:\n",
        "\n",
        "  $$\n",
        "  f_m = 1 + 0.1 \\cdot 0.5 = 1.05\n",
        "  $$\n",
        "\n",
        "  Уменьшение коэффициента обучения замедляет процесс обучения, но может привести к лучшему качеству модели.\n",
        "\n",
        "- **algorithm**: строка, значения ‘SAMME’ или ‘SAMME.R’ (по умолчанию ‘SAMME.R’) — алгоритм, который будет использован для бустинга. Если выбран ‘SAMME.R’, то применяется реальный алгоритм бустинга. Базовый классификатор должен поддерживать вычисление вероятностей классов. Если выбран ‘SAMME’, используется дискретный алгоритм бустинга. Алгоритм ‘SAMME.R’ обычно сходится быстрее и достигает меньшей ошибки на тесте при меньшем количестве итераций бустинга.\n"
      ],
      "metadata": {
        "id": "YqQQZoXvbBea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBM (Gradient Boosting Machine)\n",
        "\n",
        "**Однострочное описание**: Постепенное добавление слабых базовых моделей для аппроксимации отрицательного градиента с целью уменьшения общей ошибки.\n",
        "\n",
        "### a. Различия между AdaBoost и GBM\n",
        "AdaBoost использует экспоненциальную функцию потерь, при этом экспоненциальная потеря растет экспоненциально для отрицательных значений, что делает метод более чувствительным к выбросам. В отличие от этого, GBM позволяет использовать более устойчивые функции потерь, при условии, что они являются непрерывно дифференцируемыми.\n",
        "\n",
        "| Модели | Методы корректировки предыдущих ошибок |\n",
        "|--------|----------------------------------------|\n",
        "| **AdaBoost** | Добавление весов для неправильно классифицированных примеров и уменьшение весов для правильно классифицированных примеров. |\n",
        "| **GBM** | Использование отрицательного градиента как индикатора ошибок, сделанных предыдущими базовыми моделями, и обучение следующей базовой модели для аппроксимации отрицательного градиента предыдущих моделей. |\n",
        "\n",
        "### b. Отрицательный градиент в GBM\n",
        "\n",
        "В AdaBoost мы упоминаем метод Forward Stagewise Additive Modeling. Предположим, что мы находимся на m-ой итерации:\n",
        "\n",
        "$$\n",
        "f_m(x) = f_{m-1} + B_m b_m(x)\n",
        "$$\n",
        "\n",
        "Мы хотим уменьшить ошибку, как в AdaBoost:\n",
        "\n",
        "$$\n",
        "\\min \\sum_{i=1}^{N} \\text{Loss}(y_i, f_m(x)) \\quad \\text{или} \\quad \\min \\sum_{i=1}^{N} \\text{Loss}(y_i, f_{m-1}(x) + B_m \\cdot b_m(x))\n",
        "$$\n",
        "\n",
        "Однако здесь задача отличается от случая в AdaBoost. В AdaBoost мы точно знаем функцию потерь (экспоненциальную функцию), поэтому можем найти оптимальное значение $b_m(x)$. В GBM же мы хотим работать с любой функцией потерь, которая является дифференцируемой. Для этого мы применяем идею, аналогичную методу градиентного спуска, чтобы найти оптимальное значение $b_m(x)$ с помощью отрицательного градиента:\n",
        "\n",
        "$$\n",
        "\\min \\sum_{i=1}^{N} \\text{Loss}(y_i, f_{m-1}(x) + \\alpha_m \\cdot b_m(x)) \\quad \\Rightarrow \\quad b_m(x) = \\text{const} \\cdot \\nabla \\text{Loss}(y_i, f_{m-1}(x))\n",
        "$$\n",
        "\n",
        "Здесь $\\alpha_m$ — параметр, похожий на скорость обучения, но принимающий отрицательные значения.\n",
        "\n",
        "### c. Алгоритм GBM\n",
        "\n",
        "**Входные данные модели**: Набор данных $D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}, y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "**Выходные данные модели**: Финальный классификатор/регрессор $f_m(x)$\n",
        "\n",
        "**Шаги**:\n",
        "\n",
        "1. **Инициализация**:\n",
        "$$\n",
        "   f_0(x) = \\arg \\min \\sum_{i=1}^{N} \\text{Loss}(y_i, 7)\n",
        "$$\n",
        "\n",
        "2. Для $m = 1, 2, 3, \\dots, M$:\n",
        "   - Вычисление отрицательного градиента:\n",
        "$$\n",
        "     \\nabla \\text{Loss}(y_i, f_{m-1}(x)) \\quad \\text{для} \\quad i = 1, 2, 3, \\dots, N\n",
        "$$\n",
        "   - Обучение новой модели (например, дерева) для минимизации квадратных потерь:\n",
        "$$\n",
        "     b_m(x) = \\arg \\min \\sum_{i=1}^{N} \\left( y_i - b(x) \\right)^2\n",
        "$$\n",
        "   - Использование линейного поиска для нахождения оптимального шага (аналогично концепции скорости обучения в SGD):\n",
        "$$\n",
        "     \\alpha_m = \\arg \\min \\sum_{i=1}^{N} \\text{Loss}(y_i, f_{m-1}(x_i) + \\alpha_m b_m(x_i))\n",
        "$$\n",
        "   - Обновление функции $f_m(x)$:\n",
        "$$\n",
        "     f_m(x) = f_{m-1}(x) + \\alpha_m \\cdot b_m(x)\n",
        "$$\n",
        "\n",
        "3. Для $m = 1, 2, 3, \\dots, M$:\n",
        "$$\n",
        "   f_m(x) = f_0(x) + \\sum_{m=1}^M \\alpha_m \\cdot b_m(x)\n",
        "$$\n",
        "\n",
        "\n",
        "### d. Алгоритм регрессии на основе дерева решений GBM (Gradient Boosting Machine)\n",
        "**Вход модели:** Данные D: $D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}, y_i \\in \\mathbb{R}$  \n",
        "**Выход модели:** Финальный регрессор: $f_M(x)$  \n",
        "**Функция потерь:** Квадратичная ошибка (Square Loss)  \n",
        "**Шаги алгоритма:**\n",
        "\n",
        "1. **Инициализация:**\n",
        "   Начальное значение $f_0(x)$ выбирается как решение задачи минимизации функции потерь:\n",
        "$$\n",
        "   f_0(x) = \\arg\\min \\sum_{i=1}^N (y_i - f_0(x_i))^2\n",
        "$$\n",
        "\n",
        "2. **Для $m = 1, 2, 3, \\dots, M$:**\n",
        "   - **Вычисление отрицательного градиента** для функции потерь:\n",
        "$$\n",
        "     g_m(x) = -\\frac{\\partial}{\\partial f_{m-1}(x)} \\text{Loss}(y_i, f_{m-1}(x_i)) = 2(y_i - f_{m-1}(x_i))\n",
        "$$\n",
        "   - **Обучение нового дерева решений (CART)** для минимизации квадратичной ошибки:\n",
        "     Построение дерева с разделением области значений на $J$ частей $R_{j,m}$ для каждого шага $m$.\n",
        "$$\n",
        "     b_m(x) = \\arg\\min_{b(x)} \\sum_{i=1}^N (y_i - b(x_i))^2\n",
        "$$\n",
        "   - Вместо поиска оптимального параметра $\\theta$ для всего дерева, оптимальные параметры $\\theta_{j,m}$ находятся для каждой зоны дерева отдельно:\n",
        "$$\n",
        "     \\theta_{j,m} = \\arg\\min \\sum_{i=1}^N \\left( y_i - (f_{m-1}(x_i) + \\theta_{j,m} I(x_i \\in R_{j,m})) \\right)^2\n",
        "$$\n",
        "   - **Обновление функции предсказания**:\n",
        "$$\n",
        "     f_m(x) = f_{m-1}(x) + \\sum_{j=1}^J \\theta_{j,m} I(x \\in R_{j,m})\n",
        "$$\n",
        "\n",
        "3. **Вывод финальной модели:**\n",
        "$$\n",
        "   f(x) = f_0(x) + \\sum_{m=1}^M \\sum_{j=1}^J \\theta_{j,m} I(x \\in R_{j,m})\n",
        "$$\n",
        "\n",
        "### e. Алгоритм классификации на основе дерева решений GBM\n",
        "**Вход модели:** Данные D: $D = \\{(x_1, y_1), \\dots, (x_N, y_N)\\}, y_i \\in \\{-1, 1\\}$  \n",
        "**Выход модели:** Финальный классификатор: $f_M(x)$  \n",
        "**Функция потерь:** Девиантность (Deviance Loss)  \n",
        "**Шаги алгоритма:**\n",
        "\n",
        "1. **Инициализация:**\n",
        "   - **Функция потерь (девиантность)** для каждого элемента:\n",
        "$$\n",
        "     p(y_i = 1 | x_i) = \\frac{1}{1 + \\exp(-f_m(x_i))}\n",
        "$$\n",
        "   - Начальные значения $f_0(x)$ выбираются так, чтобы минимизировать функцию потерь:\n",
        "$$\n",
        "     f_0(x) = \\arg\\min \\sum_{i=1}^N \\text{Loss}(p(y_i | x_i), y_i)\n",
        "$$\n",
        "   - Для нахождения оптимального $f_0(x)$ решается уравнение:\n",
        "$$\n",
        "     \\sum_{i=1}^N \\left( -\\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right] \\right) = 0\n",
        "$$\n",
        "\n",
        "2. **Для $m = 1, 2, 3, \\dots, M$:**\n",
        "   - Вычисление отрицательного градиента для девиантности:\n",
        "$$\n",
        "     g_m(x_i) = \\frac{d}{df_{m-1}(x_i)} \\left[ y_i \\log(p_{m-1}(x_i)) + (1 - y_i) \\log(1 - p_{m-1}(x_i)) \\right]\n",
        "$$\n",
        "   - **Обучение нового дерева решений (CART)** для минимизации девиантности:\n",
        "$$\n",
        "     b_m(x) = \\arg\\min \\sum_{i=1}^N (y_i - b(x_i))^2\n",
        "$$\n",
        "   - Вместо поиска параметра $\\theta$ для всего дерева, параметры $\\theta_{j,m}$ оптимизируются для каждой зоны дерева:\n",
        "$$\n",
        "     \\theta_{j,m} = \\arg\\min \\sum_{i=1}^N \\left( y_i - (f_{m-1}(x_i) + \\theta_{j,m} I(x_i \\in R_{j,m})) \\right)^2\n",
        "$$\n",
        "   - **Обновление функции предсказания**:\n",
        "$$\n",
        "     f_m(x) = f_{m-1}(x) + \\sum_{j=1}^J \\theta_{j,m} I(x \\in R_{j,m})\n",
        "$$\n",
        "\n",
        "3. **Вывод финальной модели:**\n",
        "$$\n",
        "   f(x) = f_0(x) + \\sum_{m=1}^M \\sum_{j=1}^J \\theta_{j,m} I(x \\in R_{j,m})\n",
        "$$\n",
        "\n",
        "### Применение в Scikit-learn\n",
        "\n",
        "**GradientBoostingRegressor:**\n",
        "```python\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "model = GradientBoostingRegressor(\n",
        "    loss='ls',                # Тип функции потерь (по умолчанию 'ls' - минимизация квадратичной ошибки)\n",
        "    learning_rate=0.1,        # Коэффициент обучения\n",
        "    n_estimators=100,         # Количество деревьев\n",
        "    subsample=1.0,            # Фракция случайно выбранных обучающих данных для каждого базового дерева\n",
        "    max_depth=3,              # Глубина деревьев\n",
        "    random_state=None,        # Начальное состояние для воспроизводимости результатов\n",
        "    alpha=0.9,                # Альфа-квантиль для Huber loss, если он выбран\n",
        "    verbose=0,                # Отключение вывода\n",
        "    warm_start=False,         # Разрешить добавление деревьев в обученную модель\n",
        ")\n",
        "```\n",
        "\n",
        "Основные гиперпараметры для **GradientBoostingRegressor** описаны выше. Стоит отметить, что выбор гиперпараметров, таких как коэффициент обучения (`learning_rate`), количество деревьев (`n_estimators`), и выбор функции потерь (`loss`), сильно влияет на производительность модели.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JDb-iSNBdcDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pcfOwzO-eghs"
      }
    }
  ]
}