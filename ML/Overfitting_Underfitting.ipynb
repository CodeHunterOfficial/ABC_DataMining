{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOTvFstFpniVFKEQJC7Siep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/ML/Overfitting_Underfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. **Пердобучение (Overfitting)**\n",
        "\n",
        "#### Что это значит?\n",
        "**Пердобучение** — это явление, при котором модель слишком сильно подстраивается под обучающие данные, включая шум и случайные аномалии. В результате модель плохо обобщает новые, ранее не виденные данные.\n",
        "\n",
        "#### Признаки пердобучения:\n",
        "- Высокая точность на обучающей выборке.\n",
        "- Низкая точность на тестовой или валидационной выборке.\n",
        "- Модель становится слишком сложной и \"запоминает\" данные вместо того, чтобы выявлять общие закономерности.\n",
        "\n",
        "#### Пример:\n",
        "Представьте, что вы обучаете модель предсказывать цены на дома, но она учитывает даже случайные колебания цен в данных (например, временные скидки). Когда модель сталкивается с новыми данными, она даёт неточные прогнозы.\n",
        "\n",
        "#### Как бороться с пердобучением?\n",
        "1. **Регуляризация**: Использование методов, таких как лассо-регрессия или ридж-регрессия.\n",
        "2. **Уменьшение сложности модели**: Уменьшение числа параметров или глубины дерева решений.\n",
        "3. **Кросс-валидация**: Проверка модели на разных подмножествах данных.\n",
        "4. **Добавление данных**: Увеличение размера обучающей выборки для лучшего обобщения.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Дообучение (Underfitting)**\n",
        "\n",
        "#### Что это значит?\n",
        "**Дообучение** — это противоположная проблема: модель слишком простая и не может адекватно описать зависимости в данных. Она плохо работает как на обучающих, так и на тестовых данных.\n",
        "\n",
        "#### Признаки дообучения:\n",
        "- Низкая точность на обучающей выборке.\n",
        "- Низкая точность на тестовой выборке.\n",
        "- Модель не захватывает важные закономерности в данных.\n",
        "\n",
        "#### Пример:\n",
        "Если вы пытаетесь предсказать цены на дома, используя только одну переменную (например, площадь), игнорируя другие важные факторы (расположение, возраст дома и т.д.), то модель будет недообученной.\n",
        "\n",
        "#### Как исправить дообучение?\n",
        "1. **Увеличение сложности модели**: Добавление новых параметров, использование более сложных алгоритмов.\n",
        "2. **Добавление признаков**: Включение дополнительных переменных, которые могут помочь модели лучше описать данные.\n",
        "3. **Изменение гиперпараметров**: Настройка параметров модели для улучшения её производительности.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Необучение (No Learning)**\n",
        "\n",
        "#### Что это значит?\n",
        "**Необучение** — это ситуация, когда модель вообще не способна обучаться. Это может происходить по разным причинам: отсутствие подходящих данных, неправильная настройка модели или ошибки в реализации.\n",
        "\n",
        "#### Признаки необучения:\n",
        "- Модель показывает одинаковые результаты на всех данных (например, всегда предсказывает одно и то же значение).\n",
        "- Нулевая точность на обучающей и тестовой выборках.\n",
        "- Отсутствие прогресса в обучении (например, функция потерь не уменьшается).\n",
        "\n",
        "#### Пример:\n",
        "Если вы обучаете модель на данных, где целевая переменная случайна (например, метки классов присвоены произвольно), то модель не сможет найти никаких закономерностей.\n",
        "\n",
        "#### Как исправить необучение?\n",
        "1. **Проверка данных**: Убедитесь, что данные корректны и содержат полезную информацию.\n",
        "2. **Выбор подходящей модели**: Убедитесь, что модель способна решать вашу задачу.\n",
        "3. **Настройка алгоритма**: Проверьте правильность реализации и гиперпараметров.\n",
        "\n",
        "---\n",
        "\n",
        "### Сравнение трёх явлений\n",
        "\n",
        "| **Явление**         | **Описание**                                                                 | **Проблема**                                  | **Как исправить**                              |\n",
        "|---------------------|-----------------------------------------------------------------------------|-----------------------------------------------|------------------------------------------------|\n",
        "| **Пердобучение**    | Модель слишком сложная, запоминает шум и аномалии в данных                   | Плохое обобщение на новые данные              | Регуляризация, уменьшение сложности модели     |\n",
        "| **Дообучение**      | Модель слишком простая, не захватывает важные закономерности                 | Плохая производительность на всех данных      | Увеличение сложности модели, добавление признаков |\n",
        "| **Необучение**      | Модель вообще не способна обучаться                                         | Отсутствие прогресса в обучении               | Проверка данных, выбор подходящей модели       |\n",
        "\n",
        "---\n",
        "\n",
        "### Заключение\n",
        "\n",
        "- **Пердобучение** возникает, когда модель слишком сложная и запоминает данные.\n",
        "- **Дообучение** происходит, когда модель слишком простая и не может описать данные.\n",
        "- **Необучение** — это крайний случай, когда модель вообще не способна обучаться.\n",
        "\n",
        "Каждая из этих проблем требует своего подхода к решению. Важно правильно выбирать модель, настраивать её гиперпараметры и работать с качественными данными, чтобы избежать этих явлений.\n"
      ],
      "metadata": {
        "id": "P9k2OV4ekwwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1. **График функции потерь (Loss Function)**\n",
        "\n",
        "Функция потерь показывает, насколько модель ошибается при обучении. Обычно строятся два графика:\n",
        "- **Обучающая выборка**: Значение функции потерь на обучающих данных.\n",
        "- **Тестовая/валидационная выборка**: Значение функции потерь на тестовых данных.\n",
        "\n",
        "### 1.1. Как выглядит график при **переобучении**?\n",
        "- На графике видно, что:\n",
        "  - Потери на **обучающей выборке** уменьшаются и становятся очень низкими.\n",
        "  - Потери на **тестовой выборке** сначала уменьшаются, но затем начинают расти или остаются высокими.\n",
        "- Это означает, что модель \"запоминает\" обучающие данные, но плохо обобщает новые данные.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающая выборка: Loss → стремится к 0\n",
        "Тестовая выборка:   Loss → растёт после определённой эпохи\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 1.2. Как выглядит график при **недообучении**?\n",
        "- На графике видно, что:\n",
        "  - Потери на **обучающей выборке** остаются высокими.\n",
        "  - Потери на **тестовой выборке** также остаются высокими.\n",
        "- Это означает, что модель слишком простая и не может описать зависимости в данных.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающая выборка: Loss → остаётся высоким\n",
        "Тестовая выборка:   Loss → остаётся высоким\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 1.3. Как выглядит график при **необучении**?\n",
        "- На графике видно, что:\n",
        "  - Потери на **обучающей выборке** не уменьшаются.\n",
        "  - Потери на **тестовой выборке** такие же, как на обучающей.\n",
        "- Это означает, что модель вообще не обучается, например, из-за ошибок в данных или реализации.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающая выборка: Loss → постоянный (не меняется)\n",
        "Тестовая выборка:   Loss → такой же, как на обучающей\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **График точности (Accuracy)**\n",
        "\n",
        "Точность показывает, насколько хорошо модель предсказывает правильные ответы. График точности аналогичен графику потерь, но отражает обратную зависимость (точность увеличивается, когда потери уменьшаются).\n",
        "\n",
        "### 2.1. Как выглядит график при **переобучении**?\n",
        "- На графике видно, что:\n",
        "  - Точность на **обучающей выборке** стремится к 100%.\n",
        "  - Точность на **тестовой выборке** достигает максимума, а затем начинает падать.\n",
        "- Это указывает на то, что модель хорошо работает только на обучающих данных.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающая выборка: Accuracy → стремится к 100%\n",
        "Тестовая выборка:   Accuracy → растёт, затем падает\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2. Как выглядит график при **недообучении**?\n",
        "- На графике видно, что:\n",
        "  - Точность на **обучающей выборке** остаётся низкой.\n",
        "  - Точность на **тестовой выборке** также остаётся низкой.\n",
        "- Это означает, что модель не способна захватить важные закономерности.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающая выборка: Accuracy → низкая (например, 50%)\n",
        "Тестовая выборка:   Accuracy → такая же, как на обучающей\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3. Как выглядит график при **необучении**?\n",
        "- На графике видно, что:\n",
        "  - Точность на **обучающей выборке** не растёт.\n",
        "  - Точность на **тестовой выборке** такая же, как на обучающей.\n",
        "- Это указывает на то, что модель не обучается.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающая выборка: Accuracy → постоянная (например, 10%)\n",
        "Тестовая выборка:   Accuracy → такая же, как на обучающей\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **График весов модели (Weights)**\n",
        "\n",
        "Для некоторых моделей (например, линейной регрессии или нейронных сетей) можно построить графики изменения весов модели во время обучения.\n",
        "\n",
        "### 3.1. Как выглядит график при **переобучении**?\n",
        "- Веса модели становятся очень большими (положительными или отрицательными), что указывает на чрезмерную подгонку к данным.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Веса → очень большие значения (например, +1000 или -1000)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3.2. Как выглядит график при **недообучении**?\n",
        "- Веса модели остаются маленькими или близкими к начальным значениям, что указывает на недостаточную сложность модели.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Веса → маленькие значения (например, около 0)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3.3. Как выглядит график при **необучении**?\n",
        "- Веса модели практически не меняются, оставаясь равными начальным значениям.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Веса → постоянные значения (например, все равны 0.1)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **График предсказаний vs реальных значений**\n",
        "\n",
        "Этот график показывает, как предсказания модели соотносятся с реальными значениями.\n",
        "\n",
        "### 4.1. Как выглядит график при **переобучении**?\n",
        "- Предсказания точно совпадают с обучающими данными, но сильно расходятся с тестовыми данными.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающие данные: идеальное совпадение\n",
        "Тестовые данные:   большой разброс\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4.2. Как выглядит график при **недообучении**?\n",
        "- Предсказания значительно отличаются как от обучающих, так и от тестовых данных.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Обучающие данные: большой разброс\n",
        "Тестовые данные:   такой же разброс\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4.3. Как выглядит график при **необучении**?\n",
        "- Предсказания одинаковы для всех данных, независимо от входных значений.\n",
        "\n",
        "#### Пример:\n",
        "```\n",
        "Все предсказания: одно значение (например, среднее)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Заключение\n",
        "\n",
        "Анализ графиков помогает быстро диагностировать проблемы с моделью:\n",
        "\n",
        "- **Переобучение**: Модель хорошо работает на обучающих данных, но плохо на тестовых.\n",
        "- **Недообучение**: Модель плохо работает как на обучающих, так и на тестовых данных.\n",
        "- **Необучение**: Модель не проявляет прогресса в обучении.\n",
        "\n",
        "Чтобы исправить эти проблемы, важно правильно выбирать модель, настраивать её гиперпараметры и работать с качественными данными.\n"
      ],
      "metadata": {
        "id": "6MVv22Q4kzsg"
      }
    }
  ]
}