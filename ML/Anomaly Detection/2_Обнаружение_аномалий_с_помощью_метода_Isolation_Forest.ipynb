{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeZjzo5YExHsC1cumLnYJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/ML/Anomaly%20Detection/2_%D0%9E%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B0%D0%BD%D0%BE%D0%BC%D0%B0%D0%BB%D0%B8%D0%B9_%D1%81_%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%B0_Isolation_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Обнаружение аномалий с помощью метода Isolation Forest\n",
        "\n",
        "## Введение\n",
        "\n",
        "Обнаружение аномалий (Anomaly Detection) — это процесс идентификации наблюдений, которые существенно отличаются от остальных данных. Аномалии могут быть вызваны ошибками измерений, техническими сбоями, мошенничеством или другими необычными событиями. Основная задача обнаружения аномалий заключается в том, чтобы выделить такие \"выбросы\" из множества нормальных данных.\n",
        "\n",
        "Метод **Isolation Forest** (iForest) — это алгоритм машинного обучения, который был разработан специально для обнаружения аномалий. Он основывается на концепции случайных деревьев и эффективно работает с большими объемами данных. В этой лекции мы подробно рассмотрим принцип работы этого метода, его преимущества и недостатки, а также практические примеры применения.\n",
        "\n",
        "\n",
        "\n",
        "## 1. Постановка задачи обнаружения аномалий\n",
        "\n",
        "### Что такое аномалия?\n",
        "Аномалией называется объект, который значительно отличается от других объектов в датасете. Эти различия могут проявляться в различных характеристиках:\n",
        "- **Отличие по значению**: Например, температура 50°C при средней температуре 20°C.\n",
        "- **Отличие по поведению**: Например, резкий скачок трафика на сайте в определенное время.\n",
        "- **Отличие по комбинации признаков**: Например, покупка дорогой вещи в неподходящее время с использованием чужой карты.\n",
        "\n",
        "### Классификация методов обнаружения аномалий\n",
        "Существует несколько подходов к решению задачи обнаружения аномалий:\n",
        "1. **Статистические методы**: Используются распределения данных для определения выбросов.\n",
        "2. **Методы на основе плотности**: Например, DBSCAN, LOF (Local Outlier Factor).\n",
        "3. **Методы на основе близости**: Определяют аномалии через расстояние между точками.\n",
        "4. **Методы на основе моделей**: Например, Autoencoders, PCA.\n",
        "5. **Методы на основе деревьев**: Например, Isolation Forest.\n",
        "\n",
        "\n",
        "## 2. Принцип работы Isolation Forest\n",
        "\n",
        "### 2.1. Случайные деревья изоляции (Isolation Trees)\n",
        "\n",
        "#### Основная идея\n",
        "Каждое дерево изоляции строится путем **случайного разделения пространства признаков**. В отличие от традиционных деревьев решений, где разделение производится на основе оптимизации критериев (например, Gini или Information Gain), в дереве изоляции разделение выполняется **случайным образом**.\n",
        "\n",
        "#### Процесс построения дерева:\n",
        "1. **Выбор случайного признака**: На каждом уровне дерева выбирается один из доступных признаков $ X_i $ случайным образом.\n",
        "2. **Выбор случайного порога**: Для выбранного признака $ X_i $ генерируется случайное значение $ p $ в пределах диапазона значений этого признака. Например, если значения признака находятся в интервале $[a, b]$, то $ p \\in [a, b] $.\n",
        "3. **Разделение данных**: Все объекты делятся на две группы:\n",
        "   - Объекты, для которых $ X_i \\leq p $, попадают в левую ветвь дерева.\n",
        "   - Объекты, для которых $ X_i > p $, попадают в правую ветвь дерева.\n",
        "4. **Повторение процесса**: Процедура повторяется рекурсивно для каждой группы до тех пор, пока:\n",
        "   - Группа не содержит более одного объекта.\n",
        "   - Или достигнута максимальная глубина дерева (параметр `max_depth`).\n",
        "\n",
        "#### Пример построения дерева:\n",
        "Допустим, у нас есть данные с двумя признаками $ X_1 $ и $ X_2 $, и их значения находятся в следующих диапазонах:\n",
        "- $ X_1 \\in [0, 10] $\n",
        "- $ X_2 \\in [5, 15] $\n",
        "\n",
        "На первом шаге:\n",
        "1. Выбирается случайный признак, например, $ X_1 $.\n",
        "2. Генерируется случайное значение $ p = 7 $.\n",
        "3. Данные делятся на две группы:\n",
        "   - Левая ветвь: $ X_1 \\leq 7 $\n",
        "   - Правая ветвь: $ X_1 > 7 $\n",
        "\n",
        "Процесс повторяется для каждой группы, пока все объекты не будут изолированы.\n",
        "\n",
        "\n",
        "\n",
        "### 2.2. Почему аномалии изолируются быстрее?\n",
        "\n",
        "Основная концепция метода состоит в том, что **аномалии находятся в областях с меньшей плотностью данных**, а нормальные объекты сконцентрированы в областях с высокой плотностью. Поскольку разделения выполняются случайным образом, аномальные объекты чаще оказываются в малочисленных группах и изолируются быстрее.\n",
        "\n",
        "#### Как это работает?\n",
        "1. **Нормальные объекты**: Они обычно находятся в центральных областях данных, где плотность высока. Чтобы изолировать такие объекты, требуется много разделений, так как они окружены другими объектами.\n",
        "2. **Аномальные объекты**: Они находятся на периферии данных, где плотность низкая. Поэтому их можно отделить всего несколькими случайными разделениями.\n",
        "\n",
        "#### Интуитивное объяснение:\n",
        "Представьте себе карту города, где большинство людей живут в центре (нормальные объекты). Если вы случайно проводите границы через город, вам потребуется много попыток, чтобы отделить одного человека из центра. Однако люди, живущие на окраинах (аномалии), легко отделяются уже после нескольких случайных границ.\n",
        "\n",
        "\n",
        "\n",
        "### 2.3. Алгоритм Isolation Forest\n",
        "\n",
        "Isolation Forest использует ансамблевый подход: строится несколько деревьев изоляции, и результаты всех деревьев объединяются для получения финальной оценки аномальности каждого объекта.\n",
        "\n",
        "#### Шаги алгоритма:\n",
        "\n",
        "1. **Генерация случайных деревьев**:\n",
        "   - Создается $ T $ деревьев изоляции (где $ T $ — параметр числа деревьев).\n",
        "   - Каждое дерево строится независимо друг от друга, используя случайные выборки данных.\n",
        "\n",
        "2. **Вычисление пути изоляции**:\n",
        "   - Для каждого объекта $ x $ вычисляется средняя глубина изоляции $ H(x) $, на которой он был изолирован во всех деревьях.\n",
        "   - Глубина изоляции $ h_t(x) $ для конкретного дерева $ t $ — это количество разделений, необходимых для изоляции объекта $ x $.\n",
        "\n",
        "3. **Оценка аномальности**:\n",
        "   - Чем меньше средняя глубина изоляции $ H(x) $, тем выше вероятность того, что объект является аномалией.\n",
        "   - Финальная оценка аномальности может быть преобразована в вероятность или бинарный класс (аномалия/не аномалия).\n",
        "\n",
        "#### Пример:\n",
        "Пусть у нас есть три дерева, и для объекта $ x $ глубины изоляции равны:\n",
        "- В первом дереве: $ h_1(x) = 5 $\n",
        "- Во втором дереве: $ h_2(x) = 6 $\n",
        "- В третьем дереве: $ h_3(x) = 4 $\n",
        "\n",
        "Тогда средняя глубина изоляции:\n",
        "$$\n",
        "H(x) = \\frac{h_1(x) + h_2(x) + h_3(x)}{T} = \\frac{5 + 6 + 4}{3} = 5\n",
        "$$\n",
        "\n",
        "Если $ H(x) $ ниже средней глубины для всех объектов, то объект считается аномалией.\n",
        "\n",
        "\n",
        "\n",
        "### 2.4. Формальная формулировка\n",
        "\n",
        "#### Глубина изоляции\n",
        "Пусть $ h(x) $ — это глубина узла, где объект $ x $ был изолирован в одном дереве. Тогда средняя глубина изоляции для объекта $ x $ в ансамбле из $ T $ деревьев вычисляется как:\n",
        "$$\n",
        "H(x) = \\frac{1}{T} \\sum_{t=1}^T h_t(x)\n",
        "$$\n",
        "где:\n",
        "- $ h_t(x) $ — глубина изоляции объекта $ x $ в $ t $-м дереве.\n",
        "- $ T $ — общее число деревьев.\n",
        "\n",
        "#### Ожидаемая глубина изоляции\n",
        "Для нормальных объектов ожидаемая глубина изоляции $ c(n) $ зависит от количества объектов $ n $ в выборке. Она может быть аппроксимирована формулой:\n",
        "$$\n",
        "c(n) = 2H(n-1) - (2(n-1)/n)\n",
        "$$\n",
        "где $ H(n-1) $ — гармоническое число:\n",
        "$$\n",
        "H(n-1) = \\sum_{k=1}^{n-1} \\frac{1}{k}\n",
        "$$\n",
        "\n",
        "#### Нормализованная оценка аномальности\n",
        "Чтобы получить нормализованную оценку аномальности, используется следующая формула:\n",
        "$$\n",
        "S(x, n) = 2^{-\\frac{H(x)}{c(n)}}\n",
        "$$\n",
        "где:\n",
        "- $ S(x, n) $ — оценка аномальности объекта $ x $.\n",
        "- $ H(x) $ — средняя глубина изоляции объекта.\n",
        "- $ c(n) $ — ожидаемая глубина изоляции для нормальных объектов.\n",
        "\n",
        "Значения $ S(x, n) $ лежат в диапазоне $[0, 1]$:\n",
        "- $ S(x, n) \\approx 1 $: объект является аномалией.\n",
        "- $ S(x, n) \\approx 0 $: объект является нормальным.\n",
        "\n",
        "\n",
        "\n",
        "### 2.5. Особенности реализации\n",
        "\n",
        "#### Параметры алгоритма:\n",
        "1. **`n_estimators`**: Количество деревьев в ансамбле ($ T $).\n",
        "   - Больше деревьев увеличивают точность, но замедляют работу.\n",
        "2. **`max_samples`**: Размер выборки для каждого дерева.\n",
        "   - По умолчанию используется $ 256 $ объектов.\n",
        "3. **`contamination`**: Предполагаемая доля аномалий в данных.\n",
        "   - Используется для установки порога классификации.\n",
        "4. **`max_features`**: Количество признаков, используемых для разделения на каждом шаге.\n",
        "   - По умолчанию используется все признаки.\n",
        "\n",
        "#### Преимущества случайных деревьев:\n",
        "- **Эффективность**: Разделение выполняется случайным образом, что делает процесс быстрым.\n",
        "- **Масштабируемость**: Метод работает эффективно даже с большими объемами данных.\n",
        "\n",
        "\n",
        "\n",
        "### 2.6. Графическая интерпретация\n",
        "\n",
        "#### Пример двумерных данных:\n",
        "Представьте себе набор точек на плоскости:\n",
        "- Нормальные точки сосредоточены вокруг центра.\n",
        "- Аномальные точки находятся на периферии.\n",
        "\n",
        "Случайные деревья изоляции работают следующим образом:\n",
        "1. Первое разделение делит пространство на две части.\n",
        "2. Второе разделение делит каждую часть еще на две.\n",
        "3. Этот процесс продолжается, пока все точки не будут изолированы.\n",
        "\n",
        "Аномальные точки изолируются быстрее, так как они находятся в менее плотных областях.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 3. Преимущества и недостатки Isolation Forest\n",
        "\n",
        "### Преимущества:\n",
        "1. **Эффективность**: Isolation Forest работает быстро даже с большими объемами данных благодаря логарифмической сложности изоляции объектов.\n",
        "2. **Независимость от распределения данных**: Метод не предполагает никаких предположений о форме распределения данных.\n",
        "3. **Простота реализации**: Алгоритм легко реализовать и использовать.\n",
        "4. **Многомерность**: Подходит для многомерных данных без необходимости предварительной обработки.\n",
        "\n",
        "### Недостатки:\n",
        "1. **Чувствительность к параметрам**: Результат зависит от количества деревьев ($ T $) и максимальной глубины дерева.\n",
        "2. **Неустойчивость к шуму**: В некоторых случаях шумовые данные могут быть ошибочно классифицированы как аномалии.\n",
        "3. **Трудность интерпретации**: Хотя метод показывает, какие объекты являются аномалиями, он не объясняет, почему именно эти объекты выбиваются.\n",
        "\n",
        "\n",
        "\n",
        "## 4. Практическая реализация\n",
        "\n",
        "Давайте рассмотрим, как можно реализовать Isolation Forest на практике с использованием библиотеки `scikit-learn` в Python.\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Генерация синтетических данных\n",
        "np.random.seed(42)\n",
        "X = 0.3 * np.random.randn(100, 2)  # Нормальные данные\n",
        "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))  # Аномалии\n",
        "X = np.r_[X + 2, X - 2, X_outliers]  # Объединение нормальных данных и аномалий\n",
        "\n",
        "# Обучение модели Isolation Forest\n",
        "clf = IsolationForest(contamination=0.1, random_state=42)\n",
        "clf.fit(X)\n",
        "\n",
        "# Предсказание аномалий\n",
        "y_pred = clf.predict(X)\n",
        "anomalies = X[y_pred == -1]\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.scatter(X[:, 0], X[:, 1], c='blue', s=20, label='Normal')\n",
        "plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=50, marker='x', label='Anomalies')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Объяснение кода:\n",
        "1. Мы генерируем синтетический датасет с нормальными данными и аномалиями.\n",
        "2. Создаем модель Isolation Forest, указывая параметр `contamination`, который определяет долю аномалий в данных.\n",
        "3. Обучаем модель и делаем предсказания.\n",
        "4. Визуализируем результаты, где аномалии отмечены красным цветом.\n",
        "\n",
        "\n",
        "\n",
        "## 5. Примеры применения\n",
        "\n",
        "### 5.1. Обнаружение мошенничества\n",
        "Isolation Forest может использоваться для обнаружения подозрительных транзакций в банковских системах. Например, если клиент внезапно совершает покупку на крупную сумму в непривычном месте, это может быть классифицировано как аномалия.\n",
        "\n",
        "### 5.2. Мониторинг производственных процессов\n",
        "В промышленности метод применяется для обнаружения дефектов в продукции или неисправностей оборудования. Например, если температура двигателя резко возрастает, это может сигнализировать о проблеме.\n",
        "\n",
        "### 5.3. Анализ сетевых данных\n",
        "Isolation Forest помогает выявлять атаки на сети, такие как DDoS-атаки, анализируя паттерны трафика.\n",
        "\n",
        "\n",
        "\n",
        "Для лучшего понимания принципа работы метода Isolation Forest, давайте разберем конкретный числовой пример без использования кода. Мы будем использовать формулы и шаги алгоритма для вычисления аномальности объектов.\n",
        "\n",
        "\n",
        "\n",
        "## Задача\n",
        "\n",
        "У нас есть набор данных с двумя признаками $ X_1 $ и $ X_2 $. Всего 6 объектов:\n",
        "\n",
        "| Объект | $ X_1 $ | $ X_2 $ |\n",
        "|--------|----------|----------|\n",
        "| $ x_1 $ | 1        | 2        |\n",
        "| $ x_2 $ | 2        | 3        |\n",
        "| $ x_3 $ | 3        | 4        |\n",
        "| $ x_4 $ | 4        | 5        |\n",
        "| $ x_5 $ | 5        | 6        |\n",
        "| $ x_6 $ | 10       | 12       |\n",
        "\n",
        "Здесь объект $ x_6 $ является потенциальной аномалией, так как он сильно отличается от остальных объектов.\n",
        "\n",
        "\n",
        "\n",
        "## Шаг 1: Построение дерева изоляции\n",
        "\n",
        "### Первое дерево\n",
        "1. **Выбор случайного признака**: Выбираем $ X_1 $.\n",
        "2. **Выбор случайного порога**: Генерируем порог $ p = 3.5 $.\n",
        "3. **Разделение данных**:\n",
        "   - Левая ветвь ($ X_1 \\leq 3.5 $): $ x_1, x_2, x_3 $\n",
        "   - Правая ветвь ($ X_1 > 3.5 $): $ x_4, x_5, x_6 $\n",
        "\n",
        "#### Левая ветвь:\n",
        "- Выбираем $ X_2 $.\n",
        "- Генерируем порог $ p = 2.5 $.\n",
        "- Разделяем данные:\n",
        "  - Левая подветвь ($ X_2 \\leq 2.5 $): $ x_1 $\n",
        "  - Правая подветвь ($ X_2 > 2.5 $): $ x_2, x_3 $\n",
        "\n",
        "- Для $ x_2, x_3 $ повторяем процесс:\n",
        "  - Выбираем $ X_1 $.\n",
        "  - Генерируем порог $ p = 2.5 $.\n",
        "  - Разделяем данные:\n",
        "    - Левая подветвь ($ X_1 \\leq 2.5 $): $ x_2 $\n",
        "    - Правая подветвь ($ X_1 > 2.5 $): $ x_3 $\n",
        "\n",
        "#### Правая ветвь:\n",
        "- Выбираем $ X_2 $.\n",
        "- Генерируем порог $ p = 5.5 $.\n",
        "- Разделяем данные:\n",
        "  - Левая подветвь ($ X_2 \\leq 5.5 $): $ x_4, x_5 $\n",
        "  - Правая подветвь ($ X_2 > 5.5 $): $ x_6 $\n",
        "\n",
        "- Для $ x_4, x_5 $ повторяем процесс:\n",
        "  - Выбираем $ X_1 $.\n",
        "  - Генерируем порог $ p = 4.5 $.\n",
        "  - Разделяем данные:\n",
        "    - Левая подветвь ($ X_1 \\leq 4.5 $): $ x_4 $\n",
        "    - Правая подветвь ($ X_1 > 4.5 $): $ x_5 $\n",
        "\n",
        "\n",
        "\n",
        "## Шаг 2: Вычисление глубины изоляции\n",
        "\n",
        "Глубина изоляции $ h(x) $ — это количество разделений, необходимых для полной изоляции объекта.\n",
        "\n",
        "| Объект | Глубина изоляции ($ h(x) $) |\n",
        "|--------|-----------------------------|\n",
        "| $ x_1 $ | 2                           |\n",
        "| $ x_2 $ | 3                           |\n",
        "| $ x_3 $ | 3                           |\n",
        "| $ x_4 $ | 3                           |\n",
        "| $ x_5 $ | 3                           |\n",
        "| $ x_6 $ | 2                           |\n",
        "\n",
        "Обратите внимание, что $ x_6 $ был изолирован быстрее других объектов, что указывает на его потенциальную аномальность.\n",
        "\n",
        "\n",
        "\n",
        "## Шаг 3: Средняя глубина изоляции\n",
        "\n",
        "Пусть мы построили $ T = 3 $ дерева изоляции. Для каждого объекта вычислим среднюю глубину изоляции $ H(x) $.\n",
        "\n",
        "Предположим, что результаты для всех трех деревьев следующие:\n",
        "\n",
        "| Объект | $ h_1(x) $ | $ h_2(x) $ | $ h_3(x) $ | $ H(x) $ |\n",
        "|--------|-------------|-------------|-------------|-----------|\n",
        "| $ x_1 $ | 2          | 3          | 2          | 2.33      |\n",
        "| $ x_2 $ | 3          | 3          | 3          | 3.00      |\n",
        "| $ x_3 $ | 3          | 3          | 3          | 3.00      |\n",
        "| $ x_4 $ | 3          | 3          | 3          | 3.00      |\n",
        "| $ x_5 $ | 3          | 3          | 3          | 3.00      |\n",
        "| $ x_6 $ | 2          | 2          | 2          | 2.00      |\n",
        "\n",
        "Формула для средней глубины изоляции:\n",
        "$$\n",
        "H(x) = \\frac{1}{T} \\sum_{t=1}^T h_t(x)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## Шаг 4: Ожидаемая глубина изоляции\n",
        "\n",
        "Ожидаемая глубина изоляции $ c(n) $ для нормальных объектов рассчитывается по формуле:\n",
        "$$\n",
        "c(n) = 2H(n-1) - (2(n-1)/n)\n",
        "$$\n",
        "где $ H(n-1) $ — гармоническое число:\n",
        "$$\n",
        "H(n-1) = \\sum_{k=1}^{n-1} \\frac{1}{k}\n",
        "$$\n",
        "\n",
        "Для $ n = 6 $:\n",
        "$$\n",
        "H(5) = 1 + \\frac{1}{2} + \\frac{1}{3} + \\frac{1}{4} + \\frac{1}{5} \\approx 2.283\n",
        "$$\n",
        "$$\n",
        "c(6) = 2 \\cdot 2.283 - \\frac{2 \\cdot 5}{6} \\approx 4.566 - 1.667 \\approx 2.899\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## Шаг 5: Нормализованная оценка аномальности\n",
        "\n",
        "Нормализованная оценка аномальности $ S(x, n) $ вычисляется по формуле:\n",
        "$$\n",
        "S(x, n) = 2^{-\\frac{H(x)}{c(n)}}\n",
        "$$\n",
        "\n",
        "Подставляем значения:\n",
        "\n",
        "| Объект | $ H(x) $ | $ S(x, n) $ |\n",
        "|--------|-----------|--------------|\n",
        "| $ x_1 $ | 2.33      | $ 2^{-\\frac{2.33}{2.899}} \\approx 0.67 $ |\n",
        "| $ x_2 $ | 3.00      | $ 2^{-\\frac{3.00}{2.899}} \\approx 0.50 $ |\n",
        "| $ x_3 $ | 3.00      | $ 2^{-\\frac{3.00}{2.899}} \\approx 0.50 $ |\n",
        "| $ x_4 $ | 3.00      | $ 2^{-\\frac{3.00}{2.899}} \\approx 0.50 $ |\n",
        "| $ x_5 $ | 3.00      | $ 2^{-\\frac{3.00}{2.899}} \\approx 0.50 $ |\n",
        "| $ x_6 $ | 2.00      | $ 2^{-\\frac{2.00}{2.899}} \\approx 0.75 $ |\n",
        "\n",
        "\n",
        "\n",
        "## Заключение\n",
        "\n",
        "На основе значений $ S(x, n) $ можно сделать вывод:\n",
        "- Объекты $ x_2, x_3, x_4, x_5 $ имеют низкую оценку аномальности ($ S(x, n) \\approx 0.50 $), что указывает на их нормальность.\n",
        "- Объект $ x_6 $ имеет высокую оценку аномальности ($ S(x, n) \\approx 0.75 $), что указывает на его аномальность.\n",
        "\n",
        "Таким образом, метод Isolation Forest успешно обнаружил аномалию!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Пример 1: Обнаружение аномалий в двумерных данных\n",
        "\n",
        "### Задача\n",
        "Мы создадим синтетический датасет с нормальными данными и добавим несколько аномалий. Затем применим Isolation Forest для их обнаружения.\n",
        "\n",
        "### Код\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Генерация синтетических данных\n",
        "np.random.seed(42)\n",
        "X = 0.3 * np.random.randn(100, 2)  # Нормальные данные (центральные точки)\n",
        "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))  # Аномалии (периферийные точки)\n",
        "X = np.vstack((X + 2, X - 2, X_outliers))  # Объединение нормальных данных и аномалий\n",
        "\n",
        "# Обучение модели Isolation Forest\n",
        "clf = IsolationForest(contamination=0.1, random_state=42)  # Предполагаем, что 10% данных — аномалии\n",
        "clf.fit(X)\n",
        "\n",
        "# Предсказание аномалий\n",
        "y_pred = clf.predict(X)  # Возвращает +1 для нормальных объектов и -1 для аномалий\n",
        "anomalies = X[y_pred == -1]  # Выделяем аномалии\n",
        "normal = X[y_pred == 1]  # Выделяем нормальные объекты\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(normal[:, 0], normal[:, 1], c='blue', s=20, label='Normal')\n",
        "plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=50, marker='x', label='Anomalies')\n",
        "plt.title('Isolation Forest Anomaly Detection')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Объяснение кода:\n",
        "1. **Генерация данных**:\n",
        "   - Создаем нормальные данные как центральные точки, используя нормальное распределение.\n",
        "   - Добавляем аномалии как периферийные точки, используя равномерное распределение.\n",
        "2. **Обучение модели**:\n",
        "   - Используем параметр `contamination=0.1`, чтобы указать, что предполагаем 10% аномалий в данных.\n",
        "3. **Предсказание**:\n",
        "   - Метод `predict` возвращает метки: `+1` для нормальных объектов и `-1` для аномалий.\n",
        "4. **Визуализация**:\n",
        "   - Нормальные объекты отображаются синими точками.\n",
        "   - Аномалии отображаются красными крестами.\n",
        "\n",
        "\n",
        "\n",
        "## Пример 2: Обнаружение аномалий в реальных данных\n",
        "\n",
        "### Задача\n",
        "Используем датасет `Boston Housing` из `scikit-learn`. Этот датасет содержит информацию о ценах на жилье в Бостоне. Мы будем искать аномалии среди признаков.\n",
        "\n",
        "### Код\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Загрузка датасета Boston Housing\n",
        "boston = load_boston()\n",
        "X = boston.data  # Признаки\n",
        "\n",
        "# Обучение модели Isolation Forest\n",
        "clf = IsolationForest(contamination=0.05, random_state=42)  # Предполагаем 5% аномалий\n",
        "clf.fit(X)\n",
        "\n",
        "# Предсказание аномалий\n",
        "y_pred = clf.predict(X)  # Возвращает +1 для нормальных объектов и -1 для аномалий\n",
        "anomalies_indices = np.where(y_pred == -1)[0]  # Индексы аномалий\n",
        "\n",
        "# Визуализация аномалий по одному из признаков (например, CRIM)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(X)), X[:, 0], c='blue', s=20, label='Normal')  # Признак CRIM\n",
        "plt.scatter(anomalies_indices, X[anomalies_indices, 0], c='red', s=50, marker='x', label='Anomalies')\n",
        "plt.title('Anomalies in Boston Housing Dataset (CRIM feature)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('CRIM (Per capita crime rate)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Объяснение кода:\n",
        "1. **Загрузка данных**:\n",
        "   - Используем датасет `Boston Housing`.\n",
        "   - Выбираем все признаки для анализа.\n",
        "2. **Обучение модели**:\n",
        "   - Устанавливаем параметр `contamination=0.05`, так как предполагаем 5% аномалий.\n",
        "3. **Предсказание**:\n",
        "   - Находим индексы аномальных объектов.\n",
        "4. **Визуализация**:\n",
        "   - Отображаем значения одного из признаков (`CRIM`) для всех объектов.\n",
        "   - Аномальные объекты выделяются красными крестами.\n",
        "\n",
        "\n",
        "## Пример 3: Изменение параметров Isolation Forest\n",
        "\n",
        "### Задача\n",
        "Исследуем влияние параметра `contamination` на результаты детекции аномалий.\n",
        "\n",
        "### Код\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Генерация синтетических данных\n",
        "np.random.seed(42)\n",
        "X = 0.3 * np.random.randn(100, 2)  # Нормальные данные\n",
        "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))  # Аномалии\n",
        "X = np.vstack((X + 2, X - 2, X_outliers))\n",
        "\n",
        "# Функция для визуализации результатов\n",
        "def plot_anomalies(X, contamination):\n",
        "    clf = IsolationForest(contamination=contamination, random_state=42)\n",
        "    clf.fit(X)\n",
        "    y_pred = clf.predict(X)\n",
        "    anomalies = X[y_pred == -1]\n",
        "    normal = X[y_pred == 1]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(normal[:, 0], normal[:, 1], c='blue', s=20, label='Normal')\n",
        "    plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', s=50, marker='x', label='Anomalies')\n",
        "    plt.title(f'Isolation Forest (contamination={contamination})')\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Тестирование разных значений contamination\n",
        "plot_anomalies(X, contamination=0.05)  # 5% аномалий\n",
        "plot_anomalies(X, contamination=0.1)   # 10% аномалий\n",
        "plot_anomalies(X, contamination=0.2)   # 20% аномалий\n",
        "```\n",
        "\n",
        "### Объяснение кода:\n",
        "1. **Функция визуализации**:\n",
        "   - Для каждого значения параметра `contamination` строим модель Isolation Forest и визуализируем результаты.\n",
        "2. **Тестирование**:\n",
        "   - Проверяем, как меняется количество обнаруженных аномалий при различных значениях `contamination`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ##Isolation Forest для анализа временных рядов\n",
        "\n",
        "В предыдущих частях мы рассмотрели основные принципы работы метода Isolation Forest, его применение для обнаружения аномалий в двумерных данных и реальных датасетах. Теперь перейдем к более сложной задаче — **обнаружению аномалий в временных рядах**. Временные ряды представляют собой последовательности значений, измеренных через равные промежутки времени, и часто используются в таких областях, как финансы, мониторинг систем, медицина и другие.\n",
        "\n",
        "\n",
        "\n",
        "## 1. Особенности анализа временных рядов\n",
        "\n",
        "Анализ временных рядов имеет свои особенности, которые необходимо учитывать при использовании методов обнаружения аномалий:\n",
        "\n",
        "1. **Сезонность**: Временные ряды часто содержат повторяющиеся паттерны (например, суточные или недельные циклы).\n",
        "2. **Тренд**: Данные могут иметь долгосрочную тенденцию к увеличению или уменьшению.\n",
        "3. **Шум**: Реальные данные обычно содержат случайные флуктуации, которые не являются аномалиями.\n",
        "4. **Контекст**: Аномалия в одном контексте может быть нормой в другом (например, высокая температура летом — это нормально, но зимой — аномалия).\n",
        "\n",
        "Isolation Forest может эффективно работать с такими данными, если правильно подготовить их для анализа.\n",
        "\n",
        "\n",
        "## 2. Подготовка данных для анализа временных рядов\n",
        "\n",
        "Прежде чем применять Isolation Forest к временным рядам, необходимо выполнить несколько шагов подготовки данных:\n",
        "\n",
        "### 2.1. Преобразование данных в формат признаков\n",
        "Isolation Forest работает с многомерными данными, поэтому нужно преобразовать одномерный временной ряд в множество признаков. Это можно сделать несколькими способами:\n",
        "\n",
        "#### a) Оконное преобразование (Sliding Window)\n",
        "Оконное преобразование заключается в создании новых признаков на основе предыдущих значений ряда. Например, если у нас есть временной ряд $ [x_1, x_2, x_3, \\dots] $, то можно создать окно размера 3:\n",
        "$$\n",
        "\\text{Признаки: } [x_t, x_{t-1}, x_{t-2}]\n",
        "$$\n",
        "Это позволяет учесть зависимость между соседними точками.\n",
        "\n",
        "#### b) Добавление дополнительных признаков\n",
        "Можно добавить дополнительные признаки, такие как:\n",
        "- Скользящее среднее.\n",
        "- Стандартное отклонение за определенный период.\n",
        "- Производная ряда.\n",
        "- Индекс времени (например, час, день недели).\n",
        "\n",
        "Пример:\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Исходный временной ряд\n",
        "time_series = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "# Создание окна размера 3\n",
        "window_size = 3\n",
        "X = []\n",
        "for i in range(window_size, len(time_series)):\n",
        "    X.append(time_series[i - window_size:i])\n",
        "X = np.array(X)\n",
        "\n",
        "print(\"Преобразованные данные:\\n\", X)\n",
        "```\n",
        "\n",
        "Результат:\n",
        "```\n",
        "Преобразованные данные:\n",
        " [[1 2 3]\n",
        "  [2 3 4]\n",
        "  [3 4 5]\n",
        "  [4 5 6]\n",
        "  [5 6 7]]\n",
        "```\n",
        "\n",
        "\n",
        "### 2.2. Нормализация данных\n",
        "Нормализация помогает улучшить работу алгоритма, особенно если значения временного ряда сильно различаются по масштабу. Обычно используется минимаксная нормализация:\n",
        "$$\n",
        "x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n",
        "$$\n",
        "или стандартизация:\n",
        "$$\n",
        "x' = \\frac{x - \\mu}{\\sigma}\n",
        "$$\n",
        "где $ \\mu $ — среднее значение, $ \\sigma $ — стандартное отклонение.\n",
        "\n",
        "\n",
        "\n",
        "## 3. Применение Isolation Forest к временным рядам\n",
        "\n",
        "После подготовки данных можно применить Isolation Forest для обнаружения аномалий.\n",
        "\n",
        "### 3.1. Алгоритм\n",
        "1. **Подготовка данных**: Преобразуйте временной ряд в формат признаков (например, используя оконное преобразование).\n",
        "2. **Обучение модели**: Обучите модель Isolation Forest на подготовленных данных.\n",
        "3. **Предсказание аномалий**: Используйте метод `predict` для классификации объектов как нормальных (`+1`) или аномальных (`-1`).\n",
        "4. **Визуализация результатов**: Отобразите исходный временной ряд с выделенными аномалиями.\n",
        "\n",
        "\n",
        "### 3.2. Пример реализации\n",
        "\n",
        "#### Код\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Генерация синтетического временного ряда\n",
        "np.random.seed(42)\n",
        "time = np.arange(0, 100, 0.5)  # Временная ось\n",
        "data = np.sin(time) + np.random.normal(0, 0.1, len(time))  # Синусоида с шумом\n",
        "outliers = np.random.randint(0, len(data), 10)  # Индексы выбросов\n",
        "data[outliers] += np.random.uniform(2, 5, size=len(outliers))  # Добавляем выбросы\n",
        "\n",
        "# Преобразование данных в формат для Isolation Forest\n",
        "window_size = 3  # Размер окна\n",
        "X = []\n",
        "for i in range(window_size, len(data)):\n",
        "    X.append(data[i - window_size:i])\n",
        "X = np.array(X)\n",
        "\n",
        "# Обучение модели Isolation Forest\n",
        "clf = IsolationForest(contamination=0.05, random_state=42)  # Предполагаем 5% аномалий\n",
        "clf.fit(X)\n",
        "\n",
        "# Предсказание аномалий\n",
        "y_pred = clf.predict(X)  # Возвращает +1 для нормальных объектов и -1 для аномалий\n",
        "anomalies_indices = np.where(y_pred == -1)[0] + window_size  # Индексы аномалий\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time, data, c='blue', label='Time Series')\n",
        "plt.scatter(time[anomalies_indices], data[anomalies_indices], c='red', s=50, marker='x', label='Anomalies')\n",
        "plt.title('Isolation Forest for Time Series Anomaly Detection')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### Объяснение кода:\n",
        "1. **Генерация данных**:\n",
        "   - Создаем синусоидальный временной ряд с небольшим шумом.\n",
        "   - Добавляем случайные выбросы в определенные моменты времени.\n",
        "2. **Преобразование данных**:\n",
        "   - Используем оконное преобразование для создания признаков.\n",
        "3. **Обучение модели**:\n",
        "   - Устанавливаем параметр `contamination=0.05`, чтобы указать долю аномалий.\n",
        "4. **Предсказание**:\n",
        "   - Находим индексы аномалий.\n",
        "5. **Визуализация**:\n",
        "   - Отображаем временной ряд и выделяем аномалии красными крестами.\n",
        "\n",
        "\n",
        "\n",
        "## 4. Анализ результатов\n",
        "\n",
        "На графике видно, что Isolation Forest успешно обнаружил большинство добавленных аномалий. Однако важно отметить, что точность метода зависит от:\n",
        "1. **Размера окна**: Большое окно может упустить короткие аномалии, а маленькое окно может увеличить количество ложных срабатываний.\n",
        "2. **Параметра contamination**: Если установлен слишком низкий или слишком высокий уровень аномалий, это может повлиять на качество детекции.\n",
        "3. **Качества данных**: Метод лучше работает с чистыми данными, где шум минимально влияет на результат.\n",
        "\n",
        "\n",
        "## 5. Практические примеры применения\n",
        "\n",
        "### 5.1. Финансовые данные\n",
        "Isolation Forest может использоваться для обнаружения аномалий в ценовых графиках акций или валют. Например, резкие скачки цены могут быть вызваны ошибками торговли или мошенничеством.\n",
        "\n",
        "### 5.2. Мониторинг производственных процессов\n",
        "В промышленности метод применяется для обнаружения сбоев оборудования. Например, если температура двигателя внезапно возрастает, это может сигнализировать о проблеме.\n",
        "\n",
        "### 5.3. Анализ энергопотребления\n",
        "Isolation Forest помогает выявлять аномалии в потреблении электроэнергии, например, при необычно высоком или низком потреблении.\n",
        ""
      ],
      "metadata": {
        "id": "4Zxg9JsJbds5"
      }
    }
  ]
}