{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNxPm+pmwwTx1pgYBxVUuBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/Lecture%208.%20Transformers/Hugging_Face_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%D1%85_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face в задачах NLP\n",
        "\n",
        "#### Введение в Hugging Face\n",
        "\n",
        "\n",
        "Hugging Face — это платформа и сообщество, специализирующееся на разработке и распространении библиотек и моделей для работы с естественным языком (NLP). Они известны своими инновационными подходами к решению различных задач, таких как классификация текстов, вопросно-ответная система, генерация текстов и многие другие.\n",
        "\n",
        "Основные преимущества использования Hugging Face:\n",
        "\n",
        "1. Широкий выбор предобученных моделей: Hugging Face предоставляет доступ к большому количеству предобученных моделей, которые можно использовать для решения широкого спектра задач в области NLP. Это позволяет значительно ускорить разработку и сократить затраты на обучение собственных моделей.\n",
        "\n",
        "2. Простота использования: Библиотеки Hugging Face, такие как Transformers и Datasets, предоставляют удобные и интуитивно понятные интерфейсы для работы с моделями и данными. Это значительно упрощает интеграцию Hugging Face в различные проекты.\n",
        "\n",
        "3. Активное сообщество: Hugging Face имеет большое и активное сообщество разработчиков, исследователей и энтузиастов, которые активно участвуют в развитии платформы, делятся своими наработками и предоставляют поддержку другим пользователям.\n",
        "\n",
        "4. Регулярные обновления: Hugging Face регулярно обновляет свои библиотеки и модели, добавляя новые возможности и улучшая существующие. Это позволяет разработчикам всегда использовать актуальные и эффективные решения.\n",
        "\n",
        "5. Свободное использование: Большинство моделей и библиотек Hugging Face распространяются под открытыми лицензиями, что делает их доступными для широкого круга пользователей и позволяет использовать их в коммерческих и некоммерческих проектах.\n",
        "\n",
        "Таким образом, Hugging Face предоставляет мощный инструментарий для решения широкого спектра задач в области обработки естественного языка, что делает ее популярной среди разработчиков, исследователей и энтузиастов в области NLP.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N-jsg8DPksEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Примеры задач и использование Hugging Face\n",
        "\n",
        "1. **Text Classification**\n",
        "   - **Определение задачи:** Классификация текстов на основе их содержания.\n",
        "   - **Пример с использованием Hugging Face:** Использование модели `distilbert-base-uncased` для классификации отзывов на фильмы как положительные или отрицательные.\n"
      ],
      "metadata": {
        "id": "QFZTXOcvXlyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "result = classifier(\"I love this product!\")\n",
        "print(result)\n",
        "# Output: [{'label': 'POSITIVE', 'score': 0.9997}]"
      ],
      "metadata": {
        "id": "nJs1cjOZlHaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определение эмоции в тексте"
      ],
      "metadata": {
        "id": "sCyOV1ZT-9_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\",\n",
        "                     model=\"SamLowe/roberta-base-go_emotions\")\n",
        "results = classifier(\"Я в мае сдаю, боюсь сейчас) Ну как же, для себя, просто.\")\n",
        "results"
      ],
      "metadata": {
        "id": "9u0fgNG---ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классификации текста"
      ],
      "metadata": {
        "id": "QrAnqlCa_wgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\",\n",
        "                      model=\"cointegrated/rubert-tiny2-cedr-emotion-detection\")\n",
        "res=classifier(\"Я в мае сдаю, боюсь сейчас) Ну как же, для себя, просто.\",\n",
        "           return_all_scores=True)\n",
        "res"
      ],
      "metadata": {
        "id": "ItcoO3SpABqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывести на русском языке"
      ],
      "metadata": {
        "id": "yRSKr3C9Af-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Создаём словарь соответствия меток эмоций на английском и русском языках\n",
        "emotion_labels = {\n",
        "    'anger': 'гнев',\n",
        "    'fear': 'страх',\n",
        "    'joy': 'радость',\n",
        "    'neutral': 'нейтральность',\n",
        "    'sadness': 'грусть',\n",
        "    'no_emotion': 'отсутствие эмоций'\n",
        "}\n",
        "\n",
        "# Загружаем модель для классификации эмоций\n",
        "classifier = pipeline(\"text-classification\",\n",
        "                      model=\"cointegrated/rubert-tiny2-cedr-emotion-detection\")\n",
        "\n",
        "# Текст для классификации\n",
        "text = \"Я в мае сдаю, боюсь сейчас) Ну как же, для себя, просто.\"\n",
        "\n",
        "# Классифицируем текст и получаем результаты\n",
        "results = classifier(text, return_all_scores=True)[0]\n",
        "\n",
        "# Преобразуем результаты на русский язык\n",
        "russian_results = []\n",
        "for res in results:\n",
        "    if res['label'] in emotion_labels:\n",
        "        russian_results.append({'label': emotion_labels[res['label']], 'score': res['score']})\n",
        "    else:\n",
        "        russian_results.append({'label': emotion_labels['no_emotion'], 'score': res['score']})\n",
        "\n",
        "# Выводим результаты\n",
        "print(russian_results)\n",
        "\n",
        "# Выводим результаты\n",
        "for result in russian_results:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "kQlprjRFAjV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **Token Classification**\n",
        "   - **Определение задачи:** Определение класса каждого токена в тексте.\n",
        "   - **Пример с использованием Hugging Face:** Модель `bert-base-cased` для идентификации и классификации именованных сущностей в тексте, таких как имена людей или организаций.\n"
      ],
      "metadata": {
        "id": "Mn_ta1d3kvWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner_model = pipeline(\"ner\")\n",
        "result = ner_model(\"Hugging Face is a company based in New York City.\")\n",
        "print(result)\n",
        "# Output: [{'entity': 'I-ORG', 'score': 0.9986, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}, ...]"
      ],
      "metadata": {
        "id": "6ucuedoYlN4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Table Question Answering**\n",
        "   - **Определение задачи:** Ответ на вопросы, основанные на данных в табличном формате.\n",
        "   - **Пример с использованием Hugging Face:** Использование модели `roberta-large` для отвечения на вопросы, связанные с финансовыми данными, представленными в табличной форме.\n"
      ],
      "metadata": {
        "id": "AQYHqLFUkw5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 1."
      ],
      "metadata": {
        "id": "Oma5EyymUqYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import RobertaForQuestionAnswering, RobertaTokenizer\n",
        "\n",
        "# Загрузка модели и токенизатора\n",
        "model_name = 'roberta-large'\n",
        "model = RobertaForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Подготовка данных: таблица с финансовыми данными\n",
        "context = \"\"\"Дата       | Цена закрытия | Объем торгов | Изменение\n",
        "             -----------------------------------------------------\n",
        "             2023-01-01 | 100.0         | 100000       | +1.5\n",
        "             2023-01-02 | 101.5         | 120000       | +0.5\"\"\"\n",
        "\n",
        "# Формулировка вопросов\n",
        "questions = [\n",
        "    \"Какова была цена закрытия акций на 2023-01-01?\",\n",
        "    \"Какой объем торгов был 2023-01-02?\",\n",
        "    \"На сколько изменилась цена акций 2023-01-02 по сравнению с предыдущим днем?\"\n",
        "]\n",
        "\n",
        "# Токенизация вопросов и контекста\n",
        "tokenized_input = tokenizer(questions, [context]*len(questions), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Вызов модели для получения ответов\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokenized_input)\n",
        "\n",
        "# Извлечение ответов из вывода модели\n",
        "answer_start = torch.argmax(outputs.start_logits)\n",
        "answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "model_answer = tokenizer.decode(tokenized_input[\"input_ids\"][0][answer_start:answer_end])\n",
        "\n",
        "# Функция для оценки ответа пользователя\n",
        "def evaluate_answer(user_answer, model_answer):\n",
        "    user_answer = user_answer.strip().lower()\n",
        "    model_answer = model_answer.strip().lower()\n",
        "\n",
        "    if user_answer == model_answer:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Ввод ответа от пользователя\n",
        "user_answer = input(\"Введите ваш ответ на вопрос '{}': \".format(questions[0]))\n",
        "\n",
        "# Оценка ответа пользователя\n",
        "correct = evaluate_answer(user_answer, model_answer)\n",
        "\n",
        "# Вывод результата\n",
        "if correct:\n",
        "    print(\"Ваш ответ правильный!\")\n",
        "else:\n",
        "    print(\"Ваш ответ неправильный. Правильный ответ:\", model_answer)"
      ],
      "metadata": {
        "id": "zpuDkNSSUrlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Табличные данные для примера 1: Финансовые данные компании\n",
        "table_data_1 = \"\"\"\n",
        "Квартал | Выручка (млн $) | Прибыль (млн $) | Расходы (млн $)\n",
        "Q1 2023 | 500 | 120 | 380\n",
        "Q2 2023 | 600 | 150 | 450\n",
        "Q3 2023 | 700 | 200 | 500\n",
        "Q4 2023 | 800 | 250 | 550\n",
        "\"\"\"\n",
        "\n",
        "# Табличные данные для примера 2: Данные о продажах продуктов\n",
        "table_data_2 = \"\"\"\n",
        "Продукт | Продажи (шт.) | Выручка (тыс. $) | Средняя цена (тыс. $)\n",
        "Телевизоры | 200 | 400 | 2.0\n",
        "Холодильники | 150 | 450 | 3.0\n",
        "Стиральные машины | 100 | 300 | 3.0\n",
        "Кондиционеры | 250 | 500 | 2.0\n",
        "\"\"\"\n",
        "\n",
        "# Табличные данные для примера 3: Статистика по студентам\n",
        "table_data_3 = \"\"\"\n",
        "Студент | Возраст | Баллы по математике | Баллы по физике | Баллы по химии\n",
        "Иванов И.И. | 17 | 90 | 85 | 88\n",
        "Петров П.П. | 18 | 78 | 92 | 80\n",
        "Сидоров С.С. | 17 | 85 | 89 | 84\n",
        "Кузнецов К.К. | 18 | 92 | 81 | 90\n",
        "\"\"\"\n",
        "\n",
        "# Примеры вопросов для каждой таблицы\n",
        "questions_example_1 = [\n",
        "    \"Какая была выручка в Q1 2023?\",\n",
        "    \"Какая была прибыль в Q2 2023?\",\n",
        "    \"Какие были расходы в Q3 2023?\"\n",
        "]\n",
        "\n",
        "questions_example_2 = [\n",
        "    \"Сколько телевизоров было продано?\",\n",
        "    \"Какая была выручка от продажи холодильников?\",\n",
        "    \"Какова средняя цена стиральной машины?\"\n",
        "]\n",
        "\n",
        "questions_example_3 = [\n",
        "    \"Какой возраст у Иванова И.И.?\",\n",
        "    \"Сколько баллов по физике у Петрова П.П.?\",\n",
        "    \"Какие баллы по химии у Кузнецова К.К.?\"\n",
        "]\n",
        "\n",
        "# Функция для ответа на вопросы с использованием модели RobertaForQuestionAnswering\n",
        "def answer_questions(table_data, questions):\n",
        "    # Загрузка токенизатора и модели\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "    model = RobertaForQuestionAnswering.from_pretrained('roberta-large')\n",
        "\n",
        "    # Пройти по каждому вопросу и получить ответы\n",
        "    for i, question in enumerate(questions, 1):\n",
        "        print(f\"Вопрос {i}: {question}\")\n",
        "\n",
        "        # Токенизация вопроса и табличных данных\n",
        "        inputs = tokenizer(question, table_data, return_tensors='pt')\n",
        "\n",
        "        # Получение ответа от модели\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Получение начального и конечного индексов ответа\n",
        "        start_index = torch.argmax(outputs.start_logits)\n",
        "        end_index = torch.argmax(outputs.end_logits) + 1\n",
        "\n",
        "        # Преобразование токенов в строку ответа\n",
        "        answer_tokens = inputs['input_ids'][0][start_index:end_index]\n",
        "        answer = tokenizer.decode(answer_tokens)\n",
        "\n",
        "        print(f\"Ответ: {answer}\\n\")\n",
        "\n",
        "# Примеры вопросов и ответы для каждой таблицы\n",
        "print(\"Пример 1: Финансовые данные компании\")\n",
        "answer_questions(table_data_1, questions_example_1)\n",
        "\n",
        "print(\"Пример 2: Данные о продажах продуктов\")\n",
        "answer_questions(table_data_2, questions_example_2)\n",
        "\n",
        "print(\"Пример 3: Статистика по студентам\")\n",
        "answer_questions(table_data_3, questions_example_3)"
      ],
      "metadata": {
        "id": "gLtzxLkLlPft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Загрузка модели и токенизатора\n",
        "model_name = \"deepset/roberta-large-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Пример данных в табличной форме\n",
        "data = {\n",
        "    \"Year\": [2020, 2021, 2022],\n",
        "    \"Revenue\": [100, 150, 200],\n",
        "    \"Profit\": [10, 15, 25]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Функция для преобразования таблицы в текст\n",
        "def table_to_text(df):\n",
        "    text = \"\"\n",
        "    for col in df.columns:\n",
        "        text += col + \": \" + \", \".join(df[col].astype(str)) + \". \"\n",
        "    return text\n",
        "\n",
        "# Преобразование таблицы в текст\n",
        "context = table_to_text(df)\n",
        "print(\"Context:\", context)\n",
        "\n",
        "# Функция для выполнения Table QA\n",
        "def answer_question(question, context):\n",
        "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "    answer_start = torch.argmax(outputs.start_logits)\n",
        "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "    return answer\n",
        "\n",
        "# Пример вопроса\n",
        "question = \"What was the revenue in 2021?\"\n",
        "answer = answer_question(question, context)\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "v_Sc24vjLWgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. **Question Answering**\n",
        "   - **Определение задачи:** Ответ на вопросы на естественном языке, основываясь на предоставленном контексте.\n",
        "   - **Пример с использованием Hugging Face:** Модель `albert-base-v2` для ответа на вопросы, касающиеся содержания статей в новостях.\n"
      ],
      "metadata": {
        "id": "WkMQG7Zkkysw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\")\n",
        "context = \"Hugging Face is a company based in New York City.\"\n",
        "question = \"Where is Hugging Face based?\"\n",
        "result = qa_model(question=question, context=context)\n",
        "print(result)\n",
        "# Output: {'score': 0.9923, 'start': 31, 'end': 45, 'answer': 'New York City'}"
      ],
      "metadata": {
        "id": "U1jgkF_XlQAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 2."
      ],
      "metadata": {
        "id": "GpfXX37xI1wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "qa_model = pipeline(\"question-answering\", model=\"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\")\n",
        "\n",
        "context=\"\"\"Меня зовут Андрей Андреевич, я занимаюсь созданием учебных курсов по ИТ и компьютерным наукам.\n",
        "           Сейчас я работаю в Казанском федеральном университете, где мы создаем магистерскую программу по\n",
        "           Инженерии искусственного интеллекта. В программу входят курсы по компьютерному зрению,\n",
        "           обработке естественного языка, анализу временных рядов. Также есть интересный курс по\n",
        "           применению машинного обучения для информационной безопасности.\n",
        "         \"\"\"\n",
        "question=\"Как называется программа магистратуры, которую создает Андрей Андреевич?\"\n",
        "results = qa_model(question = question, context = context)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "bNAL_aXOI22S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. **Zero-Shot Classification**\n",
        "   - **Определение задачи:** Классификация текстов без предварительного обучения на данных конкретной задачи.\n",
        "   - **Пример с использованием Hugging Face:** Модель `facebook/bart-large-mnli` для классификации текстов на несколько категорий без предварительного обучения на этом конкретном наборе данных.\n"
      ],
      "metadata": {
        "id": "dI_o-Lg8k0T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "sequence = \"I am looking for a restaurant in Paris.\"\n",
        "candidate_labels = [\"food\", \"politics\", \"travel\"]\n",
        "result = classifier(sequence, candidate_labels)\n",
        "print(result)\n",
        "# Output: {'sequence': 'I am looking for a restaurant in Paris.', 'labels': ['travel', 'food', 'politics'], ...}"
      ],
      "metadata": {
        "id": "lT5MngG5lS0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. **Translation**\n",
        "   - **Определение задачи:** Перевод текста с одного языка на другой.\n",
        "   - **Пример с использованием Hugging Face:** Модель `t5-small` для перевода текстов с английского на французский.\n"
      ],
      "metadata": {
        "id": "B81BYDPok18b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece\n",
        "!pip install sacremoses\n",
        "from transformers import pipeline\n",
        "translator = pipeline(\"translation_ru_to_en\", model=\"facebook/wmt19-ru-en\")\n",
        "results = translator(\"Меня зовут Андрей и я живу в Казани\")"
      ],
      "metadata": {
        "id": "8XxnFwHAlUjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "7. **Summarization**\n",
        "   - **Определение задачи:** Создание краткого содержания исходного текста.\n",
        "   - **Пример с использованием Hugging Face:** Модель `bart-large-cnn` для генерации краткого содержания новостных статей.\n"
      ],
      "metadata": {
        "id": "vuDuaIcDk3dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "text = \"Hugging Face is a technology company specializing in NLP.\"\n",
        "summary = summarizer(text, max_length=50, min_length=20, do_sample=False)\n",
        "print(summary)\n",
        "# Output: [{'summary_text': 'Hugging Face is a technology company specializing in NLP.'}]"
      ],
      "metadata": {
        "id": "RV4Qm18wlVFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "8. **Feature Extraction**\n",
        "   - **Определение задачи:** Извлечение важных признаков из текстов для дальнейшего анализа.\n",
        "   - **Пример с использованием Hugging Face:** Использование модели `distilbert-base-uncased` для извлечения эмоциональной окраски текста.\n"
      ],
      "metadata": {
        "id": "BzWAElo1k46w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "text = \"Hugging Face is a company based in New York City.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "last_hidden_states"
      ],
      "metadata": {
        "id": "jBvE4JDVlWg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "9. **Text Generation**\n",
        "   - **Определение задачи:** Автоматическое создание текста на основе входных данных.\n",
        "   - **Пример с использованием Hugging Face:** Модель `gpt2` для генерации текста в стиле писателя.\n"
      ],
      "metadata": {
        "id": "ymYITLomk6wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "prompt = \"Once upon a time\"\n",
        "generated_text = text_generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(generated_text[0]['generated_text'])"
      ],
      "metadata": {
        "id": "GqIRzDPAlYyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "10. **Text2Text Generation**\n",
        "    - **Определение задачи:** Преобразование текста одного типа в другой.\n",
        "    - **Пример с использованием Hugging Face:** Модель `t5-base` для перевода текста в вопрос в соответствующий ответ.\n"
      ],
      "metadata": {
        "id": "7dIpPbwRk8Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text2text_generator = pipeline(\"text2text-generation\")\n",
        "input_text = \"Translate: How are you?\"\n",
        "generated_text = text2text_generator(input_text)\n",
        "print(generated_text[0]['generated_text'])"
      ],
      "metadata": {
        "id": "xVXSQL23la0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "11. **Fill-Mask**\n",
        "    - **Определение задачи:** Заполнение пропущенных частей предложения.\n",
        "    - **Пример с использованием Hugging Face:** Модель `bert-base-multilingual-cased` для автоматического заполнения пропусков в предложениях на различных языках.\n"
      ],
      "metadata": {
        "id": "WDibaNFZk95m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Создание конвейера для заполнения пропусков с моделью BERT\n",
        "fill_mask = pipeline('fill-mask', model='bert-base-multilingual-cased')\n",
        "\n",
        "# Пример предложения с пропуском на английском\n",
        "text_en = \"The [MASK] jumped over the fence.\"\n",
        "print(f\"Предложение на английском: {text_en}\")\n",
        "print(f\"Предсказания для пропуска:\")\n",
        "print(fill_mask(text_en))\n",
        "\n",
        "# Пример предложения с пропуском на русском\n",
        "text_ru = \"Кошка [MASK] на дерево.\"\n",
        "print(f\"\\nПредложение на русском: {text_ru}\")\n",
        "print(f\"Предсказания для пропуска:\")\n",
        "print(fill_mask(text_ru))\n",
        "\n",
        "# Пример предложения с пропуском на французском\n",
        "text_fr = \"Le chat a [MASK] sur l'arbre.\"\n",
        "print(f\"\\nПредложение на французском: {text_fr}\")\n",
        "print(f\"Предсказания для пропуска:\")\n",
        "print(fill_mask(text_fr))"
      ],
      "metadata": {
        "id": "DDD6zYQOlcc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "12. **Sentence Similarity**\n",
        "    - **Определение задачи:** Определение степени семантической близости между двумя предложениями.\n",
        "    - **Пример с использованием Hugging Face:** Модель `sentence-transformers/paraphrase-MiniLM-L6-v2` для определения степени близости между двумя предложениями.\n"
      ],
      "metadata": {
        "id": "WvFVy9fUk_UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "# Загрузка модели\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Определение двух предложений\n",
        "sentence1 = \"Это красивый и яркий закат над морем.\"\n",
        "sentence2 = \"Солнце медленно опускается за горизонт, окрашивая небо в потрясающие оттенки.\"\n",
        "\n",
        "# Получение векторных представлений предложений\n",
        "embeddings1 = model.encode([sentence1])\n",
        "embeddings2 = model.encode([sentence2])\n",
        "\n",
        "# Вычисление косинусного сходства\n",
        "cosine_score = util.cos_sim(embeddings1, embeddings2)[0][0]\n",
        "\n",
        "# Вывод результата\n",
        "print(f\"Степень семантической близости между предложениями: \\[{cosine_score:.4f}\\]\")"
      ],
      "metadata": {
        "id": "Q3cWvq0kleVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопросы для закрепления темы"
      ],
      "metadata": {
        "id": "KYtNDUTlWd-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Что представляет собой платформа Hugging Face и на чем она специализируется?\n",
        "\n",
        "2. Перечислите основные задачи в области NLP, которые можно решать с помощью библиотек Hugging Face.\n",
        "\n",
        "3. Как можно использовать Hugging Face для задачи классификации текстов? Приведите пример.\n",
        "\n",
        "4. Объясните, как реализовать определение эмоциональной окраски текста на русском языке с использованием Hugging Face.\n",
        "\n",
        "5. Опишите, как можно извлекать именованные сущности из текста с помощью библиотек Hugging Face.\n",
        "\n",
        "6. Расскажите о применении Hugging Face для создания вопросно-ответных систем на основе табличных данных.\n",
        "\n",
        "7. Как можно использовать Hugging Face для реализации системы ответов на вопросы, основанных на контексте?\n",
        "\n",
        "8. Объясните, как можно реализовать классификацию текстов по категориям с использованием zero-shot classification в Hugging Face.\n",
        "\n",
        "9. Опишите, как можно создать приложение для перевода текста с русского на английский, используя Hugging Face.\n",
        "\n",
        "10. Расскажите о применении Hugging Face для генерации аннотаций к текстам.\n",
        "\n",
        "11. Как можно извлекать векторные представления слов из текста с помощью Hugging Face?\n",
        "\n",
        "12. Объясните, как можно разработать систему для генерации продолжения текста, используя модели Hugging Face.\n",
        "\n",
        "13. Как можно реализовать приложение для заполнения пропусков в предложениях на разных языках с помощью Hugging Face?\n",
        "\n",
        "14. Опишите, как можно определять сходство между предложениями с использованием Hugging Face.\n",
        "\n",
        "15. Расскажите о применении Hugging Face для классификации текстов на основе их содержания.\n",
        "\n",
        "16. Как можно создать систему для идентификации языка текста с помощью Hugging Face?\n",
        "\n",
        "17. Объясните, как можно реализовать автоматическую генерацию подписей к изображениям, используя Hugging Face.\n",
        "\n",
        "18. Как можно использовать Hugging Face для автоматического суммирования текста?\n",
        "\n",
        "19. Опишите применение Hugging Face для извлечения ключевых фраз из текста.\n",
        "\n",
        "20. Расскажите о реализации анализа настроений в текстах на разных языках с помощью Hugging Face.\n",
        "\n",
        "21. Как можно использовать Hugging Face для определения возраста и пола авторов текстов?\n",
        "\n",
        "22. Объясните, как можно создать приложение для классификации текстов по жанрам, используя Hugging Face.\n",
        "\n",
        "23. Опишите применение Hugging Face для перевода текстов с английского на другие языки.\n",
        "\n",
        "24. Как можно реализовать определение уровня читабельности текста с помощью Hugging Face?\n",
        "\n",
        "25. Расскажите о применении Hugging Face для извлечения сущностей и отношений из текстов.\n",
        "\n",
        "26. Как можно использовать Hugging Face для автоматического исправления грамматических ошибок в текстах?\n",
        "\n",
        "27. Объясните, как можно реализовать определение тональности отзывов на продукты с помощью Hugging Face.\n",
        "\n",
        "28. Опишите применение Hugging Face для классификации текстов по темам.\n",
        "\n",
        "29. Как можно использовать Hugging Face для генерации аннотаций к изображениям?\n",
        "\n",
        "30. Расскажите о реализации перефразирования текстов с сохранением смысла с помощью Hugging Face."
      ],
      "metadata": {
        "id": "Rpl6XexxW-XI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Задачи для самостоятельной работы"
      ],
      "metadata": {
        "id": "iLTEKFfeWeKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Используя модель `distilbert-base-uncased`, реализуйте классификацию твитов как \"позитивные\" или \"негативные\".\n",
        "\n",
        "2. Разработайте систему для определения эмоциональной окраски текста на русском языке, используя модель `cointegrated/rubert-tiny2-cedr-emotion-detection`.\n",
        "\n",
        "3. Напишите скрипт, который извлекает именованные сущности из произвольного текста с помощью модели `bert-base-cased`.\n",
        "\n",
        "4. Создайте вопросно-ответную систему на основе таблицы данных, используя модель `roberta-large`.\n",
        "\n",
        "5. Реализуйте систему для ответа на вопросы, основанную на контексте, используя модель `distilbert-base-uncased-distilled-squad`.\n",
        "\n",
        "6. Разработайте модуль для классификации текстов по категориям с использованием zero-shot classification.\n",
        "\n",
        "7. Создайте приложение для перевода текста с русского на английский, используя модель `facebook/wmt19-ru-en`.\n",
        "\n",
        "8. Напишите скрипт, который генерирует аннотацию на основе произвольного текста, применяя модель `t5-small`.\n",
        "\n",
        "9. Реализуйте модуль для извлечения векторных представлений слов из текста с помощью модели `bert-base-uncased`.\n",
        "\n",
        "10. Разработайте систему для генерации продолжения текста на основе заданного начала, используя модель `gpt2`.\n",
        "\n",
        "11. Создайте приложение для заполнения пропусков в предложениях на русском и английском языках с помощью модели `bert-base-multilingual-cased`.\n",
        "\n",
        "12. Напишите скрипт, который определяет сходство между двумя предложениями, применяя модель `sentence-transformers/paraphrase-MiniLM-L6-v2`.\n",
        "\n",
        "13. Реализуйте функцию для классификации текстов на основе их содержания с использованием модели `distilbert-base-uncased-finetuned-sst-2-english`.\n",
        "\n",
        "14. Создайте систему для идентификации языка текста, применяя модель `distilbert-base-multilingual-cased-language-detection`.\n",
        "\n",
        "15. Разработайте модуль для автоматической генерации подписей к изображениям, используя модель `nlpconnect/vit-gpt2-image-captioning`.\n",
        "\n",
        "16. Напишите скрипт, который суммирует текст, применяя модель `sshleifer/distilbart-cnn-12-6`.\n",
        "\n",
        "17. Реализуйте систему для выявления фактов и утверждений в тексте с помощью модели `roberta-large-openai-detector`.\n",
        "\n",
        "18. Создайте приложение для перефразирования текста, используя модель `tuner007/pegasus_paraphrase`.\n",
        "\n",
        "19. Разработайте модуль для распознавания именованных сущностей в текстах на русском языке с помощью модели `DeepPavlov/rubert-base-ner-conll2003-v1`.\n",
        "\n",
        "20. Напишите скрипт, который определяет политическую окраску текста, применяя модель `bhadresh-savani/distilbert-base-uncased-emotion`.\n",
        "\n",
        "21. Реализуйте систему для извлечения ключевых фраз из текста с помощью модели `wietsedv/bert-base-dutch-cased-finetuned-tpo`.\n",
        "\n",
        "22. Создайте модуль для анализа настроений в текстах на нескольких языках с использованием модели `cardiffnlp/twitter-roberta-base-sentiment-latest`.\n",
        "\n",
        "23. Напишите скрипт, который определяет возраст и пол авторов текстов, применяя модель `nlptown/bert-base-multilingual-uncased-sentiment`.\n",
        "\n",
        "24. Разработайте приложение для классификации текстов по жанрам, используя модель `arpanghoshal/EmoRoBERTa`.\n",
        "\n",
        "25. Реализуйте систему для перевода текстов с английского на испанский, используя модель `Helsinki-NLP/opus-mt-en-es`.\n",
        "\n",
        "26. Создайте модуль для определения уровня читабельности текста, применяя модель `hpcaitech/longformer-base-readability`.\n",
        "\n",
        "27. Напишите скрипт, который извлекает сущности и отношения из текста с помощью модели `nlpaueb/legal-bert-base-uncased`.\n",
        "\n",
        "28. Разработайте приложение для автоматического исправления грамматических ошибок в текстах, используя модель `nreimers/BERT-Small-L-4-H-512-uncased-gram-corrector`.\n",
        "\n",
        "29. Реализуйте систему для определения тональности отзывов на продукты, применяя модель `affinelayer/roberta-base-product-sentiment`.\n",
        "\n",
        "30. Создайте модуль для классификации текстов по темам, используя модель `bhadresh-savani/distilbert-base-uncased-topic`.\n",
        "\n",
        "31. Напишите скрипт, который генерирует аннотации к изображениям на основе их содержимого с помощью модели `nlpconnect/vit-gpt2-image-captioning`.\n",
        "\n",
        "32. Разработайте приложение для перефразирования текстов с сохранением смысла, применяя модель `tuner007/pegasus_paraphrase`.\n",
        "\n",
        "33. Реализуйте систему для определения степени достоверности информации в текстах, используя модель `roberta-large-openai-detector`.\n",
        "\n",
        "34. Создайте модуль для автоматической генерации названий для текстов, применяя модель `miso-better/t5-base-title-generation`.\n",
        "\n",
        "35. Напишите скрипт, который выделяет основные аргументы в текстах, помогая в анализе аргументации, с помощью модели `nreimers/BERT-Small-L-4-H-512-uncased-arg-mining`.\n",
        "\n",
        "36. Разработайте приложение для извлечения ключевых фраз из текстов, используя модель `boudinlab/keybert`.\n",
        "\n",
        "37. Реализуйте систему для определения эмоциональной окраски твитов, применяя модель `cardiffnlp/twitter-roberta-base-emotion`.\n",
        "\n",
        "38. Создайте модуль для автоматической генерации вопросов к текстам, используя модель `vblagoje/bert-for-qa`.\n",
        "\n",
        "39. Напишите скрипт, который определяет стиль письма авторов текстов, применяя модель `nlptown/bert-base-multilingual-uncased-sentiment`.\n",
        "\n",
        "40. Разработайте приложение для определения языка текстов, используя модель `distilbert-base-multilingual-cased-language-detection`."
      ],
      "metadata": {
        "id": "818bhX-RWjQ8"
      }
    }
  ]
}