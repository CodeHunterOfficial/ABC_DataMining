{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN/faXRg03+BSPXBqIfki7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/NLP/NLP-2025/New/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%96%E2%80%AF11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Практическая работа № 11. Стратегии трансферного обучения для задач обработки естественного языка**\n",
        "\n",
        "## **1. Цель и задачи работы**\n",
        "\n",
        "Цель работы — формирование у обучающегося системного представления о конвейере трансферного обучения в задачах NLP, освоение практических навыков проектирования, реализации и сравнительного анализа стратегий адаптации предобученных моделей под целевые задачи с различным объёмом данных и архитектурными требованиями, а также приобретение компетенций в области анализа влияния исходного домена, калибровки предсказаний, устойчивости к лингвистическим возмущениям и обеспечения воспроизводимости результатов в соответствии с современными стандартами открытой науки.\n",
        "\n",
        "**Основные задачи работы:**  \n",
        "1. Использовать корпус текстов, сформированный в рамках Практической работы № 1 и размеченный в Практической работе № 3, в качестве экспериментальной базы.  \n",
        "2. Выполнить адаптацию моделей к трём разнородным задачам:  \n",
        " – **бинарная классификация** (тональность, ≤1 000 примеров),  \n",
        " – **последовательная разметка** (NER: PER, ORG, LOC, ~5 000 токенов),  \n",
        " – **sequence-to-sequence генерация** (абстрактное суммаризирование, ~3 000 пар).  \n",
        "3. Реализовать программные модули для пяти стратегий трансферного обучения:  \n",
        " – *feature extraction* (заморозка энкодера),  \n",
        " – *full fine-tuning* (дообучение всей модели),  \n",
        " – *layer-wise learning rates* (дифференцированное обучение слоёв),  \n",
        " – *adapter-based tuning*,  \n",
        " – *LoRA (Low-Rank Adaptation)*.  \n",
        "4. Провести сравнительный анализ влияния стратегии адаптации, типа предобученной модели (общая, специализированная, мультиязычная) и размера целевого набора на качество, скорость и устойчивость.  \n",
        "5. Освоить практики строгого обучения: мониторинг сходимости, ранняя остановка, регуляризация (dropout, weight decay, label smoothing, mixout), визуализация кривых обучения.  \n",
        "6. Применить методы оценки устойчивости: paraphrasing, back-translation, и калибровки: reliability diagrams, Expected Calibration Error (ECE), isotonic regression.  \n",
        "7. Проанализировать изменения в внутренних представлениях модели: проекции эмбеддингов (UMAP/t-SNE), attention-карты до/после адаптации, linear probing по слоям.  \n",
        "8. Разработать унифицированный и конфигурируемый пайплайн адаптации, поддерживающий смену задачи, модели и стратегии без модификации кода.  \n",
        "9. Обеспечить воспроизводимость и открытость: опубликовать размеченные поднаборы, программный код, все fine-tuned модели и аналитический отчёт, включая развёртывание демо-приложения на Hugging Face Spaces.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Теоретические предпосылки**\n",
        "\n",
        "Трансферное обучение в NLP эволюционировало от статических эмбеддингов к динамическим, контекстуализированным представлениям, предоставляемым трансформерными архитектурами. Современные предобученные модели (BERT, RoBERTa, T5, BART) служат универсальными «языковыми приорами», которые могут быть эффективно адаптированы к специфическим задачам даже при ограниченных данных.\n",
        "\n",
        "В зависимости от стратегии адаптации выделяют три ключевых направления:  \n",
        "1. **Полный трансфер (Full Fine-Tuning):**  \n",
        " – Все параметры модели обновляются;  \n",
        " – Обеспечивает наивысшее качество, но требует значительных вычислительных ресурсов и рискует переобучением на малых данных.  \n",
        "2. **Параметрически эффективная адаптация (Parameter-Efficient Transfer Learning, PEFT):**  \n",
        " – **Adapters**: вставка небольших bottleneck-слоёв между подблоками трансформера;  \n",
        " – **LoRA**: аппроксимация обновлений весов внимания через низкоранговые матрицы;  \n",
        " – Позволяют обучать <1% параметров при сохранении >95% качества full fine-tuning.  \n",
        "3. **Фиксированное извлечение признаков (Feature Extraction):**  \n",
        " – Энкодер заморожен, обучается только голова;  \n",
        " – Быстрый и устойчивый подход для ultra-low-resource сценариев, но менее гибкий.\n",
        "\n",
        "Качество трансфера напрямую зависит от:  \n",
        "– **семантической близости** домена предобучения и целевой задачи,  \n",
        "– **совместимости архитектуры** (encoder-only vs encoder-decoder),  \n",
        "– **баланса между обобщением и специализацией** (регуляризация, learning rate schedule),  \n",
        "– **калибровки вероятностей**, особенно критичной для задач с дисбалансом или safety-critical применения.\n",
        "\n",
        "Анализ внутренних представлений (через probing, attention visualisation, embedding projections) позволяет понять, **что модель сохраняет, а что теряет** при адаптации — ключевой аспект для интерпретируемости и доверия.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Порядок выполнения работы**\n",
        "\n",
        "### **3.1. Формирование размеченного экспериментального корпуса**\n",
        "\n",
        "**Задача:** Подготовить три поднабора на основе данных из Практической работы № 1.  \n",
        "**Требования к выполнению:**  \n",
        "– Источники: ТАСС, РИА Новости, Lenta.ru, Meduza, Коммерсант, belgech.ru;  \n",
        "– Типы задач и разметки:  \n",
        " ✓ **Sentiment-1K**: бинарная тональность («позитив»/«негатив»), ≤1 000 документов;  \n",
        " ✓ **RuNER-5K**: разметка сущностей (PER, ORG, LOC) в формате CoNLL, ≥5 000 токенов;  \n",
        " ✓ **NewsSumm-3K**: пары (заголовок, текст) для абстрактного суммаризирования, ≥3 000 пар;  \n",
        "– Минимальный объём: как указано выше;  \n",
        "– Структура: JSONL с полями `text`, `sentiment`, `ner_tags`, `summary`;  \n",
        "– Разделение: train/validation/test в соотношении 70/15/15 с сохранением стратификации (для классификации и NER) или случайным разбиением (для summarization);  \n",
        "– Гарантия отсутствия пересечений между поднаборами.\n",
        "\n",
        "### **3.2. Формирование признаковых представлений и выбор моделей-доноров**\n",
        "\n",
        "**Задача:** Создать входные представления и выбрать предобученные модели.  \n",
        "**Требования:**  \n",
        "– Модели-доноры:  \n",
        " ✓ `DeepPavlov/rubert-base-cased` (общий русский BERT),  \n",
        " ✓ `sberbank-ai/ruRoberta-large` (усовершенствованная RoBERTa),  \n",
        " ✓ `cointegrated/rubert-tiny2` (компактная модель),  \n",
        " ✓ `microsoft/mdeberta-v3-base` (мультиязычная DeBERTa),  \n",
        " ✓ `IlyaGusev/ruRoBERTa-finance` (специализированная, при наличии),  \n",
        " ✓ `google/mt5-base` (для summarization);  \n",
        "– Для классификации и NER: использование `AutoTokenizer.from_pretrained`;  \n",
        "– Для summarization: encoder-decoder токенизация;  \n",
        "– Формирование тензоров: `input_ids`, `attention_mask`, `labels`;  \n",
        "– Сохранение метаданных о конфигурации токенизатора в JSON.\n",
        "\n",
        "### **3.3. Реализация модуля стратегий трансферного обучения**\n",
        "\n",
        "**Задача:** Разработать конфигурируемый модуль для адаптации моделей.  \n",
        "**Функциональные требования:**  \n",
        "– Поддержка:  \n",
        " ✓ Feature extraction (заморозка backbone),  \n",
        " ✓ Full fine-tuning (с общим и дифференцированным LR),  \n",
        " ✓ Adapter tuning (Houlsby-style),  \n",
        " ✓ LoRA (для attn-проекций),  \n",
        " ✓ Linear probing (для анализа);  \n",
        "– Единый интерфейс `TransferAdaptor`;  \n",
        "– Поддержка задач: классификация, токен-классификация (NER), seq2seq;  \n",
        "– Поддержка GPU через PyTorch + Accelerate;  \n",
        "– Код в модуле `transfer_adaptors.py` с документированием и типизацией.\n",
        "\n",
        "### **3.4. Обучение моделей и стратифицированная оценка**\n",
        "\n",
        "**Задача:** Провести строгое обучение с мониторингом.  \n",
        "**Требования:**  \n",
        "– Использование отдельной валидационной выборки (15%) для early stopping;  \n",
        "– Метрики:  \n",
        " ✓ F1 (macro) — для классификации,  \n",
        " ✓ F1 (entity-level) — для NER,  \n",
        " ✓ ROUGE-L — для summarization;  \n",
        "– Визуализация:  \n",
        " ✓ Графики loss и метрик по эпохам (train/val),  \n",
        " ✓ Learning curves при разных размерах данных,  \n",
        " ✓ Нормы градиентов по слоям (для layer-wise LR);  \n",
        "– Сохранение: конфигураций, весов, логов в JSON и PyTorch.\n",
        "\n",
        "### **3.5. Сравнительный анализ стратегий трансфера**\n",
        "\n",
        "**Задача:** Эмпирически оценить эффективность подходов.  \n",
        "**Метрики:**  \n",
        "– Качество: F1, ROUGE, accuracy;  \n",
        "– Эффективность: время обучения, объём обновляемых параметров, пиковое потребление GPU RAM;  \n",
        "– Устойчивость: дисперсия метрик по случайным сидам.  \n",
        "**Форма представления:** таблица `transfer_comparison.csv`, boxplots, radar-диаграммы «качество–ресурс–скорость».\n",
        "\n",
        "### **3.6. Анализ влияния размера целевого набора**\n",
        "\n",
        "**Задача:** Исследовать зависимость качества от объёма данных.  \n",
        "**Требования:**  \n",
        "– Для каждой задачи: подвыборки размером 100, 300, 1 000, 3 000, 10 000;  \n",
        "– Обучение RuBERT всеми стратегиями на каждой подвыборке;  \n",
        "– Построение **learning curves** с доверительными интервалами;  \n",
        "– Выявление «точек насыщения» — где добавление данных перестаёт давать выигрыш.\n",
        "\n",
        "### **3.7. Оценка устойчивости и калибровки**\n",
        "\n",
        "**Задача:** Обеспечить надёжность и достоверность предсказаний.  \n",
        "**Функциональные требования:**  \n",
        "– **Парфраз-атака**: генерация 3–5 переформулировок через T5-paraphraser, оценка стабильности предсказаний;  \n",
        "– **Калибровка**:  \n",
        " ✓ Построение reliability diagrams,  \n",
        " ✓ Расчёт ECE,  \n",
        " ✓ Применение Platt scaling и isotonic regression;  \n",
        "– Оценка по метрикам: Brier score, NLL.\n",
        "\n",
        "### **3.8. Интерпретация процесса трансфера**\n",
        "\n",
        "**Задача:** Исследовать, как меняются внутренние представления.  \n",
        "**Функциональные требования:**  \n",
        "– **Linear probing**: обучение линейного классификатора на выходах каждого слоя до/после адаптации;  \n",
        "– **Проекции**: UMAP/t-SNE на [CLS]-эмбеддингах и токенных представлениях;  \n",
        "– **Визуализация внимания**: сравнение attention-карт в RuBERT до и после fine-tuning (bertviz);  \n",
        "– Анализ «забывания»: падение качества на исходной задаче предобучения (если применимо).\n",
        "\n",
        "### **3.9. Публикация и развёртывание результатов**\n",
        "\n",
        "**Задача:** Обеспечить открытость и доступность.  \n",
        "**Требования:**  \n",
        "– Публикация кода на GitHub/GitLab под лицензией MIT;  \n",
        "– Публикация поднаборов на Hugging Face Datasets;  \n",
        "– Публикация всех fine-tuned моделей на Hugging Face Hub с **Model Card**, включающим:  \n",
        " ✓ Описание задачи и стратегии,  \n",
        " ✓ Гиперпараметры, метрики, объём данных,  \n",
        " ✓ Пример кода инференса,  \n",
        " ✓ Лицензию и ограничения;  \n",
        "– Развёртывание демо-панели на Hugging Face Spaces (Streamlit/Gradio) с возможностью:  \n",
        " ✓ Выбора задачи, модели и стратегии,  \n",
        " ✓ Ввода текста,  \n",
        " ✓ Отображения предсказания, вероятностей, attention-карты,  \n",
        " ✓ Сравнения нескольких моделей на одном примере.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Дополнительные исследовательские задания**\n",
        "\n",
        "1. **Сравнение PEFT-методов**: Adapters vs LoRA — качество, скорость, потребление памяти.  \n",
        "2. **Влияние домена предобучения**: насколько финансы-модель проигрывает общему RuBERT на общей задаче?  \n",
        "3. **Zero-shot через prompting**: сравните zero-shot (через шаблоны) и few-shot (100 примеров) на тональности.  \n",
        "4. **Экономика трансфера**: измерьте CO₂ и стоимость обучения через CodeCarbon.  \n",
        "5. **Multi-task адаптация**: обучите одну модель на тональности и NER — есть ли положительный перенос?  \n",
        "6. **Калибровка после PEFT**: ухудшается ли калибровка при использовании LoRA?  \n",
        "7. **Перенос между языками**: применим ли mDeBERTa к русскому NER лучше, чем RuBERT?  \n",
        "8. **Анализ слоёв через probing**: какие слои несут синтаксическую, а какие — семантическую информацию после адаптации?\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Требования к отчёту**\n",
        "\n",
        "Отчёт оформляется в соответствии с **ГОСТ 7.32–2017** и должен содержать:  \n",
        "1. **Введение** — постановка задачи, актуальность трансферного обучения, обзор эволюции стратегий (от feature extraction к PEFT);  \n",
        "2. **Методология** — описание пайплайнов, моделей, стратегий, метрик, подходов к калибровке и устойчивости;  \n",
        "3. **Результаты** — таблицы, графики кривых обучения, learning curves, reliability diagrams, UMAP-проекции, attention-карты до/после;  \n",
        "4. **Обсуждение** — интерпретация компромиссов «качество–ресурс–обобщение», анализ «точек разрыва» трансфера, сравнение с классическими методами (Работа № 4);  \n",
        "5. **Заключение** — выводы и рекомендации по выбору стратегии трансфера для low-resource, multilingual и safety-critical сценариев;  \n",
        "6. **Список источников** — по ГОСТ Р 7.0.5–2008;  \n",
        "7. **Приложения** — фрагменты кода, скриншоты демо-панели, примеры разметки, конфигурации адаптации.\n",
        "\n",
        "Отчёт сопровождается ссылками на:  \n",
        "– Репозиторий с кодом;  \n",
        "– Hugging Face Dataset с поднаборами;  \n",
        "– Hugging Face Space с веб-демо;  \n",
        "– Опубликованные fine-tuned модели с Model Card.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Критерии оценивания**\n",
        "\n",
        "| Оценка | Критерии |\n",
        "|--------|---------|\n",
        "| **Отлично** | Реализованы ≥4 стратегии на ≥2 задачах; анализ влияния размера данных и домена предобучения; калибровка и устойчивость; интерпретация через probing и attention; функциональный веб-интерфейс на Hugging Face Spaces; публикация всех моделей с Model Card; отчёт по ГОСТ с глубоким обсуждением компромиссов и рекомендациями. |\n",
        "| **Хорошо** | Реализованы 2–3 стратегии (full tuning, adapters, LoRA); обучение на всех трёх задачах; базовый анализ устойчивости и калибровки; корректный отчёт с визуализациями. |\n",
        "| **Удовлетворительно** | Реализованы feature extraction и full fine-tuning на одной задаче; отчёт содержит описание методов и таблицы метрик. |\n",
        "| **Неудовлетворительно** | Отсутствует сравнение стратегий; нет анализа влияния размера данных или интерпретации; не опубликованы модели или код. |\n"
      ],
      "metadata": {
        "id": "fSetszIWCwXQ"
      }
    }
  ]
}