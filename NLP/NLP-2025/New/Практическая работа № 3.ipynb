{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN0UdfJETP49xTe9aiozhwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/NLP/NLP-2025/New/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%20%E2%84%96%E2%80%AF3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Практическая работа № 3  \n",
        "**Тема.** Классификация текста с помощью классических методов машинного обучения\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Цель и задачи работы\n",
        "\n",
        "**Цель работы** — формирование у обучающегося системного и практического представления о применении классических методов машинного обучения для решения задач текстовой классификации. Работа направлена на развитие навыков проектирования ML-пайплайнов, оценки влияния предварительной обработки и векторизации текста на качество модели, а также на освоение практик интерпретации предсказаний и публикации результатов.\n",
        "\n",
        "**Основные задачи работы:**\n",
        "\n",
        "1. Использовать корпус текстов, сформированный в рамках Практической работы № 1, в качестве экспериментальной базы.  \n",
        "2. Выполнить разметку корпуса для трёх типов задач: **бинарной**, **многоклассовой** и **многометочной классификации**.  \n",
        "3. Реализовать и сравнить классические методы машинного обучения: **логистическую регрессию**, **метод опорных векторов (SVM)**, **градиентный бустинг (CatBoost, XGBoost)**.  \n",
        "4. Провести контролируемый эксперимент, оценивающий влияние:  \n",
        "   - методов токенизации и нормализации (из Практической работы № 1),  \n",
        "   - методов векторизации (из Практической работы № 2),  \n",
        "   - происхождения моделей — **самостоятельно обученных** (BPE, Word2Vec и др.) и **внешних предобученных** (например, FastText от Meta).  \n",
        "5. Применить методы коррекции дисбаланса классов и строгой оценки качества.  \n",
        "6. Проанализировать интерпретируемость моделей с использованием **SHAP** и **LIME**.  \n",
        "7. Разработать интерактивный веб-интерфейс для демонстрации и сравнения работы классификаторов.  \n",
        "8. Обеспечить воспроизводимость результатов через публикацию кода и документацию.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Теоретические предпосылки\n",
        "\n",
        "Классификация текста — фундаментальная задача машинного обучения, лежащая в основе множества прикладных NLP-систем: анализа тональности, тематической категоризации, фильтрации спама, определения жанра и др. Все эти задачи формально сводятся к одной из трёх постановок:\n",
        "\n",
        "1. **Бинарная классификация** — выбор одной из двух меток (например, «позитивный» / «негативный» отзыв).  \n",
        "2. **Многоклассовая классификация** — выбор одной метки из множества (например, «политика», «экономика», «спорт»).  \n",
        "3. **Многометочная классификация** — присвоение документу нескольких меток одновременно.\n",
        "\n",
        "В настоящей работе рассматриваются следующие **классические методы машинного обучения**, работающие с фиксированным признаковым пространством:\n",
        "\n",
        "1. **Линейные модели:**  \n",
        "   - **Логистическая регрессия** — вероятностная модель с L1/L2-регуляризацией;  \n",
        "   - **Метод опорных векторов (SVM)** — мощный инструмент для разреженных признаковых пространств.\n",
        "\n",
        "2. **Ансамблевые методы на основе деревьев:**  \n",
        "   - **Случайный лес (Random Forest)** — устойчивый к шуму и переобучению ансамбль;  \n",
        "   - **Градиентный бустинг (CatBoost, XGBoost, LightGBM)** — высокопроизводительные алгоритмы с автоматической обработкой категориальных и разреженных признаков.\n",
        "\n",
        "Качество этих моделей напрямую зависит от того, **как текст преобразуется в признаковое пространство**. В настоящей работе это пространство формируется на основе:\n",
        "\n",
        "- **Токенизации**, включая подсловные модели (BPE, WordPiece), обученные вами;  \n",
        "- **Векторизации**, включая эмбеддинги (Word2Vec, FastText, GloVe), также обученные вами, а также внешние предобученные модели (например, от Meta или Stanford).\n",
        "\n",
        "Такой подход позволяет оценить, насколько важна **адаптация представления текста к домену** по сравнению с использованием универсальных решений.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Методика и порядок выполнения работы\n",
        "\n",
        "Практическая работа выполняется последовательно по восьми этапам.\n",
        "\n",
        "### 3.1. Этап 1. Подготовка экспериментального корпуса\n",
        "\n",
        "**Задача:** Использовать корпус текстов, созданный в рамках Практической работы № 1, в качестве основы для всех экспериментов.\n",
        "\n",
        "**Требования к корпусу:**\n",
        "\n",
        "- **Источники:**  \n",
        "  Основной — русскоязычные новостные порталы (ТАСС, РИА Новости, Lenta.ru, Meduza, Коммерсант и др.).  \n",
        "  Допускается включение материалов на языках народов Российской Федерации (татарский, башкирский и др.) для лингвистического разнообразия.\n",
        "\n",
        "- **Разметка:**  \n",
        "  - **Бинарная классификация**: тональность (позитив/негатив);  \n",
        "  - **Многоклассовая**: темы (политика, экономика, спорт, культура);  \n",
        "  - **Многометочная**: несколько тем на документ.\n",
        "\n",
        "- **Объём:** не менее 10 000 размеченных документов на тип задачи.  \n",
        "- **Структура документа:** поля `title`, `text`, `sentiment`, `category`, `categories`.  \n",
        "- **Формат:** JSONL (по одному документу на строку).  \n",
        "- **Разделение:** train/validation/test в соотношении 70/15/15 с сохранением стратификации.\n",
        "\n",
        "> **Примечание:** Корпус уже содержит предобработанный текст из Работы № 1, что позволяет сосредоточиться на этапе классификации.\n",
        "\n",
        "### 3.2. Этап 2. Формирование признаковых представлений\n",
        "\n",
        "**Задача:** Создать несколько независимых признаковых пространств на основе различных пайплайнов предобработки.\n",
        "\n",
        "**Варианты пайплайнов:**\n",
        "\n",
        "- **Токенизация:**  \n",
        "  - Наивная (по пробелам);  \n",
        "  - Лемматизация (`pymorphy2`);  \n",
        "  - **Подсловные модели, обученные вами** (BPE, WordPiece — из Работы № 1).\n",
        "\n",
        "- **Векторизация:**  \n",
        "  - **Статистические методы**: TF-IDF с n-граммами (1–3);  \n",
        "  - **Эмбеддинги, обученные вами**: Word2Vec, FastText, GloVe (из Работы № 2);  \n",
        "  - **Внешние предобученные эмбеддинги**: например, `cc.ru.300.vec` от Meta;  \n",
        "  - Базовый пайплайн: `TfidfVectorizer` с параметрами по умолчанию.\n",
        "\n",
        "Для эмбеддингов вектор документа формируется как **усреднение векторов всех токенов**.\n",
        "\n",
        "### 3.3. Этап 3. Реализация классических методов классификации\n",
        "\n",
        "**Задача:** Разработать модуль для классических ML-моделей.\n",
        "\n",
        "**Требования к реализации:**\n",
        "\n",
        "- Поддержка следующих алгоритмов:  \n",
        "  - Логистическая регрессия (`sklearn.linear_model.LogisticRegression`);  \n",
        "  - Линейный SVM (`sklearn.svm.LinearSVC`);  \n",
        "  - CatBoost (`catboost.CatBoostClassifier`);  \n",
        "  - XGBoost (`xgboost.XGBClassifier`).\n",
        "\n",
        "- Код оформляется в виде модуля `classical_classifiers.py`.  \n",
        "- Поддержка автоматической обработки разреженных матриц и плотных эмбеддингов.\n",
        "\n",
        "### 3.4. Этап 4. Сравнительный анализ методов классификации\n",
        "\n",
        "**Задача:** Провести эмпирическое сравнение эффективности моделей и пайплайнов.\n",
        "\n",
        "**Метрики оценки:**\n",
        "\n",
        "- **Бинарная классификация**: Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC;  \n",
        "- **Многоклассовая**: macro/micro F1, Accuracy, Confusion Matrix;  \n",
        "- **Многометочная**: Subset Accuracy, Hamming Loss, macro/micro F1.\n",
        "\n",
        "**Форма представления результатов:**  \n",
        "Сводная таблица `classification_metrics.csv` с разбивкой по типу задачи, пайплайну и модели. Дополнительно — графики ROC и Precision-Recall кривых.\n",
        "\n",
        "### 3.5. Этап 5. Борьба с дисбалансом классов\n",
        "\n",
        "**Задача:** Обеспечить корректное обучение при неравномерном распределении меток.\n",
        "\n",
        "**Методы:**\n",
        "\n",
        "- Взвешивание классов (`class_weight='balanced'`);  \n",
        "- При необходимости — синтетическая аугментация в пространстве эмбеддингов (SMOTE);  \n",
        "- Использование метрик, устойчивых к дисбалансу (PR-AUC, F1).\n",
        "\n",
        "### 3.6. Этап 6. Интерпретация и анализ предсказаний\n",
        "\n",
        "**Задача:** Проанализировать, почему модель делает то или иное предсказание.\n",
        "\n",
        "**Методы:**\n",
        "\n",
        "- Для линейных моделей — анализ весов признаков (наиболее важные слова);  \n",
        "- Для всех моделей — применение **SHAP** и **LIME** для локального объяснения;  \n",
        "- Визуализация вклада отдельных токенов в итоговое предсказание;  \n",
        "- Анализ ошибок: выборка наиболее частых ошибок и их лингвистический разбор.\n",
        "\n",
        "### 3.7. Этап 7. Разработка веб-интерфейса для анализа классификаторов\n",
        "\n",
        "**Задача:** Создать интерактивный инструмент для демонстрации работы моделей.\n",
        "\n",
        "**Функционал:**\n",
        "\n",
        "- Ввод произвольного текста;  \n",
        "- Выбор типа задачи (бинарная/многоклассовая/многометочная);  \n",
        "- Выбор пайплайна (токенизация + векторизация) и модели;  \n",
        "- Отображение предсказания с вероятностями и объяснением (SHAP/LIME);  \n",
        "- Сравнение предсказаний нескольких моделей на одном тексте.\n",
        "\n",
        "**Рекомендуемые технологии:**  \n",
        "`Streamlit`, `Gradio`, или `Flask`/`FastAPI` + `Plotly`.\n",
        "\n",
        "### 3.8. Этап 8. Публикация результатов\n",
        "\n",
        "**Задача:** Обеспечить открытость и воспроизводимость.\n",
        "\n",
        "**Требования:**\n",
        "\n",
        "- Публикация кода на GitHub/GitLab с понятной документацией;  \n",
        "- Размещение веб-приложения (например, через Hugging Face Spaces или Streamlit Cloud);  \n",
        "- Для каждой модели — описание в формате **Model Card**, включающее:  \n",
        "  - тип задачи;  \n",
        "  - пайплайн предобработки;  \n",
        "  - метрики качества;  \n",
        "  - пример использования;  \n",
        "  - лицензию (рекомендуется MIT).\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Дополнительные исследовательские задания\n",
        "\n",
        "1. **Сравнение «самообученных» и «внешних» моделей:**  \n",
        "   Оцените, насколько модели, обученные на вашем корпусе, превосходят внешние внешние предобученные эмбеддинги, опубликованные исследовательскими организациями и сообществами, такими как Meta (FAIR), Stanford NLP Group, DeepPavlov и т.п.\n",
        "\n",
        "2. **Влияние подсловной токенизации:**  \n",
        "   Исследуйте, улучшает ли использование BPE/WordPiece (обученных вами) качество классификации по сравнению с лемматизацией.\n",
        "\n",
        "3. **Интерпретация как лингвистический инструмент:**  \n",
        "   Используйте веса логистической регрессии для выявления лексических маркеров тональности в русскоязычных новостях.\n",
        "\n",
        "4. **Анализ устойчивости к шуму:**  \n",
        "   Исследуйте, как опечатки и искажения текста влияют на предсказания разных моделей.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Требования к отчёту\n",
        "\n",
        "Отчёт оформляется в соответствии с **ГОСТ 7.32–2017** и должен включать:\n",
        "\n",
        "1. Титульный лист (ФИО, учебная группа, дата, подпись преподавателя);  \n",
        "2. Постановку задачи и цели;  \n",
        "3. Описание методов и инструментов;  \n",
        "4. Структуру и характеристики размеченного корпуса;  \n",
        "5. Результаты экспериментов (таблицы, графики, визуализации);  \n",
        "6. Сравнительный анализ классических методов машинного обучения и пайплайнов предобработки;  \n",
        "7. Результаты интерпретации моделей (SHAP, LIME, анализ весов);  \n",
        "8. Ссылки на:  \n",
        "   - Исходный код (GitHub/GitLab);  \n",
        "   - Веб-приложение;  \n",
        "9. Выводы и рефлексию (какие комбинации «токенизация → векторизация → модель» оказались наиболее эффективными для русского языка; стоит ли обучать свои модели или использовать внешние).\n",
        "\n",
        "Список использованных источников оформляется в соответствии с **ГОСТ Р 7.0.5–2008**.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Критерии оценивания\n",
        "\n",
        "| Оценка | Критерии |\n",
        "|--------|----------|\n",
        "| **Отлично (5)** | Полное выполнение всех этапов, включая дополнительные задания. Чётко продемонстрировано сравнение «самообученных» и «внешних» моделей. Наличие функционального веб-интерфейса с возможностью интерпретации. Глубокий анализ результатов. Отчёт соответствует ГОСТ. |\n",
        "| **Хорошо (4)** | Выполнение всех основных этапов (1–8). Наличие веб-интерфейса и отчёта с визуализациями. Корректный сравнительный анализ пайплайнов и моделей. |\n",
        "| **Удовлетворительно (3)** | Выполнение этапов 1–6. Отчёт содержит описание методов, таблицы метрик и базовые выводы. |\n",
        "| **Неудовлетворительно (2)** | Отсутствие ключевых этапов (например, разметки, сравнения источников моделей) или отсутствие отчёта. |\n"
      ],
      "metadata": {
        "id": "FbZnOLyiVEzw"
      }
    }
  ]
}