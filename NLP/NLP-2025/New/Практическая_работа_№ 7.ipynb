{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPIv/Ml0KNnQLP5vulrbTAs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/NLP/NLP-2025/New/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%96%E2%80%AF7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Практическая работа № 7  \n",
        "**Тема.** Использование платформы Hugging Face для комплексного анализа и генерации текста\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Цель и задачи работы\n",
        "\n",
        "Платформа **Hugging Face** за последние годы превратилась из репозитория моделей в **полноценную экосистему для всего цикла работы с NLP**: от поиска и запуска предобученных моделей до их дообучения, оценки, развёртывания и публикации. Её центральные компоненты — **Model Hub**, **Datasets Hub**, **Spaces**, **Inference API** и **библиотеки (`transformers`, `datasets`, `evaluate`)** — позволяют решать практически любую задачу обработки естественного языка «из коробки».\n",
        "\n",
        "**Цель настоящей работы** — сформировать у обучающегося **системное и практическое представление** о возможностях Hugging Face как **единая интегрированная платформа для NLP**. Особое внимание уделяется не просто запуску моделей, а **осознанному выбору архитектуры под задачу**, **интерпретации результатов**, **сравнению моделей** и **демонстрации решений через веб-интерфейсы**.\n",
        "\n",
        "**Основные задачи работы:**\n",
        "\n",
        "1. Освоить **ключевые компоненты экосистемы Hugging Face**: `transformers`, `datasets`, `evaluate`, `gradio`, Spaces.  \n",
        "2. Реализовать и протестировать **все основные типы NLP-задач**, поддерживаемых платформой:  \n",
        "   - **Text Classification** (классификация текста),  \n",
        "   - **Token Classification** (NER, морфологическая разметка),  \n",
        "   - **Question Answering** (QA по контексту и табличный QA),  \n",
        "   - **Zero-Shot Classification** (классификация без обучения),  \n",
        "   - **Translation** (перевод),  \n",
        "   - **Summarization** (автоматическое реферирование),  \n",
        "   - **Feature Extraction** (получение эмбеддингов),  \n",
        "   - **Text Generation** (генерация текста),  \n",
        "   - **Fill-Mask** (восстановление пропущенных слов),  \n",
        "   - **Sentence Similarity** (семантическое сходство),  \n",
        "   - **Text Ranking** (ранжирование документов по релевантности).  \n",
        "3. Использовать **единый корпус текстов** (из Практической работы № 1) как основу для всех экспериментов.  \n",
        "4. Провести **сравнительный анализ качества** различных моделей внутри одной задачи (например, RuBERT vs ruRoBERTa для NER).  \n",
        "5. Применить **методы оценки**, встроенные в библиотеку `evaluate` (ROUGE, BLEU, F1, accuracy и др.).  \n",
        "6. Проанализировать **вычислительные затраты и скорость** различных моделей на CPU/GPU.  \n",
        "7. Разработать **единый веб-интерфейс на Gradio**, демонстрирующий все реализованные задачи.  \n",
        "8. Опубликовать интерфейс на **Hugging Face Spaces** и обеспечить воспроизводимость через `requirements.txt` и `app.py`.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Теоретические предпосылки\n",
        "\n",
        "### 2.1. Архитектура экосистемы Hugging Face\n",
        "\n",
        "Экосистема Hugging Face строится на трёх китах:\n",
        "\n",
        "- **Model Hub** — централизованный репозиторий миллионов моделей, снабжённых Model Card, лицензией и примерами использования.  \n",
        "- **Datasets Hub** — коллекция корпусов и датасетов, доступных одной строкой кода.  \n",
        "- **Spaces** — платформа для развёртывания веб-приложений (на Gradio, Streamlit) поверх моделей.\n",
        "\n",
        "Центральная библиотека — **`transformers`** — предоставляет **единый API** для всех типов задач через класс `pipeline`. Например:\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\", model=\"DeepPavlov/rubert-base-cased\")\n",
        "```\n",
        "\n",
        "Это позволяет решать сложные NLP-задачи **без написания низкоуровневого кода**.\n",
        "\n",
        "### 2.2. Типы задач и их особенности\n",
        "\n",
        "| Тип задачи | Описание | Пример модели |\n",
        "|-----------|--------|--------------|\n",
        "| **Text Classification** | Отнесение текста к категории | `cointegrated/rubert-tiny2` |\n",
        "| **Token Classification** | Разметка каждого токена (NER, POS) | `DeepPavlov/rubert-base-cased-ner` |\n",
        "| **Question Answering** | Извлечение ответа из контекста | `deepset/roberta-base-squad2` |\n",
        "| **Table QA** | Ответ на вопрос по таблице | `google/tapas-base-finetuned-wtq` |\n",
        "| **Zero-Shot Classification** | Классификация по произвольным меткам | `facebook/bart-large-mnli` |\n",
        "| **Translation** | Перевод между языками | `Helsinki-NLP/opus-mt-ru-en` |\n",
        "| **Summarization** | Сокращение текста | `IlyaGusev/rut5_base_sum_gen` |\n",
        "| **Feature Extraction** | Получение эмбеддингов | `intfloat/multilingual-e5-large` |\n",
        "| **Text Generation** | Генерация продолжения | `meta-llama/Meta-Llama-3-8B-Instruct` |\n",
        "| **Fill-Mask** | Восстановление [MASK] | `DeepPavlov/rubert-base-cased` |\n",
        "| **Sentence Similarity** | Сравнение двух предложений | `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` |\n",
        "| **Text Ranking** | Ранжирование документов по запросу | `intfloat/multilingual-e5-large` |\n",
        "\n",
        "### 2.3. Преимущества единой платформы\n",
        "\n",
        "- **Воспроизводимость**: любую модель можно загрузить по имени.  \n",
        "- **Скорость прототипирования**: запуск задачи — 3–5 строк кода.  \n",
        "- **Открытость**: большинство моделей — open-weight, с лицензией.  \n",
        "- **Интеграция**: лёгкое сочетание задач (например, NER → Summarization).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Методика и порядок выполнения работы\n",
        "\n",
        "### 3.1. Этап 1. Подготовка экспериментального корпуса\n",
        "\n",
        "- Используется корпус из Практической работы № 1 (новости, ≥10 000 документов).  \n",
        "- Для задач, требующих структуры (Table QA), создаётся **искусственный датасет** из таблиц (например, «Результаты спортивных соревнований»).  \n",
        "- Для Zero-Shot и Translation — подготавливаются тексты на русском и (опционально) татарском.\n",
        "\n",
        "### 3.2. Этап 2. Реализация задач через `pipeline`\n",
        "\n",
        "Для каждой задачи создаётся отдельный скрипт или функция:\n",
        "\n",
        "```python\n",
        "# Пример для NER\n",
        "ner = pipeline(\"ner\", model=\"DeepPavlov/rubert-base-cased-ner\", tokenizer=\"DeepPavlov/rubert-base-cased-ner\")\n",
        "result = ner(\"Президент России Владимир Путин выступил в Москве.\")\n",
        "```\n",
        "\n",
        "**Требования**:  \n",
        "- Использовать **актуальные русскоязычные модели** из Model Hub;  \n",
        "- Для каждой задачи — **минимум две модели** для сравнения.\n",
        "\n",
        "### 3.3. Этап 3. Оценка качества\n",
        "\n",
        "- Использовать библиотеку `evaluate` для расчёта метрик:  \n",
        "  - F1 для NER и Classification,  \n",
        "  - ROUGE для Summarization,  \n",
        "  - BLEU для Translation,  \n",
        "  - Accuracy для QA.  \n",
        "- Для задач без эталона (Zero-Shot, Generation) — **качественный анализ** (примеры, частота галлюцинаций).\n",
        "\n",
        "### 3.4. Этап 4. Анализ производительности\n",
        "\n",
        "- Измерить время инференса на CPU и GPU для каждой модели;  \n",
        "- Сравнить объём памяти;  \n",
        "- Сделать выводы о **компромиссе «качество–скорость»**.\n",
        "\n",
        "### 3.5. Этап 5. Сравнительный анализ\n",
        "\n",
        "- Построить сводную таблицу:  \n",
        "  `Задача | Модель | Качество | Скорость | Ресурсы`  \n",
        "- Выявить **лидера по каждой задаче** для русского языка.\n",
        "\n",
        "### 3.6. Этап 6. Интерпретация результатов\n",
        "\n",
        "- Для NER — визуализация сущностей;  \n",
        "- Для QA — выделение ответа в контексте;  \n",
        "- Для Zero-Shot — анализ confidence scores.\n",
        "\n",
        "### 3.7. Этап 7. Разработка веб-интерфейса\n",
        "\n",
        "Создаётся единый интерфейс на **Gradio** с вкладками:\n",
        "\n",
        "- **Классификация текста** (выбор модели, меток);  \n",
        "- **Извлечение сущностей** (NER);  \n",
        "- **Ответ на вопрос** (ввод контекста и вопроса);  \n",
        "- **Перевод** (выбор направления);  \n",
        "- **Реферирование**;  \n",
        "- **Zero-Shot классификация**;  \n",
        "- **Сравнение предложений** (Sentence Similarity).\n",
        "\n",
        "### 3.8. Этап 8. Публикация на Hugging Face Spaces\n",
        "\n",
        "- Создание репозитория на Hugging Face;  \n",
        "- Загрузка `app.py`, `requirements.txt`;  \n",
        "- Настройка Space с GPU (если требуется);  \n",
        "- Тестирование и публикация ссылки.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Дополнительные исследовательские задания\n",
        "\n",
        "1. **Многоязычность**: протестировать модели на татарско-русских текстах.  \n",
        "2. **Комбинация задач**: например, NER → Summarization (реферат с выделением имён).  \n",
        "3. **Оптимизация для CPU**: использовать distilled-модели (DistilBERT, rubert-tiny).  \n",
        "4. **Сравнение с API**: сопоставить локальный инференс с Hugging Face Inference API по скорости и стоимости.  \n",
        "5. **Автоматическая аннотация**: использовать NER и Classification для разметки вашего корпуса.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Требования к отчёту\n",
        "\n",
        "Отчёт по **ГОСТ 7.32–2017** должен включать:\n",
        "\n",
        "1. Введение с обоснованием роли Hugging Face в современном NLP;  \n",
        "2. Описание всех 11 типов задач и выбранных моделей;  \n",
        "3. Результаты оценки и сравнительной таблицы;  \n",
        "4. Анализ компромисса «качество–скорость»;  \n",
        "5. Скриншоты веб-интерфейса и примеры работы;  \n",
        "6. Ссылку на **Hugging Face Space**;  \n",
        "7. Выводы: какие модели наиболее эффективны для русского языка по каждой задаче?\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Критерии оценивания\n",
        "\n",
        "| Оценка | Критерии |\n",
        "|--------|----------|\n",
        "| **Отлично (5)** | Реализованы все 11 задач, есть сравнение моделей, оценка, веб-интерфейс на Spaces, анализ качества и скорости. |\n",
        "| **Хорошо (4)** | Реализовано ≥8 задач, есть интерфейс и базовый анализ. |\n",
        "| **Удовлетворительно (3)** | Реализовано ≥5 задач, есть примеры и интерфейс. |\n",
        "| **Неудовлетворительно (2)** | Отсутствует системная реализация или публикация. |\n"
      ],
      "metadata": {
        "id": "GXX40F8Jh9kX"
      }
    }
  ]
}