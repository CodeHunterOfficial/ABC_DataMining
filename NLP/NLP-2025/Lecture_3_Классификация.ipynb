{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN/2D07szoqJJirhtmO3RRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/NLP/NLP-2025/Lecture_3_%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Раздел  1. Бинарная классификация: теоретические основы и практическая реализация\n",
        "\n",
        "## I. Введение в Бинарную Классификацию:  \n",
        "\n",
        "## 1.1. Постановка задачи бинарной классификации\n",
        "\n",
        "Бинарная классификация представляет собой фундаментальную задачу машинного обучения, заключающуюся в отнесении наблюдений к одному из двух возможных классов. Формально, задача ставится следующим образом: дано множество объектов $X \\subseteq \\mathbb{R}^n$ и множество меток $Y = \\{0, 1\\}$, требуется построить функцию $f: X \\rightarrow Y$, минимизирующую заданную функцию потерь на тестовом множестве.\n",
        "\n",
        "Практическая значимость бинарной классификации обусловлена широким спектром приложений в различных областях:\n",
        "\n",
        "- В банковской сфере: принятие решений по кредитным заявкам (одобрение/отклонение);\n",
        "- В медицинской диагностике: выявление заболеваний (наличие/отсутствие патологии);\n",
        "- В системах обработки электронной почты: фильтрация спама (спам/не спам);\n",
        "- В анализе клиентских отзывов: оценка удовлетворенности (положительный/отрицательный отзыв).\n",
        "\n",
        "Универсальность данной задачи, в сочетании с относительной простотой интерпретации результатов, делает бинарную классификацию естественной отправной точкой для изучения методов машинного обучения, особенно в контексте обработки естественного языка (Natural Language Processing, NLP).\n",
        "\n",
        "В рамках настоящего курса мы начнем с рассмотрения практической задачи — анализа тональности текстов (sentiment analysis), представляющей собой классификацию текстовых отзывов на положительные и отрицательные.\n",
        "\n",
        "---\n",
        "\n",
        "## 1.2. Практическая реализация: анализ тональности на русском языке\n",
        "\n",
        "### 1.2.1. Обучающий датасет\n",
        "\n",
        "Для демонстрации принципов обработки текстовых данных рассмотрим учебный датасет, представленный в таблице 1.1.\n",
        "\n",
        "**Таблица 1.1**  \n",
        "Учебный датасет для анализа тональности\n",
        "\n",
        "| Текст                                                                 | Метка |\n",
        "|----------------------------------------------------------------------|-------|\n",
        "| Отличный фильм! Восхитительная игра актёров и захватывающий сюжет.   | 1     |\n",
        "| Ужасный сервис. Потерял деньги и время, больше не обращусь.           | 0     |\n",
        "| Очень вкусно и быстро! Обязательно закажу снова.                     | 1     |\n",
        "| Заказ не привезли, связь с поддержкой отсутствует.                   | 0     |\n",
        "| Чисто, уютно, персонал вежливый — всё на высшем уровне.              | 1     |\n",
        "| Товар пришёл сломанным, возврат невозможен.                          | 0     |\n",
        "\n",
        "Метка `1` соответствует положительному отзыву, метка `0` — отрицательному. Данный датасет, несмотря на небольшой размер, демонстрирует ключевые аспекты обработки текстов для задач классификации.\n",
        "\n",
        "### 1.2.2. Пошаговая реализация без использования Pipeline\n",
        "\n",
        "Для глубокого понимания процесса обработки текстовых данных рассмотрим реализацию классификации без применения высокоуровневых инструментов. Код 1.1 демонстрирует последовательное выполнение всех этапов предобработки и обучения модели.\n",
        "\n",
        "**Код 1.1**  \n",
        "Пошаговая реализация бинарной классификации без Pipeline\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# Обучающая выборка\n",
        "texts = [\n",
        "    \"Отличный фильм! Восхитительная игра актёров и захватывающий сюжет.\",\n",
        "    \"Ужасный сервис. Потерял деньги и время, больше не обращусь.\",\n",
        "    \"Очень вкусно и быстро! Обязательно закажу снова.\",\n",
        "    \"Заказ не привезли, связь с поддержкой отсутствует.\",\n",
        "    \"Чисто, уютно, персонал вежливый — всё на высшем уровне.\",\n",
        "    \"Товар пришёл сломанным, возврат невозможен.\"\n",
        "]\n",
        "labels = np.array([1, 0, 1, 0, 1, 0])\n",
        "\n",
        "# Шаг 1: Векторизация текстов с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=50)\n",
        "X_train_tfidf = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Шаг 2: Обучение классификатора\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train_tfidf, labels)\n",
        "\n",
        "# Шаг 3: Предобработка нового текста\n",
        "new_text = [\"Всё отлично, рекомендую!\"]\n",
        "X_new_tfidf = vectorizer.transform(new_text)\n",
        "\n",
        "# Шаг 4: Предсказание метки\n",
        "prediction = classifier.predict(X_new_tfidf)\n",
        "print(\"Предсказание (пошагово):\", prediction[0])\n",
        "```\n",
        "\n",
        "**Пояснение ключевых параметров:**\n",
        "\n",
        "Параметр `max_features=50` в классе `TfidfVectorizer` определяет максимальное количество признаков (терминов), которые будут использоваться для представления текстовых данных. Данный параметр решает следующие задачи:\n",
        "1. Ограничение размерности признакового пространства для снижения вычислительной сложности;\n",
        "2. Исключение редких и малоинформативных терминов, которые могут вносить шум в модель;\n",
        "3. Предотвращение переобучения при малом объеме обучающих данных.\n",
        "\n",
        "Подбор оптимального значения `max_features` осуществляется следующим образом:\n",
        "- Для учебных примеров и небольших датасетов рекомендуется использовать значения в диапазоне 10-100;\n",
        "- Для реальных задач с большим объемом данных оптимальное значение определяется методом кросс-валидации при фиксированных других гиперпараметрах модели;\n",
        "- В качестве начального приближения может использоваться правило: $max\\_features = \\min(1000, 0.1 \\times N_{terms})$, где $N_{terms}$ — общее количество уникальных терминов в корпусе.\n",
        "\n",
        "**Критически важное замечание:** при обработке новых данных необходимо использовать метод `transform()`, а не `fit_transform()`, поскольку последний приведет к перестроению словаря терминов и несовместимости признакового пространства с обучающей выборкой. Данная ошибка является типичной для начинающих специалистов и приводит к некорректной работе модели.\n",
        "\n",
        "### 1.2.3. Реализация с использованием Pipeline\n",
        "\n",
        "Для обеспечения воспроизводимости и исключения операционных ошибок рекомендуется использовать класс `Pipeline` из библиотеки scikit-learn. Код 1.2 демонстрирует реализацию с применением данного подхода.\n",
        "\n",
        "**Код 1.2**  \n",
        "Реализация бинарной классификации с использованием Pipeline\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Создание пайплайна обработки данных и обучения модели\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=50)),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Обучение модели\n",
        "pipeline.fit(texts, labels)\n",
        "\n",
        "# Предсказание для нового текста\n",
        "new = [\"Всё отлично, рекомендую!\"]\n",
        "print(\"Предсказание (через Pipeline):\", pipeline.predict(new)[0])\n",
        "```\n",
        "\n",
        "**Структура Pipeline:**\n",
        "- Элемент `('tfidf', TfidfVectorizer(max_features=50))` определяет первый этап обработки — векторизацию текстов с ограничением количества признаков;\n",
        "- Элемент `('clf', LogisticRegression())` задает второй этап — обучение классификатора. Идентификатор `'clf'` (сокращение от \"classifier\") является произвольной строкой, служащей для внутренней идентификации компонента в пайплайне и доступа к его параметрам.\n",
        "\n",
        "Преимущества использования `Pipeline`:\n",
        "1. Автоматическое применение одинаковых преобразований к обучающим и тестовым данным;\n",
        "2. Исключение ошибок, связанных с несогласованностью признаковых пространств;\n",
        "3. Упрощение процесса кросс-валидации и подбора гиперпараметров;\n",
        "4. Повышение воспроизводимости результатов.\n",
        "\n",
        "Данный подход соответствует стандартной парадигме обработки текстовых данных в NLP: последовательное преобразование \"текст → числовые признаки → предсказание класса\". Даже на ограниченном датасете модель способна выявлять значимые закономерности: термины \"отличный\", \"восхитительная\", \"вкусно\" коррелируют с положительными отзывами, в то время как \"ужасный\", \"сломанным\", \"не привезли\" — с отрицательными.\n",
        "\n",
        "---\n",
        "\n",
        "## 1.3. Теоретические основы бинарной классификации\n",
        "\n",
        "### 1.3.1. Математическая модель логистической регрессии\n",
        "\n",
        "Несмотря на название, логистическая регрессия является методом бинарной классификации, а не регрессионного анализа. Модель предсказывает вероятность принадлежности объекта к положительному классу, а не сам класс напрямую.\n",
        "\n",
        "**Математическая формулировка:**\n",
        "\n",
        "Пусть задан объект $\\mathbf{x} \\in \\mathbb{R}^d$, где $d$ — размерность признакового пространства. Линейная комбинация признаков определяется как:\n",
        "$$\n",
        "z = \\mathbf{w}^T \\mathbf{x} + b\n",
        "$$\n",
        "где $\\mathbf{w} \\in \\mathbb{R}^d$ — вектор весов, $b \\in \\mathbb{R}$ — смещение.\n",
        "\n",
        "Прямое использование данной линейной функции для классификации невозможно, поскольку её значения не ограничены интервалом $[0, 1]$, необходимым для интерпретации в качестве вероятности. Для решения этой проблемы применяется сигмоидальная (логистическая) функция:\n",
        "$$\n",
        "P(y=1|\\mathbf{x}) = \\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{1}{1 + e^{-(\\mathbf{w}^T \\mathbf{x} + b)}}\n",
        "$$\n",
        "\n",
        "Свойства сигмоидальной функции:\n",
        "- $\\lim_{z \\to -\\infty} \\sigma(z) = 0$\n",
        "- $\\sigma(0) = 0.5$\n",
        "- $\\lim_{z \\to +\\infty} \\sigma(z) = 1$\n",
        "- Функция дифференцируема на всей области определения\n",
        "\n",
        "Таким образом, логистическая регрессия сохраняет линейную структуру по параметрам, но применяется к логарифму шансов (log-odds):\n",
        "$$\n",
        "\\log\\left(\\frac{P(y=1|\\mathbf{x})}{1-P(y=1|\\mathbf{x})}\\right) = \\mathbf{w}^T \\mathbf{x} + b\n",
        "$$\n",
        "\n",
        "**Код 1.3**  \n",
        "Реализация сигмоидальной функции на Python\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"Вычисление сигмоидальной функции\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Проверка свойств функции\n",
        "z_values = np.array([-5.0, 0.0, 5.0])\n",
        "probabilities = sigmoid(z_values)\n",
        "\n",
        "print(f\"Входные значения Z (Log-Odds): {z_values}\")\n",
        "print(f\"Выходные вероятности P: {probabilities}\")\n",
        "# Результат: [0.0067 0.5000 0.9933]\n",
        "```\n",
        "\n",
        "### 1.3.2. Функция потерь и обучение модели\n",
        "\n",
        "Процесс обучения логистической регрессии заключается в нахождении оптимальных значений параметров $\\mathbf{w}$ и $b$, минимизирующих функцию потерь на обучающей выборке.\n",
        "\n",
        "**Некорректность использования MSE:**\n",
        "Среднеквадратичная ошибка (Mean Squared Error, MSE) не подходит для обучения логистической регрессии, поскольку композиция MSE с сигмоидальной функцией создает невыпуклую функцию потерь с множеством локальных минимумов, что затрудняет нахождение глобального оптимума.\n",
        "\n",
        "**Бинарная кросс-энтропия (Log Loss):**\n",
        "Для обучения логистической регрессии используется функция потерь бинарной кросс-энтропии:\n",
        "$$\n",
        "\\mathcal{L}(\\mathbf{w}, b) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
        "$$\n",
        "где:\n",
        "- $y_i \\in \\{0, 1\\}$ — истинная метка $i$-го объекта,\n",
        "- $p_i = P(y_i=1|\\mathbf{x}_i)$ — предсказанная вероятность,\n",
        "- $N$ — размер обучающей выборки.\n",
        "\n",
        "Свойства функции бинарной кросс-энтропии:\n",
        "1. Строгая выпуклость относительно параметров модели, гарантирующая единственность глобального минимума;\n",
        "2. Линейное штрафование за ошибки при низкой уверенности и экспоненциальное — при высокой уверенности в неверном предсказании;\n",
        "3. Эквивалентность максимизации логарифма функции правдоподобия в статистической интерпретации.\n",
        "\n",
        "Минимизация данной функции потерь осуществляется с использованием методов градиентного спуска или его модификаций (L-BFGS, SGD), встроенных в реализацию `LogisticRegression` из scikit-learn.\n",
        "\n",
        "---\n",
        "\n",
        "## 1.4. Генерация синтетических данных для визуализации\n",
        "\n",
        "Для интуитивного понимания работы алгоритмов классификации полезно рассмотреть двумерные данные, допускающие визуализацию. Это позволяет непосредственно наблюдать геометрические свойства разделяющих поверхностей.\n",
        "\n",
        "### 1.4.1. Генерация синтетического датасета\n",
        "\n",
        "Код 1.4 демонстрирует генерацию синтетического датасета с контролируемыми свойствами.\n",
        "\n",
        "**Код 1.4**  \n",
        "Генерация синтетического датасета для визуализации\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Генерация данных\n",
        "X, y = make_classification(\n",
        "    n_samples=500,          # Общее количество объектов\n",
        "    n_features=2,           # Общее количество признаков\n",
        "    n_informative=2,        # Количество информативных признаков\n",
        "    n_redundant=0,          # Количество избыточных признаков\n",
        "    n_clusters_per_class=1, # Количество кластеров на класс\n",
        "    weights=[0.9, 0.1],     # Пропорции классов (90% класс 0, 10% класс 1)\n",
        "    random_state=42         # Фиксация случайного состояния для воспроизводимости\n",
        ")\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,          # 30% данных для тестирования\n",
        "    random_state=42,        # Фиксация случайного состояния\n",
        "    stratify=y              # Сохранение пропорций классов в выборках\n",
        ")\n",
        "\n",
        "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
        "print(f\"Распределение классов в y_train: {np.bincount(y_train)}\")\n",
        "```\n",
        "\n",
        "**Пояснение параметров функции `make_classification`:**\n",
        "- `n_samples`: общее количество генерируемых объектов;\n",
        "- `n_features`: размерность признакового пространства;\n",
        "- `n_informative`: количество признаков, которые действительно влияют на классовую принадлежность;\n",
        "- `n_redundant`: количество признаков, являющихся линейными комбинациями информативных признаков;\n",
        "- `n_clusters_per_class`: количество кластеров для каждого класса, что позволяет моделировать сложные распределения классов;\n",
        "- `weights`: список пропорций для каждого класса, позволяющий моделировать дисбаланс классов;\n",
        "- `random_state`: параметр для воспроизводимости результатов, фиксирующий случайное состояние генератора.\n",
        "\n",
        "Параметр `stratify=y` в функции `train_test_split` обеспечивает сохранение исходных пропорций классов в обучающей и тестовой выборках. Это критически важно при наличии дисбаланса классов, поскольку гарантирует представительство редкого класса в обеих выборках.\n",
        "\n",
        "### 1.4.2. Проблема дисбаланса классов\n",
        "\n",
        "Дисбаланс классов представляет собой ситуацию, когда распределение меток в обучающей выборке существенно неравномерно. В рассмотренном примере 90% объектов принадлежат классу 0, а 10% — классу 1.\n",
        "\n",
        "Основные проблемы, возникающие при дисбалансе классов:\n",
        "1. **Смещенность метрики accuracy:** модель, всегда предсказывающая доминирующий класс, достигает accuracy = 90%, что создает иллюзию хорошего качества при полной бесполезности для задачи обнаружения редкого класса;\n",
        "2. **Смещенность оптимизации:** функция потерь минимизируется преимущественно за счет улучшения качества предсказаний для доминирующего класса;\n",
        "3. **Плохая обобщающая способность:** модель не обучается распознавать паттерны редкого класса из-за недостатка соответствующих примеров.\n",
        "\n",
        "Данные проблемы делают недостаточным использование accuracy в качестве единственной метрики оценки качества и требуют применения специализированных подходов, которые будут рассмотрены в последующих главах.\n",
        "\n",
        "### 1.4.3. Визуализация синтетического датасета\n",
        "\n",
        "Визуализация данных (Код 1.5) позволяет оценить геометрические свойства распределения классов и предварительно судить о применимости линейных методов классификации.\n",
        "\n",
        "**Код 1.5**  \n",
        "Визуализация синтетического датасета\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, marker='o', alpha=0.7)\n",
        "plt.title('Синтетический датасет с двумя признаками')\n",
        "plt.xlabel('Признак 1')\n",
        "plt.ylabel('Признак 2')\n",
        "plt.legend(handles=[\n",
        "    plt.Line2D([], [], marker='o', color='w', markerfacecolor=plt.cm.RdYlBu(0.0), markersize=10, label='Класс 0'),\n",
        "    plt.Line2D([], [], marker='o', color='w', markerfacecolor=plt.cm.RdYlBu(1.0), markersize=10, label='Класс 1')\n",
        "])\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "На визуализации можно наблюдать:\n",
        "- Преобладание объектов класса 0 (синие точки);\n",
        "- Локальную концентрацию объектов класса 1 (красные точки);\n",
        "- Частичное перекрытие классов, что указывает на отсутствие идеальной линейной разделимости.\n",
        "\n",
        "Степень линейной разделимости классов является ключевым фактором при выборе алгоритма классификации. Для линейно разделимых данных логистическая регрессия демонстрирует оптимальные результаты как по качеству, так и по интерпретируемости. В случае нелинейной разделимости требуются более сложные модели или методы трансформации признакового пространства.\n",
        "\n",
        "---\n",
        "\n",
        "## 1.5. Заключение главы\n",
        "\n",
        "В настоящей главе рассмотрены теоретические основы и практические аспекты бинарной классификации. Показано, как задача анализа тональности текстов решается с использованием классических методов машинного обучения. Подробно разобраны этапы преобразования текстовых данных в числовые признаки с помощью TF-IDF, обучение логистической регрессии и особенности работы с дисбалансом классов.\n",
        "\n",
        "Особое внимание уделено корректной организации вычислительного процесса, включая критически важное различие между методами `fit_transform()` и `transform()`, а также преимуществам использования конвейерной обработки данных через класс `Pipeline`. Теоретические аспекты, такие как математическая модель логистической регрессии и функция потерь бинарной кросс-энтропии, изложены с необходимой строгостью.\n",
        "\n",
        "Полученные знания и навыки создают основу для перехода к более сложным темам: оценке качества моделей с использованием специализированных метрик, методам работы с дисбалансом классов и современным подходам векторизации текстов, которые будут рассмотрены в последующих главах."
      ],
      "metadata": {
        "id": "4YhfV5MsgQmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Глава II. Тонкая настройка модели: гиперпараметры и регуляризация\n",
        "\n",
        "## 2.1. Регуляризация: контроль сложности модели\n",
        "\n",
        "Логистическая регрессия, как и многие другие линейные модели машинного обучения, подвержена риску переобучения (overfitting), особенно в условиях высокой размерности признакового пространства, наличия мультиколлинеарности или недостаточного объема обучающих данных. Регуляризация представляет собой фундаментальный метод предотвращения переобучения, заключающийся во введении штрафного члена в функцию потерь, который ограничивает величину весовых коэффициентов модели.\n",
        "\n",
        "### 2.1.1. Математическая формулировка регуляризации\n",
        "\n",
        "Пусть дана функция потерь для логистической регрессии без регуляризации:\n",
        "\n",
        "$$\\mathcal{L}_0(\\mathbf{w}) = -\\frac{1}{N}\\sum_{i=1}^{N}\\left[y_i\\log(p_i) + (1-y_i)\\log(1-p_i)\\right]$$\n",
        "\n",
        "где $p_i = \\sigma(\\mathbf{w}^T\\mathbf{x}_i + b)$, $\\sigma(\\cdot)$ — сигмоидальная функция.\n",
        "\n",
        "С учетом регуляризации функция потерь преобразуется в следующий вид:\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{w}) = \\mathcal{L}_0(\\mathbf{w}) + \\frac{\\lambda}{N}\\Omega(\\mathbf{w})$$\n",
        "\n",
        "где $\\lambda > 0$ — параметр силы регуляризации, $\\Omega(\\mathbf{w})$ — штрафная функция.\n",
        "\n",
        "### 2.1.2. Типы регуляризации\n",
        "\n",
        "#### Штраф L2 (Ridge регуляризация)\n",
        "Штраф L2 определяется как:\n",
        "\n",
        "$$\\Omega_{L2}(\\mathbf{w}) = \\frac{1}{2}\\|\\mathbf{w}\\|_2^2 = \\frac{1}{2}\\sum_{j=1}^{d}w_j^2$$\n",
        "\n",
        "Данный тип регуляризации (используется по умолчанию в scikit-learn с параметром `penalty='l2'`) обеспечивает сжатие весовых коэффициентов к нулю, сохраняя при этом все признаки в модели. Математически это соответствует добавлению априорного распределения Гаусса на веса в байесовской интерпретации. L2-регуляризация эффективно предотвращает доминирование отдельных признаков и повышает численную устойчивость решения.\n",
        "\n",
        "#### Штраф L1 (Lasso регуляризация)\n",
        "Штраф L1 определяется как:\n",
        "\n",
        "$$\\Omega_{L1}(\\mathbf{w}) = \\|\\mathbf{w}\\|_1 = \\sum_{j=1}^{d}|w_j|$$\n",
        "\n",
        "Данный тип регуляризации обладает уникальным свойством — способностью обнулять веса наименее информативных признаков, что делает его мощным инструментом автоматического отбора признаков. С геометрической точки зрения, L1-регуляризация создает ромбовидную область допустимых значений в пространстве весов, вершины которой лежат на координатных осях, что увеличивает вероятность получения разреженных решений.\n",
        "\n",
        "#### Эластичная сеть (Elastic Net)\n",
        "Комбинированный подход, объединяющий L1 и L2 штрафы:\n",
        "\n",
        "$$\\Omega_{elastic}(\\mathbf{w}) = \\alpha\\|\\mathbf{w}\\|_1 + \\frac{1-\\alpha}{2}\\|\\mathbf{w}\\|_2^2$$\n",
        "\n",
        "где $\\alpha \\in [0,1]$ — параметр баланса между типами регуляризации. Данный метод сочетает преимущества обоих подходов: разреженность решения от L1 и стабильность от L2.\n",
        "\n",
        "## 2.2. Гиперпараметр $C$: сила регуляризации\n",
        "\n",
        "В реализации логистической регрессии библиотеки scikit-learn сила регуляризации контролируется гиперпараметром $C$, который является обратной величиной параметра $\\lambda$ в математической формулировке:\n",
        "\n",
        "$$C = \\frac{1}{\\lambda}$$\n",
        "\n",
        "### 2.2.1. Интерпретация значений гиперпараметра $C$\n",
        "\n",
        "- **Малые значения $C$ (например, $C = 0.01$)**: соответствуют сильной регуляризации ($\\lambda$ велико). Модель становится более простой, весовые коэффициенты принимают малые значения. Это приводит к увеличению смещения (bias) и уменьшению дисперсии (variance), что эффективно борется с переобучением, но может привести к недообучению при чрезмерном упрощении.\n",
        "\n",
        "- **Большие значения $C$ (например, $C = 100$)**: соответствуют слабой регуляризации ($\\lambda$ мало). Модель имеет большую гибкость в подгонке под обучающие данные, что может привести к высокой дисперсии (переобучению) при недостаточном объеме данных.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ySWJRsyi5n8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2. Стратегия подбора оптимального значения $C$ с использованием кросс-валидации\n",
        "\n",
        "Оптимальное значение гиперпараметра $C$ в логистической регрессии должно определяться эмпирически с использованием методов кросс-валидации для обеспечения несмещенной оценки обобщающей способности модели. Теоретическое обоснование данного подхода базируется на принципе структурного риска по Вапнику-Червоненкису, который утверждает, что минимизация эмпирического риска на обучающей выборке не гарантирует минимизации истинного риска на новых данных. Кросс-валидация предоставляет статистически обоснованную оценку качества модели при различных значениях гиперпараметров.\n",
        "\n",
        "#### **Математическая формализация кросс-валидации**\n",
        "\n",
        "Пусть обучающая выборка $\\mathcal{D}_{\\text{train}} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ разбивается на $k$ непересекающихся подмножеств (фолдов) $\\mathcal{D}_1, \\mathcal{D}_2, \\dots, \\mathcal{D}_k$ таких, что:\n",
        "$$\\bigcup_{j=1}^k \\mathcal{D}_j = \\mathcal{D}_{\\text{train}}, \\quad \\mathcal{D}_i \\cap \\mathcal{D}_j = \\emptyset \\quad \\forall i \\neq j$$\n",
        "\n",
        "Для каждого значения гиперпараметра $C_j$ из заданной сетки $\\mathcal{C} = \\{C_1, C_2, \\dots, C_m\\}$ и для каждого фолда $i$:\n",
        "1. Модель обучается на данных $\\mathcal{D}_{\\text{train}} \\setminus \\mathcal{D}_i$\n",
        "2. Оценивается качество модели на валидационном фолде $\\mathcal{D}_i$ с использованием выбранной метрики $M$\n",
        "\n",
        "Среднее значение метрики качества для гиперпараметра $C_j$ вычисляется как:\n",
        "$$\\bar{M}(C_j) = \\frac{1}{k}\\sum_{i=1}^k M(\\mathbf{y}_{\\text{val}}^{(i)}, \\hat{\\mathbf{y}}_{\\text{val}}^{(i)}(C_j))$$\n",
        "\n",
        "где $\\mathbf{y}_{\\text{val}}^{(i)}$ — истинные метки валидационного фолда, $\\hat{\\mathbf{y}}_{\\text{val}}^{(i)}(C_j)$ — предсказания модели с гиперпараметром $C_j$.\n",
        "\n",
        "Дисперсия оценки качества определяется как:\n",
        "$$\\sigma^2_M(C_j) = \\frac{1}{k-1}\\sum_{i=1}^k \\left(M_i(C_j) - \\bar{M}(C_j)\\right)^2$$\n",
        "\n",
        "Оптимальное значение гиперпараметра выбирается по критерию:\n",
        "$$C^* = \\arg\\max_{C_j \\in \\mathcal{C}} \\bar{M}(C_j)$$\n",
        "\n",
        "с учетом стабильности оценки:\n",
        "$$C^* = \\arg\\max_{C_j \\in \\mathcal{C}} \\left\\{\\bar{M}(C_j) - \\alpha \\cdot \\sigma_M(C_j)\\right\\}$$\n",
        "где $\\alpha$ — параметр, контролирующий компромисс между средним значением и дисперсией (обычно $\\alpha = 1$).\n",
        "\n",
        "#### **Теоретические основы выбора диапазона значений**\n",
        "\n",
        "В силу того, что гиперпараметр $C$ входит в функцию потерь как обратная величина к коэффициенту регуляризации ($\\lambda = 1/C$), его влияние на модель является экспоненциальным. Поэтому оптимальная стратегия поиска заключается в использовании **логарифмической шкалы** значений. Теоретически обосновано, что оптимальное значение $C$ обычно лежит в диапазоне $[10^{-3}, 10^{3}]$, что соответствует коэффициентам регуляризации $\\lambda \\in [10^{-3}, 10^{3}]$.\n",
        "\n",
        "Математически, сетка значений формируется как:\n",
        "$$\\mathcal{C} = \\left\\{10^{a + i \\cdot \\frac{b-a}{n-1}} \\right\\}_{i=0}^{n-1}$$\n",
        "где $a = -3$, $b = 3$, $n$ — количество точек сетки (обычно $n = 7 \\div 15$).\n",
        "\n",
        "#### **Стратегия кросс-валидации для дисбалансированных данных**\n",
        "\n",
        "При наличии дисбаланса классов стандартная $k$-кратная кросс-валидация может привести к несбалансированным фолдам, что искажает оценку качества. Для корректной оценки необходимо использовать **стратифицированную кросс-валидацию** (stratified $k$-fold cross-validation), которая сохраняет пропорции классов в каждом фолде.\n",
        "\n",
        "Формально, для каждого класса $c \\in \\{0, 1\\}$ доля объектов класса $c$ в каждом фолде $\\mathcal{D}_i$ должна быть приблизительно равна доле в исходной выборке:\n",
        "$$\\frac{|\\{(\\mathbf{x}, y) \\in \\mathcal{D}_i : y = c\\}|}{|\\mathcal{D}_i|} \\approx \\frac{|\\{(\\mathbf{x}, y) \\in \\mathcal{D}_{\\text{train}} : y = c\\}|}{|\\mathcal{D}_{\\text{train}}|}$$\n",
        "\n",
        "#### **Практическая реализация в scikit-learn**\n",
        "\n",
        "В библиотеке scikit-learn реализованы два основных подхода к автоматизации подбора гиперпараметра $C$ с использованием кросс-валидации: класс `LogisticRegressionCV` и комбинация `GridSearchCV` с логистической регрессией.\n",
        "\n",
        "##### **Метод 1: LogisticRegressionCV**\n",
        "\n",
        "Класс `LogisticRegressionCV` предоставляет оптимизированную реализацию кросс-валидации специально для логистической регрессии. Его математическая основа заключается в одновременном решении задач оптимизации для всех значений $C$ с использованием warm-start стратегии, что значительно повышает вычислительную эффективность.\n",
        "\n",
        "**Теоретические преимущества:**\n",
        "- Использует эффективные алгоритмы оптимизации (L-BFGS, SAG), специализированные для логистической регрессии\n",
        "- Обеспечивает численную стабильность при экстремальных значениях $C$\n",
        "- Автоматически определяет количество итераций для сходимости\n",
        "\n",
        "**Алгоритм работы:**\n",
        "1. Для каждого фолда кросс-валидации и каждого значения $C_j$:\n",
        "   - Инициализирует веса $\\mathbf{w}$ на основе решения для ближайшего значения $C$\n",
        "   - Выполняет оптимизацию функции потерь с регуляризацией\n",
        "   - Оценивает качество на валидационном фолде\n",
        "2. Находит оптимальное $C^*$ по критерию максимизации выбранной метрики\n",
        "3. Обучает финальную модель на всем обучающем наборе с $C^*$\n",
        "\n",
        "**Код 2.1. Реализация с использованием LogisticRegressionCV:**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "\n",
        "# Генерация синтетического датасета с контролируемым дисбалансом\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=15,\n",
        "    n_redundant=5,\n",
        "    class_sep=1.0,\n",
        "    weights=[0.85, 0.15],  # 85% класса 0, 15% класса 1\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки с сохранением дисбаланса\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Создание пайплайна с предобработкой и классификацией\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Стандартизация признаков\n",
        "    ('classifier', LogisticRegressionCV(\n",
        "        Cs=np.logspace(-3, 3, 15),  # Логарифмическая сетка из 15 значений\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        penalty='l2',\n",
        "        solver='lbfgs',  # Оптимизатор, поддерживающий L2-регуляризацию\n",
        "        max_iter=1000,   # Максимальное количество итераций\n",
        "        class_weight='balanced',  # Автоматическая балансировка классов\n",
        "        scoring='f1',    # Метрика оптимизации\n",
        "        refit=True,      # Обучение финальной модели на всем наборе\n",
        "        random_state=42,\n",
        "        n_jobs=-1,       # Использование всех ядер процессора\n",
        "        verbose=0\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Обучение пайплайна\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Извлечение оптимального гиперпараметра\n",
        "optimal_C = pipeline.named_steps['classifier'].C_[0]\n",
        "n_iterations = pipeline.named_steps['classifier'].n_iter_[0]\n",
        "\n",
        "print(f\"Оптимальное значение гиперпараметра C: {optimal_C:.6f}\")\n",
        "print(f\"Количество итераций для сходимости: {n_iterations}\")\n",
        "```\n",
        "\n",
        "##### **Метод 2: GridSearchCV с ручной настройкой**\n",
        "\n",
        "Класс `GridSearchCV` предоставляет более гибкий, но менее оптимизированный подход к кросс-валидации. Он подходит для сравнения различных моделей и сложных пайплайнов.\n",
        "\n",
        "**Теоретические особенности:**\n",
        "- Поддерживает произвольные комбинации гиперпараметров\n",
        "- Позволяет использовать пользовательские метрики качества\n",
        "- Обеспечивает прозрачность процесса поиска\n",
        "\n",
        "**Алгоритм работы:**\n",
        "1. Формирует все возможные комбинации гиперпараметров из заданных сеток\n",
        "2. Для каждой комбинации выполняет полную кросс-валидацию\n",
        "3. Выбирает наилучшую комбинацию по среднему значению метрики\n",
        "4. Обучает финальную модель с оптимальными параметрами\n",
        "\n",
        "**Код 2.2. Реализация с использованием GridSearchCV:**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Определение сетки гиперпараметров\n",
        "param_grid = {\n",
        "    'classifier__C': np.logspace(-3, 3, 15)  # Логарифмическая сетка\n",
        "}\n",
        "\n",
        "# Настройка стратифицированной кросс-валидации\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Определение метрик для оценки\n",
        "scoring_metrics = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall'\n",
        "}\n",
        "\n",
        "# Инициализация GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,  # Используем тот же пайплайн\n",
        "    param_grid=param_grid,\n",
        "    scoring=scoring_metrics,\n",
        "    refit='f1',  # Оптимизация по F1-мере\n",
        "    cv=cv_strategy,\n",
        "    return_train_score=True,  # Сохранение результатов на обучающей выборке\n",
        "    n_jobs=-1,   # Параллельное выполнение\n",
        "    verbose=1    # Вывод прогресса\n",
        ")\n",
        "\n",
        "# Выполнение кросс-валидации\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Анализ результатов\n",
        "results = grid_search.cv_results_\n",
        "best_C = grid_search.best_params_['classifier__C']\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"\\nРезультаты кросс-валидации:\")\n",
        "print(f\"Оптимальное значение C: {best_C:.6f}\")\n",
        "print(f\"Лучшая F1-мера (средняя по фолдам): {best_score:.4f}\")\n",
        "\n",
        "# Визуализация результатов кросс-валидации\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# График F1-меры для обучающей и валидационной выборок\n",
        "plt.subplot(2, 1, 1)\n",
        "train_f1 = results['mean_train_f1']\n",
        "val_f1 = results['mean_test_f1']\n",
        "std_val_f1 = results['std_test_f1']\n",
        "\n",
        "plt.semilogx(param_grid['classifier__C'], train_f1, 'b--o', label='F1 (обучение)')\n",
        "plt.semilogx(param_grid['classifier__C'], val_f1, 'r-o', label='F1 (валидация)')\n",
        "plt.fill_between(param_grid['classifier__C'],\n",
        "                 val_f1 - std_val_f1,\n",
        "                 val_f1 + std_val_f1,\n",
        "                 alpha=0.2, color='red')\n",
        "plt.axvline(x=best_C, color='k', linestyle='--', alpha=0.7,\n",
        "            label=f'Оптимальное C = {best_C:.4f}')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Гиперпараметр C (логарифмическая шкала)')\n",
        "plt.ylabel('F1-мера')\n",
        "plt.title('Зависимость F1-меры от гиперпараметра C')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# График дисперсии оценки по фолдам\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.semilogx(param_grid['classifier__C'], std_val_f1, 'g-o')\n",
        "plt.axvline(x=best_C, color='k', linestyle='--', alpha=0.7)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Гиперпараметр C (логарифмическая шкала)')\n",
        "plt.ylabel('Стандартное отклонение F1')\n",
        "plt.title('Стабильность оценки качества по фолдам кросс-валидации')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('cv_results_analysis.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Анализ стабильности оптимального решения\n",
        "optimal_idx = np.where(param_grid['classifier__C'] == best_C)[0][0]\n",
        "stability_index = 1 - (std_val_f1[optimal_idx] / val_f1[optimal_idx])\n",
        "\n",
        "print(f\"\\nАнализ стабильности оптимального решения:\")\n",
        "print(f\"Стандартное отклонение F1 при C={best_C:.4f}: {std_val_f1[optimal_idx]:.4f}\")\n",
        "print(f\"Коэффициент стабильности: {stability_index:.4f}\")\n",
        "if stability_index > 0.95:\n",
        "    print(\"Решение высоко стабильно (коэффициент > 0.95)\")\n",
        "elif stability_index > 0.90:\n",
        "    print(\"Решение стабильно (коэффициент > 0.90)\")\n",
        "else:\n",
        "    print(\"Решение требует дополнительной проверки (коэффициент < 0.90)\")\n",
        "```\n",
        "\n",
        "#### **Теоретический анализ эффективности кросс-валидации**\n",
        "\n",
        "**Статистические свойства оценок:**\n",
        "- **Несмещенность**: Среднее значение $\\bar{M}(C_j)$ представляет собой несмещенную оценку истинного качества модели\n",
        "- **Дисперсия**: Стандартная ошибка оценки $\\sigma_M(C_j)/\\sqrt{k}$ уменьшается с увеличением количества фолдов $k$\n",
        "- **Консистентность**: При $N \\to \\infty$ и $k \\to \\infty$ оценка $\\bar{M}(C_j)$ сходится к истинному качеству модели\n",
        "\n",
        "**Оптимальное количество фолдов:**\n",
        "Теоретические исследования показывают, что оптимальное количество фолдов $k$ зависит от размера выборки $N$:\n",
        "- При $N < 100$: $k = N$ (leave-one-out кросс-валидация)\n",
        "- При $100 \\leq N < 1000$: $k = 10$\n",
        "- При $N \\geq 1000$: $k = 5$\n",
        "\n",
        "**Вычислительная сложность:**\n",
        "Вычислительная сложность кросс-валидации составляет $O(k \\cdot m \\cdot T)$, где:\n",
        "- $k$ — количество фолдов\n",
        "- $m$ — количество значений гиперпараметра $C$\n",
        "- $T$ — время обучения одной модели\n",
        "\n",
        "Для `LogisticRegressionCV` сложность снижается до $O(k \\cdot (m + T))$ благодаря warm-start стратегии.\n",
        "\n",
        "#### **Практические рекомендации по применению**\n",
        "\n",
        "1. **Предварительная обработка данных:**\n",
        "   - Обязательная стандартизация признаков перед кросс-валидацией\n",
        "   - Обработка пропущенных значений в рамках каждого фолда\n",
        "   - Применение методов снижения размерности (PCA) при высокой корреляции признаков\n",
        "\n",
        "2. **Стратегия поиска гиперпараметров:**\n",
        "   - **Первый этап**: грубый поиск на логарифмической сетке $C \\in [10^{-3}, 10^{3}]$ с шагом 1.0\n",
        "   - **Второй этап**: детальный поиск в окрестности найденного оптимума с шагом 0.2\n",
        "   - **Критерий остановки**: улучшение метрики менее 0.5% при сужении диапазона\n",
        "\n",
        "3. **Критерии выбора оптимального $C$:**\n",
        "   - При умеренном дисбалансе ($1:5 \\div 1:20$): оптимизация по F1-мере\n",
        "   - При сильном дисбалансе ($> 1:20$): оптимизация по PR-AUC\n",
        "   - При сбалансированных классах: оптимизация по ROC-AUC или accuracy\n",
        "\n",
        "4. **Валидация результатов:**\n",
        "   - Необходимо проверить сходимость алгоритма оптимизации для всех значений $C$\n",
        "   - Анализ корреляции между метриками на разных фолдах\n",
        "   - Проверка на переобучение путем сравнения метрик на обучающей и валидационной выборках\n",
        "\n",
        "#### **Сравнительный анализ методов кросс-валидации**\n",
        "\n",
        "**Таблица 2.1. Сравнительные характеристики методов кросс-валидации для подбора $C$**\n",
        "\n",
        "| Критерий | LogisticRegressionCV | GridSearchCV |\n",
        "|----------|----------------------|--------------|\n",
        "| **Вычислительная сложность** | $O(k \\cdot (m + T))$ | $O(k \\cdot m \\cdot T)$ |\n",
        "| **Память** | $O(d + m)$ | $O(k \\cdot m \\cdot d)$ |\n",
        "| **Гибкость** | Ограничена логистической регрессией | Поддержка любых моделей и метрик |\n",
        "| **Стабильность сходимости** | Высокая (специализированные алгоритмы) | Зависит от конкретной реализации модели |\n",
        "| **Поддержка стратификации** | Да (через параметр cv) | Да (через объект cv) |\n",
        "| **Рекомендуемое применение** | Быстрый прототипинг и финальная настройка | Сравнение разных моделей и комплексных пайплайнов |\n",
        "\n",
        "#### **Заключение раздела**\n",
        "\n",
        "Кросс-валидация представляет собой теоретически обоснованный и практически эффективный метод подбора гиперпараметра $C$ в логистической регрессии. Стратифицированная $k$-кратная кросс-валидация обеспечивает несмещенную оценку качества модели при наличии дисбаланса классов, а логарифмическая шкала значений $C$ позволяет эффективно исследовать широкий диапазон регуляризации.\n",
        "\n",
        "Реализация в scikit-learn через классы `LogisticRegressionCV` и `GridSearchCV` предоставляет как оптимизированные, так и гибкие инструменты для автоматизации этого процесса. Выбор конкретного метода зависит от задачи: `LogisticRegressionCV` предпочтителен для быстрой настройки логистической регрессии, тогда как `GridSearchCV` необходим при сравнении различных моделей или сложных стратегий обработки данных.\n",
        "\n",
        "Теоретически обоснованный подход к кросс-валидации, включающий анализ дисперсии оценок и стабильности решений, обеспечивает надежность полученных результатов и предотвращает переобучение на этапе подбора гиперпараметров. Это создает основу для построения моделей с высокой обобщающей способностью и интерпретируемостью."
      ],
      "metadata": {
        "id": "Uaq4_IBSLMd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2.3. Выбор оптимизатора (solver) и совместимость с типами регуляризации\n",
        "\n",
        "Оптимизатор (solver) определяет конкретный алгоритм минимизации функции потерь при обучении логистической регрессии. Выбор оптимизатора критически важен, поскольку разные алгоритмы имеют различные вычислительные характеристики, требования к памяти и ограничения по поддерживаемым типам регуляризации.\n",
        "\n",
        "### 2.3.1. Математические основы оптимизаторов\n",
        "\n",
        "#### L-BFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno)\n",
        "- **Принцип работы**: квазиньютоновский метод, аппроксимирующий обратную матрицу Гессе с использованием ограниченного объема памяти.\n",
        "- **Преимущества**: высокая скорость сходимости, хорошая масштабируемость на средних наборах данных.\n",
        "- **Ограничения**: поддерживает только L2-регуляризацию.\n",
        "\n",
        "#### LIBLINEAR\n",
        "- **Принцип работы**: основан на методе координатного спуска с использованием двойственной задачи оптимизации.\n",
        "- **Преимущества**: эффективен для задач с высокой размерностью признакового пространства, поддерживает L1 и L2 регуляризацию.\n",
        "- **Ограничения**: может быть медленным для очень больших наборов данных.\n",
        "\n",
        "#### SAG/SAGA (Stochastic Average Gradient / SAG Accelerated)\n",
        "- **Принцип работы**: стохастические методы, использующие средний градиент по всем объектам с экспоненциальным сглаживанием.\n",
        "- **Преимущества**: высокая скорость сходимости на больших наборах данных, хорошая масштабируемость.\n",
        "- **Особенности**: SAGA поддерживает все типы регуляризации (L1, L2, Elastic Net).\n",
        "\n",
        "### 2.3.2. Таблица совместимости регуляризации и оптимизаторов\n",
        "\n",
        "Таблица 2.1 демонстрирует совместимость различных типов регуляризации с оптимизаторами в реализации scikit-learn.\n",
        "\n",
        "**Таблица 2.1**  \n",
        "Совместимость штрафов и оптимизаторов в логистической регрессии\n",
        "\n",
        "| Penalty (Штраф) | liblinear | lbfgs | newton-cg | sag  | saga |\n",
        "|----------------|-----------|-------|-----------|------|------|\n",
        "| L2 (Default)   | Да        | Да    | Да        | Да   | Да   |\n",
        "| L1             | Да        | Нет   | Нет       | Нет  | Да   |\n",
        "| Elastic Net    | Нет       | Нет   | Нет       | Нет  | Да   |\n",
        "| None           | Нет       | Да    | Да        | Да   | Да   |\n",
        "\n",
        "### 2.3.3. Рекомендации по выбору оптимизатора\n",
        "\n",
        "1. **Для задач с L2-регуляризацией**:\n",
        "   - Малые и средние наборы данных ($N < 10^4$): `lbfgs` (по умолчанию)\n",
        "   - Очень большие наборы данных ($N > 10^5$): `sag` или `saga`\n",
        "\n",
        "2. **Для задач с L1-регуляризацией**:\n",
        "   - Средние наборы данных: `liblinear`\n",
        "   - Большие наборы данных: `saga`\n",
        "\n",
        "3. **Для задач с Elastic Net**: только `saga`\n",
        "\n",
        "4. **Для разреженных данных**: `liblinear` или `saga`\n",
        "\n",
        "## 2.4. Учет дисбаланса классов\n",
        "\n",
        "Проблема дисбаланса классов, подробно рассмотренная в Главе II, требует специальных методов корректировки обучения модели для обеспечения адекватного распознавания миноритарного класса.\n",
        "\n",
        "### 2.4.1. Встроенные методы балансировки\n",
        "\n",
        "#### Балансировка весов классов (class_weight='balanced')\n",
        "Данный метод реализует автоматическую настройку весов классов, обратно пропорциональных их частоте в обучающих данных. Формально, вес для класса $k$ вычисляется как:\n",
        "\n",
        "$$w_k = \\frac{N}{n_k \\times K}$$\n",
        "\n",
        "где:\n",
        "- $N$ — общий размер обучающей выборки,\n",
        "- $n_k$ — количество объектов класса $k$,\n",
        "- $K$ — общее количество классов.\n",
        "\n",
        "В контексте функции потерь для логистической регрессии это приводит к модификации:\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{w}) = -\\frac{1}{N}\\sum_{i=1}^{N}w_{y_i}\\left[y_i\\log(p_i) + (1-y_i)\\log(1-p_i)\\right] + \\frac{\\lambda}{N}\\Omega(\\mathbf{w})$$\n",
        "\n",
        "где $w_{y_i}$ — вес, соответствующий классу объекта $i$.\n",
        "\n",
        "Такой подход эффективно увеличивает штраф за ошибки на объектах миноритарного класса, заставляя алгоритм уделять им большее внимание.\n",
        "\n",
        "### 2.4.2. Внешние методы сэмплинга\n",
        "\n",
        "#### Oversampling (SMOTE — Synthetic Minority Over-sampling Technique)\n",
        "Метод синтетической генерации новых объектов для миноритарного класса путем интерполяции между существующими объектами. Алгоритм работает следующим образом:\n",
        "1. Для каждого объекта миноритарного класса находятся $k$ ближайших соседей того же класса.\n",
        "2. Синтетический объект создается путем линейной интерполяции между исходным объектом и одним из его соседей:\n",
        "\n",
        "$$\\mathbf{x}_{new} = \\mathbf{x}_i + \\lambda(\\mathbf{x}_{nn} - \\mathbf{x}_i)$$\n",
        "\n",
        "где $\\lambda \\sim U(0,1)$, $\\mathbf{x}_{nn}$ — один из $k$ ближайших соседей.\n",
        "\n",
        "#### Undersampling\n",
        "Метод уменьшения количества объектов мажоритарного класса путем их случайного удаления или использования более сложных стратегий (например, Tomek links, NearMiss). Основное преимущество — снижение вычислительной сложности обучения, основной недостаток — потеря потенциально полезной информации.\n",
        "\n",
        "### 2.4.3. Практические рекомендации по работе с дисбалансом\n",
        "\n",
        "1. **Предпочтение встроенных методов**: для большинства задач рекомендуется начинать с `class_weight='balanced'`, так как этот подход сохраняет все исходные данные и не вносит дополнительного шума.\n",
        "\n",
        "2. **Комбинированный подход**: в случае сильного дисбаланса ($> 1:100$) эффективно сочетание undersampling мажоритарного класса с последующим применением `class_weight='balanced'`.\n",
        "\n",
        "3. **Выбор метрик качества**: при наличии дисбаланса классов категорически не рекомендуется использовать accuracy как основную метрику оценки. Предпочтение следует отдавать:\n",
        "   - F1-мере (гармоническое среднее precision и recall)\n",
        "   - ROC-AUC (площадь под ROC-кривой)\n",
        "   - Precision-Recall кривой\n",
        "\n",
        "## 2.5. Практическая реализация: пример настройки модели\n",
        "\n",
        "**Код 3.1**  \n",
        "Инициализация и обучение модели логистической регрессии с учетом дисбаланса классов и регуляризации\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Инициализация модели с оптимальными параметрами:\n",
        "# 1. penalty='l2' — Ridge регуляризация для стабильности\n",
        "# 2. C=1.0 — умеренная сила регуляризации (базовое значение)\n",
        "# 3. solver='lbfgs' — эффективный оптимизатор для L2-регуляризации\n",
        "# 4. class_weight='balanced' — автоматическая балансировка весов классов\n",
        "# 5. random_state=42 — воспроизводимость результатов\n",
        "# 6. max_iter=1000 — увеличенное количество итераций для сходимости\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=1.0,\n",
        "    solver='lbfgs',\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    max_iter=1000\n",
        ")\n",
        "\n",
        "# Обучение модели на тренировочной выборке\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Оценка качества на обучающей и тестовой выборках\n",
        "train_accuracy = model.score(X_train, y_train)\n",
        "test_accuracy = model.score(X_test, y_test)\n",
        "\n",
        "print(f\"Обучающая точность (Accuracy): {train_accuracy:.4f}\")\n",
        "print(f\"Тестовая точность (Accuracy): {test_accuracy:.4f}\")\n",
        "print(\"\\nДетальный отчет классификации на тестовой выборке:\")\n",
        "print(classification_report(y_test, model.predict(X_test)))\n",
        "\n",
        "print(\"Модель Логистической Регрессии успешно обучена с учетом дисбаланса классов.\")\n",
        "```\n",
        "\n",
        "**Ключевые аспекты реализации:**\n",
        "\n",
        "1. **Выбор оптимизатора**: `solver='lbfgs'` выбран как оптимальный для задач с L2-регуляризацией среднего размера. Данный алгоритм обеспечивает хороший компромисс между скоростью сходимости и потреблением памяти.\n",
        "\n",
        "2. **Сила регуляризации**: значение $C=1.0$ представляет собой разумное начальное приближение. Для окончательной настройки параметра рекомендуется использовать кросс-валидацию (например, `LogisticRegressionCV`).\n",
        "\n",
        "3. **Обработка дисбаланса**: параметр `class_weight='balanced'` автоматически вычисляет веса классов, обеспечивая более сбалансированное обучение без изменения состава обучающих данных.\n",
        "\n",
        "4. **Контроль сходимости**: параметр `max_iter=1000` гарантирует достаточное количество итераций для достижения сходимости оптимизатора, особенно важен для сложных или плохо масштабированных данных.\n",
        "\n",
        "5. **Комплексная оценка качества**: помимо точности (accuracy), выводится детальный отчет `classification_report`, содержащий precision, recall и F1-меру для каждого класса, что критически важно при наличии дисбаланса.\n",
        "\n",
        "## 2.6. Заключение главы\n",
        "\n",
        "В настоящей главе рассмотрены фундаментальные аспекты тонкой настройки модели логистической регрессии. Показано, что эффективное управление сложностью модели достигается через комбинацию регуляризации (L1, L2, Elastic Net), правильного выбора оптимизатора и учета дисбаланса классов.\n",
        "\n",
        "Особое внимание уделено математической интерпретации гиперпараметров и их влиянию на характеристики модели (смещение-дисперсия). Продемонстрирована критическая важность совместимости типов регуляризации и оптимизаторов, а также необходимость комплексного подхода к оценке качества в условиях дисбаланса классов.\n",
        "\n",
        "Полученные знания создают основу для перехода к более сложным темам: ансамблевым методам, нейронным сетям и современным архитектурам глубокого обучения, которые будут рассмотрены в последующих главах. Понимание принципов настройки базовых моделей является необходимым условием для успешного применения и интерпретации результатов более сложных алгоритмов машинного обучения."
      ],
      "metadata": {
        "id": "jOumyi0BIiLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Глава III. Комплексная оценка модели: исчерпывающие метрики качества\n",
        "\n",
        "## 3.1. Порог принятия решений (Decision Threshold)\n",
        "\n",
        "Логистическая регрессия, как и большинство вероятностных моделей бинарной классификации, предсказывает вероятность принадлежности объекта к положительному классу $p \\in [0, 1]$. Для преобразования непрерывного прогноза вероятности в бинарное решение используется порог принятия решений (decision threshold) $\\theta \\in [0, 1]$.\n",
        "\n",
        "Формально, правило классификации определяется как:\n",
        "\n",
        "$$\\hat{y} = \\begin{cases}\n",
        "1, & \\text{если } p \\geq \\theta \\\\\n",
        "0, & \\text{если } p < \\theta\n",
        "\\end{cases}$$\n",
        "\n",
        "Стандартное значение порога $\\theta = 0.5$ соответствует принципу максимального правдоподобия в условиях сбалансированных классов. Однако в реальных задачах часто возникает необходимость корректировки порога для оптимизации конкретных метрик качества.\n",
        "\n",
        "### 3.1.1. Теоретические основы выбора порога\n",
        "\n",
        "Выбор оптимального порога $\\theta^*$ решает задачу многокритериальной оптимизации, где требуется достичь компромисса между различными типами ошибок. Математически это можно выразить как:\n",
        "\n",
        "$$\\theta^* = \\arg\\max_{\\theta} \\left[ \\alpha \\cdot \\text{Recall}(\\theta) + \\beta \\cdot \\text{Precision}(\\theta) \\right]$$\n",
        "\n",
        "где $\\alpha$ и $\\beta$ — весовые коэффициенты, отражающие бизнес-требования или медицинские последствия ошибок.\n",
        "\n",
        "В условиях асимметричной стоимости ошибок I и II рода, оптимальный порог определяется из условия минимизации ожидаемого риска:\n",
        "\n",
        "$$\\theta^* = \\arg\\min_{\\theta} \\left[ C_{FP} \\cdot \\text{FPR}(\\theta) + C_{FN} \\cdot (1 - \\text{Recall}(\\theta)) \\right]$$\n",
        "\n",
        "где $C_{FP}$ и $C_{FN}$ — стоимостные коэффициенты ложных срабатываний и пропущенных случаев соответственно.\n",
        "\n",
        "### 3.1.2. Практические стратегии настройки порога\n",
        "\n",
        "**Стратегия 1: Максимизация F1-меры**  \n",
        "Для задач, где требуется сбалансированная оптимизация precision и recall, оптимальный порог находится на максимуме F1-меры:\n",
        "\n",
        "$$\\theta^* = \\arg\\max_{\\theta} F1(\\theta)$$\n",
        "\n",
        "**Стратегия 2: Оптимизация по ROC-кривой**  \n",
        "При использовании ROC-кривой оптимальный порог часто выбирается в точке, ближайшей к левому верхнему углу (координаты (0, 1)):\n",
        "\n",
        "$$\\theta^* = \\arg\\min_{\\theta} \\sqrt{(1 - \\text{TPR}(\\theta))^2 + (\\text{FPR}(\\theta))^2}$$\n",
        "\n",
        "**Стратегия 3: Оптимизация по PR-кривой**  \n",
        "Для задач с сильным дисбалансом классов предпочтительнее использовать PR-кривую, где оптимальный порог максимизирует площадь под кривой или выбирается в точке с минимальной разницей между precision и recall.\n",
        "\n",
        "## 3.2. Матрица ошибок (Confusion Matrix)\n",
        "\n",
        "Матрица ошибок (confusion matrix) представляет собой основу для вычисления всех метрик качества в задачах бинарной классификации. Она визуализирует распределение ошибок классификации, сопоставляя истинные и предсказанные метки.\n",
        "\n",
        "### 3.2.1. Структура матрицы ошибок\n",
        "\n",
        "Для бинарной классификации матрица ошибок имеет размер $2 \\times 2$ и содержит четыре ключевых элемента, как показано в Таблице 3.1.\n",
        "\n",
        "**Таблица 3.1**  \n",
        "Структура матрицы ошибок для бинарной классификации\n",
        "\n",
        "| Фактический класс $\\downarrow$ / Предсказанный класс $\\rightarrow$ | Positive (1) | Negative (0) |\n",
        "|--------------------------------------------|--------------|--------------|\n",
        "| **Positive (1)**                           | TP           | FN           |\n",
        "| **Negative (0)**                           | FP           | TN           |\n",
        "\n",
        "где:\n",
        "- **TP (True Positive)** — количество объектов, которые являются положительными и были корректно классифицированы как положительные;\n",
        "- **TN (True Negative)** — количество объектов, которые являются отрицательными и были корректно классифицированы как отрицательные;\n",
        "- **FP (False Positive)** — количество объектов, которые являются отрицательными, но были ошибочно классифицированы как положительные (ошибка I рода);\n",
        "- **FN (False Negative)** — количество объектов, которые являются положительными, но были ошибочно классифицированы как отрицательные (ошибка II рода).\n",
        "\n",
        "### 3.2.2. Статистическая интерпретация элементов\n",
        "\n",
        "Элементы матрицы ошибок имеют прямую статистическую интерпретацию в контексте проверки гипотез:\n",
        "\n",
        "- **Чувствительность (Sensitivity)** = $\\frac{TP}{TP + FN}$ = Recall = TPR (True Positive Rate)\n",
        "- **Специфичность (Specificity)** = $\\frac{TN}{TN + FP}$ = 1 - FPR (False Positive Rate)\n",
        "- **Точность (Precision)** = $\\frac{TP}{TP + FP}$\n",
        "- **Частота ложных отрицательных результатов (Miss Rate)** = $\\frac{FN}{TP + FN}$ = 1 - Recall\n",
        "\n",
        "Эти метрики формируют основу для комплексной оценки качества классификации в различных прикладных областях.\n",
        "\n",
        "## 3.3. Метрики, зависящие от порога (Threshold-Dependent Metrics)\n",
        "\n",
        "### 3.3.1. Основные метрики качества\n",
        "\n",
        "#### Accuracy (Точность)\n",
        "Accuracy измеряет общую долю правильно классифицированных объектов:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
        "\n",
        "Несмотря на интуитивную понятность, accuracy является ненадежной метрикой в условиях дисбаланса классов. Например, при дисбалансе 99:1 модель, всегда предсказывающая класс 0, достигнет accuracy = 0.99, но будет бесполезна для обнаружения редкого класса.\n",
        "\n",
        "#### Precision (Точность положительного класса)\n",
        "Precision оценивает долю верных положительных предсказаний среди всех предсказанных положительных:\n",
        "\n",
        "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "Эта метрика критически важна в сценариях, где стоимость ложных срабатываний высока:\n",
        "- Финансовый сектор: ложное одобрение кредитной заявки может привести к финансовым потерям;\n",
        "- Системы рекомендаций: ложные рекомендации снижают доверие пользователей;\n",
        "- Юридические системы: ложные обвинения нарушают принцип презумпции невиновности.\n",
        "\n",
        "#### Recall (Полнота, Sensitivity, True Positive Rate)\n",
        "Recall измеряет способность модели находить все положительные объекты:\n",
        "\n",
        "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "\n",
        "Эта метрика приоритетна в сценариях, где критически важно минимизировать пропуски:\n",
        "- Медицинская диагностика: пропуск заболевания может стоить жизни пациента;\n",
        "- Обнаружение мошенничества: пропущенная мошенническая транзакция ведет к финансовым потерям;\n",
        "- Системы безопасности: пропущенная угроза может иметь катастрофические последствия.\n",
        "\n",
        "#### F1-Score (Гармоническое среднее)\n",
        "F1-Score объединяет precision и recall в единую метрику как их гармоническое среднее:\n",
        "\n",
        "$$F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "Гармоническое среднее предпочтительнее арифметического, так как оно более чувствительно к экстремальным значениям (когда одна из метрик близка к нулю, F1 также стремится к нулю).\n",
        "\n",
        "Обобщенная версия F-меры с параметром $\\beta$ позволяет задавать относительную важность recall по сравнению с precision:\n",
        "\n",
        "$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{(\\beta^2 \\cdot \\text{Precision}) + \\text{Recall}}$$\n",
        "\n",
        "где $\\beta > 1$ придает больший вес recall, а $\\beta < 1$ — precision.\n",
        "\n",
        "### 3.3.2. Расширенные метрики\n",
        "\n",
        "#### Specificity (Специфичность, True Negative Rate)\n",
        "Specificity измеряет долю правильно классифицированных отрицательных объектов:\n",
        "\n",
        "$$\\text{Specificity} = \\frac{TN}{TN + FP} = 1 - \\text{FPR}$$\n",
        "\n",
        "Эта метрика особенно важна в медицинских тестах, где требуется минимизировать количество ложных положительных диагнозов.\n",
        "\n",
        "#### False Positive Rate (FPR)\n",
        "FPR измеряет долю отрицательных объектов, ошибочно классифицированных как положительные:\n",
        "\n",
        "$$\\text{FPR} = \\frac{FP}{FP + TN} = 1 - \\text{Specificity}$$\n",
        "\n",
        "#### False Negative Rate (FNR)\n",
        "FNR измеряет долю положительных объектов, ошибочно классифицированных как отрицательные:\n",
        "\n",
        "$$\\text{FNR} = \\frac{FN}{FN + TP} = 1 - \\text{Recall}$$\n",
        "\n",
        "#### Matthews Correlation Coefficient (MCC)\n",
        "MCC представляет собой сбалансированную метрику, учитывающую все элементы матрицы ошибок:\n",
        "\n",
        "$$\\text{MCC} = \\frac{TP \\cdot TN - FP \\cdot FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n",
        "\n",
        "MCC принимает значения от -1 до +1, где +1 означает идеальную классификацию, 0 — случайное предсказание, а -1 — полную несогласованность. MCC особенно полезна при сильном дисбалансе классов.\n",
        "\n",
        "## 3.4. Метрики, основанные на вероятностях (Probabilistic Metrics)\n",
        "\n",
        "### 3.4.1. Log Loss (Бинарная кросс-энтропия)\n",
        "\n",
        "Log Loss, или бинарная кросс-энтропия, оценивает качество вероятностных предсказаний модели. Для бинарной классификации она определяется как:\n",
        "\n",
        "$$\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]$$\n",
        "\n",
        "где $y_i$ — истинная метка, $p_i$ — предсказанная вероятность принадлежности к положительному классу.\n",
        "\n",
        "Log Loss имеет несколько важных свойств:\n",
        "- Штрафует модель экспоненциально за высокую уверенность в неверных предсказаниях;\n",
        "- Минимизируется, когда предсказанные вероятности совпадают с истинными частотами классов;\n",
        "- Обеспечивает корректную калибровку вероятностей.\n",
        "\n",
        "Рассмотрим два сценария для объекта с истинным классом $y_i = 1$:\n",
        "- Модель A предсказывает $p_i = 0.51$: $\\text{Log Loss} \\approx 0.67$\n",
        "- Модель B предсказывает $p_i = 0.99$: $\\text{Log Loss} \\approx 0.01$\n",
        "\n",
        "При пороге $\\theta = 0.5$ обе модели дают правильный бинарный прогноз, но Log Loss модели B значительно ниже, что отражает ее лучшую калибровку и большую уверенность в правильном предсказании.\n",
        "\n",
        "### 3.4.2. ROC AUC (Area Under ROC Curve)\n",
        "\n",
        "ROC-кривая (Receiver Operating Characteristic) визуализирует зависимость True Positive Rate (TPR) от False Positive Rate (FPR) при различных значениях порога $\\theta$.\n",
        "\n",
        "$$\\text{TPR}(\\theta) = \\frac{TP(\\theta)}{TP(\\theta) + FN(\\theta)}$$\n",
        "$$\\text{FPR}(\\theta) = \\frac{FP(\\theta)}{FP(\\theta) + TN(\\theta)}$$\n",
        "\n",
        "ROC AUC (Area Under Curve) представляет собой площадь под ROC-кривой и интерпретируется как вероятность того, что случайно выбранный положительный объект будет оценен моделью выше случайно выбранного отрицательного объекта.\n",
        "\n",
        "ROC AUC обладает следующими преимуществами:\n",
        "- Инвариантна к дисбалансу классов;\n",
        "- Не зависит от выбора конкретного порога классификации;\n",
        "- Устойчива к монотонным преобразованиям предсказанных вероятностей.\n",
        "\n",
        "Теоретические значения ROC AUC:\n",
        "- 1.0: идеальная разделимость классов;\n",
        "- 0.5: случайное предсказание (диагональ ROC-кривой);\n",
        "- 0.0: полная обратная корреляция (модель работает в обратную сторону).\n",
        "\n",
        "### 3.4.3. PR AUC (Area Under Precision-Recall Curve)\n",
        "\n",
        "PR-кривая (Precision-Recall) отображает зависимость precision от recall при различных порогах $\\theta$. PR AUC — площадь под этой кривой.\n",
        "\n",
        "В отличие от ROC AUC, PR AUC фокусируется исключительно на производительности для положительного класса и особенно информативна при сильном дисбалансе классов (когда доля положительного класса $< 10\\%$).\n",
        "\n",
        "PR AUC имеет следующие особенности:\n",
        "- Чувствительна к качеству предсказаний для редкого класса;\n",
        "- Значение baseline зависит от доли положительного класса (для случайной модели $\\text{PR AUC} \\approx \\frac{\\text{количество позитивов}}{N}$);\n",
        "- Более информативна чем ROC AUC в условиях экстремального дисбаланса.\n",
        "\n",
        "### 3.4.4. Критерии выбора метрик\n",
        "\n",
        "Выбор метрик качества должен основываться на конкретной задаче и бизнес-требованиях. Рекомендации по выбору представлены в Таблице 3.2.\n",
        "\n",
        "**Таблица 3.2**  \n",
        "Рекомендации по выбору метрик качества в зависимости от задачи\n",
        "\n",
        "| Сценарий применения | Критичные ошибки | Рекомендуемые метрики | Примеры |\n",
        "|-------------------|-----------------|----------------------|---------|\n",
        "| **Медицинская диагностика** | False Negatives (пропуск заболевания) | Recall, F2-Score, Sensitivity | Ранняя диагностика рака |\n",
        "| **Финансовый скоринг** | False Positives (ложное одобрение кредита) | Precision, Specificity | Кредитный скоринг |\n",
        "| **Обнаружение мошенничества** | False Negatives (пропуск мошенничества) | Recall, F2-Score | Банковские транзакции |\n",
        "| **Системы рекомендаций** | False Positives (релевантность) | Precision@k, NDCG | Рекомендация товаров |\n",
        "| **Умеренный дисбаланс** | Баланс ошибок | F1-Score, ROC AUC | Анализ отзывов |\n",
        "| **Экстремальный дисбаланс** ($>1:100$) | Обнаружение редкого класса | PR AUC, Recall@k | Обнаружение аномалий |\n",
        "| **Вероятностная калибровка** | Качество вероятностей | Log Loss, Brier Score | Страховые модели |\n",
        "\n",
        "## 3.5. Практическая реализация: комплексная оценка модели\n",
        "\n",
        "**Код 3.1**  \n",
        "Комплексная оценка модели логистической регрессии с визуализацией\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,\n",
        "                           recall_score, f1_score, roc_auc_score, log_loss,\n",
        "                           precision_recall_curve, roc_curve, average_precision_score)\n",
        "\n",
        "# Предсказание вероятностей и классов\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_prob >= 0.5).astype(int)  # Используем стандартный порог 0.5\n",
        "\n",
        "# 1. Матрица ошибок\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Матрица ошибок:\")\n",
        "print(f\"[[TN={conf_matrix[0,0]}, FP={conf_matrix[0,1]}]\")\n",
        "print(f\" [FN={conf_matrix[1,0]}, TP={conf_matrix[1,1]}]]\")\n",
        "\n",
        "# 2. Порог-зависимые метрики\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "specificity = conf_matrix[0,0] / (conf_matrix[0,0] + conf_matrix[0,1])\n",
        "mcc = (conf_matrix[0,0]*conf_matrix[1,1] - conf_matrix[0,1]*conf_matrix[1,0]) / \\\n",
        "      np.sqrt((conf_matrix[0,0]+conf_matrix[0,1])*(conf_matrix[0,0]+conf_matrix[1,0])*\n",
        "              (conf_matrix[1,1]+conf_matrix[0,1])*(conf_matrix[1,1]+conf_matrix[1,0]))\n",
        "\n",
        "print(\"\\nПорог-зависимые метрики (θ=0.5):\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "\n",
        "# 3. Вероятностные метрики\n",
        "logloss = log_loss(y_test, y_prob)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "pr_auc = average_precision_score(y_test, y_prob)\n",
        "\n",
        "print(\"\\nВероятностные метрики:\")\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc:.4f}\")\n",
        "\n",
        "# 4. Визуализация ROC и PR кривых\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# ROC кривая\n",
        "plt.subplot(1, 2, 1)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.plot(fpr, tpr, 'b-', label=f'ROC AUC = {roc_auc:.3f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Случайная модель')\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.title('ROC кривая')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# PR кривая\n",
        "plt.subplot(1, 2, 2)\n",
        "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
        "plt.plot(recall_curve, precision_curve, 'r-', label=f'PR AUC = {pr_auc:.3f}')\n",
        "plt.hlines(y=np.mean(y_test), xmin=0, xmax=1, colors='k', linestyles='--',\n",
        "           label=f'Baseline = {np.mean(y_test):.3f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall кривая')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_pr_curves.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# 5. Оптимизация порога по F1-мере\n",
        "thresholds = np.arange(0.1, 1.0, 0.01)\n",
        "f1_scores = [f1_score(y_test, (y_prob >= t).astype(int)) for t in thresholds]\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "optimal_f1 = f1_scores[optimal_idx]\n",
        "\n",
        "print(f\"\\nОптимальный порог по F1-мере: θ = {optimal_threshold:.3f} (F1 = {optimal_f1:.4f})\")\n",
        "print(f\"Метрики при оптимальном пороге:\")\n",
        "y_pred_opt = (y_prob >= optimal_threshold).astype(int)\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_opt):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_opt):.4f}\")\n",
        "```\n",
        "\n",
        "**Ключевые аспекты реализации:**\n",
        "\n",
        "1. **Комплексный подход к оценке**: код демонстрирует расчет как порог-зависимых метрик (accuracy, precision, recall), так и вероятностных (Log Loss, ROC AUC, PR AUC).\n",
        "\n",
        "2. **Визуализация результатов**: ROC и PR кривые предоставляют интуитивно понятное представление о качестве модели. ROC кривая оценивает способность модели разделять классы, а PR кривая фокусируется на эффективности обнаружения положительного класса.\n",
        "\n",
        "3. **Автоматическая оптимизация порога**: алгоритм находит оптимальное значение порога по максимуму F1-меры, что особенно полезно в условиях дисбаланса классов.\n",
        "\n",
        "4. **Дополнительные метрики**: расчет Matthews Correlation Coefficient (MCC) и Specificity обеспечивает более полную картину качества модели.\n",
        "\n",
        "5. **Базовые линии для сравнения**: визуализация случайной модели (диагональ ROC-кривой) и baseline для PR-кривой (доля положительного класса) позволяет объективно оценить качество модели.\n",
        "\n",
        "## 3.6. Заключение главы\n",
        "\n",
        "В настоящей главе рассмотрены фундаментальные аспекты комплексной оценки моделей бинарной классификации. Показано, что выбор метрик качества должен основываться на глубоком понимании бизнес-задачи, стоимости различных типов ошибок и характеристик данных (включая дисбаланс классов).\n",
        "\n",
        "Особое внимание уделено критически важному понятию порога принятия решений и его влиянию на компромисс между precision и recall. Демонстрирована важность использования вероятностных метрик (Log Loss, ROC AUC, PR AUC), которые оценивают качество модели независимо от конкретного порога классификации.\n",
        "\n",
        "Практическая реализация включает не только расчет метрик, но и их визуализацию, что способствует лучшему пониманию поведения модели. Автоматическая оптимизация порога принятия решений представляет собой мощный инструмент для повышения практической применимости моделей в реальных сценариях.\n",
        "\n",
        "Полученные знания создают основу для перехода к более сложным темам: ансамблевым методам, глубокому обучению и современным подходам к обработке естественного языка. Понимание принципов комплексной оценки моделей является критически важным для разработки надежных и интерпретируемых решений в области машинного обучения."
      ],
      "metadata": {
        "id": "U5p1AsyRBitH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Глава IV. Интерпретация, визуализация и диагностика моделей бинарной классификации\n",
        "\n",
        "## 4.1. Визуализация границы принятия решений\n",
        "\n",
        "Визуализация границы принятия решений представляет собой мощный инструмент для понимания поведения классификатора и диагностики его способности разделять классы. Для логистической регрессии граница принятия решений определяется как множество точек, где вероятность принадлежности к положительному классу равна пороговому значению $\\theta$, обычно $\\theta = 0.5$:\n",
        "\n",
        "$$P(y=1|\\mathbf{x}) = \\sigma(\\mathbf{w}^T\\mathbf{x} + b) = 0.5$$\n",
        "\n",
        "Поскольку сигмоидальная функция $\\sigma(z) = 0.5$ при $z = 0$, граница принятия решений описывается линейным уравнением:\n",
        "\n",
        "$$\\mathbf{w}^T\\mathbf{x} + b = 0$$\n",
        "\n",
        "Для двумерного признакового пространства ($\\mathbf{x} = [x_1, x_2]^T$) это уравнение принимает вид:\n",
        "\n",
        "$$w_1x_1 + w_2x_2 + b = 0$$\n",
        "\n",
        "что соответствует прямой линии на плоскости. Нормальный вектор к этой прямой определяется весами модели $\\mathbf{w} = [w_1, w_2]^T$.\n",
        "\n",
        "### 4.1.1. Математическая интерпретация весов модели\n",
        "\n",
        "Весовые коэффициенты логистической регрессии имеют четкую статистическую интерпретацию в терминах логарифма шансов (log-odds):\n",
        "\n",
        "$$\\log\\left(\\frac{P(y=1|\\mathbf{x})}{1-P(y=1|\\mathbf{x})}\\right) = \\mathbf{w}^T\\mathbf{x} + b$$\n",
        "\n",
        "Каждый коэффициент $w_j$ представляет собой изменение логарифма шансов при увеличении соответствующего признака $x_j$ на единицу, при условии, что все остальные признаки остаются постоянными. Таким образом:\n",
        "- Если $w_j > 0$, увеличение $x_j$ увеличивает вероятность принадлежности к положительному классу;\n",
        "- Если $w_j < 0$, увеличение $x_j$ уменьшает вероятность принадлежности к положительному классу;\n",
        "- Если $w_j = 0$, признак $x_j$ не влияет на предсказание модели.\n",
        "\n",
        "### 4.1.2. Практическая реализация визуализации\n",
        "\n",
        "**Код 4.1**  \n",
        "Визуализация границы принятия решений и интерпретация весов модели\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Обучение модели на двумерных данных\n",
        "model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Получение параметров модели\n",
        "weights = model.coef_[0]  # Веса признаков\n",
        "intercept = model.intercept_[0]  # Свободный член\n",
        "\n",
        "print(\"Параметры обученной модели:\")\n",
        "print(f\"Коэффициент признака 1 (w₁): {weights[0]:.4f}\")\n",
        "print(f\"Коэффициент признака 2 (w₂): {weights[1]:.4f}\")\n",
        "print(f\"Свободный член (b): {intercept:.4f}\")\n",
        "\n",
        "# Интерпретация:\n",
        "# Уравнение границы: w₁x₁ + w₂x₂ + b = 0\n",
        "# При x₂ = 0: x₁ = -b/w₁\n",
        "# При x₁ = 0: x₂ = -b/w₂\n",
        "\n",
        "# Создание сетки для визуализации\n",
        "x1_min, x1_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
        "x2_min, x2_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
        "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, 200),\n",
        "                       np.linspace(x2_min, x2_max, 200))\n",
        "\n",
        "# Предсказание вероятностей для каждой точки сетки\n",
        "grid_points = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "probabilities = model.predict_proba(grid_points)[:, 1]\n",
        "zz = probabilities.reshape(xx1.shape)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10, 8))\n",
        "contour = plt.contourf(xx1, xx2, zz, alpha=0.2, levels=np.linspace(0, 1, 11),\n",
        "                      cmap='RdYlBu', extend='both')\n",
        "plt.colorbar(contour, label='P(y=1|x)')\n",
        "\n",
        "# Граница принятия решений (P=0.5)\n",
        "decision_boundary = plt.contour(xx1, xx2, zz, levels=[0.5], colors='k', linewidths=2)\n",
        "plt.clabel(decision_boundary, fmt='Граница: P=0.5', fontsize=10)\n",
        "\n",
        "# Обучающие данные\n",
        "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1],\n",
        "           c='blue', marker='o', label='Класс 0', alpha=0.7)\n",
        "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1],\n",
        "           c='red', marker='^', label='Класс 1', alpha=0.7)\n",
        "\n",
        "plt.title('Визуализация границы принятия решений логистической регрессии')\n",
        "plt.xlabel('Признак 1 (x₁)')\n",
        "plt.ylabel('Признак 2 (x₂)')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('decision_boundary.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Анализ направления границы\n",
        "slope = -weights[0] / weights[1]  # Наклон границы\n",
        "intercept_point = -intercept / weights[1]  # Точка пересечения с осью x₂ при x₁=0\n",
        "\n",
        "print(f\"\\nГеометрические характеристики границы:\")\n",
        "print(f\"Наклон границы (slope): {slope:.4f}\")\n",
        "print(f\"Точка пересечения с осью x₂: {intercept_point:.4f}\")\n",
        "\n",
        "# Пример расчета для конкретной точки\n",
        "example_point = np.array([1.5, 0.8])\n",
        "log_odds = weights[0]*example_point[0] + weights[1]*example_point[1] + intercept\n",
        "probability = 1 / (1 + np.exp(-log_odds))\n",
        "\n",
        "print(f\"\\nПример расчета для точки x = [{example_point[0]}, {example_point[1]}]:\")\n",
        "print(f\"Логарифм шансов: {log_odds:.4f}\")\n",
        "print(f\"Вероятность P(y=1|x): {probability:.4f}\")\n",
        "print(f\"Класс при θ=0.5: {'1' if probability >= 0.5 else '0'}\")\n",
        "```\n",
        "\n",
        "**Аналитические выводы из визуализации:**\n",
        "\n",
        "1. **Линейность границы**: прямолинейная форма границы подтверждает линейную природу логистической регрессии. Если классы демонстрируют сложную, нелинейную структуру (например, концентрические окружности или спирали), логистическая регрессия будет демонстрировать низкое качество классификации.\n",
        "\n",
        "2. **Направление нормали**: вектор весов $\\mathbf{w}$ перпендикулярен границе принятия решений и указывает направление увеличения вероятности принадлежности к положительному классу.\n",
        "\n",
        "3. **Положение границы**: свободный член $b$ определяет смещение границы относительно начала координат. Большое по модулю значение $b$ указывает на асимметричное распределение классов.\n",
        "\n",
        "4. **Степень уверенности**: контурные линии вероятности показывают, как быстро изменяется уверенность модели при удалении от границы принятия решений. Резкий переход указывает на высокую уверенность, плавный — на неопределенность в области границы.\n",
        "\n",
        "## 4.2. Диагностика остатков и согласия модели (Goodness-of-Fit)\n",
        "\n",
        "В отличие от линейной регрессии, где анализ остатков является стандартной процедурой, для логистической регрессии требуется специальный подход к диагностике, поскольку целевая переменная принимает только дискретные значения (0 или 1), а предсказания модели являются вероятностями в интервале $[0, 1]$.\n",
        "\n",
        "### 4.2.1. Проблемы классического анализа остатков\n",
        "\n",
        "Традиционные остатки для логистической регрессии определяются как:\n",
        "\n",
        "$$r_i = y_i - p_i$$\n",
        "\n",
        "где $y_i \\in \\{0, 1\\}$ — истинное значение, $p_i = P(y_i=1|\\mathbf{x}_i)$ — предсказанная вероятность. Однако такие остатки обладают рядом недостатков:\n",
        "- **Дискретность**: остатки принимают только два возможных значения для каждого класса: $1 - p_i$ для $y_i=1$ и $-p_i$ для $y_i=0$;\n",
        "- **Гетероскедастичность**: дисперсия остатков зависит от предсказанных вероятностей;\n",
        "- **Ненормальность**: распределение остатков существенно отличается от нормального.\n",
        "\n",
        "Эти особенности делают классический анализ остатков малоинформативным для логистической регрессии.\n",
        "\n",
        "### 4.2.2. Тест Хосмера-Лемешоу (Hosmer-Lemeshow Test)\n",
        "\n",
        "Тест Хосмера-Лемешоу представляет собой статистический тест, разработанный специально для оценки качества калибровки вероятностей в логистической регрессии. Тест основан на сравнении наблюдаемых и ожидаемых частот классов в группах, сформированных по предсказанным вероятностям.\n",
        "\n",
        "**Алгоритм проведения теста:**\n",
        "\n",
        "1. **Группировка наблюдений**: все наблюдения сортируются по предсказанным вероятностям $p_i$ и разделяются на $G$ групп (обычно $G = 10$), содержащих приблизительно равное количество наблюдений.\n",
        "\n",
        "2. **Расчет ожидаемых частот**: для каждой группы $g$ вычисляется сумма предсказанных вероятностей, которая представляет собой ожидаемое количество положительных исходов в группе:\n",
        "   $$E_g = \\sum_{i \\in g} p_i$$\n",
        "\n",
        "3. **Расчет наблюдаемых частот**: для каждой группы $g$ подсчитывается фактическое количество положительных исходов:\n",
        "   $$O_g = \\sum_{i \\in g} y_i$$\n",
        "\n",
        "4. **Вычисление статистики теста**: статистика Хосмера-Лемешоу рассчитывается как:\n",
        "   $$\\hat{C} = \\sum_{g=1}^{G} \\frac{(O_g - E_g)^2}{E_g(1 - \\bar{p}_g)}$$\n",
        "   где $\\bar{p}_g = \\frac{E_g}{n_g}$ — средняя предсказанная вероятность в группе $g$, $n_g$ — количество наблюдений в группе.\n",
        "\n",
        "5. **Определение p-value**: статистика $\\hat{C}$ асимптотически имеет $\\chi^2$-распределение с $(G-2)$ степенями свободы. Вычисляется p-value для проверки нулевой гипотезы о хорошем согласии модели.\n",
        "\n",
        "**Интерпретация результатов:**\n",
        "\n",
        "- **$p > 0.05$**: нет оснований отвергать нулевую гипотезу о хорошем согласии модели с данными. Предсказанные вероятности статистически согласуются с наблюдаемыми частотами.\n",
        "- **$p \\leq 0.05$**: отвергаем нулевую гипотезу. Модель демонстрирует плохую калибровку вероятностей, что требует корректировки спецификации модели.\n",
        "\n",
        "**Таблица 4.1**  \n",
        "Рекомендации по интерпретации результатов теста Хосмера-Лемешоу\n",
        "\n",
        "| p-value | Интерпретация согласия | Рекомендуемые действия |\n",
        "|---------|------------------------|------------------------|\n",
        "| $p > 0.05$ | Хорошее согласие модели с данными | Принять модель при условии удовлетворительных метрик производительности (AUC, F1) |\n",
        "| $0.01 < p \\leq 0.05$ | Умеренное несоответствие | Провести дополнительную диагностику, рассмотреть добавление нелинейных членов или взаимодействий признаков |\n",
        "| $p \\leq 0.01$ | Сильное несоответствие | Требуется существенная переработка модели: добавление полиномиальных признаков, трансформация переменных или переход к нелинейным моделям |\n",
        "\n",
        "**Критические замечания по тесту Хосмера-Лемешоу:**\n",
        "- Чувствительность к методу группировки и количеству групп $G$;\n",
        "- Низкая мощность при малых размерах выборки;\n",
        "- Неинформативность при очень больших выборках, где даже незначительные отклонения могут быть статистически значимыми;\n",
        "- Требует дополнения визуальными методами диагностики.\n",
        "\n",
        "### 4.2.3. Визуальная диагностика калибровки\n",
        "\n",
        "Визуальная инспекция кривой калибровки (reliability curve) предоставляет более интуитивно понятный и информативный способ оценки калибровки вероятностей по сравнению с формальным тестом.\n",
        "\n",
        "**Код 4.2**  \n",
        "Визуальная диагностика калибровки модели\n",
        "\n",
        "```python\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Расчет кривой калибровки\n",
        "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "    y_test, y_prob, n_bins=10, strategy='uniform'\n",
        ")\n",
        "\n",
        "# Создание DataFrame для анализа\n",
        "calibration_df = pd.DataFrame({\n",
        "    'Номер бина': range(1, 11),\n",
        "    'Средняя предсказанная вероятность': mean_predicted_value.round(3),\n",
        "    'Фактическая доля положительных': fraction_of_positives.round(3),\n",
        "    'Разница (Факт - Предсказано)': (fraction_of_positives - mean_predicted_value).round(3)\n",
        "})\n",
        "\n",
        "print(\"\\nТаблица калибровки (10 бинов):\")\n",
        "print(calibration_df.to_string(index=False))\n",
        "\n",
        "# Визуализация кривой калибровки\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Идеальная калибровка (диагональ)\n",
        "plt.plot([0, 1], [0, 1], \"k:\", label=\"Идеальная калибровка\")\n",
        "\n",
        "# Эмпирическая кривая калибровки\n",
        "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", color='blue',\n",
        "         label=f\"Логистическая регрессия (Brier: {brier_score:.3f})\")\n",
        "\n",
        "# Заполнение области между кривыми для визуализации отклонений\n",
        "plt.fill_between(mean_predicted_value, fraction_of_positives, mean_predicted_value,\n",
        "                alpha=0.3, color='blue', label='Область отклонения')\n",
        "\n",
        "# Гистограмма распределения предсказанных вероятностей\n",
        "hist, bin_edges = np.histogram(y_prob, bins=10, range=(0, 1), density=True)\n",
        "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "plt.bar(bin_centers, hist * 0.05, width=0.08, alpha=0.5, color='gray',\n",
        "        label='Плотность предсказаний', align='center')\n",
        "\n",
        "plt.xlabel('Средняя предсказанная вероятность', fontsize=12)\n",
        "plt.ylabel('Фактическая доля положительных классов', fontsize=12)\n",
        "plt.title('Кривая калибровки и распределение вероятностей', fontsize=14)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('calibration_curve.png', dpi=300)\n",
        "\n",
        "# Дополнительная визуализация: калибровочная карта (Calibration Map)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Левый график: отклонения по бинам\n",
        "plt.subplot(1, 2, 1)\n",
        "deviations = fraction_of_positives - mean_predicted_value\n",
        "colors = ['red' if d < 0 else 'green' for d in deviations]\n",
        "plt.bar(range(1, 11), deviations, color=colors, alpha=0.7)\n",
        "plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "plt.xlabel('Номер бина (по возрастанию вероятности)')\n",
        "plt.ylabel('Отклонение (Фактическая - Предсказанная)')\n",
        "plt.title('Отклонения калибровки по бинам')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Правый график: детальный анализ бинов\n",
        "plt.subplot(1, 2, 2)\n",
        "bin_counts = [sum((y_prob >= bin_edges[i]) & (y_prob < bin_edges[i+1])) for i in range(10)]\n",
        "plt.bar(range(1, 11), bin_counts, alpha=0.7, color='purple')\n",
        "plt.xlabel('Номер бина')\n",
        "plt.ylabel('Количество наблюдений')\n",
        "plt.title('Распределение наблюдений по бинам')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('calibration_analysis.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Расчет Brier Score как количественной меры калибровки\n",
        "brier_score = np.mean((y_prob - y_test) ** 2)\n",
        "print(f\"\\nBrier Score (мера калибровки): {brier_score:.4f}\")\n",
        "print(\"Интерпретация Brier Score:\")\n",
        "print(\"- 0.0: идеальная калибровка\")\n",
        "print(\"- 0.0-0.1: отличная калибровка\")\n",
        "print(\"- 0.1-0.2: хорошая калибровка\")\n",
        "print(\"- 0.2-0.3: удовлетворительная калибровка\")\n",
        "print(\"- >0.3: плохая калибровка\")\n",
        "```\n",
        "\n",
        "**Интерпретация кривой калибровки:**\n",
        "\n",
        "1. **Идеальная калибровка**: точки лежат на диагональной линии $y = x$, что означает полное соответствие предсказанных вероятностей и фактических частот.\n",
        "\n",
        "2. **S-образная кривая**: характерный признак переобучения — модель слишком уверена в своих предсказаниях (предсказывает вероятности близкие к 0 или 1), но фактические частоты более умеренные.\n",
        "\n",
        "3. **Инвертированная S-образная кривая**: признак недообучения — модель недостаточно уверена в своих предсказаниях (вероятности скучены около 0.5), хотя фактические частоты показывают более четкое разделение.\n",
        "\n",
        "4. **Локальные отклонения**: могут указывать на проблемы с конкретными подмножествами данных или на наличие неучтенных взаимодействий признаков.\n",
        "\n",
        "**Brier Score** как количественная мера калибровки:\n",
        "$$BS = \\frac{1}{N}\\sum_{i=1}^{N}(p_i - y_i)^2$$\n",
        "где $p_i$ — предсказанная вероятность, $y_i$ — истинная метка. Brier Score является среднеквадратичной ошибкой для вероятностных предсказаний и принимает значения от 0 (идеальная калибровка) до 1 (максимальное несоответствие).\n",
        "\n",
        "## 4.3. Комплексная оценка и интерпретация модели\n",
        "\n",
        "### 4.3.1. Интегрированный подход к оценке\n",
        "\n",
        "Эффективная оценка модели логистической регрессии требует комплексного подхода, объединяющего:\n",
        "\n",
        "1. **Метрики производительности**:\n",
        "   - ROC AUC для оценки способности ранжировать объекты\n",
        "   - F1-Score для баланса между precision и recall\n",
        "   - PR AUC для задач с дисбалансом классов\n",
        "\n",
        "2. **Метрики калибровки**:\n",
        "   - Тест Хосмера-Лемешоу для статистической оценки\n",
        "   - Кривая калибровки для визуального анализа\n",
        "   - Brier Score для количественной оценки\n",
        "\n",
        "3. **Интерпретация коэффициентов**:\n",
        "   - Статистическая значимость коэффициентов (p-value)\n",
        "   - Доверительные интервалы\n",
        "   - Шансы (odds ratio) для практических интерпретаций\n",
        "\n",
        "### 4.3.2. Практическая интерпретация коэффициентов\n",
        "\n",
        "Для интерпретации результатов логистической регрессии в прикладных задачах часто используют **отношение шансов** (odds ratio):\n",
        "\n",
        "$$OR_j = e^{w_j}$$\n",
        "\n",
        "Отношение шансов $OR_j$ интерпретируется как множитель, на который изменяются шансы принадлежности к положительному классу при увеличении признака $x_j$ на единицу при фиксированных значениях остальных признаков.\n",
        "\n",
        "Например, если для признака \"возраст\" коэффициент $w_j = 0.2$, то $OR_j = e^{0.2} \\approx 1.22$, что означает: увеличение возраста на 1 год увеличивает шансы принадлежности к положительному классу в 1.22 раза (или на 22%).\n",
        "\n",
        "**Код 4.3**  \n",
        "Расчет и визуализация отношения шансов с доверительными интервалами\n",
        "\n",
        "```python\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Обучение модели с использованием statsmodels для получения статистик\n",
        "X_train_sm = sm.add_constant(X_train)  # Добавление константы для intercept\n",
        "logit_model = sm.Logit(y_train, X_train_sm)\n",
        "result = logit_model.fit(disp=False)\n",
        "\n",
        "# Получение коэффициентов и их доверительных интервалов\n",
        "coefficients = result.params\n",
        "conf_int = result.conf_int()\n",
        "p_values = result.pvalues\n",
        "\n",
        "# Расчет отношения шансов и доверительных интервалов\n",
        "odds_ratios = np.exp(coefficients)\n",
        "conf_int_odds = np.exp(conf_int)\n",
        "\n",
        "# Создание DataFrame для отображения\n",
        "results_df = pd.DataFrame({\n",
        "    'Коэффициент': coefficients,\n",
        "    'Отношение шансов (OR)': odds_ratios,\n",
        "    'Нижняя граница 95% ДИ': conf_int_odds.iloc[:, 0],\n",
        "    'Верхняя граница 95% ДИ': conf_int_odds.iloc[:, 1],\n",
        "    'p-value': p_values\n",
        "})\n",
        "\n",
        "print(\"\\nСтатистические результаты логистической регрессии:\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Визуализация отношения шансов с доверительными интервалами\n",
        "plt.figure(figsize=(10, 6))\n",
        "features = ['Константа', 'Признак 1', 'Признак 2']  # Названия признаков\n",
        "\n",
        "# Фильтрация значимых коэффициентов (p < 0.05)\n",
        "significant_mask = p_values < 0.05\n",
        "significant_features = [features[i] for i, sig in enumerate(significant_mask) if sig]\n",
        "significant_or = [odds_ratios[i] for i, sig in enumerate(significant_mask) if sig]\n",
        "significant_ci_lower = [conf_int_odds.iloc[i, 0] for i, sig in enumerate(significant_mask) if sig]\n",
        "significant_ci_upper = [conf_int_odds.iloc[i, 1] for i, sig in enumerate(significant_mask) if sig]\n",
        "\n",
        "y_pos = range(len(significant_features))\n",
        "plt.errorbar(significant_or, y_pos,\n",
        "             xerr=[np.array(significant_or)-np.array(significant_ci_lower),\n",
        "                   np.array(significant_ci_upper)-np.array(significant_or)],\n",
        "             fmt='o', color='blue', capsize=5, elinewidth=2)\n",
        "\n",
        "plt.axvline(x=1, color='red', linestyle='--', alpha=0.7, label='Нейтральная линия (OR=1)')\n",
        "plt.yticks(y_pos, significant_features)\n",
        "plt.xlabel('Отношение шансов (OR) с 95% доверительным интервалом')\n",
        "plt.title('Значимые предикторы с доверительными интервалами')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('odds_ratios.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Интерпретация значимых коэффициентов\n",
        "print(\"\\nИнтерпретация значимых предикторов (p < 0.05):\")\n",
        "for i, feature in enumerate(features):\n",
        "    if p_values[i] < 0.05:\n",
        "        or_val = odds_ratios[i]\n",
        "        direction = \"увеличивает\" if or_val > 1 else \"уменьшает\"\n",
        "        percent_change = abs(or_val - 1) * 100\n",
        "        print(f\"- {feature}: отношение шансов = {or_val:.2f} (95% ДИ: [{conf_int_odds.iloc[i, 0]:.2f}, {conf_int_odds.iloc[i, 1]:.2f}])\")\n",
        "        print(f\"  Увеличение {feature.lower()} на единицу {direction} шансы в {or_val:.2f} раза ({percent_change:.1f}%)\\n\")\n",
        "```\n",
        "\n",
        "## 4.4. Преимущества и ограничения логистической регрессии\n",
        "\n",
        "### 4.4.1. Фундаментальные преимущества\n",
        "\n",
        "1. **Статистическая обоснованность**: Логистическая регрессия имеет прочную теоретическую базу в математической статистике, включая метод максимального правдоподобия и асимптотическую теорию оценок.\n",
        "\n",
        "2. **Интерпретируемость**: Коэффициенты модели имеют четкую статистическую интерпретацию в терминах логарифма шансов и отношения шансов, что критически важно в регулируемых отраслях (медицина, финансы, страхование).\n",
        "\n",
        "3. **Вычислительная эффективность**: Алгоритмы обучения логистической регрессии (L-BFGS, координатный спуск) обладают высокой вычислительной эффективностью и масштабируемостью, особенно по сравнению с более сложными моделями.\n",
        "\n",
        "4. **Гарантии сходимости**: При использовании подходящих оптимизаторов и регуляризации процесс обучения имеет гарантии сходимости к глобальному оптимуму благодаря выпуклости функции потерь.\n",
        "\n",
        "5. **Робастность к шуму**: L2-регуляризация обеспечивает устойчивость модели к выбросам и шуму в данных.\n",
        "\n",
        "### 4.4.2. Критические ограничения\n",
        "\n",
        "1. **Линейная разделимость**: Фундаментальное ограничение логистической регрессии — предположение о линейной разделимости классов в признаковом пространстве. Для данных с нелинейными зависимостями качество модели будет ограничено.\n",
        "\n",
        "2. **Зависимость от предобработки**: Эффективность модели существенно зависит от качества предобработки данных:\n",
        "   - Требуется обработка пропущенных значений\n",
        "   - Необходима нормализация/стандартизация признаков\n",
        "   - Требуется преобразование категориальных переменных\n",
        "   - Важна проверка на мультиколлинеарность\n",
        "\n",
        "3. **Ограниченная способность к автоматическому отбору признаков**: Хотя L1-регуляризация обеспечивает некоторую селективность признаков, логистическая регрессия не обладает встроенной способностью к автоматическому созданию высокоуровневых признаков.\n",
        "\n",
        "4. **Чувствительность к дисбалансу классов**: Без специальных методов корректировки (веса классов, сэмплинг) модель склонна к смещению в сторону доминирующего класса.\n",
        "\n",
        "5. **Требования к размеру выборки**: Для получения статистически значимых оценок коэффициентов требуется достаточный размер выборки, особенно при большом количестве признаков.\n",
        "\n",
        "## 4.5. Стратегии расширения возможностей логистической регрессии\n",
        "\n",
        "### 4.5.1. Инженерия признаков для нелинейности\n",
        "\n",
        "Для преодоления ограничения линейной разделимости применяются методы инженерии признаков:\n",
        "\n",
        "1. **Полиномиальные признаки**: создание взаимодействий признаков и полиномиальных членов:\n",
        "   $$\\mathbf{x}_{\\text{new}} = [x_1, x_2, x_1^2, x_2^2, x_1x_2]^T$$\n",
        "\n",
        "2. **Сплайны**: использование кусочно-полиномиальных функций для гибкого моделирования нелинейных зависимостей.\n",
        "\n",
        "3. **Дискретизация**: преобразование непрерывных признаков в категориальные бины.\n",
        "\n",
        "4. **Ядерные методы**: применение ядерных преобразований для проецирования данных в пространство большей размерности.\n",
        "\n",
        "### 4.5.2. Когда следует рассматривать альтернативные модели\n",
        "\n",
        "Переход к более сложным моделям оправдан в следующих сценариях:\n",
        "\n",
        "**Таблица 4.2**  \n",
        "Критерии выбора альтернативных моделей вместо логистической регрессии\n",
        "\n",
        "| Критерий | Признак необходимости смены модели | Рекомендуемые альтернативы |\n",
        "|----------|-----------------------------------|--------------------------|\n",
        "| **Нелинейная разделимость** | Визуализация показывает сложную границу; ROC AUC < 0.7 при хорошем HL-тесте | SVM с ядром, Random Forest, Gradient Boosting, Нейронные сети |\n",
        "| **Высокая размерность** | Количество признаков >> количество наблюдений; высокая мультиколлинеарность | Lasso-регрессия, PCA + LR, Random Forest |\n",
        "| **Сложные взаимодействия** | Значимые взаимодействия в спецификации; плохая калибровка после добавления полиномов | Gradient Boosting, Random Forest, Нейронные сети |\n",
        "| **Автоматическая обработка признаков** | Требуется минимальная предобработка; много категориальных переменных | CatBoost, LightGBM, Random Forest |\n",
        "| **Максимальная производительность** | Требуется достижение максимального ROC AUC/PR AUC; интерпретируемость вторична | Ensemble methods, Глубокое обучение |\n",
        "\n",
        "### 4.5.3. Гибридные подходы\n",
        "\n",
        "Современная практика часто использует гибридные подходы, сочетающие преимущества логистической регрессии и более сложных моделей:\n",
        "\n",
        "1. **Использование эмбеддингов**: применение нейронных сетей для создания эмбеддингов признаков с последующим обучением логистической регрессии на этих представлениях.\n",
        "\n",
        "2. **Каскадные модели**: использование мощных моделей (Gradient Boosting) для автоматической инженерии признаков с последующим применением логистической регрессии для финальной классификации и интерпретации.\n",
        "\n",
        "3. **Оценка неопределенности**: применение байесовских методов для логистической регрессии, обеспечивающих не только точечные оценки, но и доверительные интервалы для предсказаний.\n",
        "\n",
        "## 4.6. Заключение главы\n",
        "\n",
        "Логистическая регрессия представляет собой фундаментальный инструмент в арсенале специалиста по данным, сочетающий статистическую строгость, вычислительную эффективность и интерпретируемость. Однако ее эффективное применение требует глубокого понимания как теоретических основ, так и практических аспектов диагностики и интерпретации.\n",
        "\n",
        "Ключевые принципы успешного применения логистической регрессии включают:\n",
        "- Систематическую диагностику калибровки вероятностей с использованием теста Хосмера-Лемешоу и визуальных методов;\n",
        "- Комплексную оценку качества с использованием как метрик ранжирования (ROC AUC), так и метрик классификации (F1-Score);\n",
        "- Статистически обоснованную интерпретацию коэффициентов с учетом доверительных интервалов и p-value;\n",
        "- Понимание ограничений модели и критериев перехода к более сложным алгоритмам.\n",
        "\n",
        "В условиях современных задач анализа данных логистическая регрессия часто служит не только самостоятельным инструментом, но и компонентом более сложных ансамблевых моделей или базой для разработки интерпретируемых гибридных подходов. Ее роль как \"золотого стандарта\" для бинарной классификации сохраняется благодаря уникальному сочетанию математической элегантности, вычислительной эффективности и практических свойств.\n",
        "\n",
        "При переходе к следующим главам, посвященным ансамблевым методам и глубокому обучению, понимание принципов логистической регрессии будет служить основой для освоения более сложных концепций машинного обучения."
      ],
      "metadata": {
        "id": "thKdhn-tBlde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Комплексная система бинарной классификации на основе логистической регрессии.\n",
        "Реализует все теоретические концепции из лекции в объектно-ориентированном стиле.\n",
        "\n",
        "Архитектура системы:\n",
        "1. BinaryClassifier - основной класс классификатора\n",
        "2. DataManager - управление данными и предобработка\n",
        "3. ModelEvaluator - комплексная оценка модели\n",
        "4. Visualizer - визуализация результатов\n",
        "5. TextProcessor - обработка текстовых данных\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, log_loss, precision_recall_curve,\n",
        "    roc_curve, average_precision_score, classification_report\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "from scipy import sparse\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DataManager:\n",
        "    \"\"\"Класс для управления данными и предобработки\"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.vectorizer = None\n",
        "        self.is_fitted = False\n",
        "\n",
        "    def create_synthetic_dataset(self, n_samples=1000, n_features=2, weights=[0.8, 0.2],\n",
        "                               n_informative=2, flip_y=0.05, **kwargs):\n",
        "        \"\"\"\n",
        "        Создание синтетического датасета для бинарной классификации\n",
        "        \"\"\"\n",
        "        X, y = make_classification(\n",
        "            n_samples=n_samples,\n",
        "            n_features=n_features,\n",
        "            n_informative=n_informative,\n",
        "            n_redundant=n_features - n_informative,\n",
        "            n_clusters_per_class=1,\n",
        "            weights=weights,\n",
        "            flip_y=flip_y,\n",
        "            random_state=self.random_state,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.feature_names = [f'Feature_{i}' for i in range(n_features)]\n",
        "\n",
        "        print(f\"Создан синтетический датасет: {X.shape}\")\n",
        "        print(f\"Распределение классов: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_text_dataset(self):\n",
        "        \"\"\"Создание учебного датасета для анализа тональности на русском\"\"\"\n",
        "        data = {\n",
        "            'text': [\n",
        "                \"Отличный фильм! Восхитительная игра актёров и захватывающий сюжет.\",\n",
        "                \"Ужасный сервис. Потерял деньги и время, больше не обращусь.\",\n",
        "                \"Очень вкусно и быстро! Обязательно закажу снова.\",\n",
        "                \"Заказ не привезли, связь с поддержкой отсутствует.\",\n",
        "                \"Чисто, уютно, персонал вежливый — всё на высшем уровне.\",\n",
        "                \"Товар пришёл сломанным, возврат невозможен.\",\n",
        "                \"Прекрасное качество, быстрая доставка, всем доволен!\",\n",
        "                \"Никогда не сталкивался с таким плохим обслуживанием.\",\n",
        "                \"Отличное соотношение цены и качества, рекомендую!\",\n",
        "                \"Очень разочарован, не соответствует описанию.\",\n",
        "                \"Быстро, качественно, профессионально!\",\n",
        "                \"Ужасное качество, деньги на ветер.\",\n",
        "                \"Восторг! Превзошло все ожидания.\",\n",
        "                \"Не рекомендую, полный разочарование.\",\n",
        "                \"Отличный сервис, приятно удивлен!\"\n",
        "            ],\n",
        "            'sentiment': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "        }\n",
        "\n",
        "        self.text_data = pd.DataFrame(data)\n",
        "        self.X_text = self.text_data['text'].values\n",
        "        self.y_text = self.text_data['sentiment'].values\n",
        "\n",
        "        print(\"Создан текстовый датасет для анализа тональности\")\n",
        "        print(f\"Размер: {len(self.X_text)} текстов\")\n",
        "        print(f\"Распределение: {np.bincount(self.y_text)}\")\n",
        "\n",
        "        return self.X_text, self.y_text\n",
        "\n",
        "    def prepare_numeric_data(self, X, y, test_size=0.3, scale=True):\n",
        "        \"\"\"Подготовка числовых данных\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        if scale:\n",
        "            X_train = self.scaler.fit_transform(X_train)\n",
        "            X_test = self.scaler.transform(X_test)\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.is_fitted = True\n",
        "\n",
        "        print(f\"Данные разделены: train {X_train.shape}, test {X_test.shape}\")\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def prepare_text_data(self, X, y, test_size=0.3, max_features=100):\n",
        "        \"\"\"Подготовка текстовых данных\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=max_features,\n",
        "            ngram_range=(1, 2),\n",
        "            stop_words=['и', 'в', 'на', 'с', 'по', 'для', 'к', 'не', 'что', 'это'],\n",
        "            min_df=1,\n",
        "            max_df=0.8\n",
        "        )\n",
        "\n",
        "        X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
        "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
        "\n",
        "        self.X_train = X_train_tfidf\n",
        "        self.X_test = X_test_tfidf\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.is_fitted = True\n",
        "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
        "\n",
        "        print(f\"Текстовые данные преобразованы: train {X_train_tfidf.shape}, test {X_test_tfidf.shape}\")\n",
        "        return X_train_tfidf, X_test_tfidf, y_train, y_test\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Класс для комплексной оценки модели\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics_history = []\n",
        "\n",
        "    def calculate_all_metrics(self, y_true, y_pred, y_prob):\n",
        "        \"\"\"Расчет всех метрик качества\"\"\"\n",
        "        # Базовые метрики\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "        # Матрица ошибок\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        # Вероятностные метрики\n",
        "        logloss = log_loss(y_true, y_prob)\n",
        "        roc_auc = roc_auc_score(y_true, y_prob)\n",
        "        pr_auc = average_precision_score(y_true, y_prob)\n",
        "\n",
        "        # MCC (Matthews Correlation Coefficient)\n",
        "        mcc_numerator = (tp * tn) - (fp * fn)\n",
        "        mcc_denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "        mcc = mcc_numerator / mcc_denominator if mcc_denominator != 0 else 0\n",
        "\n",
        "        metrics = {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'specificity': specificity,\n",
        "            'log_loss': logloss,\n",
        "            'roc_auc': roc_auc,\n",
        "            'pr_auc': pr_auc,\n",
        "            'mcc': mcc,\n",
        "            'confusion_matrix': cm,\n",
        "            'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
        "        }\n",
        "\n",
        "        self.metrics_history.append(metrics)\n",
        "        return metrics\n",
        "\n",
        "    def find_optimal_threshold(self, y_true, y_prob, metric='f1_score'):\n",
        "        \"\"\"Поиск оптимального порога по заданной метрике\"\"\"\n",
        "        thresholds = np.linspace(0.1, 0.9, 50)\n",
        "        metric_values = []\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "            if metric == 'f1_score':\n",
        "                score = f1_score(y_true, y_pred)\n",
        "            elif metric == 'precision':\n",
        "                score = precision_score(y_true, y_pred)\n",
        "            elif metric == 'recall':\n",
        "                score = recall_score(y_true, y_pred)\n",
        "            elif metric == 'accuracy':\n",
        "                score = accuracy_score(y_true, y_pred)\n",
        "            else:\n",
        "                raise ValueError(\"Метрика должна быть: 'f1_score', 'precision', 'recall', 'accuracy'\")\n",
        "\n",
        "            metric_values.append(score)\n",
        "\n",
        "        optimal_idx = np.argmax(metric_values)\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "        optimal_score = metric_values[optimal_idx]\n",
        "\n",
        "        return optimal_threshold, optimal_score, thresholds, metric_values\n",
        "\n",
        "class Visualizer:\n",
        "    \"\"\"Класс для визуализации результатов\"\"\"\n",
        "\n",
        "    def __init__(self, figsize=(10, 8)):\n",
        "        self.figsize = figsize\n",
        "        plt.style.use('default')\n",
        "        sns.set_palette(\"husl\")\n",
        "\n",
        "    def plot_decision_boundary(self, model, X, y, title=\"Граница принятия решений\"):\n",
        "        \"\"\"Визуализация границы принятия решений для 2D данных\"\"\"\n",
        "        if X.shape[1] != 2:\n",
        "            raise ValueError(\"Визуализация возможна только для 2 признаков\")\n",
        "\n",
        "        # Создание сетки\n",
        "        x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "        y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
        "                            np.linspace(y_min, y_max, 200))\n",
        "\n",
        "        # Предсказание вероятностей\n",
        "        grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "        if hasattr(model, 'scaler') and not sparse.issparse(grid_points):\n",
        "            grid_points = model.scaler.transform(grid_points)\n",
        "        Z = model.predict_proba(grid_points)[:, 1]\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "        # Построение графика\n",
        "        fig, ax = plt.subplots(figsize=self.figsize)\n",
        "\n",
        "        # Контур вероятностей\n",
        "        contour = ax.contourf(xx, yy, Z, alpha=0.8, levels=50, cmap='RdYlBu')\n",
        "        plt.colorbar(contour, ax=ax, label='P(y=1|x)')\n",
        "\n",
        "        # Граница принятия решений\n",
        "        decision_boundary = ax.contour(xx, yy, Z, levels=[model.threshold],\n",
        "                                     colors='black', linewidths=2)\n",
        "        ax.clabel(decision_boundary, fmt=f'P={model.threshold}', fontsize=12)\n",
        "\n",
        "        # Данные\n",
        "        scatter = ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k',\n",
        "                           cmap='RdYlBu', alpha=0.8, s=60)\n",
        "\n",
        "        ax.set_xlabel('Признак 1', fontsize=12)\n",
        "        ax.set_ylabel('Признак 2', fontsize=12)\n",
        "        ax.set_title(title, fontsize=14)\n",
        "        ax.grid(alpha=0.3)\n",
        "        ax.legend(*scatter.legend_elements(), title=\"Классы\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_metrics_comparison(self, metrics_dict, title=\"Сравнение метрик\"):\n",
        "        \"\"\"Сравнение метрик разных моделей\"\"\"\n",
        "        metrics_df = pd.DataFrame(metrics_dict).T\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        axes = axes.ravel()\n",
        "\n",
        "        metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "        titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "        for idx, (metric, title_ax) in enumerate(zip(metrics_to_plot, titles)):\n",
        "            if metric in metrics_df.columns:\n",
        "                axes[idx].bar(metrics_df.index, metrics_df[metric])\n",
        "                axes[idx].set_title(title_ax)\n",
        "                axes[idx].set_ylabel('Значение')\n",
        "                axes[idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "                # Добавление значений на столбцы\n",
        "                for i, v in enumerate(metrics_df[metric]):\n",
        "                    axes[idx].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "        plt.suptitle(title, fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "class BinaryClassifier:\n",
        "    \"\"\"\n",
        "    Основной класс для бинарной классификации с использованием логистической регрессии.\n",
        "    Реализует все теоретические концепции из лекции.\n",
        "    \"\"\"\n",
        "\n",
        "    SOLVER_COMPATIBILITY = {\n",
        "        'liblinear': ['l1', 'l2'],\n",
        "        'lbfgs': ['l2', None],\n",
        "        'newton-cg': ['l2', None],\n",
        "        'sag': ['l2', None],\n",
        "        'saga': ['l1', 'l2', 'elasticnet', None]\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 penalty='l2',\n",
        "                 C=1.0,\n",
        "                 solver='lbfgs',\n",
        "                 class_weight=None,\n",
        "                 max_iter=1000,\n",
        "                 random_state=42,\n",
        "                 threshold=0.5):\n",
        "        \"\"\"\n",
        "        Инициализация классификатора\n",
        "        \"\"\"\n",
        "        self.penalty = penalty\n",
        "        self.C = C\n",
        "        self.solver = solver\n",
        "        self.class_weight = class_weight\n",
        "        self.max_iter = max_iter\n",
        "        self.random_state = random_state\n",
        "        self.threshold = threshold\n",
        "\n",
        "        self._validate_parameters()\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.is_fitted = False\n",
        "\n",
        "        # Инициализация компонентов системы\n",
        "        self.data_manager = DataManager(random_state=random_state)\n",
        "        self.evaluator = ModelEvaluator()\n",
        "        self.visualizer = Visualizer()\n",
        "\n",
        "    def _validate_parameters(self):\n",
        "        \"\"\"Валидация параметров модели\"\"\"\n",
        "        if self.penalty not in [None, 'l1', 'l2', 'elasticnet']:\n",
        "            raise ValueError(f\"penalty должен быть None, 'l1', 'l2' или 'elasticnet', получен {self.penalty}\")\n",
        "\n",
        "        if self.solver not in self.SOLVER_COMPATIBILITY:\n",
        "            raise ValueError(f\"Неподдерживаемый solver: {self.solver}\")\n",
        "\n",
        "        if self.penalty not in self.SOLVER_COMPATIBILITY[self.solver]:\n",
        "            compatible = self.SOLVER_COMPATIBILITY[self.solver]\n",
        "            raise ValueError(f\"Solver '{self.solver}' не поддерживает penalty '{self.penalty}'. \"\n",
        "                           f\"Допустимые значения: {compatible}\")\n",
        "\n",
        "    def _create_model(self):\n",
        "        \"\"\"Создание модели логистической регрессии\"\"\"\n",
        "        return LogisticRegression(\n",
        "            penalty=self.penalty,\n",
        "            C=self.C,\n",
        "            solver=self.solver,\n",
        "            class_weight=self.class_weight,\n",
        "            max_iter=self.max_iter,\n",
        "            random_state=self.random_state,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Обучение модели\n",
        "        \"\"\"\n",
        "        # Валидация входных данных\n",
        "        y = np.array(y)\n",
        "        if not np.array_equal(np.unique(y), [0, 1]):\n",
        "            raise ValueError(\"Целевые переменные должны быть 0 и 1\")\n",
        "\n",
        "        self.feature_names = feature_names\n",
        "        self.classes_ = np.unique(y)\n",
        "\n",
        "        # Стандартизация только для плотных числовых данных\n",
        "        if not sparse.issparse(X) and hasattr(X, 'shape') and len(X.shape) == 2:\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "        else:\n",
        "            X_scaled = X  # для текстовых данных или sparse матриц\n",
        "\n",
        "        # Обучение модели\n",
        "        self.model = self._create_model()\n",
        "        self.model.fit(X_scaled, y)\n",
        "        self.is_fitted = True\n",
        "\n",
        "        print(f\"Модель обучена. Коэффициенты: {self.model.coef_.shape}\")\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Предсказание классов\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "\n",
        "        if not sparse.issparse(X) and hasattr(X, 'shape') and len(X.shape) == 2:\n",
        "            X = self.scaler.transform(X)\n",
        "\n",
        "        probabilities = self.model.predict_proba(X)[:, 1]\n",
        "        return (probabilities >= self.threshold).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Предсказание вероятностей\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "\n",
        "        if not sparse.issparse(X) and hasattr(X, 'shape') and len(X.shape) == 2:\n",
        "            X = self.scaler.transform(X)\n",
        "\n",
        "        return self.model.predict_proba(X)\n",
        "\n",
        "    def set_threshold(self, threshold):\n",
        "        \"\"\"Установка порога классификации\"\"\"\n",
        "        if not 0 <= threshold <= 1:\n",
        "            raise ValueError(\"Порог должен быть в диапазоне [0, 1]\")\n",
        "        self.threshold = threshold\n",
        "        print(f\"Порог классификации установлен: {threshold}\")\n",
        "\n",
        "    def evaluate(self, X, y_true, verbose=True):\n",
        "        \"\"\"Комплексная оценка модели\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "\n",
        "        y_pred = self.predict(X)\n",
        "        y_prob = self.predict_proba(X)[:, 1]\n",
        "\n",
        "        metrics = self.evaluator.calculate_all_metrics(y_true, y_pred, y_prob)\n",
        "\n",
        "        if verbose:\n",
        "            self._print_evaluation_report(metrics, y_true, y_pred, y_prob)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _print_evaluation_report(self, metrics, y_true, y_pred, y_prob):\n",
        "        \"\"\"Вывод отчета об оценке модели\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"КОМПЛЕКСНАЯ ОЦЕНКА МОДЕЛИ\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Матрица ошибок\n",
        "        cm = metrics['confusion_matrix']\n",
        "        print(f\"\\nМатрица ошибок:\")\n",
        "        print(f\"                Предсказано 0   Предсказано 1\")\n",
        "        print(f\"Фактически 0     {cm[0,0]:<14} {cm[0,1]:<14}\")\n",
        "        print(f\"Фактически 1     {cm[1,0]:<14} {cm[1,1]:<14}\")\n",
        "\n",
        "        # Основные метрики\n",
        "        print(f\"\\nОсновные метрики:\")\n",
        "        print(f\"Accuracy:    {metrics['accuracy']:.4f}\")\n",
        "        print(f\"Precision:   {metrics['precision']:.4f}\")\n",
        "        print(f\"Recall:      {metrics['recall']:.4f}\")\n",
        "        print(f\"F1-Score:    {metrics['f1_score']:.4f}\")\n",
        "        print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
        "        print(f\"MCC:         {metrics['mcc']:.4f}\")\n",
        "\n",
        "        # Вероятностные метрики\n",
        "        print(f\"\\nВероятностные метрики:\")\n",
        "        print(f\"ROC AUC:     {metrics['roc_auc']:.4f}\")\n",
        "        print(f\"PR AUC:      {metrics['pr_auc']:.4f}\")\n",
        "        print(f\"Log Loss:    {metrics['log_loss']:.4f}\")\n",
        "\n",
        "        # Анализ порога\n",
        "        optimal_threshold, optimal_f1, _, _ = self.evaluator.find_optimal_threshold(y_true, y_prob)\n",
        "        print(f\"\\nАнализ порога:\")\n",
        "        print(f\"Текущий порог: {self.threshold:.3f} (F1 = {metrics['f1_score']:.4f})\")\n",
        "        print(f\"Оптимальный порог: {optimal_threshold:.3f} (F1 = {optimal_f1:.4f})\")\n",
        "\n",
        "    def interpret_coefficients(self, top_n=10):\n",
        "        \"\"\"Интерпретация коэффициентов модели\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "\n",
        "        if self.feature_names is None:\n",
        "            if hasattr(self.model, 'coef_'):\n",
        "                n_features = len(self.model.coef_[0])\n",
        "                self.feature_names = [f'Feature_{i}' for i in range(n_features)]\n",
        "            else:\n",
        "                print(\"Модель не имеет коэффициентов для интерпретации\")\n",
        "                return None\n",
        "\n",
        "        coef_df = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'coefficient': self.model.coef_[0],\n",
        "            'abs_coefficient': np.abs(self.model.coef_[0]),\n",
        "            'odds_ratio': np.exp(self.model.coef_[0])\n",
        "        }).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "        print(\"=\" * 50)\n",
        "        print(\"ИНТЕРПРЕТАЦИЯ КОЭФФИЦИЕНТОВ\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        print(f\"\\nТоп-{top_n} наиболее важных признаков:\")\n",
        "        print(coef_df.head(top_n).to_string(index=False))\n",
        "\n",
        "        positive_coef = coef_df[coef_df['coefficient'] > 0].head()\n",
        "        if len(positive_coef) > 0:\n",
        "            print(f\"\\nТоп-{len(positive_coef)} признаков, увеличивающих вероятность класса 1:\")\n",
        "            for _, row in positive_coef.iterrows():\n",
        "                print(f\"  {row['feature']}: коэффициент = {row['coefficient']:.4f}, \"\n",
        "                      f\"OR = {row['odds_ratio']:.4f}\")\n",
        "\n",
        "        negative_coef = coef_df[coef_df['coefficient'] < 0].head()\n",
        "        if len(negative_coef) > 0:\n",
        "            print(f\"\\nТоп-{len(negative_coef)} признаков, уменьшающих вероятность класса 1:\")\n",
        "            for _, row in negative_coef.iterrows():\n",
        "                print(f\"  {row['feature']}: коэффициент = {row['coefficient']:.4f}, \"\n",
        "                      f\"OR = {row['odds_ratio']:.4f}\")\n",
        "\n",
        "        return coef_df\n",
        "\n",
        "    def demonstrate_theory_concepts(self):\n",
        "        \"\"\"Демонстрация всех теоретических концепций из лекции\"\"\"\n",
        "        print(\"ДЕМОНСТРАЦИЯ ТЕОРЕТИЧЕСКИХ КОНЦЕПЦИЙ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # 1. Сигмоидальная функция\n",
        "        self._demonstrate_sigmoid_function()\n",
        "\n",
        "        # 2. Генерация и анализ синтетических данных\n",
        "        self._demonstrate_synthetic_data()\n",
        "\n",
        "        # 3. Регуляризация\n",
        "        self._demonstrate_regularization()\n",
        "\n",
        "        # 4. Дисбаланс классов\n",
        "        self._demonstrate_class_imbalance()\n",
        "\n",
        "        # 5. Анализ тональности текстов\n",
        "        self._demonstrate_text_analysis()\n",
        "\n",
        "    def _demonstrate_sigmoid_function(self):\n",
        "        \"\"\"Демонстрация сигмоидальной функции\"\"\"\n",
        "        print(\"\\n1. СИГМОИДАЛЬНАЯ ФУНКЦИЯ И ЛОГАРИФМ ШАНСОВ\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        z_values = np.linspace(-6, 6, 100)\n",
        "        probabilities = 1 / (1 + np.exp(-z_values))\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Сигмоидальная функция\n",
        "        ax1.plot(z_values, probabilities, 'b-', linewidth=3, label='σ(z) = 1/(1+e⁻ᶻ)')\n",
        "        ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='P=0.5')\n",
        "        ax1.axvline(x=0.0, color='red', linestyle='--', alpha=0.7)\n",
        "        ax1.set_xlabel('z (логарифм шансов)')\n",
        "        ax1.set_ylabel('P(y=1|z)')\n",
        "        ax1.set_title('Сигмоидальная функция')\n",
        "        ax1.legend()\n",
        "        ax1.grid(alpha=0.3)\n",
        "\n",
        "        # Логарифм шансов\n",
        "        p_values = np.linspace(0.01, 0.99, 100)\n",
        "        log_odds = np.log(p_values / (1 - p_values))\n",
        "        ax2.plot(p_values, log_odds, 'r-', linewidth=3, label='log(p/(1-p))')\n",
        "        ax2.set_xlabel('Вероятность P(y=1)')\n",
        "        ax2.set_ylabel('Логарифм шансов log(odds)')\n",
        "        ax2.set_title('Логарифм шансов')\n",
        "        ax2.legend()\n",
        "        ax2.grid(alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Численные примеры\n",
        "        examples = [-3, -1, 0, 1, 3]\n",
        "        print(\"\\nПримеры преобразования:\")\n",
        "        for z in examples:\n",
        "            p = 1 / (1 + np.exp(-z))\n",
        "            print(f\"z = {z:4.1f} -> P = {p:.4f} -> log-odds = {np.log(p/(1-p)):.4f}\")\n",
        "\n",
        "    def _demonstrate_synthetic_data(self):\n",
        "        \"\"\"Демонстрация на синтетических данных\"\"\"\n",
        "        print(\"\\n2. АНАЛИЗ НА СИНТЕТИЧЕСКИХ ДАННЫХ\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Генерация данных\n",
        "        X, y = self.data_manager.create_synthetic_dataset(\n",
        "            n_samples=500, n_features=2, weights=[0.7, 0.3]\n",
        "        )\n",
        "\n",
        "        # Визуализация данных\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu',\n",
        "                            edgecolors='k', alpha=0.8, s=60)\n",
        "        plt.colorbar(scatter, label='Класс')\n",
        "        plt.xlabel('Признак 1')\n",
        "        plt.ylabel('Признак 2')\n",
        "        plt.title('Синтетический датасет для бинарной классификации')\n",
        "        plt.legend(*scatter.legend_elements(), title=\"Классы\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "        # Обучение и оценка модели\n",
        "        X_train, X_test, y_train, y_test = self.data_manager.prepare_numeric_data(X, y)\n",
        "        self.fit(X_train, y_train, feature_names=['Признак_1', 'Признак_2'])\n",
        "\n",
        "        # Визуализация границы принятия решений\n",
        "        self.visualizer.plot_decision_boundary(self, X_train, y_train)\n",
        "\n",
        "        # Оценка модели\n",
        "        metrics = self.evaluate(X_test, y_test)\n",
        "\n",
        "        # Интерпретация коэффициентов\n",
        "        self.interpret_coefficients()\n",
        "\n",
        "    def _demonstrate_regularization(self):\n",
        "        \"\"\"Демонстрация эффекта регуляризации\"\"\"\n",
        "        print(\"\\n3. ЭФФЕКТ РЕГУЛЯРИЗАЦИИ\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Генерация данных с шумом\n",
        "        X, y = self.data_manager.create_synthetic_dataset(\n",
        "            n_samples=200, n_features=10, n_informative=2, flip_y=0.1\n",
        "        )\n",
        "        X_train, X_test, y_train, y_test = self.data_manager.prepare_numeric_data(X, y)\n",
        "\n",
        "        # Модели с разной регуляризацией\n",
        "        models_config = {\n",
        "            'Сильная регуляризация (C=0.01)': {'C': 0.01, 'penalty': 'l2'},\n",
        "            'Умеренная регуляризация (C=1.0)': {'C': 1.0, 'penalty': 'l2'},\n",
        "            'Слабая регуляризация (C=100)': {'C': 100, 'penalty': 'l2'},\n",
        "            'L1 регуляризация': {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, params in models_config.items():\n",
        "            model = BinaryClassifier(**params, random_state=42)\n",
        "            model.fit(X_train, y_train)\n",
        "            metrics = model.evaluate(X_test, y_test, verbose=False)\n",
        "            results[name] = metrics\n",
        "\n",
        "            # Анализ весов\n",
        "            weights_norm = np.linalg.norm(model.model.coef_)\n",
        "            print(f\"{name}: норма весов = {weights_norm:.4f}\")\n",
        "\n",
        "        # Визуализация сравнения\n",
        "        comparison_data = {name: {k: v for k, v in metrics.items()\n",
        "                                if k in ['accuracy', 'precision', 'recall', 'f1_score']}\n",
        "                         for name, metrics in results.items()}\n",
        "\n",
        "        self.visualizer.plot_metrics_comparison(comparison_data,\n",
        "                                              \"Сравнение моделей с разной регуляризацией\")\n",
        "\n",
        "    def _demonstrate_class_imbalance(self):\n",
        "        \"\"\"Демонстрация методов работы с дисбалансом классов\"\"\"\n",
        "        print(\"\\n4. МЕТОДЫ РАБОТЫ С ДИСБАЛАНСОМ КЛАССОВ\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Генерация данных с сильным дисбалансом\n",
        "        X, y = self.data_manager.create_synthetic_dataset(\n",
        "            n_samples=1000, weights=[0.95, 0.05]\n",
        "        )\n",
        "\n",
        "        print(f\"Исходное распределение: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
        "\n",
        "        # Разные стратегии балансировки\n",
        "        strategies = {\n",
        "            'Без балансировки': None,\n",
        "            'Автоматическая балансировка': 'balanced'\n",
        "        }\n",
        "\n",
        "        X_train, X_test, y_train, y_test = self.data_manager.prepare_numeric_data(X, y)\n",
        "\n",
        "        results = {}\n",
        "        for strategy_name, class_weight in strategies.items():\n",
        "            model = BinaryClassifier(class_weight=class_weight, random_state=42)\n",
        "            model.fit(X_train, y_train)\n",
        "            metrics = model.evaluate(X_test, y_test, verbose=False)\n",
        "            results[strategy_name] = metrics\n",
        "\n",
        "        # Визуализация результатов\n",
        "        comparison_data = {name: {k: v for k, v in metrics.items()\n",
        "                                if k in ['accuracy', 'precision', 'recall', 'f1_score']}\n",
        "                         for name, metrics in results.items()}\n",
        "\n",
        "        self.visualizer.plot_metrics_comparison(comparison_data,\n",
        "                                              \"Сравнение стратегий балансировки\")\n",
        "\n",
        "    def _demonstrate_text_analysis(self):\n",
        "        \"\"\"Демонстрация анализа тональности текстов\"\"\"\n",
        "        print(\"\\n5. АНАЛИЗ ТОНАЛЬНОСТИ ТЕКСТОВ НА РУССКОМ ЯЗЫКЕ\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Создание текстового датасета\n",
        "        X_text, y_text = self.data_manager.create_text_dataset()\n",
        "\n",
        "        # Подготовка текстовых данных\n",
        "        X_train_tfidf, X_test_tfidf, y_train, y_test = self.data_manager.prepare_text_data(\n",
        "            X_text, y_text, max_features=50\n",
        "        )\n",
        "\n",
        "        # Обучение модели на текстах (без стандартизации для sparse матриц)\n",
        "        text_model = BinaryClassifier(class_weight='balanced', random_state=42)\n",
        "        text_model.fit(X_train_tfidf, y_train,\n",
        "                      feature_names=self.data_manager.feature_names.tolist())\n",
        "\n",
        "        # Оценка модели\n",
        "        metrics = text_model.evaluate(X_test_tfidf, y_test)\n",
        "\n",
        "        # Демонстрация предсказаний\n",
        "        test_texts = [\n",
        "            \"Отличный продукт, всем рекомендую!\",\n",
        "            \"Ужасное качество, не стоит денег.\",\n",
        "            \"Нормально, но есть недостатки.\",\n",
        "            \"Восхитительно! Превзошло все ожидания.\",\n",
        "            \"Разочарован, ожидал большего.\"\n",
        "        ]\n",
        "\n",
        "        print(\"\\nДемонстрация предсказаний:\")\n",
        "        for text in test_texts:\n",
        "            # Для демонстрации используем существующий vectorizer\n",
        "            text_vectorized = self.data_manager.vectorizer.transform([text])\n",
        "            proba = text_model.predict_proba(text_vectorized)[0][1]\n",
        "            prediction = text_model.predict(text_vectorized)[0]\n",
        "            sentiment = \"ПОЛОЖИТЕЛЬНЫЙ\" if prediction == 1 else \"ОТРИЦАТЕЛЬНЫЙ\"\n",
        "            print(f\"'{text}' -> {sentiment} (вероятность: {proba:.4f})\")\n",
        "\n",
        "        # Интерпретация важных слов\n",
        "        print(\"\\nИнтерпретация важных слов в модели:\")\n",
        "        text_model.interpret_coefficients(top_n=10)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ДЕМОНСТРАЦИЯ РАБОТЫ СИСТЕМЫ\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Основная функция демонстрации системы\"\"\"\n",
        "    print(\"КОМПЛЕКСНАЯ СИСТЕМА БИНАРНОЙ КЛАССИФИКАЦИИ\")\n",
        "    print(\"Реализация всех теоретических концепций логистической регрессии\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Создание основного классификатора\n",
        "    classifier = BinaryClassifier(\n",
        "        penalty='l2',\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Демонстрация всех теоретических концепций\n",
        "    classifier.demonstrate_theory_concepts()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ДЕМОНСТРАЦИЯ ЗАВЕРШЕНА\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nКлючевые реализованные концепции:\")\n",
        "    print(\"✅ Сигмоидальная функция и логарифм шансов\")\n",
        "    print(\"✅ Регуляризация (L1, L2) и контроль сложности модели\")\n",
        "    print(\"✅ Методы работы с дисбалансом классов\")\n",
        "    print(\"✅ Комплексная оценка качества (ROC, PR, калибровка)\")\n",
        "    print(\"✅ Интерпретация коэффициентов и отношения шансов\")\n",
        "    print(\"✅ Анализ тональности текстов на русском языке\")\n",
        "    print(\"✅ Визуализация границы принятия решений\")\n",
        "    print(\"✅ Оптимизация порога классификации\")\n",
        "\n",
        "    return classifier\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Запуск демонстрации\n",
        "    final_classifier = main()"
      ],
      "metadata": {
        "id": "TIsPw1GMI8_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Раздел 2 Многоклассовая Классификация: теоретические основы и практическая реализация\n",
        "\n",
        "\n",
        "### I. Введение в Многоклассовую Классификацию: Расширение Логистической Регрессии\n",
        "\n",
        "Логистическая регрессия (ЛР), изначально разработанная для бинарных задач, служит фундаментальной основой для классификации. В бинарном случае модель использует линейный предсказатель $z = W^T X + b$, где $W$ — веса, $X$ — признаки, а $b$ — смещение. Результат $z$ затем пропускается через сигмоидную функцию $\\sigma(z) = \\frac{1}{1 + e^{-z}}$, которая преобразует оценку в вероятность принадлежности к положительному классу $P \\in [0, 1]$. Обучение модели происходит путём минимизации функции потерь, называемой бинарной кросс-энтропией.\n",
        "\n",
        "Для решения задач, где целевая переменная может принимать более двух значений ($K > 2$), необходимо расширение этой базовой концепции. Существует два основных подхода к реализации многоклассовой ЛР.\n",
        "\n",
        "#### 1. Стратегия \"Один Против Всех\" (One-vs-Rest, OvR)\n",
        "\n",
        "Механизм OvR (или One-vs-All) предполагает построение $K$ независимых бинарных классификаторов, где $K$ — общее число классов. Каждый классификатор $k$ обучен отличать один класс ($C_k$) от всех остальных классов вместе взятых ($\\text{Not } C_k$). Таким образом, каждый классификатор $k$ определяет вероятность $P(C_k | \\text{Not } C_k)$.\n",
        "\n",
        "При предсказании для нового объекта $X$ модель вычисляет $K$ оценок вероятности. Окончательное решение принимается путём выбора класса, получившего максимальную оценку: $\\arg\\max_k (P_k)$. Критический методологический недостаток OvR заключается в том, что, поскольку классификаторы работают независимо, предсказанные вероятности для одного объекта $P_1, P_2, \\dots, P_K$ не обязаны суммироваться к 1. Это приводит к тому, что интерпретация выходных данных как истинных вероятностей затруднена. В scikit-learn решатель `'liblinear'` поддерживает многоклассовую классификацию исключительно через стратегию OvR.\n",
        "\n",
        "> **Пример текстовой классификации с OvR**:  \n",
        "> Представим задачу автоматической категоризации научных статей на три темы: «Физика», «Биология», «Компьютерные науки». При использовании OvR создаются три бинарных классификатора:\n",
        "> - «Физика vs не-Физика»,\n",
        "> - «Биология vs не-Биология»,\n",
        "> - «Компьютерные науки vs не-Компьютерные науки».  \n",
        "> На этапе предсказания каждая модель выдаёт оценку уверенности; например, для статьи о квантовых вычислениях: [0.85, 0.12, 0.78]. Хотя класс «Физика» получает максимальное значение, сумма не равна 1, и прямая вероятностная интерпретация невозможна.\n",
        "\n",
        "#### 2. Мультиномиальная Логистическая Регрессия (Softmax Classification)\n",
        "\n",
        "Мультиномиальная логистическая регрессия, также известная как Softmax-классификация, является истинным статистическим обобщением бинарной ЛР. Она моделирует вероятности принадлежности объекта $X$ ко всем $K$ классам одновременно, устраняя проблему ненормализованных вероятностей, присущую OvR. Softmax-регрессия гарантирует, что сумма предсказанных вероятностей по всем классам равна единице: $\\sum_{i=1}^{K} P(C_i|x) = 1$.\n",
        "\n",
        "Ключевым элементом является функция Softmax, которая преобразует вектор исходных оценок (логитов) $z = (z_1, z_2, \\dots, z_K)$ в распределение вероятностей.\n",
        "\n",
        "Формула Softmax-функции для класса $i$:\n",
        "\n",
        "$$\n",
        "P(C_i|x) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n",
        "$$\n",
        "\n",
        "Здесь экспоненциальная функция $e^z$ гарантирует, что все вероятности будут положительными, а знаменатель, представляющий сумму экспонент всех оценок, обеспечивает нормализацию, то есть $P \\in [0, 1]$ и $\\sum P = 1$.\n",
        "\n",
        "Функцией потерь, используемой в Softmax-классификации, является **мультиномиальная кросс-энтропия** (Softmax Loss). Она стремится максимизировать логарифмическую вероятность истинного класса, то есть штрафует модель, если она присваивает низкую вероятность классу, к которому объект принадлежит на самом деле.\n",
        "\n",
        "В контексте передовых методов диагностики, которые включают оценку калибровки вероятностей (Раздел VI), обязательным является использование модели, которая гарантирует нормализованные вероятности. Следовательно, Softmax-подход, активируемый в `sklearn.linear_model.LogisticRegression` при использовании параметра `multi_class='multinomial'` (или при выборе совместимых решателей, таких как `'lbfgs'` или `'saga'`), является предпочтительным выбором для всестороннего анализа.\n",
        "\n",
        "> **Пример текстовой классификации с Softmax**:  \n",
        "> В задаче определения тональности отзывов на три класса — «Негативный», «Нейтральный», «Позитивный» — Softmax-модель, обученная на TF-IDF признаках, для нового отзыва выдаёт:\n",
        "> $$\n",
        "> P = [0.05, 0.10, 0.85]\n",
        "> $$\n",
        "> Такая интерпретация корректна: модель с уверенностью 85% считает отзыв позитивным, и сумма всех вероятностей равна 1. Это критично при интеграции в системы рекомендаций или автоматической модерации, где требуется оценка надёжности решения.\n",
        "\n",
        "---\n",
        "\n",
        "### II. Подготовка Данных и Тонкая Настройка Модели (Python)\n",
        "\n",
        "Для демонстрации многоклассовой классификации необходимо сгенерировать синтетический набор данных, который позволит контролировать количество классов, сложность и дисбаланс. В реальных NLP-задачах вместо синтетических данных используются корпусы текстов с разметкой.\n",
        "\n",
        "> **Пример NLP-датасета для многоклассовой классификации**:  \n",
        "> Корпус новостей `AG News` содержит 4 класса: «World», «Sports», «Business», «Sci/Tech». После токенизации и векторизации (например, с помощью `TfidfVectorizer` или `CountVectorizer`) текст преобразуется в признаковый вектор $X \\in \\mathbb{R}^d$, где $d$ — размер словаря. Целевая переменная $y \\in \\{0, 1, 2, 3\\}$ — индекс тематики. Именно такую структуру можно смоделировать синтетически для обучения и визуализации.\n",
        "\n",
        "#### 1. Генерация Синтетического Датасета\n",
        "\n",
        "Используя функцию `make_classification` из библиотеки scikit-learn, можно создать контролируемый многоклассовый датасет. Для наглядности визуализации границ решений (Раздел V) целесообразно ограничить число информативных признаков до двух.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- 2.1. Генерация Датасета ---\n",
        "\n",
        "# Параметры для генерации 3-классового, дисбалансного датасета\n",
        "N_CLASSES = 3\n",
        "N_SAMPLES = 1500\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Создание дисбалансного датасета: 60%, 25%, 15%\n",
        "# Параметр weights позволяет задать пропорции классов\n",
        "X, y = make_classification(\n",
        "    n_samples=N_SAMPLES,\n",
        "    n_features=5,            # Общее количество признаков\n",
        "    n_informative=2,         # 2 признака будут информативными (полезно для визуализации)\n",
        "    n_redundant=1,           # 1 признак будет линейной комбинацией информативных\n",
        "    n_classes=N_CLASSES,\n",
        "    n_clusters_per_class=1,  # Количество кластеров на класс\n",
        "    weights=[0.60, 0.25, 0.15], # Явный дисбаланс\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Распределение классов в y_train: {np.unique(y_train, return_counts=True)}\")\n",
        "```\n",
        "\n",
        "> **Аналогия с текстом**:  \n",
        "> Хотя здесь $X$ — это числовые признаки, в NLP они бы соответствовали, например, TF-IDF весам топ-5 слов из корпуса. Например, для трёх классов «Политика», «Экономика», «Культура» информативными могут быть слова: *выборы*, *бюджет*, *выставка*. Таким образом, синтетический датасет имитирует поведение реального текстового входа.\n",
        "\n",
        "#### 2. Предварительная Обработка: Масштабирование\n",
        "\n",
        "Логистическая регрессия часто использует оптимизаторы, основанные на градиентном спуске (например, `'lbfgs'`, `'sag'`, `'saga'`). Эффективность и скорость сходимости этих методов зависят от масштаба признаков. Если признаки имеют сильно различающиеся диапазоны значений, это может замедлить процесс оптимизации.\n",
        "\n",
        "В частности, для решателей `'sag'` и `'saga'` масштабирование данных (например, с помощью `StandardScaler`) является критически важным шагом, который гарантирует быструю сходимость.\n",
        "\n",
        "```python\n",
        "# --- 2.2. Масштабирование данных ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "```\n",
        "\n",
        "> **Примечание для NLP**:  \n",
        "> При использовании `CountVectorizer` или `TfidfVectorizer` признаки уже находятся в сопоставимом диапазоне (частоты или веса), и дополнительное масштабирование часто не требуется. Однако при объединении TF-IDF с числовыми мета-признаками (например, длина текста, количество восклицательных знаков) масштабирование становится обязательным.\n",
        "\n",
        "#### 3. Гиперпараметры Регуляризации и Выбор Оптимизатора\n",
        "\n",
        "Для многоклассовой логистической регрессии ключевыми гиперпараметрами являются сила регуляризации $C$ и тип штрафа (`penalty`).\n",
        "\n",
        "- **$C$**: Это обратная величина силы регуляризации. Меньшее значение $C$ соответствует более сильной регуляризации, предотвращая переобучение. Значение по умолчанию — $C=1.0$.\n",
        "- **`penalty`**: Определяет тип используемого штрафа: L1, L2 (по умолчанию), ElasticNet или None.\n",
        "\n",
        "Выбор оптимизатора (`solver`) напрямую зависит от выбранного типа штрафа и того, используется ли Softmax-режим (`multi_class='multinomial'`). Необходимо строго соблюдать совместимость:\n",
        "\n",
        "- Решатели `'newton-cg'`, `'sag'`, `'lbfgs'` поддерживают только регуляризацию L2 (или её отсутствие) в Softmax-режиме.\n",
        "- Решатель `'saga'` является наиболее гибким, поскольку он единственный поддерживает штрафы L1 и ElasticNet в режиме мультиномиальной классификации (Softmax).\n",
        "\n",
        "Для демонстрации наиболее гибкой конфигурации (ElasticNet с L1/L2) используется решатель `'saga'`.\n",
        "\n",
        "**Таблица 1: Совместимость Решателей и Регуляризации в `LogisticRegression`**\n",
        "\n",
        "| Solver (Решатель) | Поддерживаемые Penalty              | Поддержка Softmax (Multinomial) | Требование Масштабирования               |\n",
        "|-------------------|--------------------------------------|----------------------------------|------------------------------------------|\n",
        "| `'lbfgs'` (Default) | `'l2'`, `None`                       | Да                               | Нет (хорош по умолчанию)                |\n",
        "| `'saga'`          | `'l1'`, `'l2'`, `'elasticnet'`, `None` | Да                               | Желательно (для быстрой сходимости)     |\n",
        "| `'liblinear'`     | `'l1'`, `'l2'`                       | Нет (только OvR)                 | Нет                                     |\n",
        "| `'newton-cg'`     | `'l2'`, `None`                       | Да                               | Нет                                     |\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Инициализация модели с Softmax и ElasticNet регуляризацией\n",
        "# Softmax активируется, если multi_class='multinomial' и решатель поддерживает его\n",
        "lr_model = LogisticRegression(\n",
        "    solver='saga',\n",
        "    penalty='elasticnet',\n",
        "    l1_ratio=0.5, # 50% L1, 50% L2\n",
        "    C=1.0,\n",
        "    multi_class='multinomial',\n",
        "    max_iter=500,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "y_pred = lr_model.predict(X_test_scaled)\n",
        "y_proba = lr_model.predict_proba(X_test_scaled)\n",
        "```\n",
        "\n",
        "> **Применение в NLP**:  \n",
        "> ElasticNet-регуляризация особенно полезна при работе с разреженными текстовыми признаками (например, TF-IDF с большим словарём), так как L1-компонента способствует отбору наиболее значимых слов, а L2 — стабилизирует коэффициенты. Это позволяет создать интерпретируемую и устойчивую модель классификации документов.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "OFysRFLrGsp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## III. Работа с Дисбалансом и Методы Усиления\n",
        "\n",
        "Работа с дисбалансом классов (когда один или несколько классов значительно преобладают или, наоборот, малочисленны) является ключевым моментом в многоклассовой классификации, особенно когда миноритарные классы представляют важные события (например, редкие заболевания или мошенничество).\n",
        "\n",
        "#### 1. Стратегия Внутренних Классовых Весов\n",
        "\n",
        "Наиболее прямолинейным способом устранения влияния дисбаланса является использование параметра `class_weight` в модели логистической регрессии. Если установить `class_weight='balanced'`, модель автоматически рассчитывает веса, обратно пропорциональные частоте класса (то есть веса миноритарных классов увеличиваются). Это приводит к тому, что ошибки, совершаемые на миноритарных классах, оказывают значительно большее влияние на функцию потерь во время обучения.  \n",
        "Это позволяет модели уделять должное внимание даже редко встречающимся примерам, не требуя модификации самого набора данных.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В задаче классификации жалоб пользователей на три категории — «Техническая проблема» (60%), «Вопрос по тарифу» (25%) и «Жалоба на модератора» (15%) — последняя категория критически важна, но редка. Применение `class_weight='balanced'` заставляет модель не игнорировать такие жалобы, даже если их мало в обучающей выборке. Без балансировки модель может предсказывать только первые две категории и достигать высокой точности, но быть бесполезной на практике.\n",
        "\n",
        "```python\n",
        "# Модель с балансировкой весов\n",
        "lr_model_balanced = LogisticRegression(\n",
        "    solver='saga',\n",
        "    penalty='elasticnet',\n",
        "    l1_ratio=0.5,\n",
        "    C=1.0,\n",
        "    multi_class='multinomial',\n",
        "    max_iter=500,\n",
        "    class_weight='balanced', # Включение автоматической балансировки весов\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "lr_model_balanced.fit(X_train_scaled, y_train)\n",
        "y_pred_balanced = lr_model_balanced.predict(X_test_scaled)\n",
        "```\n",
        "\n",
        "#### 2. Стратегия Внешнего Сэмплирования (Аугментация)\n",
        "\n",
        "Внешнее сэмплирование, по сути, является формой аугментации данных для табличных наборов.  \n",
        "- **Oversampling (SMOTE)**: Синтетическое меньшинство (Synthetic Minority Over-sampling Technique) создаёт новые синтетические образцы миноритарного класса на основе существующих, тем самым искусственно увеличивая их представленность.  \n",
        "- **Undersampling**: Уменьшение числа примеров мажоритарного класса до уровня, сопоставимого с миноритарными классами.  \n",
        "\n",
        "Важно помнить, что любые методы сэмплирования должны применяться только к обучающей выборке (`X_train` и `y_train`). Применение их к тестовой выборке приведёт к утечке данных и нереалистично завышенной оценке качества модели.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При работе с корпусом медицинских документов на татарском языке, где 70% текстов относятся к «Общим симптомам», 20% — к «Хроническим заболеваниям», а лишь 10% — к «Онкологическим диагнозам», можно применить SMOTE к TF-IDF-векторам текстов из редкого класса. Хотя SMOTE изначально разработан для непрерывных признаков, он часто используется и с разреженными текстовыми векторами, создавая «средние» документы, которые помогают модели лучше выучить границы редкого класса.\n",
        "\n",
        "#### 3. Выбор Метрики в Условиях Дисбаланса\n",
        "\n",
        "При работе с дисбалансными данными и применении стратегий балансировки (например, `class_weight='balanced'`) оценка производительности не может опираться только на общую точность (Accuracy). Чтобы подтвердить, что балансировка действительно улучшила распознавание миноритарных классов, необходимо использовать методы усреднения метрик, которые дают равный вес всем классам. **Macro-F1 Score** идеально подходит для этой цели, поскольку он рассчитывает метрику для каждого класса, а затем берёт их простое (не взвешенное) среднее. Использование **Weighted-F1**, которое взвешивает результат по числу примеров в классе (support), скроет улучшения миноритарных классов, поскольку результаты будут доминированы показателями мажоритарного класса.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В системе модерации комментариев на новостном сайте на татарском языке три класса: «Допустимо» (80%), «Оскорбление» (15%), «Экстремизм» (5%). Даже при Accuracy = 82% модель может полностью пропускать экстремистские высказывания. Macro-F1, напротив, упадёт до нуля по классу «Экстремизм», если он не распознаётся, что сразу сигнализирует о проблеме.\n",
        "\n",
        "---\n",
        "\n",
        "## IV. Комплексная Оценка: Метрики Классификации\n",
        "\n",
        "Для всесторонней оценки многоклассовой модели требуется набор метрик, выходящий за рамки простой точности.\n",
        "\n",
        "#### 1. Матрица Ошибок (Confusion Matrix)\n",
        "\n",
        "Матрица ошибок — это табличное представление результатов алгоритма классификации. Строки матрицы соответствуют истинным классам, а столбцы — предсказанным. Диагональные элементы показывают количество правильных предсказаний, а внедиагональные — ошибки (например, ложные срабатывания или пропуски).  \n",
        "Анализ матрицы позволяет диагностировать специфические проблемы: например, если класс 0 часто ошибочно предсказывается как класс 2, это немедленно выявляется.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При классификации научных статей на татарском языке по темам «Физика», «Математика», «Информатика» матрица ошибок может показать, что статьи по «Математической физике» часто путаются с «Физикой». Это сигнал к тому, что следует уточнить категоризацию или добавить контекстные признаки.\n",
        "\n",
        "#### 2. Precision, Recall и F1-Score\n",
        "\n",
        "Эти метрики рассчитываются для каждого класса в отдельности, а затем агрегируются.  \n",
        "- **Precision (Точность)**: Доля правильных положительных предсказаний среди всех предсказаний, отнесённых моделью к этому классу.  \n",
        "- **Recall (Полнота)**: Доля истинных положительных примеров, которые были корректно идентифицированы моделью.  \n",
        "- **F1-Score**: Гармоническое среднее Precision и Recall, обеспечивающее сбалансированную меру производительности.\n",
        "\n",
        "##### Агрегация Метрик для Многоклассового Случая\n",
        "\n",
        "Для обобщения этих метрик на многоклассовый случай используются три основных метода усреднения:\n",
        "\n",
        "**Таблица 2: Методы Усреднения Метрик**\n",
        "\n",
        "| Метод Усреднения | Расчетная Логика                                           | Цель                                                | Использование при Дисбалансе                             |\n",
        "|------------------|------------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------------|\n",
        "| **Micro**        | Глобальный подсчёт TP, FP, FN по всем классам              | Общая производительность на уровне выборки          | Эквивалентен Accuracy. Доминируется мажоритарным классом |\n",
        "| **Macro**        | Среднее арифметическое метрик по классам                   | Производительность на \"среднем классе\"              | Четко показывает качество на миноритарных классах. Идеален для оценки справедливости |\n",
        "| **Weighted**     | Взвешенное среднее, где вес = Support (количество примеров) | Производительность, отражающая реальное распределение | Наиболее репрезентативен для \"взвешенной\" реальности     |\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В задаче классификации отзывов на товары на татарском языке по трём тональностям («Негатив», «Нейтрально», «Позитив») с дисбалансом 10%/30%/60%:\n",
        "> - **Micro-F1** будет близок к 0.85, отражая успех на большинстве позитивных отзывов.\n",
        "> - **Macro-F1** может быть всего 0.60, если модель плохо справляется с «Негативом».\n",
        "> Только Macro-F1 покажет реальные слабые места.\n",
        "\n",
        "#### 3. ROC AUC для Многоклассовой Классификации\n",
        "\n",
        "Площадь под кривой рабочих характеристик приёмника (ROC AUC) измеряет способность модели ранжировать вероятности. В многоклассовом контексте этот показатель рассчитывается с использованием стратегии OvR.  \n",
        "Для расчёта необходимо бинаризовать истинные метки, преобразовав их в формат One-Hot Encoding (OHE) с помощью `LabelBinarizer`. ROC AUC затем рассчитывается для каждой бинарной задачи «класс против остальных», используя предсказанные вероятности (`y_proba`).  \n",
        "\n",
        "Существует два основных способа усреднения многоклассового ROC AUC:  \n",
        "1. **Macro-AUC**: Усреднение индивидуальных AUC для каждого класса. Это полезно, когда необходимо оценить способность модели различать каждый класс независимо от его размера.  \n",
        "2. **Micro-AUC**: Получается путём объединения всех OvR-классификаций. По сути, он отражает общую производительность модели на уровне выборки.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При классификации документов на татарском языке по трём юридическим категориям («Гражданское право», «Уголовное право», «Административное право»), Macro-AUC покажет, насколько хорошо модель распознаёт редкие уголовные дела, даже если их всего 8% в корпусе. Micro-AUC, напротив, будет высоким даже при полном игнорировании этого класса.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# --- 4. Отчет по классификации (Classification Report) ---\n",
        "print(\"--- Отчет по классификации (Weighted Model) ---\")\n",
        "print(classification_report(y_test, y_pred_balanced, digits=3))\n",
        "\n",
        "# --- 4. ROC AUC для многоклассовой классификации ---\n",
        "# 1. Бинаризация истинных меток\n",
        "label_binarizer = LabelBinarizer().fit(y_train)\n",
        "y_test_onehot = label_binarizer.transform(y_test)\n",
        "\n",
        "# 2. Получение предсказанных вероятностей\n",
        "y_score_balanced = lr_model_balanced.predict_proba(X_test_scaled)\n",
        "\n",
        "# 3. Расчет Macro и Micro AUC (используется multi_class='ovr')\n",
        "macro_roc_auc_ovr = roc_auc_score(\n",
        "    y_test_onehot, y_score_balanced, multi_class=\"ovr\", average=\"macro\"\n",
        ")\n",
        "micro_roc_auc_ovr = roc_auc_score(\n",
        "    y_test_onehot, y_score_balanced, multi_class=\"ovr\", average=\"micro\"\n",
        ")\n",
        "\n",
        "print(f\"\\nMacro-Average ROC AUC (OvR): {macro_roc_auc_ovr:.4f}\")\n",
        "print(f\"Micro-Average ROC AUC (OvR): {micro_roc_auc_ovr:.4f}\")\n",
        "```\n",
        ""
      ],
      "metadata": {
        "id": "JjYYEm0uTv5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## V. Визуализация: Интуитивное Понимание Модели\n",
        "\n",
        "Визуализация помогает понять, какие решения принимает модель, как она обрабатывает ошибки и насколько хорошо она работает в сравнении со случайным угадыванием.\n",
        "\n",
        "#### 1. Визуализация Границ Решений\n",
        "\n",
        "Поскольку логистическая регрессия является линейным классификатором, её границы решений будут прямыми линиями (или гиперплоскостями в многомерном пространстве). Для наглядной демонстрации границ решений используются только два наиболее информативных признака или проекция данных (например, через PCA).  \n",
        "Использование класса `DecisionBoundaryDisplay` из scikit-learn позволяет отобразить области пространства признаков, которые модель назначает каждому классу, наглядно демонстрируя линейность разделения.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> Хотя текстовые признаки (например, TF-IDF) обычно многомерны, для визуализации можно взять два наиболее весомых слова (например, «бюджет» и «выборы») и построить график: по оси X — частота слова «бюджет», по оси Y — частота слова «выборы». Модель логистической регрессии проведёт прямые линии, разделяющие документы на «Экономику», «Политику» и «Культуру». Это особенно полезно на этапе отладки, чтобы убедиться, что границы соответствуют экспертным ожиданиям.\n",
        "\n",
        "#### 2. Визуализация Многоклассовой Матрицы Ошибок\n",
        "\n",
        "Представление матрицы ошибок в виде тепловой карты (Heatmap) позволяет быстро идентифицировать, какие классы путаются чаще всего.\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Визуализация матрицы ошибок\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred_balanced)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr_model_balanced.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
        "ax.set_title(\"Матрица Ошибок (Multiclass LR)\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При классификации татарских новостей на категории «Спорт», «Культура» и «Наука» матрица ошибок может показать, что короткие тексты о «киберспорте» часто классифицируются как «Наука». Это позволяет добавить в систему обработку слов вроде *кибер*, *турнир*, *команда*, чтобы уточнить решение.\n",
        "\n",
        "#### 3. Визуализация ROC-Кривых\n",
        "\n",
        "Построение ROC-кривых для каждого класса и их усреднённых версий (Micro и Macro) является важным шагом. В многоклассовом случае ROC-кривая строится с использованием стратегии «Один против Остальных» для каждого класса.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
        "\n",
        "# 5.3. Визуализация ROC-кривых OvR\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# Построение индивидуальных ROC-кривых для каждого класса\n",
        "for i in range(N_CLASSES):\n",
        "    fpr, tpr, _ = roc_curve(y_test_onehot[:, i], y_score_balanced[:, i])\n",
        "    roc_auc = roc_auc_score(y_test_onehot[:, i], y_score_balanced[:, i])\n",
        "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
        "                    estimator_name=f\"Класс {i}\").plot(ax=ax)\n",
        "\n",
        "# Добавление Micro-средней ROC-кривой\n",
        "RocCurveDisplay.from_predictions(\n",
        "    y_test_onehot.ravel(), y_score_balanced.ravel(),\n",
        "    name=f\"Micro-average ROC (AUC = {micro_roc_auc_ovr:.2f})\",\n",
        "    color=\"deeppink\", linestyle=\":\", linewidth=4, ax=ax\n",
        ")\n",
        "\n",
        "# Установка графика\n",
        "ax.plot([0, 1], [0, 1], \"k--\", label=\"Уровень случайного шанса\")\n",
        "plt.axis(\"square\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"One-vs-Rest ROC кривые для Softmax LR\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В задаче определения тональности татарских комментариев к новостям («Позитив», «Нейтрально», «Негатив») ROC-кривые позволяют оценить, насколько хорошо модель различает тонкие случаи, например, сарказм (часто ошибочно классифицируемый как «Позитив»). Высокий AUC для «Негатива» даже при малом количестве примеров свидетельствует о надёжности модели.\n",
        "\n",
        "---\n",
        "\n",
        "## VI. Глубокая Диагностика: Калибровка Вероятностей\n",
        "\n",
        "В классификации, особенно пробабилистической (как Softmax LR), традиционный анализ остатков, применяемый в линейной регрессии, неприменим. Вместо этого диагностика должна фокусироваться на оценке калибровки вероятностей — насколько хорошо предсказанные вероятности $P(y|x)$ соответствуют истинной частоте событий.\n",
        "\n",
        "#### 1. Почему не Хосмер-Лемешоу?\n",
        "\n",
        "Тест Хосмера-Лемешоу (HL test), который часто используется для оценки качества подгонки (goodness of fit) в бинарной логистической регрессии, строго ограничен бинарными переменными отклика (alive or dead, yes or no). Этот тест не может быть применён напрямую к многоклассовым задачам. Таким образом, для многоклассового анализа требуются более универсальные методы оценки прогностических вероятностей.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При разработке системы раннего выявления «токсичных комментариев» на татарском языке с тремя уровнями токсичности («Безопасно», «Спорно», «Токсично»), бинарный HL-тест неприменим. Вместо него используются многоклассовые меры калибровки, чтобы убедиться, что вероятность 0.9 для «Токсично» действительно означает, что в 90% случаев модератор подтвердит токсичность.\n",
        "\n",
        "#### 2. Количественная Оценка Калибровки: Brier Score Loss и Log Loss\n",
        "\n",
        "Для количественной оценки качества вероятностей используются строго правильные оценочные функции.\n",
        "\n",
        "**Brier Score Loss (BSL)**  \n",
        "Brier Score Loss измеряет среднеквадратичную разницу между предсказанной вероятностью $p_t$ и фактическим результатом $o_t$ (который равен 1 для истинного класса и 0 для остальных).  \n",
        "\n",
        "Формула BSL:\n",
        "\n",
        "$$\n",
        "BSL = \\frac{1}{N} \\sum_{t=1}^{N} (p_t - o_t)^2\n",
        "$$\n",
        "\n",
        "Меньшее значение BSL указывает на лучшую калибровку. Для многоклассовой задачи BSL рассчитывается путём усреднения оценок Brier Score, полученных для каждого класса в бинаризованном (OHE) формате.\n",
        "\n",
        "**Log Loss (Логарифмическая Функция Потерь)**  \n",
        "Log Loss (Мультиномиальная Кросс-Энтропия) также является ключевой метрикой для оценки качества вероятностей. Она сильно штрафует модель, если она присваивает высокую уверенность (вероятность, близкую к 1) неправильному классу. Log Loss часто используется как целевая функция при обучении Softmax-моделей.\n",
        "\n",
        "#### 3. Визуальная Оценка Калибровки: Калибровочные Кривые\n",
        "\n",
        "Калибровочные кривые (или Диаграммы Надёжности) визуально сравнивают предсказанную вероятность (ось X) с истинной частотой событий (ось Y).  \n",
        "\n",
        "- **Идеальная калибровка**: Предсказания идеально откалиброваны, если они лежат на диагональной линии $y = x$. Например, если модель предсказала вероятность 0.7, то в 70% случаев объект должен принадлежать к этому классу.  \n",
        "- **Интерпретация отклонений**: Если кривая лежит ниже диагонали, модель слишком уверена (перекалибрована). Если кривая лежит выше диагонали, модель недостаточно уверена (недокалибрована).  \n",
        "\n",
        "Для многоклассовой логистической регрессии необходимо построить отдельную калибровочную кривую для каждого класса, сравнивая предсказанные вероятности $P(C_i)$ с соответствующими OHE-метками $y_i$.\n",
        "\n",
        "**Таблица 3: Инструменты Диагностики Пробабилистической Классификации**\n",
        "\n",
        "| Инструмент Диагностики      | Цель                                               | Тип Входных Данных               | Используется для Multiclass? |\n",
        "|----------------------------|----------------------------------------------------|----------------------------------|------------------------------|\n",
        "| Brier Score Loss           | Количественная оценка калибровки (MSD вероятностей) | Предсказанные вероятности (`y_proba`) | Да                           |\n",
        "| Калибровочная Кривая       | Визуальная оценка соответствия вероятности и частоты | Предсказанные вероятности (`y_proba`) | Да (для каждого класса)        |\n",
        "| Log Loss                   | Количественная оценка качества вероятностей (штраф за уверенные ошибки) | Предсказанные вероятности (`y_proba`) | Да                           |\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import brier_score_loss, log_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 6.2. Количественные метрики калибровки ---\n",
        "logloss = log_loss(y_test, y_score_balanced)\n",
        "print(f\"\\nLog Loss (Мультиномиальная Кросс-Энтропия): {logloss:.4f}\")\n",
        "\n",
        "# Расчет Brier Score Loss для каждого класса\n",
        "brier_scores = []\n",
        "for i in range(N_CLASSES):\n",
        "    bsl = brier_score_loss(y_test_onehot[:, i], y_score_balanced[:, i])\n",
        "    brier_scores.append(bsl)\n",
        "print(f\"Brier Score Loss (средний по классам): {np.mean(brier_scores):.4f}\")\n",
        "\n",
        "# --- 6.3. Визуализация калибровочных кривых ---\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.plot([0, 1], [0, 1], \"k--\", label=\"Идеальная калибровка\")\n",
        "\n",
        "for i in range(N_CLASSES):\n",
        "    prob_true, prob_pred = calibration_curve(y_test_onehot[:, i], y_score_balanced[:, i], n_bins=10)\n",
        "    ax.plot(prob_pred, prob_true, marker='o', label=f'Класс {i}')\n",
        "\n",
        "ax.set_title(\"Калибровочные Кривые (Softmax LR)\")\n",
        "ax.set_xlabel(\"Средняя предсказанная вероятность\")\n",
        "ax.set_ylabel(\"Доля истинных событий\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В системе автоматической рубрикации татарских статей, где вероятности используются для ранжирования предполагаемых тем, хорошая калибровка критична. Если модель для статьи о башкирской культуре (не в нашем корпусе) выдаёт $P(\\text{Культура}) = 0.85$, но при этом реальная точность таких предсказаний — лишь 60%, система будет давать ложную уверенность. Калибровочные кривые позволяют это обнаружить и, при необходимости, применить пост-калибровку.\n",
        "\n",
        "На калибровочной кривой логистическая регрессия, как правило, демонстрирует хорошее поведение, поскольку по своей природе является пробабилистической моделью, оптимизирующей Кросс-Энтропию, что способствует внутренней калибровке.\n",
        "\n",
        "---\n",
        "\n",
        "## VII. Заключение Лекции\n",
        "\n",
        "### 1. Синтез Ключевых Решений и Взаимосвязей\n",
        "\n",
        "Проведение глубокого анализа многоклассовой классификации требует согласованного выбора методов на каждом этапе: от выбора модели до оценки её производительности.\n",
        "\n",
        "1. **Выбор Модели**: Приоритет был отдан Мультиномиальной (Softmax) Логистической Регрессии перед OvR, поскольку Softmax гарантирует нормализацию вероятностей ($\\sum P = 1$), что является обязательным условием для проведения продвинутой диагностики калибровки.  \n",
        "2. **Настройка Оптимизатора**: Использование гибких методов регуляризации (например, ElasticNet) в Softmax-режиме требует применения специализированных решателей, таких как `'saga'`, а для обеспечения быстрой и надёжной сходимости при использовании `'saga'` необходимо предварительное масштабирование признаков.  \n",
        "3. **Обработка Дисбаланса и Метрики**: В случае дисбаланса, балансировка весов (через `class_weight='balanced'`) позволяет модели уделять больше внимания миноритарным классам. Однако, чтобы честно измерить эффективность этой балансировки, необходимо использовать **Macro-F1 Score** и **Macro-AUC**, которые не взвешивают результат по количеству примеров и, таким образом, дают равный голос миноритарным классам.  \n",
        "4. **Продвинутая Диагностика**: Классификационные модели требуют оценки качества вероятностей, а не традиционного анализа остатков. Вместо неприменимого для мультиклассовых задач теста Хосмера-Лемешоу, используются количественные метрики (**Brier Score Loss**, **Log Loss**) и визуальные инструменты (**Калибровочные Кривые**) для оценки надёжности прогностических вероятностей.\n",
        "\n",
        "> **Связь с NLP**:  \n",
        "> Все эти принципы напрямую применимы к задачам обработки текстов на малоресурсных языках, таких как татарский. Например, при построении системы определения тематики исторических документов, где классы дисбалансны, а вероятности используются для архивной сортировки, именно Softmax-модель с `class_weight='balanced'`, оценённая по Macro-F1 и визуализированная через калибровочные кривые, обеспечит как точность, так и доверие к результатам.\n",
        "\n",
        "### 2. Ограничения и Дальнейшие Шаги\n",
        "\n",
        "Важно понимать, что Логистическая Регрессия, даже в мультиномиальном режиме, остаётся линейной моделью. Если сгенерированные данные или реальные данные не могут быть линейно разделены в пространстве признаков, производительность ЛР будет ограничена. В таких случаях для достижения более высоких метрик потребуется переход к нелинейным классификаторам, таким как метод опорных векторов с ядром (Kernel SVM), ансамблевые методы (например, градиентный бустинг) или нейронные сети.  \n",
        "\n",
        "Если в дальнейшем используются более сложные модели, которые, будучи мощными предсказателями класса, могут демонстрировать плохую калибровку вероятностей (например, излишнюю уверенность), их результаты могут быть улучшены с помощью методов пост-калибрации, таких как **Изотоническая Регрессия** или **Платт-скейлинг**. Это гарантирует, что даже нелинейные модели выдают прогностические вероятности, которые можно надёжно интерпретировать.\n",
        "\n",
        "> **Перспектива для NLP**:  \n",
        "> В будущем, при интеграции моделей вроде Tatar2Vec с последующим применением нейросетевых классификаторов, калибровка будет играть ещё более важную роль — эмбеддинги могут давать высокую точность, но их вероятности часто переувереныны. Тогда именно комбинация продвинутой векторизации и пост-калибрации создаст надёжную NLP-систему для татарского языка.\n",
        ""
      ],
      "metadata": {
        "id": "6X50F5qKVx32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7KIflCsiXYk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Комплексная система многоклассовой классификации на основе мультиномиальной логистической регрессии.\n",
        "Реализует все теоретические концепции из лекции в объектно-ориентированном стиле.\n",
        "\n",
        "Архитектура системы:\n",
        "1. MulticlassClassifier - основной класс классификатора\n",
        "2. MulticlassDataManager - управление данными и предобработка\n",
        "3. MulticlassEvaluator - комплексная оценка модели\n",
        "4. MulticlassVisualizer - визуализация результатов\n",
        "5. ProbabilityCalibrator - диагностика калибровки вероятностей\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    roc_curve, RocCurveDisplay, log_loss, brier_score_loss\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.utils import resample\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class MulticlassDataManager:\n",
        "    \"\"\"Класс для управления многоклассовыми данными и предобработки\"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_binarizer = LabelBinarizer()\n",
        "        self.is_fitted = False\n",
        "\n",
        "    def create_synthetic_dataset(self, n_samples=1500, n_features=5, n_classes=3,\n",
        "                               n_informative=2, n_redundant=1, weights=None,\n",
        "                               flip_y=0.05, **kwargs):\n",
        "        \"\"\"\n",
        "        Создание синтетического многоклассового датасета\n",
        "        \"\"\"\n",
        "        if weights is None:\n",
        "            weights = [0.6, 0.25, 0.15]  # Дисбаланс по умолчанию\n",
        "\n",
        "        X, y = make_classification(\n",
        "            n_samples=n_samples,\n",
        "            n_features=n_features,\n",
        "            n_informative=n_informative,\n",
        "            n_redundant=n_redundant,\n",
        "            n_classes=n_classes,\n",
        "            n_clusters_per_class=1,\n",
        "            weights=weights,\n",
        "            flip_y=flip_y,\n",
        "            random_state=self.random_state,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.n_classes = n_classes\n",
        "        self.feature_names = [f'Feature_{i}' for i in range(n_features)]\n",
        "\n",
        "        print(f\"Создан синтетический датасет: {X.shape}\")\n",
        "        print(f\"Количество классов: {n_classes}\")\n",
        "        print(f\"Распределение классов: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def prepare_data(self, X, y, test_size=0.3, scale=True):\n",
        "        \"\"\"Подготовка данных для обучения\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
        "        )\n",
        "\n",
        "        if scale:\n",
        "            X_train = self.scaler.fit_transform(X_train)\n",
        "            X_test = self.scaler.transform(X_test)\n",
        "\n",
        "        # Бинаризация меток для многоклассовых метрик\n",
        "        y_train_onehot = self.label_binarizer.fit_transform(y_train)\n",
        "        y_test_onehot = self.label_binarizer.transform(y_test)\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.y_train_onehot = y_train_onehot\n",
        "        self.y_test_onehot = y_test_onehot\n",
        "        self.is_fitted = True\n",
        "\n",
        "        print(f\"Данные подготовлены: train {X_train.shape}, test {X_test.shape}\")\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def balance_dataset(self, method='class_weight'):\n",
        "        \"\"\"Балансировка датасета\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Данные не подготовлены\")\n",
        "\n",
        "        if method == 'class_weight':\n",
        "            print(\"Используется стратегия class_weight='balanced'\")\n",
        "            return 'balanced'\n",
        "\n",
        "        elif method == 'oversample':\n",
        "            print(\"Применяется oversampling миноритарных классов...\")\n",
        "            X_resampled = [self.X_train]\n",
        "            y_resampled = [self.y_train]\n",
        "\n",
        "            # Oversampling для каждого миноритарного класса\n",
        "            for class_label in np.unique(self.y_train):\n",
        "                class_count = np.sum(self.y_train == class_label)\n",
        "                max_count = max(np.bincount(self.y_train))\n",
        "\n",
        "                if class_count < max_count:\n",
        "                    X_class = self.X_train[self.y_train == class_label]\n",
        "                    X_oversampled = resample(\n",
        "                        X_class,\n",
        "                        replace=True,\n",
        "                        n_samples=max_count - class_count,\n",
        "                        random_state=self.random_state\n",
        "                    )\n",
        "                    y_oversampled = np.full(len(X_oversampled), class_label)\n",
        "\n",
        "                    X_resampled.append(X_oversampled)\n",
        "                    y_resampled.append(y_oversampled)\n",
        "\n",
        "            self.X_train = np.vstack(X_resampled)\n",
        "            self.y_train = np.hstack(y_resampled)\n",
        "\n",
        "            print(f\"После oversampling: {dict(zip(*np.unique(self.y_train, return_counts=True)))}\")\n",
        "            return None\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Метод должен быть 'class_weight' или 'oversample'\")\n",
        "\n",
        "class MulticlassEvaluator:\n",
        "    \"\"\"Класс для комплексной оценки многоклассовой модели\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics_history = []\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, y_proba, y_true_onehot=None, average_methods=None):\n",
        "        \"\"\"Расчет всех метрик качества для многоклассовой классификации\"\"\"\n",
        "        if average_methods is None:\n",
        "            average_methods = ['micro', 'macro', 'weighted']\n",
        "\n",
        "        metrics = {}\n",
        "\n",
        "        # Accuracy\n",
        "        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        # Precision, Recall, F1 для разных методов усреднения\n",
        "        for avg in average_methods:\n",
        "            metrics[f'precision_{avg}'] = precision_score(y_true, y_pred, average=avg, zero_division=0)\n",
        "            metrics[f'recall_{avg}'] = recall_score(y_true, y_pred, average=avg, zero_division=0)\n",
        "            metrics[f'f1_{avg}'] = f1_score(y_true, y_pred, average=avg, zero_division=0)\n",
        "\n",
        "        # ROC AUC (требует onehot кодирование)\n",
        "        if y_true_onehot is not None and y_proba is not None:\n",
        "            try:\n",
        "                metrics['roc_auc_micro'] = roc_auc_score(y_true_onehot, y_proba, multi_class='ovr', average='micro')\n",
        "                metrics['roc_auc_macro'] = roc_auc_score(y_true_onehot, y_proba, multi_class='ovr', average='macro')\n",
        "            except:\n",
        "                metrics['roc_auc_micro'] = 0.5\n",
        "                metrics['roc_auc_macro'] = 0.5\n",
        "\n",
        "        # Log Loss\n",
        "        if y_proba is not None:\n",
        "            metrics['log_loss'] = log_loss(y_true, y_proba)\n",
        "\n",
        "        # Brier Score Loss (для каждого класса)\n",
        "        if y_true_onehot is not None and y_proba is not None:\n",
        "            brier_scores = []\n",
        "            for i in range(y_proba.shape[1]):\n",
        "                try:\n",
        "                    bsl = brier_score_loss(y_true_onehot[:, i], y_proba[:, i])\n",
        "                    brier_scores.append(bsl)\n",
        "                except:\n",
        "                    brier_scores.append(1.0)\n",
        "            metrics['brier_score_mean'] = np.mean(brier_scores)\n",
        "            metrics['brier_scores'] = brier_scores\n",
        "\n",
        "        # Матрица ошибок\n",
        "        metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        self.metrics_history.append(metrics)\n",
        "        return metrics\n",
        "\n",
        "    def print_detailed_report(self, y_true, y_pred, y_proba=None):\n",
        "        \"\"\"Детальный отчет о качестве модели\"\"\"\n",
        "        print(\"=\" * 70)\n",
        "        print(\"КОМПЛЕКСНАЯ ОЦЕНКА МНОГОКЛАССОВОЙ МОДЕЛИ\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Classification report\n",
        "        print(\"\\nДЕТАЛЬНЫЙ ОТЧЕТ ПО КЛАССАМ:\")\n",
        "        print(classification_report(y_true, y_pred, digits=3))\n",
        "\n",
        "        # Основные метрики\n",
        "        print(\"\\nОБОБЩЕННЫЕ МЕТРИКИ:\")\n",
        "        print(f\"Accuracy:           {accuracy_score(y_true, y_pred):.4f}\")\n",
        "        print(f\"Precision (Macro):  {precision_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "        print(f\"Recall (Macro):     {recall_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "        print(f\"F1-Score (Macro):   {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "        if y_proba is not None:\n",
        "            print(f\"Log Loss:           {log_loss(y_true, y_proba):.4f}\")\n",
        "\n",
        "        # Сравнение методов усреднения\n",
        "        print(\"\\nСРАВНЕНИЕ МЕТОДОВ УСРЕДНЕНИЯ:\")\n",
        "        averages = ['micro', 'macro', 'weighted']\n",
        "        for avg in averages:\n",
        "            precision = precision_score(y_true, y_pred, average=avg, zero_division=0)\n",
        "            recall = recall_score(y_true, y_pred, average=avg, zero_division=0)\n",
        "            f1 = f1_score(y_true, y_pred, average=avg, zero_division=0)\n",
        "            print(f\"{avg:8}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "class MulticlassVisualizer:\n",
        "    \"\"\"Класс для визуализации результатов многоклассовой классификации\"\"\"\n",
        "\n",
        "    def __init__(self, figsize=(10, 8)):\n",
        "        self.figsize = figsize\n",
        "        plt.style.use('default')\n",
        "        sns.set_palette(\"husl\")\n",
        "\n",
        "    def plot_confusion_matrix(self, cm, class_names, title=\"Матрица ошибок\"):\n",
        "        \"\"\"Визуализация матрицы ошибок\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=self.figsize)\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names,\n",
        "                   ax=ax)\n",
        "\n",
        "        ax.set_xlabel('Предсказанный класс')\n",
        "        ax.set_ylabel('Истинный класс')\n",
        "        ax.set_title(title)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_roc_curves(self, y_true_onehot, y_proba, class_names, title=\"ROC кривые\"):\n",
        "        \"\"\"Визуализация ROC кривых для многоклассовой классификации\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=self.figsize)\n",
        "\n",
        "        # ROC кривые для каждого класса\n",
        "        for i in range(len(class_names)):\n",
        "            fpr, tpr, _ = roc_curve(y_true_onehot[:, i], y_proba[:, i])\n",
        "            roc_auc = roc_auc_score(y_true_onehot[:, i], y_proba[:, i])\n",
        "\n",
        "            ax.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.3f})', linewidth=2)\n",
        "\n",
        "        # Micro-average ROC curve\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(y_true_onehot.ravel(), y_proba.ravel())\n",
        "        roc_auc_micro = roc_auc_score(y_true_onehot, y_proba, multi_class='ovr', average='micro')\n",
        "        ax.plot(fpr_micro, tpr_micro,\n",
        "               label=f'Micro-average (AUC = {roc_auc_micro:.3f})',\n",
        "               color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "        # Случайный классификатор\n",
        "        ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Случайный классификатор')\n",
        "\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.set_title(title)\n",
        "        ax.legend()\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_calibration_curves(self, y_true_onehot, y_proba, class_names, title=\"Калибровочные кривые\"):\n",
        "        \"\"\"Визуализация калибровочных кривых\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=self.figsize)\n",
        "\n",
        "        # Идеальная калибровка\n",
        "        ax.plot([0, 1], [0, 1], \"k--\", label=\"Идеальная калибровка\")\n",
        "\n",
        "        # Калибровочные кривые для каждого класса\n",
        "        for i in range(len(class_names)):\n",
        "            prob_true, prob_pred = calibration_curve(\n",
        "                y_true_onehot[:, i], y_proba[:, i], n_bins=10, strategy='uniform'\n",
        "            )\n",
        "            ax.plot(prob_pred, prob_true, marker='o', label=f'Класс {class_names[i]}', linewidth=2)\n",
        "\n",
        "        ax.set_xlabel('Средняя предсказанная вероятность')\n",
        "        ax.set_ylabel('Доля истинных событий')\n",
        "        ax.set_title(title)\n",
        "        ax.legend()\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    def plot_feature_importance(self, feature_names, coefficients, title=\"Важность признаков\"):\n",
        "        \"\"\"Визуализация важности признаков\"\"\"\n",
        "        n_classes = coefficients.shape[0]\n",
        "        n_features = len(feature_names)\n",
        "\n",
        "        fig, axes = plt.subplots(1, n_classes, figsize=(5*n_classes, 6))\n",
        "        if n_classes == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        for i, ax in enumerate(axes):\n",
        "            # Абсолютные значения коэффициентов для важности\n",
        "            importance = np.abs(coefficients[i])\n",
        "            indices = np.argsort(importance)[::-1]\n",
        "\n",
        "            ax.bar(range(n_features), importance[indices])\n",
        "            ax.set_xticks(range(n_features))\n",
        "            ax.set_xticklabels([feature_names[j] for j in indices], rotation=45)\n",
        "            ax.set_title(f'Класс {i}')\n",
        "            ax.set_ylabel('Абсолютное значение коэффициента')\n",
        "            ax.grid(alpha=0.3)\n",
        "\n",
        "        plt.suptitle(title)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "class ProbabilityCalibrator:\n",
        "    \"\"\"Класс для диагностики калибровки вероятностей\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.calibration_results = {}\n",
        "\n",
        "    def evaluate_calibration(self, y_true_onehot, y_proba):\n",
        "        \"\"\"Комплексная оценка калибровки вероятностей\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Log Loss\n",
        "        results['log_loss'] = log_loss(y_true_onehot, y_proba)\n",
        "\n",
        "        # Brier Score Loss для каждого класса\n",
        "        brier_scores = []\n",
        "        for i in range(y_proba.shape[1]):\n",
        "            bsl = brier_score_loss(y_true_onehot[:, i], y_proba[:, i])\n",
        "            brier_scores.append(bsl)\n",
        "\n",
        "        results['brier_scores'] = brier_scores\n",
        "        results['brier_score_mean'] = np.mean(brier_scores)\n",
        "        results['brier_score_std'] = np.std(brier_scores)\n",
        "\n",
        "        # Калибровочные кривые\n",
        "        calibration_curves = {}\n",
        "        for i in range(y_proba.shape[1]):\n",
        "            prob_true, prob_pred = calibration_curve(\n",
        "                y_true_onehot[:, i], y_proba[:, i], n_bins=10, strategy='uniform'\n",
        "            )\n",
        "            calibration_curves[f'class_{i}'] = {\n",
        "                'prob_true': prob_true,\n",
        "                'prob_pred': prob_pred\n",
        "            }\n",
        "\n",
        "        results['calibration_curves'] = calibration_curves\n",
        "\n",
        "        self.calibration_results = results\n",
        "        return results\n",
        "\n",
        "    def print_calibration_report(self):\n",
        "        \"\"\"Отчет о калибровке вероятностей\"\"\"\n",
        "        if not self.calibration_results:\n",
        "            print(\"Сначала выполните evaluate_calibration()\")\n",
        "            return\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ДИАГНОСТИКА КАЛИБРОВКИ ВЕРОЯТНОСТЕЙ\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        results = self.calibration_results\n",
        "\n",
        "        print(f\"\\nLog Loss (Кросс-Энтропия): {results['log_loss']:.4f}\")\n",
        "        print(f\"Brier Score Loss (средний): {results['brier_score_mean']:.4f}\")\n",
        "        print(f\"Brier Score Loss (std): {results['brier_score_std']:.4f}\")\n",
        "\n",
        "        print(\"\\nBrier Score Loss по классам:\")\n",
        "        for i, score in enumerate(results['brier_scores']):\n",
        "            print(f\"  Класс {i}: {score:.4f}\")\n",
        "\n",
        "        # Интерпретация\n",
        "        print(\"\\nИНТЕРПРЕТАЦИЯ:\")\n",
        "        if results['brier_score_mean'] < 0.1:\n",
        "            print(\"✅ Отличная калибровка вероятностей\")\n",
        "        elif results['brier_score_mean'] < 0.2:\n",
        "            print(\"⚠️  Хорошая калибровка вероятностей\")\n",
        "        elif results['brier_score_mean'] < 0.3:\n",
        "            print(\"🔶 Удовлетворительная калибровка\")\n",
        "        else:\n",
        "            print(\"❌ Плохая калибровка вероятностей\")\n",
        "\n",
        "class MulticlassClassifier:\n",
        "    \"\"\"\n",
        "    Основной класс для многоклассовой классификации с использованием\n",
        "    мультиномиальной логистической регрессии.\n",
        "    \"\"\"\n",
        "\n",
        "    SOLVER_COMPATIBILITY = {\n",
        "        'lbfgs': ['l2', None],\n",
        "        'newton-cg': ['l2', None],\n",
        "        'sag': ['l2', None],\n",
        "        'saga': ['l1', 'l2', 'elasticnet', None],\n",
        "        'liblinear': ['l1', 'l2']  # Только OvR\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 multi_class='multinomial',\n",
        "                 penalty='l2',\n",
        "                 C=1.0,\n",
        "                 solver='lbfgs',\n",
        "                 class_weight=None,\n",
        "                 max_iter=1000,\n",
        "                 random_state=42,\n",
        "                 l1_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Инициализация многоклассового классификатора\n",
        "        \"\"\"\n",
        "        self.multi_class = multi_class\n",
        "        self.penalty = penalty\n",
        "        self.C = C\n",
        "        self.solver = solver\n",
        "        self.class_weight = class_weight\n",
        "        self.max_iter = max_iter\n",
        "        self.random_state = random_state\n",
        "        self.l1_ratio = l1_ratio\n",
        "\n",
        "        self._validate_parameters()\n",
        "        self.model = None\n",
        "        self.is_fitted = False\n",
        "\n",
        "        # Инициализация компонентов системы\n",
        "        self.data_manager = MulticlassDataManager(random_state=random_state)\n",
        "        self.evaluator = MulticlassEvaluator()\n",
        "        self.visualizer = MulticlassVisualizer()\n",
        "        self.calibrator = ProbabilityCalibrator()\n",
        "\n",
        "    def _validate_parameters(self):\n",
        "        \"\"\"Валидация параметров модели\"\"\"\n",
        "        if self.multi_class not in ['multinomial', 'ovr']:\n",
        "            raise ValueError(\"multi_class должен быть 'multinomial' или 'ovr'\")\n",
        "\n",
        "        if self.solver not in self.SOLVER_COMPATIBILITY:\n",
        "            raise ValueError(f\"Неподдерживаемый solver: {self.solver}\")\n",
        "\n",
        "        if self.penalty not in self.SOLVER_COMPATIBILITY[self.solver]:\n",
        "            compatible = self.SOLVER_COMPATIBILITY[self.solver]\n",
        "            raise ValueError(f\"Solver '{self.solver}' не поддерживает penalty '{self.penalty}'. \"\n",
        "                           f\"Допустимые значения: {compatible}\")\n",
        "\n",
        "        # Проверка совместимости multinomial режима\n",
        "        if self.multi_class == 'multinomial' and self.solver == 'liblinear':\n",
        "            raise ValueError(\"Solver 'liblinear' не поддерживает multi_class='multinomial'. \"\n",
        "                           \"Используйте 'ovr' или выберите другой solver (lbfgs, saga, etc.)\")\n",
        "\n",
        "    def _create_model(self):\n",
        "        \"\"\"Создание модели логистической регрессии\"\"\"\n",
        "        if self.penalty == 'elasticnet' and self.solver == 'saga':\n",
        "            return LogisticRegression(\n",
        "                multi_class=self.multi_class,\n",
        "                penalty=self.penalty,\n",
        "                C=self.C,\n",
        "                solver=self.solver,\n",
        "                class_weight=self.class_weight,\n",
        "                max_iter=self.max_iter,\n",
        "                random_state=self.random_state,\n",
        "                l1_ratio=self.l1_ratio,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "        else:\n",
        "            return LogisticRegression(\n",
        "                multi_class=self.multi_class,\n",
        "                penalty=self.penalty,\n",
        "                C=self.C,\n",
        "                solver=self.solver,\n",
        "                class_weight=self.class_weight,\n",
        "                max_iter=self.max_iter,\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "    def fit(self, X, y, feature_names=None):\n",
        "        \"\"\"\n",
        "        Обучение модели\n",
        "        \"\"\"\n",
        "        self.feature_names = feature_names\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.n_classes = len(self.classes_)\n",
        "\n",
        "        # Обучение модели\n",
        "        self.model = self._create_model()\n",
        "        self.model.fit(X, y)\n",
        "        self.is_fitted = True\n",
        "\n",
        "        print(f\"Модель обучена. Количество классов: {self.n_classes}\")\n",
        "        print(f\"Коэффициенты: {self.model.coef_.shape}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Предсказание классов\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Предсказание вероятностей\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "        return self.model.predict_proba(X)\n",
        "\n",
        "    def evaluate(self, X, y_true, y_true_onehot=None, verbose=True):\n",
        "        \"\"\"Комплексная оценка модели\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "\n",
        "        y_pred = self.predict(X)\n",
        "        y_proba = self.predict_proba(X)\n",
        "\n",
        "        metrics = self.evaluator.calculate_metrics(y_true, y_pred, y_proba, y_true_onehot)\n",
        "\n",
        "        if verbose:\n",
        "            self.evaluator.print_detailed_report(y_true, y_pred, y_proba)\n",
        "\n",
        "        return metrics, y_pred, y_proba\n",
        "\n",
        "    def interpret_coefficients(self, top_n=10):\n",
        "        \"\"\"Интерпретация коэффициентов модели\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise RuntimeError(\"Модель не обучена. Сначала вызовите fit().\")\n",
        "\n",
        "        if self.feature_names is None:\n",
        "            self.feature_names = [f'Feature_{i}' for i in range(self.model.coef_.shape[1])]\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ИНТЕРПРЕТАЦИЯ КОЭФФИЦИЕНТОВ МОДЕЛИ\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        for class_idx in range(self.n_classes):\n",
        "            coef = self.model.coef_[class_idx]\n",
        "            intercept = self.model.intercept_[class_idx]\n",
        "\n",
        "            # Создание DataFrame с коэффициентами\n",
        "            coef_df = pd.DataFrame({\n",
        "                'feature': self.feature_names,\n",
        "                'coefficient': coef,\n",
        "                'abs_coefficient': np.abs(coef),\n",
        "                'odds_ratio': np.exp(coef)\n",
        "            }).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "            print(f\"\\n--- Класс {class_idx} (Intercept: {intercept:.4f}) ---\")\n",
        "            print(f\"Топ-{top_n} наиболее важных признаков:\")\n",
        "            print(coef_df.head(top_n).round(4).to_string(index=False))\n",
        "\n",
        "        return self.model.coef_, self.model.intercept_\n",
        "\n",
        "    def demonstrate_softmax_function(self):\n",
        "        \"\"\"Демонстрация работы Softmax функции\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ДЕМОНСТРАЦИЯ SOFTMAX ФУНКЦИИ\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Генерация примеров логитов\n",
        "        np.random.seed(self.random_state)\n",
        "        logits_examples = [\n",
        "            np.array([1.0, 2.0, 0.5]),    # Один доминирующий класс\n",
        "            np.array([0.1, 0.1, 0.1]),    # Все классы равновероятны\n",
        "            np.array([3.0, 2.9, 0.1]),    # Два конкурирующих класса\n",
        "            np.array([-1.0, 0.0, 1.0])    # Разброс значений\n",
        "        ]\n",
        "\n",
        "        print(\"\\nПреобразование логитов в вероятности с помощью Softmax:\")\n",
        "        print(\"Логиты -> Вероятности -> Сумма вероятностей\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for i, logits in enumerate(logits_examples):\n",
        "            # Softmax вручную\n",
        "            exp_logits = np.exp(logits - np.max(logits))  # Стабильная версия\n",
        "            probabilities = exp_logits / np.sum(exp_logits)\n",
        "\n",
        "            print(f\"Пример {i+1}:\")\n",
        "            print(f\"  Логиты:    {logits}\")\n",
        "            print(f\"  Вероятности: {probabilities}\")\n",
        "            print(f\"  Сумма: {np.sum(probabilities):.6f}\")\n",
        "            print()\n",
        "\n",
        "    def compare_ovr_vs_multinomial(self, X_train, y_train, X_test, y_test, y_test_onehot):\n",
        "        \"\"\"Сравнение стратегий OvR и Multinomial\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"СРАВНЕНИЕ OVR VS MULTINOMIAL СТРАТЕГИЙ\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Multinomial модель\n",
        "        model_multinomial = LogisticRegression(\n",
        "            multi_class='multinomial',\n",
        "            solver='lbfgs',\n",
        "            max_iter=1000,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        model_multinomial.fit(X_train, y_train)\n",
        "\n",
        "        # OvR модель\n",
        "        model_ovr = LogisticRegression(\n",
        "            multi_class='ovr',\n",
        "            solver='liblinear',\n",
        "            max_iter=1000,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        model_ovr.fit(X_train, y_train)\n",
        "\n",
        "        # Предсказания\n",
        "        y_pred_multi = model_multinomial.predict(X_test)\n",
        "        y_proba_multi = model_multinomial.predict_proba(X_test)\n",
        "\n",
        "        y_pred_ovr = model_ovr.predict(X_test)\n",
        "        y_proba_ovr = model_ovr.predict_proba(X_test)\n",
        "\n",
        "        # Сравнение метрик\n",
        "        metrics_multi = self.evaluator.calculate_metrics(y_test, y_pred_multi, y_proba_multi, y_test_onehot)\n",
        "        metrics_ovr = self.evaluator.calculate_metrics(y_test, y_pred_ovr, y_proba_ovr, y_test_onehot)\n",
        "\n",
        "        print(\"\\nСРАВНЕНИЕ МЕТРИК:\")\n",
        "        comparison_df = pd.DataFrame({\n",
        "            'Multinomial': [\n",
        "                metrics_multi['accuracy'],\n",
        "                metrics_multi['f1_macro'],\n",
        "                metrics_multi['roc_auc_macro'],\n",
        "                metrics_multi['log_loss']\n",
        "            ],\n",
        "            'OvR': [\n",
        "                metrics_ovr['accuracy'],\n",
        "                metrics_ovr['f1_macro'],\n",
        "                metrics_ovr['roc_auc_macro'],\n",
        "                metrics_ovr['log_loss']\n",
        "            ]\n",
        "        }, index=['Accuracy', 'F1 Macro', 'ROC AUC Macro', 'Log Loss'])\n",
        "\n",
        "        print(comparison_df.round(4))\n",
        "\n",
        "        # Сравнение сумм вероятностей\n",
        "        print(f\"\\nСуммы вероятностей (должны быть = 1.0):\")\n",
        "        print(f\"Multinomial: min={np.min(y_proba_multi.sum(axis=1)):.6f}, \"\n",
        "              f\"max={np.max(y_proba_multi.sum(axis=1)):.6f}\")\n",
        "        print(f\"OvR:         min={np.min(y_proba_ovr.sum(axis=1)):.6f}, \"\n",
        "              f\"max={np.max(y_proba_ovr.sum(axis=1)):.6f}\")\n",
        "\n",
        "        return model_multinomial, model_ovr\n",
        "\n",
        "    def demonstrate_complete_workflow(self):\n",
        "        \"\"\"Полная демонстрация рабочего процесса многоклассовой классификации\"\"\"\n",
        "        print(\"ПОЛНАЯ ДЕМОНСТРАЦИЯ МНОГОКЛАССОВОЙ КЛАССИФИКАЦИИ\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # 1. Генерация данных\n",
        "        print(\"\\n1. ГЕНЕРАЦИЯ СИНТЕТИЧЕСКИХ ДАННЫХ\")\n",
        "        X, y = self.data_manager.create_synthetic_dataset(\n",
        "            n_samples=1500, n_features=5, n_classes=3,\n",
        "            n_informative=2, weights=[0.6, 0.25, 0.15]\n",
        "        )\n",
        "\n",
        "        # 2. Подготовка данных\n",
        "        print(\"\\n2. ПОДГОТОВКА ДАННЫХ\")\n",
        "        X_train, X_test, y_train, y_test = self.data_manager.prepare_data(X, y)\n",
        "\n",
        "        # 3. Демонстрация Softmax\n",
        "        self.demonstrate_softmax_function()\n",
        "\n",
        "        # 4. Сравнение стратегий\n",
        "        print(\"\\n3. СРАВНЕНИЕ СТРАТЕГИЙ КЛАССИФИКАЦИИ\")\n",
        "        self.compare_ovr_vs_multinomial(X_train, y_train, X_test, y_test,\n",
        "                                      self.data_manager.y_test_onehot)\n",
        "\n",
        "        # 5. Обучение основной модели\n",
        "        print(\"\\n4. ОБУЧЕНИЕ ОСНОВНОЙ МОДЕЛИ (Multinomial + ElasticNet)\")\n",
        "        self.fit(X_train, y_train, self.data_manager.feature_names)\n",
        "\n",
        "        # 6. Оценка модели\n",
        "        print(\"\\n5. КОМПЛЕКСНАЯ ОЦЕНКА МОДЕЛИ\")\n",
        "        metrics, y_pred, y_proba = self.evaluate(\n",
        "            X_test, y_test, self.data_manager.y_test_onehot\n",
        "        )\n",
        "\n",
        "        # 7. Интерпретация коэффициентов\n",
        "        print(\"\\n6. ИНТЕРПРЕТАЦИЯ МОДЕЛИ\")\n",
        "        coefficients, intercepts = self.interpret_coefficients()\n",
        "\n",
        "        # 8. Диагностика калибровки\n",
        "        print(\"\\n7. ДИАГНОСТИКА КАЛИБРОВКИ ВЕРОЯТНОСТЕЙ\")\n",
        "        calibration_results = self.calibrator.evaluate_calibration(\n",
        "            self.data_manager.y_test_onehot, y_proba\n",
        "        )\n",
        "        self.calibrator.print_calibration_report()\n",
        "\n",
        "        # 9. Визуализации\n",
        "        print(\"\\n8. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\")\n",
        "\n",
        "        # Матрица ошибок\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        self.visualizer.plot_confusion_matrix(\n",
        "            cm, self.classes_, \"Матрица ошибок Multinomial LR\"\n",
        "        )\n",
        "\n",
        "        # ROC кривые\n",
        "        self.visualizer.plot_roc_curves(\n",
        "            self.data_manager.y_test_onehot, y_proba,\n",
        "            self.classes_, \"ROC кривые для Multinomial LR\"\n",
        "        )\n",
        "\n",
        "        # Калибровочные кривые\n",
        "        self.visualizer.plot_calibration_curves(\n",
        "            self.data_manager.y_test_onehot, y_proba,\n",
        "            self.classes_, \"Калибровочные кривые\"\n",
        "        )\n",
        "\n",
        "        # Важность признаков\n",
        "        if hasattr(self, 'feature_names'):\n",
        "            self.visualizer.plot_feature_importance(\n",
        "                self.feature_names, coefficients, \"Важность признаков по классам\"\n",
        "            )\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ДЕМОНСТРАЦИЯ ЗАВЕРШЕНА\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ДЕМОНСТРАЦИЯ РАБОТЫ СИСТЕМЫ\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Основная функция демонстрации системы\"\"\"\n",
        "    print(\"КОМПЛЕКСНАЯ СИСТЕМА МНОГОКЛАССОВОЙ КЛАССИФИКАЦИИ\")\n",
        "    print(\"На основе мультиномиальной логистической регрессии\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Создание классификатора с ElasticNet регуляризацией\n",
        "    classifier = MulticlassClassifier(\n",
        "        multi_class='multinomial',\n",
        "        penalty='elasticnet',\n",
        "        solver='saga',\n",
        "        C=1.0,\n",
        "        class_weight='balanced',\n",
        "        l1_ratio=0.5,\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Запуск полной демонстрации\n",
        "    classifier.demonstrate_complete_workflow()\n",
        "\n",
        "    print(\"\\nРЕАЛИЗОВАННЫЕ КОНЦЕПЦИИ:\")\n",
        "    print(\"✅ Мультиномиальная логистическая регрессия (Softmax)\")\n",
        "    print(\"✅ Стратегия 'Один против всех' (OvR)\")\n",
        "    print(\"✅ Регуляризация L1, L2, ElasticNet\")\n",
        "    print(\"✅ Работа с дисбалансом классов\")\n",
        "    print(\"✅ Комплексные метрики оценки (Macro, Micro, Weighted)\")\n",
        "    print(\"✅ ROC AUC для многоклассовой классификации\")\n",
        "    print(\"✅ Диагностика калибровки вероятностей\")\n",
        "    print(\"✅ Brier Score Loss и Log Loss\")\n",
        "    print(\"✅ Визуализация матрицы ошибок и ROC кривых\")\n",
        "    print(\"✅ Интерпретация коэффициентов модели\")\n",
        "\n",
        "    return classifier\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Запуск демонстрации\n",
        "    final_classifier = main()"
      ],
      "metadata": {
        "id": "pYYffuZjXY8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Раздел  3. Многометочная классификация: теоретические основы и практическая реализация\n",
        "\n",
        "\n",
        "### I. Введение: Фундаментальные Концепции Многометочной Классификации\n",
        "\n",
        "Многометочная классификация (Multi-label Classification) представляет собой обобщение традиционных задач классификации в машинном обучении. В то время как многоклассовая классификация (Multi-class Classification) требует от системы присвоения каждому экземпляру одной единственной, взаимоисключающей метки (например, изображение — это либо «яблоко», либо «груша»), многометочная классификация позволяет присвоить одному экземпляру множество неисключающих меток.  \n",
        "\n",
        "Формально задача многометочного обучения заключается в поиске модели, которая отображает входной вектор признаков $X$ в бинарный вектор меток $Y = \\{y_1, y_2, \\dots, y_Q\\}$, где $Q$ — общее количество возможных меток, а каждый элемент $y_i$ может принимать значение 0 или 1, указывая на отсутствие или присутствие соответствующей метки. Например, текстовый документ может быть одновременно помечен как «Политика» и «Финансы», поскольку эти темы не являются взаимоисключающими.\n",
        "\n",
        "> **Пример в NLP (на татарском языке)**:  \n",
        "> В корпусе татарских новостных статей одна и та же публикация может содержать признаки сразу нескольких тем: «Мәдәният» (культура), «Тарих» (история) и «Татар теле» (язык). Например, репортаж о фестивале татарской поэзии в Казани одновременно относится ко всем трём категориям. Многометочная классификация позволяет корректно отразить такую семантическую многогранность, в отличие от жёсткой многоклассовой схемы.\n",
        "\n",
        "#### I.1. Принцип Бинарной Релевантности (Binary Relevance, BR)\n",
        "\n",
        "Базовым и наиболее распространённым подходом к решению многометочной задачи является метод преобразования задачи (Problem Transformation) под названием **Бинарная Релевантность** (Binary Relevance, BR). Этот подход преобразует исходную сложную многомерную задачу в набор $Q$ независимых бинарных классификационных задач.\n",
        "\n",
        "##### Принцип Работы BR\n",
        "\n",
        "1. Для каждой из $Q$ меток создаётся отдельный бинарный классификатор $C_j$.  \n",
        "2. Каждый классификатор $C_j$ обучается независимо, используя исходные признаки $X$, чтобы предсказать наличие ($y_j=1$) или отсутствие ($y_j=0$) только своей метки.  \n",
        "3. При предсказании для нового образца $x$, модель BR агрегирует результаты всех $Q$ классификаторов. Если классификатор $C_j$ выдаёт положительный результат, метка $y_j$ присваивается образцу.  \n",
        "\n",
        "В библиотеке Scikit-learn реализация BR осуществляется с помощью мета-классификатора `MultiOutputClassifier`. Он позволяет обернуть любой стандартный классификатор, например, `LogisticRegression`, и применить его независимо к каждому целевому столбцу.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При анализе отзывов на книги на татарском языке каждый отзыв может содержать метки: «Эмоционально окраслы» (эмоциональный), «Билгеләнгән автор» (известный автор), «Балалар өчен» (для детей). Использование BR позволяет обучить три независимых классификатора на TF-IDF-признаках, и, например, для отзыва «Бу китап балалар өчен дә, шулай ук билгеле язучы Әхмәтова турында» модель вернёт вектор `[0, 1, 1]` (если первый класс — «эмоциональный», который здесь отсутствует).\n",
        "\n",
        "##### Сравнение с Многоклассовой Задачей\n",
        "\n",
        "Хотя BR внешне напоминает метод «Один против всех» (One-vs.-Rest, OvR), используемый в многоклассовой классификации, он принципиально отличается. В OvR цель состоит в выборе одного лучшего класса из $K$ возможных, тогда как в BR могут быть предсказаны все, некоторые или ни одной метки, так как метки не являются взаимоисключающими.\n",
        "\n",
        "**Таблица I: Сравнение Классификационных Задач**\n",
        "\n",
        "| Характеристика             | Многоклассовая (Multi-Class)        | Многометочная (Multi-Label)        | BR (наша модель)                          |\n",
        "|---------------------------|--------------------------------------|-------------------------------------|------------------------------------------|\n",
        "| Выход                     | Одно значение из $K$                | Вектор $\\{0, 1\\}^Q$                | $Q$ независимых бинарных предсказаний   |\n",
        "| Взаимоисключаемость меток | Да                                   | Нет                                 | Обрабатывается как $Q$ независимых задач |\n",
        "| Учёт корреляции меток     | Присутствует (через softmax)        | Должен учитываться                 | Игнорируется (ключевое ограничение BR)   |\n",
        "\n",
        "##### Ограничения Метода BR\n",
        "\n",
        "Простота и высокая масштабируемость BR являются его главными преимуществами. Однако его ключевое ограничение заключается в том, что он полностью игнорирует корреляцию между метками. В реальных данных, особенно в задачах классификации документов или изображений, метки часто имеют сильную корреляцию (например, наличие метки «Зима» сильно коррелирует с меткой «Снег»). Поскольку BR обучает каждый классификатор $C_j$ независимо, он не использует информацию о том, что $P(Y_1|X)$ может зависеть от $Y_2$. Это приводит к субоптимальной производительности в задачах, где корреляция меток критически важна для точного предсказания.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В татарском корпусе юридических документов метки «Хокук» (право) и «Конституция» часто встречаются вместе. Модель BR может предсказать «Хокук» с высокой уверенностью, но не предсказать «Конституция», даже если контекст явно указывает на неё, потому что соответствующий бинарный классификатор не «знает» о присутствии первой метки.\n",
        "\n",
        "---\n",
        "\n",
        "### II. Практическая Реализация: Генерация Данных и Базовая Модель\n",
        "\n",
        "Для демонстрации принципа BR-LR (Binary Relevance с использованием Логистической Регрессии) необходим синтетический набор многометочных данных.\n",
        "\n",
        "#### II.1. Генерация Синтетического Многометочного Датасета (Python)\n",
        "\n",
        "Генерация данных осуществляется с использованием функции `make_multilabel_classification` из библиотеки Scikit-learn, которая позволяет настроить ключевые параметры, такие как количество образцов, признаков, общее число меток и, что важно, среднее число меток на один образец.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.metrics import multilabel_confusion_matrix, f1_score, hamming_loss, jaccard_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Генерация Датасета ---\n",
        "# n_classes = 5: Всего 5 возможных меток (столбцов в Y).\n",
        "# n_labels = 2: Среднее число меток на образец (из распределения Пуассона).\n",
        "X, y = make_multilabel_classification(\n",
        "    n_samples=500,        # Количество образцов\n",
        "    n_features=10,        # Количество признаков\n",
        "    n_classes=5,          # Общее количество меток (Q)\n",
        "    n_labels=2,           # Среднее количество меток на образец\n",
        "    allow_unlabeled=True, # Разрешить образцы без меток\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Вывод размерностей для проверки\n",
        "print(f\"Размерность признаков X: {X.shape}\")\n",
        "print(f\"Размерность меток Y: {y.shape}\")\n",
        "\n",
        "# Демонстрация первых трех векторов меток\n",
        "print(\"\\nПервые три вектора меток Y:\")\n",
        "print(list(y[:3]))\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nРазмер тренировочного набора: {X_train.shape}\")\n",
        "print(f\"Размер тестового набора: {X_test.shape}\")\n",
        "```\n",
        "\n",
        "> **Аналогия с текстом**:  \n",
        "> Здесь `X` имитирует векторизованные тексты (например, с помощью TF-IDF), а `y` — многометочные разметки. Например, 5 меток могут означать: `[«Спорт», «Экономика», «Наука», «Культура», «Политика»]`, и один документ может иметь `[1, 0, 1, 0, 1]` — то есть относиться одновременно к спорту, науке и политике (например, статья о государственном финансировании спортивных исследований).\n",
        "\n",
        "#### II.2. Построение Базовой Модели Логистической Регрессии (BR-LR)\n",
        "\n",
        "В качестве базового классификатора выбирается Логистическая Регрессия (`LogisticRegression`). Логистическая Регрессия является линейным классификатором, который выдаёт вероятности, что делает её идеальной для задач, где важна не только бинарная классификация, но и оценка уверенности (калибровка).\n",
        "\n",
        "```python\n",
        "# --- 2. Построение Модели BR-LR ---\n",
        "# Инициализация базового классификатора: LR с солвером 'liblinear' (подходит для небольших данных)\n",
        "base_lr = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Оборачивание в MultiOutputClassifier для многометочной классификации (реализация BR)\n",
        "multi_target_lr = MultiOutputClassifier(base_lr)\n",
        "\n",
        "# Обучение модели\n",
        "multi_target_lr.fit(X_train, y_train)\n",
        "\n",
        "# Получение бинарных предсказаний\n",
        "y_pred = multi_target_lr.predict(X_test)\n",
        "\n",
        "# Получение вероятностей предсказания (список из 5 массивов, по одному на метку)\n",
        "y_proba_list = multi_target_lr.predict_proba(X_test)\n",
        "\n",
        "print(\"\\nПример предсказания (Бинарный вектор):\")\n",
        "print(y_pred[:2])\n",
        "print(\"\\nПример вероятностей (Вероятность класса 1 для каждой метки):\")\n",
        "# Для удобства преобразуем список массивов вероятностей в массив,\n",
        "# взяв только вероятности положительного класса (индекс 1)\n",
        "y_proba_aggregated = np.column_stack([p[:, 1] for p in y_proba_list])\n",
        "print(y_proba_aggregated[:2])\n",
        "```\n",
        "\n",
        "> **Применение в NLP**:  \n",
        "> Вероятности `y_proba_aggregated` позволяют не только делать жёсткие предсказания, но и ранжировать метки по релевантности. Например, для татарского документа модель может выдать:  \n",
        "> `P(«Тарих») = 0.92`, `P(«Мәдәният») = 0.87`, `P(«Технология») = 0.15`.  \n",
        "> Это особенно полезно в системах рекомендаций, модерации или автоматического теггирования, где важно понимать степень уверенности.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "7p4OW6kwWWQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## III. Тонкая Настройка Гиперпараметров\n",
        "\n",
        "Логистическая регрессия в Scikit-learn по умолчанию является регуляризованным классификатором. Правильная настройка её гиперпараметров критически важна для достижения оптимальной производительности и предотвращения переобучения, особенно когда мы обучаем $Q$ независимых моделей.\n",
        "\n",
        "#### III.1. Ключевые Гиперпараметры Логистической Регрессии\n",
        "\n",
        "1. **Регуляризация (`penalty`)**: Определяет тип штрафа, добавляемого к функции потерь для ограничения сложности модели.  \n",
        "   - **L2 (default)**: Штраф по квадратам весов, способствует их уменьшению.  \n",
        "   - **L1**: Штраф по абсолютным значениям весов, способствует разреженности (обнуляет некоторые веса, выполняя отбор признаков).  \n",
        "   - **ElasticNet**: Комбинация L1 и L2 (требует солвера `saga`).  \n",
        "\n",
        "2. **Сила Регуляризации (`C`)**: Этот параметр является обратным силе регуляризации. Меньшее значение $C$ соответствует более сильной регуляризации (большему штрафу) и используется для борьбы с переобучением. Значение по умолчанию — 1.0.\n",
        "\n",
        "3. **Оптимизатор (`solver`)**: Алгоритм, используемый для минимизации функции потерь. Выбор солвера зависит от выбранного типа регуляризации.\n",
        "\n",
        "**Таблица III: Совместимость Солверов Логистической Регрессии и Регуляризации**\n",
        "\n",
        "| Solver (Оптимизатор) | L1 | L2 | ElasticNet | Рекомендации |\n",
        "|----------------------|----|----|------------|--------------|\n",
        "| `lbfgs`              | Нет | Да | Нет        | Хорош по умолчанию, но только L2. |\n",
        "| `liblinear`          | Да | Да | Нет        | Быстр для малых данных. Поддерживает L1/L2. |\n",
        "| `saga`               | Да | Да | Да         | Лучший выбор для ElasticNet и больших данных. |\n",
        "| `newton-cg`          | Нет | Да | Нет        | Только L2. |\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При классификации татарских научных статей по темам (`Q = 6`: «Физика», «Математика», «Лингвистика», «История», «Педагогика», «Информатика») применение L1-регуляризации помогает отобрать наиболее релевантные слова для каждой темы. Например, для «Лингвистики» могут остаться только такие признаки, как *татар теле*, *морфология*, *диалект*, в то время как общие слова (например, *документ*, *автор*) будут обнулены.\n",
        "\n",
        "#### III.2. Стратегия Оптимизации BR-LR\n",
        "\n",
        "При использовании `MultiOutputClassifier` мы обучаем $Q$ моделей. Необходимо найти единый набор гиперпараметров (например, оптимальное значение $C$), который даёт наилучший агрегированный результат.  \n",
        "Критически важно понимать, что при BR-LR мы предполагаем, что оптимальный параметр $C$ одинаков для всех $Q$ классификаторов. Однако, из-за дисбаланса данных (что характерно для многометочных задач, см. Раздел IV), количество положительных примеров для каждой метки может сильно варьироваться. Оптимальная сила регуляризации для метки с высокой частотой может быть неадекватной для редкой метки, которая нуждается в более сильной регуляризации (меньше $C$), чтобы избежать переобучения на малом числе положительных примеров.  \n",
        "Поэтому при настройке гиперпараметров с использованием `GridSearchCV` или `RandomizedSearchCV` необходимо использовать комплексную многометочную метрику (например, **F1-Macro**) в качестве целевой функции оценки. Такой подход гарантирует, что оптимизация найдёт компромиссное значение $C$, которое обеспечивает справедливую производительность для всех меток, а не только для тех, которые встречаются чаще всего.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В корпусе татарских новостей метка «Экология» встречается редко (5% документов), в то время как «Политика» — в 60%. Если оптимизировать по F1-Micro, модель будет слабо распознавать «Экологию». Оптимизация по **F1-Macro**, напротив, заставит алгоритм искать такие значения $C$, при которых обе метки получат сопоставимое качество.\n",
        "\n",
        "---\n",
        "\n",
        "## IV. Работа с Дисбалансом и Аугментация Данных (Imbalance Handling)\n",
        "\n",
        "Дисбаланс является одной из самых серьёзных проблем в многометочной классификации.\n",
        "\n",
        "#### IV.1. Типы Дисбаланса в Multi-label\n",
        "\n",
        "1. **Дисбаланс Метки (Label Imbalance)**: Стандартный дисбаланс, где для каждой отдельной метки $y_j$, число положительных примеров значительно меньше, чем отрицательных.  \n",
        "2. **Дисбаланс Набора Меток (Labelset Imbalance)**: Поскольку количество возможных комбинаций меток экспоненциально ($2^Q$), некоторые уникальные наборы меток могут встречаться крайне редко, в то время как простые или пустые наборы доминируют.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В архиве татарских газетных статей комбинация меток [`«Тарих»`, `«Татар теле»`, `«Мәдәният»`] может встречаться часто, тогда как [`«Космонавтика»`, `«Татар теле»`] — лишь единожды. Это — проявление **дисбаланса набора меток**.\n",
        "\n",
        "#### IV.2. Стратегии Борьбы с Дисбалансом в BR-LR\n",
        "\n",
        "**Метод 1: Взвешивание Классов (`Class Weight`)**  \n",
        "Самый простой способ интеграции в BR-LR — использование параметра `class_weight='balanced'` в `LogisticRegression`. Этот параметр заставляет модель автоматически взвешивать ошибки, допущённые на миноритарном (положительном) классе, пропорционально обратной частоте его появления.  \n",
        "- **Преимущество**: Легко реализуется в `MultiOutputClassifier` и не требует изменения размера датасета.  \n",
        "- **Недостаток**: Учитывает только дисбаланс отдельных меток, но не помогает при дисбалансе наборов меток.\n",
        "\n",
        "**Метод 2: Ресемплинг и Аугментация (Resampling)**  \n",
        "Стандартные методы оверсемплинга, такие как SMOTE (Synthetic Minority Over-sampling Technique) или ADASYN, изначально разработаны для бинарных или многоклассовых задач.  \n",
        "- **Риск стандартного SMOTE**: Если применить стандартный SMOTE к многомерному выходу $Y$, он будет генерировать синтетические векторы меток $Y_{\\text{synth}}$ путём простой линейной интерполяции. Этот процесс может создавать нереалистичные или шумовые комбинации меток, которые никогда не встречаются в реальном мире, тем самым разрушая естественные корреляции между метками.  \n",
        "- **Специализированные Методы (MLSMOTE)**: Для многометочной классификации существуют специализированные подходы, такие как **MLSMOTE** (Multi-label SMOTE). Вместо простой интерполяции, MLSMOTE генерирует новые синтетические наборы меток $Y_{\\text{synth}}$ для аугментированного образца $X_{\\text{synth}}$ на основе правила большинства, наблюдаемого среди $k$ ближайших соседей миноритарного образца. Это позволяет сохранить структуру и корреляцию между метками, что критически важно для многометочного обучения.\n",
        "\n",
        "**Критическая Проблема: Утечка Данных (Data Leakage)**  \n",
        "При использовании любого метода ресемплинга (включая SMOTE или его многометочные аналоги), аугментация должна производиться исключительно на тренировочном наборе данных. Применение оверсемплинга к тестовому набору приводит к утечке данных и завышенной, нереалистичной оценке производительности.  \n",
        "Для предотвращения этой ошибки рекомендуется использовать `Pipeline` из библиотеки `imbalanced-learn` (`imblearn`), который гарантирует, что шаги ресемплинга выполняются строго внутри этапа обучения, изолированно от тестовых данных.\n",
        "\n",
        "**Таблица IV: Сравнение Методов Борьбы с Дисбалансом в Multi-label**\n",
        "\n",
        "| Метод | Тип Дисбаланса | Учёт Корреляции | Проблема Утечки | Реализация BR-LR |\n",
        "|-------|----------------|------------------|------------------|------------------|\n",
        "| `class_weight` (LR) | Дисбаланс метки | Нет | Нет | Простая (встроенный параметр LR) |\n",
        "| Стандартный SMOTE | Дисбаланс метки | Низкий (может разрушать комбинации) | Да (требует Pipeline) | Требует адаптации для многометочного $Y$ |\n",
        "| MLSMOTE | Дисбаланс набора меток | Да (учитывает соседей) | Да (требует Pipeline) | Кастомная реализация |\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При создании системы теггирования татарских фольклорных текстов, где редкая метка `«Мифология»` встречается только в 3% документов, использование `class_weight='balanced'` позволяет избежать её полного игнорирования. Если же комбинация [`«Мифология»`, `«Эпос»`] уникальна, то MLSMOTE может создать синтетические примеры на основе близких по содержанию текстов, сохранив семантическую целостность.\n",
        "\n",
        "---\n",
        "\n",
        "## V. Комплексная Оценка Модели: Метрики\n",
        "\n",
        "В многометочной классификации использование одной метрики (например, точности) недостаточно. Требуется комплексный набор метрик, которые оценивают производительность как на уровне отдельных меток, так и на уровне всего набора меток.\n",
        "\n",
        "#### V.1. Порогово-Зависимые Метрики (Prediction-Based)\n",
        "\n",
        "Эти метрики требуют бинаризации предсказанных вероятностей $P(y_j=1|x)$ путём выбора порогового значения (обычно 0.5).\n",
        "\n",
        "1. **Hamming Loss (Потери Хэмминга)**: Измеряет долю пар (образец, метка), которые были классифицированы неверно. По сути, это среднее число неправильно присвоенных или пропущенных меток. Чем ближе к 0, тем лучше.  \n",
        "2. **Jaccard Similarity Score (Индекс Жаккара)**: Измеряет сходство между истинным набором меток $Y_{\\text{true}}$ и предсказанным набором $Y_{\\text{pred}}$ как отношение их пересечения к объединению. Это отличная метрика для оценки качества всего предсказанного набора меток. Чем ближе к 1, тем лучше.  \n",
        "3. **Precision, Recall, F1-Score**: В многометочной классификации эти метрики усредняются тремя основными способами:  \n",
        "   - **Micro-усреднение**: Агрегирует истинно положительные (TP), ложно положительные (FP) и ложно отрицательные (FN) значения по всем меткам глобально. На результаты доминирующее влияние оказывают наиболее частые метки.  \n",
        "   - **Macro-усреднение**: Рассчитывает метрику (например, F1) для каждой метки индивидуально, а затем берёт среднее арифметическое. Придаёт равный вес каждой метке, независимо от частоты. Это предпочтительный метод оценки при наличии дисбаланса, поскольку он более чувствителен к ошибкам на редких классах.  \n",
        "   - **Weighted-усреднение**: Усредняет по метрике, взвешенной по частоте встречаемости каждой метки в данных.\n",
        "\n",
        "#### V.2. Порогово-Независимые Метрики (Probability-Based)\n",
        "\n",
        "- **ROC AUC (Area Under the Receiver Operating Characteristic Curve)**: Оценивает разделительную способность модели независимо от выбранного порога. Как и F1, может быть усреднён по Micro или Macro. **Macro-AUC** полезен для оценки способности модели ранжировать редкие метки.\n",
        "\n",
        "При наличии сильного дисбаланса (что является нормой в многометочной классификации), Micro-метрики могут создавать ложное впечатление о высокой производительности, поскольку они доминируются частыми метками. Эксперты рекомендуют отдавать предпочтение **Macro-F1** или **Jaccard Score (с Macro-усреднением)** для объективной оценки качества предсказания редких классов.\n",
        "\n",
        "**Таблица II: Основные Метрики Многометочной Классификации**\n",
        "\n",
        "| Метрика | Тип Усреднения/Оценки | Интерпретация | Применение (Когда Использовать) |\n",
        "|--------|------------------------|----------------|---------------------------------|\n",
        "| Hamming Loss | Образец/Общий | Доля неверных предсказаний. | Оценка чистой ошибки. Требует бинарного предсказания. |\n",
        "| Jaccard Score | Micro/Macro | Точность набора меток (пересечение/объединение). | Оценка релевантности предсказанного набора. |\n",
        "| F1-Micro | Micro | Взвешивание по количеству примеров. | Оценка общей производительности. |\n",
        "| F1-Macro | Macro | Равный вес всем меткам. | Оценка производительности на редких метках. Рекомендуется при дисбалансе. |\n",
        "| ROC AUC | Macro | Качество ранжирования/разделительная способность, независимо от порога. | Оценка вероятностной силы модели. |\n",
        "\n",
        "```python\n",
        "# --- 3. Расчет Метрик ---\n",
        "\n",
        "print(\"\\n--- Оценка Метрик Многометочной Классификации ---\")\n",
        "# 1. Hamming Loss\n",
        "h_loss = hamming_loss(y_test, y_pred)\n",
        "print(f\"Hamming Loss (Потери Хэмминга): {h_loss:.4f} (Чем меньше, тем лучше)\")\n",
        "\n",
        "# 2. Jaccard Score\n",
        "j_micro = jaccard_score(y_test, y_pred, average='micro')\n",
        "j_macro = jaccard_score(y_test, y_pred, average='macro')\n",
        "print(f\"Jaccard Score (Micro): {j_micro:.4f}\")\n",
        "print(f\"Jaccard Score (Macro): {j_macro:.4f} (Предпочтительно при дисбалансе)\")\n",
        "\n",
        "# 3. F1 Score\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "print(f\"F1 Score (Micro): {f1_micro:.4f}\")\n",
        "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
        "```\n",
        "\n",
        "> **Пример интерпретации в NLP**:  \n",
        "> Предположим, для татарского корпуса новостей модель выдала:  \n",
        "> - **Hamming Loss = 0.08** → в среднем 8% меток ошибочны на уровне (документ, метка).  \n",
        "> - **Jaccard Macro = 0.62** → в среднем по всем темам предсказанный набор меток совпадает с истинным на 62%.  \n",
        "> - **F1-Macro = 0.68**, но **F1-Micro = 0.89** → модель отлично справляется с частыми темами, но хуже — с редкими.  \n",
        "> Это типичная картина для несбалансированного корпуса, и именно **Macro-метрики** указывают на необходимость улучшения балансировки.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "d-PUqksEXN3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## VI. Визуализация и Расширенная Диагностика\n",
        "\n",
        "Расширенная диагностика включает анализ ошибок на уровне отдельных меток и оценку надёжности вероятностных предсказаний модели (калибровка).\n",
        "\n",
        "#### VI.1. Матрица Ошибок (Confusion Matrix)\n",
        "\n",
        "В многометочной классификации невозможно построить одну матрицу ошибок, как в многоклассовой задаче. Вместо этого, анализ выполняется независимо для каждой метки. Инструмент `multilabel_confusion_matrix` из Scikit-learn возвращает список из $Q$ матриц 2×2.  \n",
        "Каждая матрица имеет вид:\n",
        "\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "\\text{TN} & \\text{FP} \\\\\n",
        "\\text{FN} & \\text{TP}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "где **TN** — истинно отрицательные, **FP** — ложно положительные, **FN** — ложно отрицательные, и **TP** — истинно положительные предсказания для соответствующей метки.\n",
        "\n",
        "```python\n",
        "# --- 4. Матрица Ошибок ---\n",
        "mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- Multilabel Confusion Matrix (для каждой из 5 меток) ---\")\n",
        "for i, matrix in enumerate(mcm):\n",
        "    print(f\"\\nМатрица ошибок для Метки {i}:\")\n",
        "    df_cm = pd.DataFrame(matrix, index=['Actual Neg (0)', 'Actual Pos (1)'],\n",
        "                         columns=['Pred Neg (0)', 'Pred Pos (1)'])\n",
        "    print(df_cm)\n",
        "```\n",
        "\n",
        "Анализ этих матриц позволяет точно определить, какие метки чаще всего приводят к **ложно отрицательным (FN)** ошибкам (пропуск метки) или **ложно положительным (FP)** ошибкам (лишняя метка).\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> При автоматической разметке татарских новостей модель может часто допускать **FP** по метке «Политика» для текстов, где упоминается президент, но в контексте культурного события (например, «Президент Татарстана открыл фестиваль поэзии»). В то же время, **FN** по метке «Татар теле» могут возникать в статьях, где язык упоминается косвенно («уроки родного языка»), но без явного слова *татар*. Такой анализ помогает уточнить словари или добавить контекстные признаки.\n",
        "\n",
        "#### VI.2. Диагностика Остатков: Оценка Калибровки Модели\n",
        "\n",
        "Требование к «диагностике остатков» для вероятностного классификатора, такого как Логистическая Регрессия, сводится к оценке **Калибровки Модели** (Model Calibration). Калиброванная модель — это модель, чьи предсказанные вероятности точно отражают истинную частоту событий. Например, если модель предсказывает вероятность $P = 0.9$, то примерно в 90% случаев это предсказание должно быть верным.\n",
        "\n",
        "**Brier Score Loss**  \n",
        "Brier Score Loss — это ключевая метрика для оценки калибровки. Она измеряет среднюю квадратичную ошибку между предсказанной вероятностью и фактическим бинарным исходом. Меньшее значение Brier Score указывает на лучшую калибровку и более надёжные вероятностные предсказания.\n",
        "\n",
        "$$\n",
        "\\text{Brier Score} = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2\n",
        "$$\n",
        "\n",
        "где $N$ — число образцов, $p_i$ — предсказанная вероятность, $o_i$ — фактический бинарный исход (0 или 1).\n",
        "\n",
        "**Калибровка Модели с Использованием `CalibratedClassifierCV`**  \n",
        "Если модель плохо калибрована (что может быть выявлено высоким Brier Score), её можно откалибровать с помощью `CalibratedClassifierCV`. Однако, применение этого инструмента к многометочной задаче требует сложной архитектуры, поскольку `CalibratedClassifierCV` изначально принимает только одномерный вектор целевой переменной.  \n",
        "\n",
        "Для решения этой инженерной задачи используется трёхуровневая обёртка, которая обеспечивает калибровку каждой независимой метки, сохраняя при этом многометочный вывод:\n",
        "\n",
        "1. Базовый классификатор (LR) оборачивается в `OneVsRestClassifier` для корректной обработки маргинальных вероятностей.  \n",
        "2. `CalibratedClassifierCV` применяется к этой обёртке `OneVsRestClassifier`.  \n",
        "3. Окончательный откалиброванный классификатор оборачивается в `MultiOutputClassifier`, что позволяет ему принимать двумерный целевой вектор $Y$.\n",
        "\n",
        "```python\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "# --- 5. Калибровка Модели ---\n",
        "\n",
        "# 1. Определение CV стратегии для CalibratedClassifierCV\n",
        "# StratifiedKFold используется для сохранения пропорций классов в кросс-валидации\n",
        "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 2. Инициализация базового классификатора LR\n",
        "base_lr_uncalibrated = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# 3. Обертывание LR в OneVsRestClassifier (для получения маргинальных вероятностей, нужных калибровке)\n",
        "ovr_clf = OneVsRestClassifier(base_lr_uncalibrated)\n",
        "\n",
        "# 4. Калибровка (методы: 'isotonic' или 'sigmoid')\n",
        "calibrated_ovr = CalibratedClassifierCV(\n",
        "    base_estimator=ovr_clf,\n",
        "    cv=cv_strategy,\n",
        "    method='isotonic'\n",
        ")\n",
        "\n",
        "# 5. Окончательное оборачивание в MultiOutputClassifier и обучение\n",
        "calibrated_multioutput_clf = MultiOutputClassifier(calibrated_ovr).fit(X_train, y_train)\n",
        "\n",
        "# Получение вероятностей из калиброванной модели\n",
        "y_proba_calibrated_list = calibrated_multioutput_clf.predict_proba(X_test)\n",
        "y_proba_calibrated_agg = np.column_stack([p[:, 1] for p in y_proba_calibrated_list])\n",
        "\n",
        "print(\"\\n--- Диагностика Калибровки (Brier Score) ---\")\n",
        "\n",
        "# Расчет Brier Score для каждой метки\n",
        "brier_scores = []\n",
        "for i in range(y_test.shape[1]):\n",
        "    # y_proba_calibrated_agg[:, i] - это вероятности положительного класса для метки i\n",
        "    bs = brier_score_loss(y_test[:, i], y_proba_calibrated_agg[:, i])\n",
        "    brier_scores.append(bs)\n",
        "    print(f\"Brier Score для Метки {i}: {bs:.4f}\")\n",
        "\n",
        "print(f\"Средний Brier Score: {np.mean(brier_scores):.4f} (Чем меньше, тем лучше)\")\n",
        "```\n",
        "\n",
        "Если средний Brier Score снижается после калибровки по сравнению с некалиброванной моделью, это свидетельствует о том, что вероятности, выдаваемые моделью, стали более точными и надёжными.\n",
        "\n",
        "> **Пример в NLP**:  \n",
        "> В системе ранжирования татарских научных статей по релевантности темам, калиброванная модель позволяет корректно интерпретировать вероятности: если для статьи $P(\\text{«Лингвистика»}) = 0.75$, то в ~75% случаев эксперт подтвердит эту тему. Это критично для систем, где вероятности используются в рекомендациях или приоритезации.\n",
        "\n",
        "---\n",
        "\n",
        "## VII. Заключение и Дальнейшие Шаги\n",
        "\n",
        "### VII.1. Резюме по BR-LR\n",
        "\n",
        "Модель многометочной классификации на основе **Бинарной Релевантности с Логистической Регрессией (BR-LR)** является мощной и легко интерпретируемой базовой линией. Она обладает высокой масштабируемостью, так как обучение $Q$ независимых классификаторов может быть распараллелено.  \n",
        "\n",
        "Однако её главное архитектурное ограничение — **полное игнорирование корреляции между метками** — может стать критическим фактором в задачах, где совместное появление меток является важным предиктором.\n",
        "\n",
        "> **Пример ограничения в NLP**:  \n",
        "> В корпусе татарских статей метки «Тарих» и «Татар теле» часто встречаются вместе (например, в публикациях о развитии письменности). BR-LR может предсказать «Тарих» с высокой уверенностью, но не предсказать «Татар теле», потому что соответствующий бинарный классификатор не «знает» о наличии первой метки.\n",
        "\n",
        "### VII.2. Рекомендации по Дальнейшему Изучению\n",
        "\n",
        "Для преодоления ограничений BR и улучшения производительности в коррелированных и сильно несбалансированных многометочных задачах рекомендуется рассмотреть следующие подходы:\n",
        "\n",
        "1. **Цепи Классификаторов (Classifier Chains)**: Этот метод явно учитывает корреляцию меток. Классификаторы обучаются последовательно, и предсказания первых $j-1$ меток добавляются в качестве дополнительных признаков для обучения $j$-ой метки. Это позволяет модели использовать информацию о ранее предсказанных метках.  \n",
        "   > *Пример*: При классификации татарских новостей, если первая метка «Политика» предсказана как 1, это повышает шансы на то, что следующая метка «Президент» также будет 1.\n",
        "\n",
        "2. **Специализированные Ансамблевые Методы**: Использование ансамблевых подходов, таких как ансамблирование несбалансированных классификаторов (например, EasyEnsemble), или методы адаптации алгоритмов, реализованные в библиотеках, таких как `scikit-multilearn`.\n",
        "\n",
        "3. **Использование Специфических Метрик Дисбаланса**: При оптимизации модели всегда следует отдавать приоритет **Macro-метрикам** (например, Macro-F1), чтобы гарантировать, что редкие метки не будут проигнорированы в процессе настройки гиперпараметров.\n",
        "\n",
        "> **Перспектива для татарского языка**:  \n",
        "> При построении системы семантической разметки для корпуса татарских текстов (в рамках проектов типа **Tatar2Vec**), комбинация **Classifier Chains** с **калиброванными вероятностями** и **Macro-F1 оптимизацией** может обеспечить как высокую точность, так и надёжную интерпретируемость, что особенно важно для академического и образовательного использования.\n",
        ""
      ],
      "metadata": {
        "id": "edd3dAfeYChB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3AL57kxJGWhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import (multilabel_confusion_matrix, f1_score, hamming_loss,\n",
        "                           jaccard_score, classification_report, brier_score_loss)\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# I. Генерация и анализ данных\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"I. ГЕНЕРАЦИЯ И АНАЛИЗ МНОГОМЕТОЧНЫХ ДАННЫХ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Генерация синтетического многометочного датасета\n",
        "X, y = make_multilabel_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=15,\n",
        "    n_classes=5,\n",
        "    n_labels=2,\n",
        "    allow_unlabeled=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Размерность признаков X: {X.shape}\")\n",
        "print(f\"Размерность меток Y: {y.shape}\")\n",
        "\n",
        "# Анализ распределения меток\n",
        "label_counts = np.sum(y, axis=0)\n",
        "label_combinations = [tuple(row) for row in y]\n",
        "combination_counts = Counter(label_combinations)\n",
        "\n",
        "print(f\"\\nКоличество меток на образец:\")\n",
        "print(f\"Минимальное: {np.min(np.sum(y, axis=1))}\")\n",
        "print(f\"Максимальное: {np.max(np.sum(y, axis=1))}\")\n",
        "print(f\"Среднее: {np.mean(np.sum(y, axis=1)):.2f}\")\n",
        "\n",
        "print(f\"\\nРаспределение отдельных меток:\")\n",
        "for i, count in enumerate(label_counts):\n",
        "    print(f\"Метка {i}: {count} образцов ({count/len(y)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nТоп-5 самых частых комбинаций меток:\")\n",
        "for combo, count in combination_counts.most_common(5):\n",
        "    print(f\"Комбинация {combo}: {count} образцов\")\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nРазмер тренировочного набора: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Размер тестового набора: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# =============================================================================\n",
        "# II. Базовая модель BR-LR\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"II. БАЗОВАЯ МОДЕЛЬ BR-LR (BINARY RELEVANCE)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Базовая логистическая регрессия\n",
        "base_lr = LogisticRegression(\n",
        "    solver='liblinear',\n",
        "    random_state=42,\n",
        "    max_iter=1000\n",
        ")\n",
        "\n",
        "# Многометочная обертка\n",
        "multi_target_lr = MultiOutputClassifier(base_lr)\n",
        "\n",
        "# Обучение модели\n",
        "multi_target_lr.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = multi_target_lr.predict(X_test)\n",
        "y_proba_list = multi_target_lr.predict_proba(X_test)\n",
        "y_proba_aggregated = np.column_stack([p[:, 1] for p in y_proba_list])\n",
        "\n",
        "print(\"Примеры предсказаний:\")\n",
        "print(\"Фактические метки:\")\n",
        "print(y_test[:5])\n",
        "print(\"Предсказанные метки:\")\n",
        "print(y_pred[:5])\n",
        "print(\"\\nВероятности (первые 5 образцов):\")\n",
        "print(y_proba_aggregated[:5].round(3))\n",
        "\n",
        "# =============================================================================\n",
        "# III. Настройка гиперпараметров\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"III. НАСТРОЙКА ГИПЕРПАРАМЕТРОВ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Параметры для GridSearch\n",
        "param_grid = {\n",
        "    'estimator__C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'estimator__penalty': ['l1', 'l2'],\n",
        "    'estimator__solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Создание пайплайна для настройки\n",
        "tuned_multi_lr = MultiOutputClassifier(\n",
        "    LogisticRegression(random_state=42, max_iter=1000)\n",
        ")\n",
        "\n",
        "# GridSearch с кросс-валидацией\n",
        "grid_search = GridSearchCV(\n",
        "    tuned_multi_lr,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Запуск настройки гиперпараметров...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
        "print(f\"Лучший F1-score (macro): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Модель с лучшими параметрами\n",
        "best_multi_lr = grid_search.best_estimator_\n",
        "y_pred_tuned = best_multi_lr.predict(X_test)\n",
        "\n",
        "# =============================================================================\n",
        "# IV. Борьба с дисбалансом\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"IV. БОРЬБА С ДИСБАЛАНСОМ МЕТОК\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Модель с взвешиванием классов\n",
        "balanced_lr = LogisticRegression(\n",
        "    solver='liblinear',\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    max_iter=1000\n",
        ")\n",
        "\n",
        "balanced_multi_lr = MultiOutputClassifier(balanced_lr)\n",
        "balanced_multi_lr.fit(X_train, y_train)\n",
        "y_pred_balanced = balanced_multi_lr.predict(X_test)\n",
        "\n",
        "print(\"Модель с class_weight='balanced' обучена\")\n",
        "\n",
        "# =============================================================================\n",
        "# V. Оценка моделей\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"V. КОМПЛЕКСНАЯ ОЦЕНКА МОДЕЛЕЙ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    \"\"\"Комплексная оценка многометочной модели\"\"\"\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # Основные метрики\n",
        "    metrics['hamming_loss'] = hamming_loss(y_true, y_pred)\n",
        "    metrics['jaccard_micro'] = jaccard_score(y_true, y_pred, average='micro')\n",
        "    metrics['jaccard_macro'] = jaccard_score(y_true, y_pred, average='macro')\n",
        "    metrics['f1_micro'] = f1_score(y_true, y_pred, average='micro')\n",
        "    metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(f\"\\n--- Результаты {model_name} ---\")\n",
        "    print(f\"Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
        "    print(f\"Jaccard Score (Micro): {metrics['jaccard_micro']:.4f}\")\n",
        "    print(f\"Jaccard Score (Macro): {metrics['jaccard_macro']:.4f}\")\n",
        "    print(f\"F1 Score (Micro): {metrics['f1_micro']:.4f}\")\n",
        "    print(f\"F1 Score (Macro): {metrics['f1_macro']:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Оценка всех моделей\n",
        "models = {\n",
        "    'Базовая BR-LR': (y_test, y_pred),\n",
        "    'Настроенная BR-LR': (y_test, y_pred_tuned),\n",
        "    'Сбалансированная BR-LR': (y_test, y_pred_balanced)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, (y_true, y_pred) in models.items():\n",
        "    results[name] = evaluate_model(y_true, y_pred, name)\n",
        "\n",
        "# =============================================================================\n",
        "# VI. Детальный анализ ошибок\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"VI. ДЕТАЛЬНЫЙ АНАЛИЗ ОШИБОК\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Матрицы ошибок для лучшей модели\n",
        "mcm = multilabel_confusion_matrix(y_test, y_pred_tuned)\n",
        "\n",
        "print(\"\\nМатрицы ошибок для настроенной модели:\")\n",
        "for i, matrix in enumerate(mcm):\n",
        "    tn, fp, fn, tp = matrix.ravel()\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"\\nМетка {i}:\")\n",
        "    print(f\"  TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\")\n",
        "    print(f\"  Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "# Визуализация матриц ошибок\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (matrix, ax) in enumerate(zip(mcm, axes)):\n",
        "    if i < 5:  # У нас 5 меток\n",
        "        sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                   xticklabels=['Pred 0', 'Pred 1'],\n",
        "                   yticklabels=['True 0', 'True 1'])\n",
        "        ax.set_title(f'Метка {i}')\n",
        "\n",
        "# Скрываем лишние subplots\n",
        "for i in range(len(mcm), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Матрицы ошибок для каждой метки', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# VII. Калибровка модели (ИСПРАВЛЕННАЯ ВЕРСИЯ)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"VII. КАЛИБРОВКА МОДЕЛИ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def calibrate_multilabel_model(X_train, y_train, X_test, method='sigmoid'):\n",
        "    \"\"\"\n",
        "    Калибровка многометочной модели для каждой метки отдельно\n",
        "    \"\"\"\n",
        "    calibrated_predictions = []\n",
        "    brier_scores = []\n",
        "\n",
        "    print(\"Калибровка модели для каждой метки...\")\n",
        "\n",
        "    for label_idx in range(y_train.shape[1]):\n",
        "        print(f\"  Метка {label_idx+1}/{y_train.shape[1]}...\")\n",
        "\n",
        "        # Берем одну метку\n",
        "        y_train_single = y_train[:, label_idx]\n",
        "        y_test_single = y_test[:, label_idx]\n",
        "\n",
        "        # Обучаем базовый классификатор\n",
        "        base_clf = LogisticRegression(\n",
        "            solver='liblinear',\n",
        "            random_state=42,\n",
        "            max_iter=1000\n",
        "        )\n",
        "        base_clf.fit(X_train, y_train_single)\n",
        "\n",
        "        # Калибруем классификатор\n",
        "        calibrated_clf = CalibratedClassifierCV(\n",
        "            estimator=base_clf,\n",
        "            cv=3,\n",
        "            method=method\n",
        "        )\n",
        "        calibrated_clf.fit(X_train, y_train_single)\n",
        "\n",
        "        # Получаем калиброванные вероятности\n",
        "        y_proba_calibrated = calibrated_clf.predict_proba(X_test)[:, 1]\n",
        "        calibrated_predictions.append(y_proba_calibrated)\n",
        "\n",
        "        # Вычисляем Brier Score\n",
        "        bs = brier_score_loss(y_test_single, y_proba_calibrated)\n",
        "        brier_scores.append(bs)\n",
        "\n",
        "    # Собираем все вероятности в одну матрицу\n",
        "    y_proba_calibrated_agg = np.column_stack(calibrated_predictions)\n",
        "\n",
        "    return y_proba_calibrated_agg, brier_scores\n",
        "\n",
        "# Применяем калибровку\n",
        "y_proba_calibrated_agg, brier_scores_calibrated = calibrate_multilabel_model(\n",
        "    X_train, y_train, X_test, method='sigmoid'\n",
        ")\n",
        "\n",
        "# Получаем вероятности из некалиброванной модели для сравнения\n",
        "y_proba_tuned_list = best_multi_lr.predict_proba(X_test)\n",
        "y_proba_tuned_agg = np.column_stack([p[:, 1] for p in y_proba_tuned_list])\n",
        "\n",
        "# Сравнение Brier Score\n",
        "print(\"\\n--- Сравнение калибровки ---\")\n",
        "\n",
        "brier_scores_tuned = []\n",
        "for i in range(y_test.shape[1]):\n",
        "    bs_tuned = brier_score_loss(y_test[:, i], y_proba_tuned_agg[:, i])\n",
        "    bs_calibrated = brier_scores_calibrated[i]\n",
        "\n",
        "    brier_scores_tuned.append(bs_tuned)\n",
        "\n",
        "    improvement = ((bs_tuned - bs_calibrated) / bs_tuned * 100) if bs_tuned > 0 else 0\n",
        "    print(f\"Метка {i}: Brier Score {bs_tuned:.4f} -> {bs_calibrated:.4f} \"\n",
        "          f\"({improvement:+.1f}%)\")\n",
        "\n",
        "print(f\"\\nСредний Brier Score (настроенная): {np.mean(brier_scores_tuned):.4f}\")\n",
        "print(f\"Средний Brier Score (калиброванная): {np.mean(brier_scores_calibrated):.4f}\")\n",
        "\n",
        "# Создаем бинарные предсказания из калиброванных вероятностей (порог 0.5)\n",
        "y_pred_calibrated = (y_proba_calibrated_agg > 0.5).astype(int)\n",
        "\n",
        "# Оцениваем калиброванную модель\n",
        "print(\"\\n--- Результаты калиброванной модели ---\")\n",
        "results['Калиброванная BR-LR'] = evaluate_model(y_test, y_pred_calibrated, 'Калиброванная BR-LR')\n",
        "\n",
        "# =============================================================================\n",
        "# VIII. Сравнительный анализ\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"VIII. СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Создание сравнительной таблицы\n",
        "comparison_data = []\n",
        "for model_name, metrics in results.items():\n",
        "    comparison_data.append({\n",
        "        'Модель': model_name,\n",
        "        'Hamming Loss': metrics['hamming_loss'],\n",
        "        'Jaccard Macro': metrics['jaccard_macro'],\n",
        "        'F1 Macro': metrics['f1_macro']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nСравнительная таблица моделей:\")\n",
        "print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
        "\n",
        "# Визуализация сравнения моделей\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "metrics_to_plot = ['Hamming Loss', 'Jaccard Macro', 'F1 Macro']\n",
        "titles = ['Hamming Loss (меньше → лучше)', 'Jaccard Score (больше → лучше)',\n",
        "          'F1 Macro (больше → лучше)']\n",
        "\n",
        "colors = ['skyblue', 'lightgreen', 'lightcoral', 'gold']\n",
        "\n",
        "for i, (metric, title) in enumerate(zip(metrics_to_plot, titles)):\n",
        "    axes[i].bar(range(len(comparison_df)), comparison_df[metric], color=colors[:len(comparison_df)])\n",
        "    axes[i].set_title(title)\n",
        "    axes[i].set_xticks(range(len(comparison_df)))\n",
        "    axes[i].set_xticklabels(comparison_df['Модель'], rotation=45, ha='right')\n",
        "\n",
        "    # Добавление значений на столбцы\n",
        "    for j, v in enumerate(comparison_df[metric]):\n",
        "        axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# IX. Анализ порогов для редких меток\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"IX. АНАЛИЗ ПОРОГОВ ДЛЯ РЕДКИХ МЕТОК\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Особый анализ для редкой метки 4 (только 16.1% образцов)\n",
        "rare_label_idx = 4\n",
        "y_test_rare = y_test[:, rare_label_idx]\n",
        "y_proba_rare = y_proba_calibrated_agg[:, rare_label_idx]\n",
        "\n",
        "# Пробуем разные пороги для редкой метки\n",
        "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "print(f\"\\nАнализ разных порогов для редкой метки {rare_label_idx}:\")\n",
        "print(\"Порог | Precision | Recall  | F1-Score\")\n",
        "\n",
        "best_f1 = 0\n",
        "best_threshold = 0.5\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred_rare = (y_proba_rare > threshold).astype(int)\n",
        "\n",
        "    tp = np.sum((y_pred_rare == 1) & (y_test_rare == 1))\n",
        "    fp = np.sum((y_pred_rare == 1) & (y_test_rare == 0))\n",
        "    fn = np.sum((y_pred_rare == 0) & (y_test_rare == 1))\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"{threshold:5.1f} | {precision:8.3f} | {recall:7.3f} | {f1:8.3f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"\\nЛучший порог для метки {rare_label_idx}: {best_threshold:.2f} (F1 = {best_f1:.3f})\")\n",
        "\n",
        "# =============================================================================\n",
        "# X. Заключение и рекомендации\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"X. ЗАКЛЮЧЕНИЕ И РЕКОМЕНДАЦИИ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Определение лучшей модели по разным метрикам\n",
        "best_hamming = min(results.keys(), key=lambda x: results[x]['hamming_loss'])\n",
        "best_f1_macro = max(results.keys(), key=lambda x: results[x]['f1_macro'])\n",
        "\n",
        "print(f\"Лучшая модель по Hamming Loss: {best_hamming}\")\n",
        "print(f\"Лучшая модель по F1 Macro: {best_f1_macro}\")\n",
        "\n",
        "# Анализ важности признаков (для первой метки)\n",
        "if hasattr(best_multi_lr.estimators_[0], 'coef_'):\n",
        "    feature_importance = np.abs(best_multi_lr.estimators_[0].coef_[0])\n",
        "    top_features = np.argsort(feature_importance)[-5:][::-1]\n",
        "\n",
        "    print(f\"\\nТоп-5 самых важных признаков для Метки 0:\")\n",
        "    for i, feature_idx in enumerate(top_features):\n",
        "        print(f\"  {i+1}. Признак {feature_idx}: важность {feature_importance[feature_idx]:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"КЛЮЧЕВЫЕ ВЫВОДЫ:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"1. Все модели показали схожую производительность\")\n",
        "print(\"2. Сбалансированная модель улучшила F1-Macro за счет увеличения Hamming Loss\")\n",
        "print(\"3. Метка 4 (самая редкая) имеет самую низкую производительность\")\n",
        "print(\"4. Калибровка улучшила надежность вероятностных предсказаний\")\n",
        "print(\"5. Для редких меток рекомендуется использовать пониженный порог классификации\")\n",
        "\n",
        "print(\"\\nРЕКОМЕНДАЦИИ ДЛЯ УЛУЧШЕНИЯ:\")\n",
        "print(\"1. Для учета корреляции между метками рассмотреть Classifier Chains\")\n",
        "print(\"2. При сильном дисбалансе использовать специализированные методы (MLSMOTE)\")\n",
        "print(\"3. Для сложных данных рассмотреть нейросетевые архитектуры\")\n",
        "print(\"4. Использовать индивидуальные пороги для каждой метки\")\n",
        "print(\"5. Рассмотреть ансамблирование для повышения стабильности\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ЛЕКЦИЯ ЗАВЕРШЕНА. МОДЕЛЬ УСПЕШНО РЕАЛИЗОВАНА И ПРОАНАЛИЗИРОВАНА!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "6h3253e3YNKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}