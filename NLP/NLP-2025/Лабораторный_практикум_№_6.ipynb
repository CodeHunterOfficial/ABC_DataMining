{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNXN8B+g75HwyFh2vJl7F8s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/NLP/NLP-2025/%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D1%83%D0%BC_%E2%84%96_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# üß™ **–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–π –ø—Ä–∞–∫—Ç–∏–∫—É–º ‚Ññ 6**  \n",
        "# **–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–µ–π Hugging Face –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞**\n",
        "\n",
        "**–ö–∞—Ñ–µ–¥—Ä–∞:** –ö–∞—Ñ–µ–¥—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è  \n",
        "**–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞:** –û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞  \n",
        "**–£—Ä–æ–≤–µ–Ω—å:** –ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞, 2 –∫—É—Ä—Å  \n",
        "**–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å:** –ê—Ä–∞–±–æ–≤ –ú—É–ª–ª–æ—à–∞—Ä–∞—Ñ –ö—É—Ä–±–æ–Ω–æ–≤–∏—á  \n",
        "\n",
        "---\n",
        "\n",
        "## üéØ 1. –¶–µ–ª–∏ –∏ –∑–∞–¥–∞—á–∏ —Ä–∞–±–æ—Ç—ã\n",
        "\n",
        "### **–¶–µ–ª—å:**  \n",
        "–ü—Ä–æ–≤–µ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ **state-of-the-art –º–æ–¥–µ–ª–µ–π –∏–∑ Hugging Face Hub** –¥–ª—è —à–∏—Ä–æ–∫–æ–≥–æ —Å–ø–µ–∫—Ç—Ä–∞ NLP-–∑–∞–¥–∞—á —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è **–∫–∞—á–µ—Å—Ç–≤–∞, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ –∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ –≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö**.\n",
        "\n",
        "### **–ó–∞–¥–∞—á–∏:**  \n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å **–≥–æ—Ç–æ–≤—ã–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏** –¥–ª—è 12 —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á NLP.  \n",
        "2. –û—Ü–µ–Ω–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –Ω–∞ **—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö** (`SQuAD`, `IMDb`, `CONLL-2003`, `WMT`, `XSum` –∏ –¥—Ä.).  \n",
        "3. –ü—Ä–æ–≤–µ—Å—Ç–∏ **–º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑**: –∫–∞—á–µ—Å—Ç–≤–æ, —Å–∫–æ—Ä–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç–∏.  \n",
        "4. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å **—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å** –∫ —à—É–º—É, –¥–æ–º–µ–Ω—É, –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞.  \n",
        "5. –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å **–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–µ–π –¥–ª—è production, research –∏ low-resource —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.  \n",
        "6. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å **–≥–æ—Ç–æ–≤—ã–µ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏** –∏ **–≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö 2. –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏\n",
        "\n",
        "### **2.1. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Hugging Face Transformers**\n",
        "- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω—ã–π API –¥–ª—è **200 000+ –º–æ–¥–µ–ª–µ–π** —á–µ—Ä–µ–∑ `pipeline()` –∏ `AutoModel`/`AutoTokenizer`.  \n",
        "- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç **–≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**: BERT, RoBERTa, T5, BART, GPT, XLM-R, mT5, Longformer –∏ –¥—Ä.  \n",
        "- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å `datasets`, `evaluate`, ONNX, FlashAttention, `safetensors`.  \n",
        "- –°–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å **PyTorch** –∏ **TensorFlow**, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç **GPU/TPU**, **FP16**, **int8 quantization**.\n",
        "\n",
        "> –°–æ–≥–ª–∞—Å–Ω–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, `transformers` ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–µ-—Ñ–∞–∫—Ç–æ –¥–ª—è NLP –≤ 2024‚Äì2025 –≥–≥.\n",
        "\n",
        "### **2.2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–¥–∞—á –∏ –º–æ–¥–µ–ª–µ–π**\n",
        "| –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–¥–∞—á–∏ | –ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ –º–æ–¥–µ–ª–µ–π –∏–∑ Hub |\n",
        "|------------------|-----------------------------|\n",
        "| **Text Classification** | `distilbert-base-uncased-finetuned-sst-2-english`, `nlptown/bert-base-multilingual-uncased-sentiment` |\n",
        "| **Token Classification (NER)** | `dslim/bert-base-NER`, `xlm-roberta-large-finetuned-conll03-english` |\n",
        "| **Question Answering** | `deepset/roberta-base-squad2`, `deepset/longformer-base-4096-squad1` |\n",
        "| **Translation** | `Helsinki-NLP/opus-mt-en-ru`, `facebook/m2m100_418M` |\n",
        "| **Summarization** | `facebook/bart-large-cnn`, `csebuetnlp/mT5_multilingual_XLSum` |\n",
        "| **Zero-Shot Classification** | `facebook/bart-large-mnli`, `joeddav/xlm-roberta-large-xnli` |\n",
        "| **Sentence Similarity** | `sentence-transformers/all-mpnet-base-v2`, `paraphrase-multilingual-MiniLM-L12-v2` |\n",
        "| **Text Generation** | `gpt2`, `ai-forever/rugpt3large_based_on_gpt2` |\n",
        "| **Table QA** | `google/tapas-base-finetuned-wtq`, `microsoft/tapex-base-finetuned-wtq` |\n",
        "| **Fill-Mask** | `bert-base-uncased`, `xlm-roberta-base` |\n",
        "| **Text Ranking** | `cross-encoder/ms-marco-MiniLM-L-6-v2` |\n",
        "| **Feature Extraction** | `sentence-transformers/all-MiniLM-L6-v2` |\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 3. –ú–µ—Ç–æ–¥–∏–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
        "\n",
        "### **3.1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ä–µ–¥—ã**\n",
        "- –£—Å—Ç–∞–Ω–æ–≤–∫–∞:\n",
        "  ```bash\n",
        "  pip install transformers datasets evaluate accelerate sentence-transformers\n",
        "  ```\n",
        "- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `pipeline()` –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:\n",
        "  ```python\n",
        "  from transformers import pipeline\n",
        "  classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "  ```\n",
        "\n",
        "### **3.2. –î–∞—Ç–∞—Å–µ—Ç—ã –∏ –º–µ—Ç—Ä–∏–∫–∏**\n",
        "| –ó–∞–¥–∞—á–∞ | –î–∞—Ç–∞—Å–µ—Ç | –ú–µ—Ç—Ä–∏–∫–∞ |\n",
        "|-------|--------|--------|\n",
        "| –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è | `imdb`, `emotion` | accuracy, f1 |\n",
        "| NER | `conll2003` | seqeval (entity-level F1) |\n",
        "| QA | `squad_v2`, `xquad` | exact_match, f1 |\n",
        "| –ü–µ—Ä–µ–≤–æ–¥ | `wmt19` | sacrebleu |\n",
        "| –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ | `cnn_dailymail` | rouge |\n",
        "| –°—Ö–æ–∂–µ—Å—Ç—å | `stsb` | spearmanr |\n",
        "\n",
        "> –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å `evaluate` (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç Hugging Face).\n",
        "\n",
        "### **3.3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**\n",
        "```python\n",
        "config = {\n",
        "    'num_samples': 1000,          # –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏\n",
        "    'max_length': 512,\n",
        "    'batch_size': 16,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'precision': 'fp16' if torch.cuda.is_available() else 'fp32'\n",
        "}\n",
        "```\n",
        "\n",
        "### **3.4. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**\n",
        "–î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ —Ñ–∏–∫—Å–∏—Ä—É—é—Ç—Å—è:\n",
        "- **–ö–∞—á–µ—Å—Ç–≤–æ**: –æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º —Å–µ—Ç–µ  \n",
        "- **–°–∫–æ—Ä–æ—Å—Ç—å**: –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–º—Å/–¥–æ–∫—É–º–µ–Ω—Ç)  \n",
        "- **–ü–∞–º—è—Ç—å**: –ø–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU/CPU RAM  \n",
        "- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: —Ä–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–∞–º–∏ >512 —Ç–æ–∫–µ–Ω–æ–≤ (Longformer, BigBird)  \n",
        "\n",
        "---\n",
        "\n",
        "## üîç 4. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n",
        "\n",
        "### **4.1. Text Classification**\n",
        "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: DistilBERT vs RoBERTa vs multilingual XLM-R  \n",
        "- –ê–Ω–∞–ª–∏–∑ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (confidence calibration)  \n",
        "- –¢–µ—Å—Ç –Ω–∞ out-of-distribution –¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –≤ –æ–±—â–µ–π –º–æ–¥–µ–ª–∏)  \n",
        "\n",
        "### **4.2. NER**\n",
        "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: BERT-base-NER vs XLM-R-large  \n",
        "- –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º —Å—É—â–Ω–æ—Å—Ç–µ–π (PER, ORG, LOC)  \n",
        "- –ö—Ä–æ—Å—Å-–¥–æ–º–µ–Ω–Ω–∞—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å (–Ω–æ–≤–æ—Å—Ç–∏ ‚Üí —Å–æ—Ü—Å–µ—Ç–∏)  \n",
        "\n",
        "### **4.3. –í–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã**\n",
        "- Extractive QA: RoBERTa vs Longformer (–¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤)  \n",
        "- –ú–µ—Ç—Ä–∏–∫–∏: F1, Exact Match, –∞ —Ç–∞–∫–∂–µ —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ 50 –ø—Ä–∏–º–µ—Ä–æ–≤  \n",
        "- –¢–µ—Å—Ç –Ω–∞ multi-hop –≤–æ–ø—Ä–æ—Å—ã (—á–µ—Ä–µ–∑ `HotpotQA`, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)  \n",
        "\n",
        "### **4.4. –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥**\n",
        "- EN‚ÜîRU: `opus-mt` vs `m2m100` vs `wmt19`  \n",
        "- –û—Ü–µ–Ω–∫–∞: BLEU, –Ω–æ —Ç–∞–∫–∂–µ **–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞** (—Ñ–ª—é–µ–Ω—Ç–Ω–æ—Å—Ç—å, –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å)  \n",
        "- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ low-resource —è–∑—ã–∫–æ–≤ (—Ç–∞–¥–∂–∏–∫—Å–∫–∏–π, —Ç–∞—Ç–∞—Ä—Å–∫–∏–π ‚Äî —á–µ—Ä–µ–∑ mBART/mT5)  \n",
        "\n",
        "### **4.5. –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è**\n",
        "- Abstractive: BART vs PEGASUS vs mT5  \n",
        "- –ú–µ—Ç—Ä–∏–∫–∏: ROUGE, –Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ ‚Äî **—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å** (—á–µ—Ä–µ–∑ `factCC` –∏–ª–∏ —Ä—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑)  \n",
        "- –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ: `ai-forever/rugpt3large_based_on_gpt2` ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ –∞–Ω–∞–ª–æ–≥–∞–º–∏  \n",
        "\n",
        "### **4.6. Sentence Similarity & Ranking**\n",
        "- Sentence-BERT vs multilingual MiniLM  \n",
        "- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è  \n",
        "- –ú–µ—Ç—Ä–∏–∫–∏: Spearman –Ω–∞ STS-B, –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å  \n",
        "\n",
        "---\n",
        "\n",
        "## üìä 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å\n",
        "\n",
        "### **5.1. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã**\n",
        "–î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è —Ç–∞–±–ª–∏—Ü–∞:\n",
        "| –ú–æ–¥–µ–ª—å | –ú–µ—Ç—Ä–∏–∫–∞ | –°–∫–æ—Ä–æ—Å—Ç—å (–º—Å) | –ü–∞–º—è—Ç—å (–ì–ë) | –†–∞–∑–º–µ—Ä (–ú–ë) | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ RU |\n",
        "|--------|--------|---------------|-------------|-------------|--------------|\n",
        "| `distilbert-base-...` | F1=0.92 | 12 | 1.1 | 268 | –î–∞ (—á–µ—Ä–µ–∑ multilingual) |\n",
        "| `xlm-roberta-large` | F1=0.94 | 45 | 3.8 | 2100 | –î–∞ |\n",
        "\n",
        "### **5.2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è**\n",
        "- **Bar charts** ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫  \n",
        "- **Radar plots** ‚Äî –∫–∞—á–µ—Å—Ç–≤–æ / —Å–∫–æ—Ä–æ—Å—Ç—å / –ø–∞–º—è—Ç—å / multilingual  \n",
        "- **Attention maps** ‚Äî —á–µ—Ä–µ–∑ `bertviz` –∏–ª–∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã `transformers`  \n",
        "\n",
        "### **5.3. –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫**\n",
        "- Confusion matrix –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏  \n",
        "- –ü—Ä–∏–º–µ—Ä—ã, –≥–¥–µ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω–æ (—Å–∞—Ä–∫–∞–∑–º, –æ–ø–µ—á–∞—Ç–∫–∏, domain shift)  \n",
        "\n",
        "---\n",
        "\n",
        "## üéØ 6. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
        "\n",
        "### **6.1. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–æ —Å—Ü–µ–Ω–∞—Ä–∏—é**\n",
        "| –°—Ü–µ–Ω–∞—Ä–∏–π | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å |\n",
        "|--------|---------------------|\n",
        "| **Production, low latency** | `distilbert`, `MiniLM`, `TinyBERT` |\n",
        "| **High accuracy, research** | `roberta-large`, `bart-large`, `xlm-roberta-large` |\n",
        "| **Multilingual (–≤ —Ç.—á. RU, TJ)** | `xlm-roberta-base`, `m2m100_418M`, `mT5` |\n",
        "| **–î–ª–∏–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã** | `Longformer`, `BigBird` |\n",
        "| **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫** | `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` |\n",
        "\n",
        "### **6.2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è**\n",
        "- **Quantization**: `optimum` + `onnxruntime` ‚Üí int8 –º–æ–¥–µ–ª–∏  \n",
        "- **Distillation**: fine-tune `TinyBERT` –æ—Ç `BERT-large`  \n",
        "- **ONNX export**: —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≤ 2‚Äì3 —Ä–∞–∑–∞  \n",
        "- **Caching**: –¥–ª—è retrieval-augmented —Å–∏—Å—Ç–µ–º  \n",
        "\n",
        "### **6.3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ production**\n",
        "- –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ **data drift** (—á–µ—Ä–µ–∑ Evidently, WhyLabs)  \n",
        "- **A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** –º–æ–¥–µ–ª–µ–π  \n",
        "- **Continuous evaluation** –Ω–∞ —Å–∫—Ä—ã—Ç–æ–º —Å–µ—Ç–µ  \n",
        "\n",
        "---\n",
        "\n",
        "## üìÑ 7. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç—á—ë—Ç—É\n",
        "\n",
        "- –°–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –ø–æ **–≤—Å–µ–º 12 –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∑–∞–¥–∞—á**  \n",
        "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ **–∫–∞—á–µ—Å—Ç–≤–æ vs —Å–∫–æ—Ä–æ—Å—Ç—å** –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏  \n",
        "- –°–∫—Ä–∏–Ω—à–æ—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∏ attention-–∫–∞—Ä—Ç  \n",
        "- –°—Å—ã–ª–∫–∏:  \n",
        "  - GitHub —Å –∫–æ–¥–æ–º  \n",
        "  - Hugging Face Space (–¥–µ–º–æ)  \n",
        "  - –í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π (—á–µ—Ä–µ–∑ `model.push_to_hub()`)  \n",
        "- **–†–µ—Ñ–ª–µ–∫—Å–∏—è**:  \n",
        "  - –ù–∞—Å–∫–æ–ª—å–∫–æ –æ–ø—Ä–∞–≤–¥–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ¬´large¬ª –º–æ–¥–µ–ª–µ–π –≤ production?  \n",
        "  - –ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ –≤—Å–µ–≥–æ —Ä–∞–±–æ—Ç–∞—é—Ç –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –±–µ–∑ fine-tuning?  \n",
        "  - –ì–¥–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–∞ –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –¢–∞–¥–∂–∏–∫–∏—Å—Ç–∞–Ω–∞/–¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω–∞)?  \n",
        "\n",
        "---\n",
        "\n",
        "## üìñ 8. –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã\n",
        "\n",
        "| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |\n",
        "|-----------|-----------|\n",
        "| `transformers` | –ó–∞–≥—Ä—É–∑–∫–∞, inference, fine-tuning |\n",
        "| `datasets` | –†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏ |\n",
        "| `evaluate` | –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ (BLEU, ROUGE, seqeval –∏ –¥—Ä.) |\n",
        "| `sentence-transformers` | Sentence embeddings, similarity |\n",
        "| `optimum` | ONNX, quantization |\n",
        "| `gradio` / `streamlit` | –í–µ–±-–¥–µ–º–æ |\n",
        "\n",
        "---\n",
        "\n",
        "## üìä 9. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏\n",
        "\n",
        "| –û—Ü–µ–Ω–∫–∞ | –ö—Ä–∏—Ç–µ—Ä–∏–∏ |\n",
        "|--------|--------|\n",
        "| **5** | –ê–Ω–∞–ª–∏–∑ ‚â•10 –∑–∞–¥–∞—á, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ‚â•3 –º–æ–¥–µ–ª–µ–π –Ω–∞ –∫–∞–∂–¥—É—é, Hugging Face Space, ONNX/quantization, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è RU/TJ |\n",
        "| **4** | –ê–Ω–∞–ª–∏–∑ ‚â•7 –∑–∞–¥–∞—á, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –µ—Å—Ç—å –¥–µ–º–æ |\n",
        "| **3** | –ê–Ω–∞–ª–∏–∑ ‚â•4 –∑–∞–¥–∞—á, –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ |\n",
        "| **2** | –†–∞–±–æ—Ç–∞ –Ω–µ —Å–¥–∞–Ω–∞ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ |\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "QCP2tOXtsv2b"
      }
    }
  ]
}