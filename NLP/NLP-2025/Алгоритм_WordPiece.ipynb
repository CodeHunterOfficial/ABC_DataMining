{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPgP8k+ehbDfVL3d5bILEfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/NLP/NLP-2025/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_WordPiece.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìò –ê–ª–≥–æ—Ä–∏—Ç–º WordPiece ‚Äî —Å—É–±—Å–ª–æ–≤–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è\n",
        "\n",
        "\n",
        "## üîπ –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**WordPiece** ‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º —Å—É–±—Å–ª–æ–≤–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π Google –∏ –≤–ø–µ—Ä–≤—ã–µ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–π –≤ –º–æ–¥–µ–ª–∏ **BERT**. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å–ª–æ–≤–∞, –Ω–µ –≤—Ö–æ–¥—è—â–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å (OOV ‚Äî out-of-vocabulary), —Ä–∞–∑–±–∏–≤–∞—è –∏—Ö –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ –ø–æ–¥—á–∞—Å—Ç–∏ ‚Äî *—Å—É–±—Ç–æ–∫–µ–Ω—ã*. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç BPE, WordPiece –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π** –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–∞—Ä –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—é ‚Äî –æ–Ω –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç **–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ** –∫–æ—Ä–ø—É—Å–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –û—Å–Ω–æ–≤–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è –æ—Ç BPE\n",
        "\n",
        "| –ö—Ä–∏—Ç–µ—Ä–∏–π             | BPE                          | WordPiece                          |\n",
        "|----------------------|------------------------------|------------------------------------|\n",
        "| –ö—Ä–∏—Ç–µ—Ä–∏–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è | –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–∞—è –ø–∞—Ä–∞         | –ü–∞—Ä–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º score: `freq(pair) / (freq(A) * freq(B))` |\n",
        "| –ü—Ä–µ—Ñ–∏–∫—Å—ã             | –ù–µ—Ç                          | `##` –¥–ª—è –Ω–µ-–Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å—É–±—Ç–æ–∫–µ–Ω–æ–≤   |\n",
        "| –¶–µ–ª—å                 | –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω—ã –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è| –ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è –∫–æ—Ä–ø—É—Å–∞ |\n",
        "| –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ        | GPT, RoBERTa                 | BERT, ALBERT, ELECTRA              |\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞: –ü–æ—á–µ–º—É `score = freq(pair) / (freq(A) * freq(B))`?\n",
        "\n",
        "### üî∏ –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—é –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è\n",
        "\n",
        "WordPiece –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –ø—Ä–∏–Ω—Ü–∏–ø–µ **–º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–ø–æ–¥–æ–±–∏—è** (Maximum Likelihood Estimation) –¥–ª—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º —ç—Ç–æ—Ç –≤—ã–≤–æ–¥ –ø–æ–¥—Ä–æ–±–Ω–æ.\n",
        "\n",
        "**–®–∞–≥ 1: –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞**\n",
        "\n",
        "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ –Ω–∞—à –∫–æ—Ä–ø—É—Å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å—É–±—Ç–æ–∫–µ–Ω–æ–≤. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–æ—Ä–ø—É—Å–∞ –º–æ–∂–Ω–æ –≤—ã—Ä–∞–∑–∏—Ç—å —á–µ—Ä–µ–∑ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–∞—Ä (–±–∏–≥—Ä–∞–º–º–Ω–∞—è –º–æ–¥–µ–ª—å):\n",
        "\n",
        "$$\n",
        "P(\\text{–∫–æ—Ä–ø—É—Å}) = \\prod_{(X,Y)} P(Y | X)^{freq(X,Y)}\n",
        "$$\n",
        "\n",
        "–≥–¥–µ $freq(X,Y)$ ‚Äî —á–∞—Å—Ç–æ—Ç–∞ –ø–∞—Ä—ã (X, Y) –≤ –∫–æ—Ä–ø—É—Å–µ.\n",
        "\n",
        "**–®–∞–≥ 2: –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ**\n",
        "\n",
        "–î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–º—É –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—é:\n",
        "\n",
        "$$\n",
        "\\log P(\\text{–∫–æ—Ä–ø—É—Å}) = \\sum_{(X,Y)} freq(X,Y) \\cdot \\log P(Y | X)\n",
        "$$\n",
        "\n",
        "**–®–∞–≥ 3: –≠—Ñ—Ñ–µ–∫—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–∞—Ä**\n",
        "\n",
        "–ö–æ–≥–¥–∞ –º—ã –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–∞—Ä—É (A, B) –≤ –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω AB, –º—ã –∏–∑–º–µ–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ—Ä–ø—É—Å–∞. –ü—Ä–∏ —ç—Ç–æ–º:\n",
        "\n",
        "1. –ò—Å—á–µ–∑–∞—é—Ç –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –ø–∞—Ä—ã (A, B)\n",
        "2. –ü–æ—è–≤–ª—è—é—Ç—Å—è –Ω–æ–≤—ã–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ AB\n",
        "3. –ú–µ–Ω—è—é—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤\n",
        "\n",
        "**–®–∞–≥ 4: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è**\n",
        "\n",
        "–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è –º–æ–∂–Ω–æ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫:\n",
        "\n",
        "$$\n",
        "\\Delta \\log P \\approx freq(A,B) \\cdot \\log \\left( \\frac{P(AB)}{P(A) \\cdot P(B)} \\right) - \\left[ freq(A) \\cdot H_A + freq(B) \\cdot H_B \\right]\n",
        "$$\n",
        "\n",
        "–≥–¥–µ $H_A$ –∏ $H_B$ ‚Äî —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π —Å–ª–µ–¥—É—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ A –∏ B —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ.\n",
        "\n",
        "**–®–∞–≥ 5: –£–ø—Ä–æ—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è**\n",
        "\n",
        "–ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –≤—Ç–æ—Ä—ã–º —Å–ª–∞–≥–∞–µ–º—ã–º —á–∞—Å—Ç–æ –ø—Ä–µ–Ω–µ–±—Ä–µ–≥–∞—é—Ç, —Ç–∞–∫ –∫–∞–∫:\n",
        "- –≠–Ω—Ç—Ä–æ–ø–∏–π–Ω—ã–µ —á–ª–µ–Ω—ã —Å–ª–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª—è—Ç—å –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ\n",
        "- –û—Å–Ω–æ–≤–Ω–æ–π –≤–∫–ª–∞–¥ –≤–Ω–æ—Å–∏—Ç –ø–µ—Ä–≤–æ–µ —Å–ª–∞–≥–∞–µ–º–æ–µ\n",
        "- –î–ª—è —á–∞—Å—Ç—ã—Ö –ø–∞—Ä —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ $\\frac{P(AB)}{P(A)P(B)}$ —è–≤–ª—è–µ—Ç—Å—è —Ö–æ—Ä–æ—à–∏–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º\n",
        "\n",
        "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø–æ–ª—É—á–∞–µ–º:\n",
        "\n",
        "$$\n",
        "\\Delta \\log P \\propto freq(A,B) \\cdot \\log \\left( \\frac{P(AB)}{P(A) \\cdot P(B)} \\right)\n",
        "$$\n",
        "\n",
        "**–®–∞–≥ 6: –ü–µ—Ä–µ—Ö–æ–¥ –∫ —á–∞—Å—Ç–æ—Ç–∞–º**\n",
        "\n",
        "–ï—Å–ª–∏ –º—ã –æ—Ü–µ–Ω–∏–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã:\n",
        "\n",
        "$$\n",
        "P(X) \\approx \\frac{freq(X)}{N}, \\quad P(AB) \\approx \\frac{freq(AB)}{N}\n",
        "$$\n",
        "\n",
        "–≥–¥–µ N ‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, —Ç–æ:\n",
        "\n",
        "$$\n",
        "\\frac{P(AB)}{P(A)P(B)} \\approx \\frac{freq(AB) \\cdot N}{freq(A) \\cdot freq(B)}\n",
        "$$\n",
        "\n",
        "–ü–æ—Å–∫–æ–ª—å–∫—É N ‚Äî –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞, –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "$$\n",
        "score(A,B) = \\frac{freq(A,B)}{freq(A) \\cdot freq(B)}\n",
        "$$\n",
        "\n",
        "—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è.\n",
        "\n",
        "### üî∏ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è\n",
        "\n",
        "–§–æ—Ä–º—É–ª–∞ $ \\frac{freq(A,B)}{freq(A)freq(B)} $ –∏–º–µ–µ—Ç –≥–ª—É–±–æ–∫–∏–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:\n",
        "\n",
        "1. **–í–∑–∞–∏–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è**: Score –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª–µ–Ω —Ç–æ—á–µ—á–Ω–æ–π –≤–∑–∞–∏–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (Pointwise Mutual Information) –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏ A –∏ B:\n",
        "   \n",
        "   $$\n",
        "   PMI(A,B) = \\log \\frac{P(A,B)}{P(A)P(B)} \\approx \\log score(A,B)\n",
        "   $$\n",
        "\n",
        "2. **–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —É—Å—Ç–æ–π—á–∏–≤—ã—Ö —Å–æ—á–µ—Ç–∞–Ω–∏–π**: –í—ã—Å–æ–∫–∏–π score —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Ç–æ, —á—Ç–æ –ø–∞—Ä–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —á–∞—â–µ, —á–µ–º –µ—Å–ª–∏ –±—ã —Ç–æ–∫–µ–Ω—ã –±—ã–ª–∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã. –≠—Ç–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ –¥–ª—è:\n",
        "   - –ú–æ—Ä—Ñ–µ–º–Ω—ã—Ö —Å–æ—á–µ—Ç–∞–Ω–∏–π (\"##–Ω–∏–µ\", \"##—Ç–µ–ª—å\")\n",
        "   - –£—Å—Ç–æ–π—á–∏–≤—ã—Ö –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π\n",
        "   - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–∞—Ä\n",
        "\n",
        "3. **–ó–∞—â–∏—Ç–∞ –æ—Ç —Ä–µ–¥–∫–∏—Ö –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–π**: –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç BPE, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –æ–±—ä–µ–¥–∏–Ω—è—Ç—å —Ä–µ–¥–∫–∏–µ, –Ω–æ —á–∞—Å—Ç—ã–µ –ø–∞—Ä—ã, WordPiece –∏–∑–±–µ–≥–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–∞—Ä —Å –Ω–∏–∑–∫–æ–π –≤–∑–∞–∏–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —á–∞—Å—Ç–æ.\n",
        "\n",
        "### üî∏ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "–ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º –≤—ã—á–∏—Å–ª—è–µ—Ç score –¥–ª—è –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–∞—Ä –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ø–∞—Ä—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º:\n",
        "\n",
        "```python\n",
        "def calculate_score(pair, frequencies):\n",
        "    A, B = pair\n",
        "    freq_A = frequencies[A]\n",
        "    freq_B = frequencies[B]\n",
        "    freq_AB = frequencies.get(pair, 0)\n",
        "    \n",
        "    if freq_A * freq_B == 0:\n",
        "        return 0\n",
        "    return freq_AB / (freq_A * freq_B)\n",
        "```\n",
        "\n",
        "–≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã–±–æ—Ä –ø–∞—Ä, –∫–æ—Ç–æ—Ä—ã–µ:\n",
        "- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ —Å–≤—è–∑–∞–Ω—ã\n",
        "- –û–±—Ä–∞–∑—É—é—Ç –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã\n",
        "- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏–µ –∫–æ—Ä–ø—É—Å–∞\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
        "\n",
        "–í —Å–ª–æ–≤–∞—Ä–µ WordPiece (–∏ BERT) –≤—Å–µ–≥–¥–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã:\n",
        "\n",
        "- **[UNK]** ‚Äî *unknown token*. –ó–∞–º–µ–Ω—è–µ—Ç –ª—é–±–æ–µ —Å–ª–æ–≤–æ –∏–ª–∏ —Å–∏–º–≤–æ–ª, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π –≤ —Å–ª–æ–≤–∞—Ä—å.\n",
        "- **[CLS]** ‚Äî *classification token*. –°—Ç–∞–≤–∏—Ç—Å—è –≤ –Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –í –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–º–µ–Ω–Ω–æ –≤–µ–∫—Ç–æ—Ä —ç—Ç–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
        "- **[SEP]** ‚Äî *separator token*. –†–∞–∑–¥–µ–ª—è–µ—Ç –¥–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –∑–∞–¥–∞—á–µ –ø–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ1-–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ2).\n",
        "- **[MASK]** ‚Äî *mask token*. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –æ–±—É—á–µ–Ω–∏–∏ BERT –¥–ª—è –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è —á–∞—Å—Ç–∏ —Å–ª–æ–≤ ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å, —á—Ç–æ –±—ã–ª–æ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–æ.\n",
        "\n",
        "–≠—Ç–∏ —Ç–æ–∫–µ–Ω—ã **–Ω–µ —É—á–∞—Å—Ç–≤—É—é—Ç –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è WordPiece**, –Ω–æ **–¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –≤—Ä—É—á–Ω—É—é** –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –ü–æ—à–∞–≥–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º WordPiece —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏\n",
        "\n",
        "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∫–æ—Ä–ø—É—Å –∏–∑ –¥–≤—É—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã):\n",
        "\n",
        "> \"–£—á–µ–Ω–∏–∫ —É—á–∏—Ç—Å—è\"  \n",
        "> \"–£—á–µ–Ω–∏–∫ —á–∏—Ç–∞–µ—Ç\"\n",
        "\n",
        "–¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: `V = 20` (–≤–∫–ª—é—á–∞—è —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã).\n",
        "\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 0: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ—Ä–ø—É—Å–∞\n",
        "\n",
        "–†–∞–∑–±–∏–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –Ω–∞ —Å–∏–º–≤–æ–ª—ã, –¥–æ–±–∞–≤–ª—è—è `##` –∫–æ –≤—Å–µ–º —Å–∏–º–≤–æ–ª–∞–º, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ.\n",
        "\n",
        "```\n",
        "–£—á–µ–Ω–∏–∫ ‚Üí ['–£', '##—á', '##–µ', '##–Ω', '##–∏', '##–∫']\n",
        "—É—á–∏—Ç—Å—è ‚Üí ['—É', '##—á', '##–∏', '##—Ç', '##—Å', '##—è']\n",
        "—á–∏—Ç–∞–µ—Ç ‚Üí ['—á', '##–∏', '##—Ç', '##–∞', '##–µ', '##—Ç']\n",
        "```\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –∫–æ—Ä–ø—É—Å ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:\n",
        "\n",
        "```python\n",
        "corpus = [\n",
        "    ['–£', '##—á', '##–µ', '##–Ω', '##–∏', '##–∫', '—É', '##—á', '##–∏', '##—Ç', '##—Å', '##—è'],\n",
        "    ['–£', '##—á', '##–µ', '##–Ω', '##–∏', '##–∫', '—á', '##–∏', '##—Ç', '##–∞', '##–µ', '##—Ç']\n",
        "]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è\n",
        "\n",
        "–°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã/—Å—É–±—Ç–æ–∫–µ–Ω—ã:\n",
        "\n",
        "```python\n",
        "vocab = {'[UNK]', '[CLS]', '[SEP]', '[MASK]'}  # —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã\n",
        "vocab |= {'–£', '—É', '—á', '##—á', '##–µ', '##–Ω', '##–∏', '##–∫', '##—Ç', '##—Å', '##—è', '##–∞'}\n",
        "```\n",
        "\n",
        "–¢–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä: 16 —Ç–æ–∫–µ–Ω–æ–≤. –ù—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë 4.\n",
        "\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 2: –ü–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç –ø–∞—Ä –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ score\n",
        "\n",
        "–ü—Ä–æ–π–¥—ë–º –ø–æ –≤—Å–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º –∏ –ø–æ—Å—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã **—Å–º–µ–∂–Ω—ã—Ö –ø–∞—Ä**.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä –¥–ª—è –ø–µ—Ä–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
        "\n",
        "```\n",
        "['–£', '##—á'] ‚Üí 1\n",
        "['##—á', '##–µ'] ‚Üí 1\n",
        "['##–µ', '##–Ω'] ‚Üí 1\n",
        "['##–Ω', '##–∏'] ‚Üí 1\n",
        "['##–∏', '##–∫'] ‚Üí 1\n",
        "['##–∫', '—É'] ‚Üí 1\n",
        "['—É', '##—á'] ‚Üí 1\n",
        "['##—á', '##–∏'] ‚Üí 1\n",
        "['##–∏', '##—Ç'] ‚Üí 1\n",
        "['##—Ç', '##—Å'] ‚Üí 1\n",
        "['##—Å', '##—è'] ‚Üí 1\n",
        "```\n",
        "\n",
        "–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è –≤—Ç–æ—Ä–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
        "\n",
        "```\n",
        "['–£', '##—á'] ‚Üí 1 (–∏—Ç–æ–≥–æ 2)\n",
        "['##—á', '##–µ'] ‚Üí 1 (–∏—Ç–æ–≥–æ 2)\n",
        "['##–µ', '##–Ω'] ‚Üí 1 (–∏—Ç–æ–≥–æ 2)\n",
        "['##–Ω', '##–∏'] ‚Üí 1 (–∏—Ç–æ–≥–æ 2)\n",
        "['##–∏', '##–∫'] ‚Üí 1 (–∏—Ç–æ–≥–æ 2)\n",
        "['##–∫', '—á'] ‚Üí 1\n",
        "['—á', '##–∏'] ‚Üí 1\n",
        "['##–∏', '##—Ç'] ‚Üí 1 (–∏—Ç–æ–≥–æ 2)\n",
        "['##—Ç', '##–∞'] ‚Üí 1\n",
        "['##–∞', '##–µ'] ‚Üí 1\n",
        "['##–µ', '##—Ç'] ‚Üí 1\n",
        "```\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –ø–æ—Å—á–∏—Ç–∞–µ–º **score = freq(pair) / (freq(first) * freq(second))**\n",
        "\n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä, –≤–æ–∑—å–º—ë–º –ø–∞—Ä—É `('##—á', '##–µ')`:\n",
        "\n",
        "- freq(pair) = 2\n",
        "- freq('##—á') = 3 (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤: –£—á–µ–Ω–∏–∫√ó2, —É—á–∏—Ç—Å—è√ó1)\n",
        "- freq('##–µ') = 3 (–£—á–µ–Ω–∏–∫√ó2, —á–∏—Ç–∞–µ—Ç√ó1)\n",
        "- score = 2 / (3 * 3) = 2/9 ‚âà 0.222\n",
        "\n",
        "–ü–∞—Ä–∞ `('##–Ω', '##–∏')`:\n",
        "\n",
        "- freq(pair) = 2\n",
        "- freq('##–Ω') = 2\n",
        "- freq('##–∏') = 4 (–£—á–µ–Ω–∏–∫√ó2, —É—á–∏—Ç—Å—è√ó1, —á–∏—Ç–∞–µ—Ç√ó1)\n",
        "- score = 2 / (2 * 4) = 2/8 = 0.25 ‚Üê **–ª—É—á—à–µ!**\n",
        "\n",
        "–ü–∞—Ä–∞ `('##–∏', '##–∫')`:\n",
        "\n",
        "- freq(pair) = 2\n",
        "- freq('##–∏') = 4\n",
        "- freq('##–∫') = 2\n",
        "- score = 2 / (4 * 2) = 2/8 = 0.25 ‚Üê **—Ç–æ–∂–µ 0.25**\n",
        "\n",
        "–ü–∞—Ä–∞ `('##–∏', '##—Ç')`:\n",
        "\n",
        "- freq(pair) = 2\n",
        "- freq('##–∏') = 4\n",
        "- freq('##—Ç') = 3 (—É—á–∏—Ç—Å—è√ó1, —á–∏—Ç–∞–µ—Ç√ó2)\n",
        "- score = 2 / (4 * 3) = 2/12 ‚âà 0.166\n",
        "\n",
        "‚Üí **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π score = 0.25** —É –ø–∞—Ä `('##–Ω', '##–∏')` –∏ `('##–∏', '##–∫')`.\n",
        "\n",
        "–í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É ‚Äî `('##–Ω', '##–∏')`.\n",
        "\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 3: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞\n",
        "\n",
        "–û–±—ä–µ–¥–∏–Ω—è–µ–º `##–Ω` + `##–∏` ‚Üí `##–Ω–∏`\n",
        "\n",
        "–û–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
        "\n",
        "–ë—ã–ª–æ:\n",
        "```\n",
        "['–£', '##—á', '##–µ', '##–Ω', '##–∏', '##–∫', ...]\n",
        "```\n",
        "\n",
        "–°—Ç–∞–ª–æ:\n",
        "```\n",
        "['–£', '##—á', '##–µ', '##–Ω–∏', '##–∫', ...]\n",
        "```\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã —Å —É—á—ë—Ç–æ–º –Ω–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞.\n",
        "\n",
        "–î–æ–±–∞–≤–ª—è–µ–º `##–Ω–∏` –≤ —Å–ª–æ–≤–∞—Ä—å ‚Üí —Ä–∞–∑–º–µ—Ä = 17.\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 4: –°–ª–µ–¥—É—é—â–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å —Å—á–∏—Ç–∞–µ–º –ø–∞—Ä—ã —Å —É—á–∞—Å—Ç–∏–µ–º `##–Ω–∏`.\n",
        "\n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä, –ø–∞—Ä–∞ `('##–µ', '##–Ω–∏')`:\n",
        "\n",
        "- freq(pair) = 2\n",
        "- freq('##–µ') = 3\n",
        "- freq('##–Ω–∏') = 2\n",
        "- score = 2 / (3 * 2) = 1/3 ‚âà 0.333 ‚Üê **–Ω–æ–≤—ã–π –º–∞–∫—Å–∏–º—É–º!**\n",
        "\n",
        "–ü–∞—Ä–∞ `('##–Ω–∏', '##–∫')`:\n",
        "\n",
        "- freq(pair) = 2\n",
        "- freq('##–Ω–∏') = 2\n",
        "- freq('##–∫') = 2\n",
        "- score = 2 / (2 * 2) = 0.5 ‚Üê **–µ—â—ë –ª—É—á—à–µ!**\n",
        "\n",
        "‚Üí –í—ã–±–∏—Ä–∞–µ–º `('##–Ω–∏', '##–∫')` ‚Üí –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤ `##–Ω–∏–∫`\n",
        "\n",
        "–û–±–Ω–æ–≤–ª—è–µ–º –∫–æ—Ä–ø—É—Å:\n",
        "\n",
        "```\n",
        "['–£', '##—á', '##–µ', '##–Ω–∏–∫', ...]\n",
        "```\n",
        "\n",
        "–î–æ–±–∞–≤–ª—è–µ–º `##–Ω–∏–∫` –≤ —Å–ª–æ–≤–∞—Ä—å ‚Üí —Ä–∞–∑–º–µ—Ä = 18.\n",
        "\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 5: –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –ø–∞—Ä–∞ `('##–µ', '##–Ω–∏–∫')`:\n",
        "\n",
        "- freq = 2\n",
        "- freq('##–µ') = 3\n",
        "- freq('##–Ω–∏–∫') = 2\n",
        "- score = 2/(3*2) = 0.333\n",
        "\n",
        "–ü–∞—Ä–∞ `('##—á', '##–µ')`:\n",
        "\n",
        "- freq = 2\n",
        "- freq('##—á') = 3\n",
        "- freq('##–µ') = 3\n",
        "- score = 2/9 ‚âà 0.222\n",
        "\n",
        "–ü–∞—Ä–∞ `('–£', '##—á')`:\n",
        "\n",
        "- freq = 2\n",
        "- freq('–£') = 2\n",
        "- freq('##—á') = 3\n",
        "- score = 2/(2*3) = 1/3 ‚âà 0.333\n",
        "\n",
        "‚Üí –ú–∞–∫—Å–∏–º—É–º —É `('##–µ', '##–Ω–∏–∫')` –∏ `('–£', '##—á')` ‚Äî –æ–±–∞ 0.333.\n",
        "\n",
        "–í—ã–±–∏—Ä–∞–µ–º `('–£', '##—á')` ‚Üí –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤ `–£—á`\n",
        "\n",
        "–û–±–Ω–æ–≤–ª—è–µ–º:\n",
        "\n",
        "```\n",
        "['–£—á', '##–µ', '##–Ω–∏–∫', ...]\n",
        "```\n",
        "\n",
        "–î–æ–±–∞–≤–ª—è–µ–º `–£—á` ‚Üí —Ä–∞–∑–º–µ—Ä = 19.\n",
        "\n",
        "\n",
        "\n",
        "### üî∏ –®–∞–≥ 6: –ü–æ—Å–ª–µ–¥–Ω—è—è –∏—Ç–µ—Ä–∞—Ü–∏—è\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –ø–∞—Ä–∞ `('–£—á', '##–µ')`:\n",
        "\n",
        "- freq = 2\n",
        "- freq('–£—á') = 2\n",
        "- freq('##–µ') = 3\n",
        "- score = 2/(2*3) = 0.333\n",
        "\n",
        "–ü–∞—Ä–∞ `('##–µ', '##–Ω–∏–∫')` ‚Äî —Ç–æ–∂–µ 0.333\n",
        "\n",
        "–í—ã–±–∏—Ä–∞–µ–º `('–£—á', '##–µ')` ‚Üí `–£—á–µ`\n",
        "\n",
        "–î–æ–±–∞–≤–ª—è–µ–º `–£—á–µ` ‚Üí —Ä–∞–∑–º–µ—Ä = 20. ‚úÖ –¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞.\n",
        "\n",
        "–§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å (—É–ø—Ä–æ—â—ë–Ω–Ω–æ):\n",
        "\n",
        "```python\n",
        "{\n",
        "    '[UNK]', '[CLS]', '[SEP]', '[MASK]',\n",
        "    '–£', '—É', '—á', '##—á', '##–µ', '##–Ω', '##–∏', '##–∫', '##—Ç', '##—Å', '##—è', '##–∞',\n",
        "    '##–Ω–∏', '##–Ω–∏–∫', '–£—á', '–£—á–µ'\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å:\n",
        "\n",
        "> \"–£—á–µ–Ω–∏–∫ —É—á–∏—Ç—Å—è\"\n",
        "\n",
        "–ü—Ä–æ—Ü–µ—Å—Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî **–∂–∞–¥–Ω—ã–π**: –∏–¥—ë–º —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ, –±–µ—Ä—ë–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω—ã–π —Ç–æ–∫–µ–Ω –∏–∑ —Å–ª–æ–≤–∞—Ä—è.\n",
        "\n",
        "1. \"–£—á\" ‚Äî –µ—Å—Ç—å ‚Üí —Ç–æ–∫–µ–Ω `–£—á`\n",
        "2. –æ—Å—Ç–∞—Ç–æ–∫: \"–µ–Ω–∏–∫ —É—á–∏—Ç—Å—è\"\n",
        "3. \"–µ\" ‚Äî –µ—Å—Ç—å –∫–∞–∫ `##–µ`, –Ω–æ –ª—É—á—à–µ –≤–∑—è—Ç—å `–£—á–µ`? –ù–µ—Ç, \"–£—á–µ\" —É–∂–µ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, —Ç.–∫. —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å \"–µ\".\n",
        "4. \"–µ\" ‚Üí `##–µ`\n",
        "5. \"–Ω–∏\" ‚Üí `##–Ω–∏`\n",
        "6. \"–∫\" ‚Üí `##–∫` ‚Üí –Ω–æ —É –Ω–∞—Å –µ—Å—Ç—å `##–Ω–∏–∫`! ‚Üí –ø—Ä–æ–≤–µ—Ä—è–µ–º: \"–µ–Ω–∏–∫\" ‚Üí `##–µ` + `##–Ω–∏–∫` ‚Üí –µ—Å—Ç—å `##–Ω–∏–∫` ‚Üí –æ–±—ä–µ–¥–∏–Ω—è–µ–º ‚Üí `##–µ` + `##–Ω–∏–∫` ‚Üí –Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ –Ω–µ—Ç `##–µ–Ω–∏–∫`, –∑–∞—Ç–æ –µ—Å—Ç—å `##–Ω–∏–∫` ‚Üí –º–æ–∂–Ω–æ –ª–∏ –≤–∑—è—Ç—å `##–µ` + `##–Ω–∏–∫`? –î–∞, –µ—Å–ª–∏ –æ–Ω–∏ –∏–¥—É—Ç –ø–æ–¥—Ä—è–¥.\n",
        "\n",
        "‚Üí –ù–æ –≤ —Å–ª–æ–≤–∞—Ä–µ —É –Ω–∞—Å –µ—Å—Ç—å `–£—á–µ` –∏ `##–Ω–∏–∫`, –Ω–æ –Ω–µ—Ç `##–µ–Ω–∏–∫`.\n",
        "\n",
        "–õ—É—á—à–µ: –ø–æ—Å–ª–µ `–£—á` ‚Üí –æ—Å—Ç–∞—Ç–æ–∫ \"–µ–Ω–∏–∫\" ‚Üí –ø—Ä–æ–±—É–µ–º \"–µ\" ‚Üí `##–µ`, –∑–∞—Ç–µ–º \"–Ω–∏–∫\" ‚Üí `##–Ω–∏–∫` ‚Üí –ø–æ–ª—É—á–∞–µ–º `['–£—á', '##–µ', '##–Ω–∏–∫']`\n",
        "\n",
        "–î–∞–ª–µ–µ: –ø—Ä–æ–±–µ–ª ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ–º. \"—É—á–∏—Ç—Å—è\" ‚Üí \"—É\" + \"—á–∏—Ç—Å—è\"\n",
        "\n",
        "- \"—É\" ‚Üí –µ—Å—Ç—å\n",
        "- \"—á\" ‚Üí –Ω–µ—Ç –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ, –Ω–æ –µ—Å—Ç—å `##—á` ‚Äî –Ω–æ –æ–Ω –Ω–µ –Ω–∞—á–∞–ª—å–Ω—ã–π! ‚Üí –æ—à–∏–±–∫–∞?\n",
        "\n",
        "‚ùó **–í–∞–∂–Ω–æ**: –≤ WordPiece —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä **–Ω–µ –º–æ–∂–µ—Ç –Ω–∞—á–∞—Ç—å —Å–ª–æ–≤–æ —Å `##`**. –ü–æ—ç—Ç–æ–º—É –µ—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Å–∏–º–≤–æ–ª–∞, –∫–æ—Ç–æ—Ä—ã–π –≤ —Å–ª–æ–≤–∞—Ä–µ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Å `##`, ‚Äî —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞.\n",
        "\n",
        "–ó–Ω–∞—á–∏—Ç, –≤ –Ω–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ **–Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–æ–∫–µ–Ω–∞ \"—á\" –±–µ–∑ `##`** ‚Äî –Ω–æ –æ–Ω —É –Ω–∞—Å –µ—Å—Ç—å! –í –Ω–∞—á–∞–ª—å–Ω–æ–º —Å–ª–æ–≤–∞—Ä–µ –±—ã–ª `'—á'` (–∏–∑ —Å–ª–æ–≤–∞ \"—á–∏—Ç–∞–µ—Ç\").\n",
        "\n",
        "‚Üí \"—É—á–∏—Ç—Å—è\":  \n",
        "- \"—É\" ‚Üí –µ—Å—Ç—å  \n",
        "- \"—á\" ‚Üí –µ—Å—Ç—å (–±–µ–∑ `##`)  \n",
        "- \"–∏\" ‚Üí `##–∏`? –ù–æ —É –Ω–∞—Å –Ω–µ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ \"–∏\", —Ç–æ–ª—å–∫–æ `##–∏`. ‚Üí –ø—Ä–æ–±–ª–µ–º–∞.\n",
        "\n",
        "‚ùó –≠—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç: **–≤ –Ω–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –±–∞–∑–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –±–µ–∑ `##` –¥–ª—è –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –Ω–∞—á–∞–ª—å–Ω—ã—Ö –±—É–∫–≤**.\n",
        "\n",
        "‚Üí –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ, WordPiece **–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –±–µ–∑ `##`**, –∏ —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–æ–º–µ—á–∞—é—Ç—Å—è.\n",
        "\n",
        "–ó–Ω–∞—á–∏—Ç, –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ, —Å–ª–æ–≤–æ \"—É—á–∏—Ç—Å—è\" —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫:\n",
        "\n",
        "- \"—É\" ‚Üí `'—É'`\n",
        "- \"—á\" ‚Üí `'—á'` (–µ—Å—Ç—å!)\n",
        "- \"–∏\" ‚Üí –Ω–µ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ `'–∏'`, —Ç–æ–ª—å–∫–æ `'##–∏'` ‚Üí –∑–Ω–∞—á–∏—Ç, –±–µ—Ä—ë–º `'—á'` + `'##–∏'`? –ù–æ `'—á'` –∏ `'##–∏'` ‚Äî —ç—Ç–æ —Ä–∞–∑–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã, –∏ –≤ —Å–ª–æ–≤–∞—Ä–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–∞—Ä–∞ `'—á##–∏'`? –ù–µ—Ç.\n",
        "\n",
        "‚Üí –¢–æ–≥–¥–∞ —Ä–∞–∑–±–∏–≤–∞–µ–º: `'—á'`, `'##–∏'`, `'##—Ç'`, `'##—Å'`, `'##—è'`\n",
        "\n",
        "‚Üí –ò—Ç–æ–≥–æ: `['—É', '—á', '##–∏', '##—Ç', '##—Å', '##—è']`\n",
        "\n",
        "–ù–æ —É –Ω–∞—Å –≤ —Å–ª–æ–≤–∞—Ä–µ –µ—Å—Ç—å `'##–∏—Ç'`? –ù–µ—Ç. –ê –º–æ–≥–ª–æ –±—ã –±—ã—Ç—å, –µ—Å–ª–∏ –±—ã –º—ã –ø—Ä–æ–¥–æ–ª–∂–∏–ª–∏ –æ–±—É—á–µ–Ω–∏–µ.\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –ò—Ç–æ–≥–æ–≤–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "- \"–£—á–µ–Ω–∏–∫\" ‚Üí `['–£—á', '##–µ', '##–Ω–∏–∫']` –∏–ª–∏ `['–£', '##—á', '##–µ', '##–Ω–∏–∫']` ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–æ–π —Ç–æ–∫–µ–Ω –¥–ª–∏–Ω–Ω–µ–µ –∏ –µ—Å—Ç—å –ª–∏ –æ–Ω.\n",
        "\n",
        "–í –Ω–∞—à–µ–º —Å–ª–æ–≤–∞—Ä–µ `'–£—á–µ'` –µ—Å—Ç—å, –Ω–æ –ø–æ—Å–ª–µ –Ω–µ–≥–æ –æ—Å—Ç–∞—ë—Ç—Å—è `'–Ω–∏–∫'` ‚Äî –∞ `'–Ω–∏–∫'` –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω —É –Ω–∞—Å –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –∫–∞–∫ `'##–Ω–∏–∫'`, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –º–æ–∂–µ—Ç –Ω–∞—á–∏–Ω–∞—Ç—å —Å–ª–æ–≤–æ.\n",
        "\n",
        "‚Üí –ü–æ—ç—Ç–æ–º—É —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤—ã–±–µ—Ä–µ—Ç: `'–£—á'` + `'##–µ'` + `'##–Ω–∏–∫'`\n",
        "\n",
        "- \"—É—á–∏—Ç—Å—è\" ‚Üí `'—É'` + `'—á'` + `'##–∏'` + `'##—Ç'` + `'##—Å'` + `'##—è'`\n",
        "\n",
        "‚Üí –ü–æ–ª–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:  \n",
        "`['–£—á', '##–µ', '##–Ω–∏–∫', '—É', '—á', '##–∏', '##—Ç', '##—Å', '##—è']`\n",
        "\n",
        "–ï—Å–ª–∏ –±—ã —É –Ω–∞—Å –±—ã–ª —Ç–æ–∫–µ–Ω `'##–∏—Ç—Å—è'`, –±—ã–ª–æ –±—ã –ª—É—á—à–µ.\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –ü–æ—á–µ–º—É WordPiece —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω?\n",
        "\n",
        "1. **–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç OOV**: –ª—é–±–æ–µ —Å–ª–æ–≤–æ –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ —Å—É–±—Ç–æ–∫–µ–Ω—ã.\n",
        "2. **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã**: `##–Ω–∏–∫`, `##—Ç–µ–ª—å`, `##—Å—Ç–≤–æ` ‚Äî —á–∞—Å—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –º–æ—Ä—Ñ–µ–º–∞–º.\n",
        "3. **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞**: `##` –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ —Ç–æ–∫–µ–Ω ‚Äî —á–∞—Å—Ç—å —Å–ª–æ–≤–∞.\n",
        "4. **–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω**: –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è > –∂–∞–¥–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞.\n",
        "\n",
        "\n",
        "\n",
        "## üîπ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "WordPiece ‚Äî —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ ¬´BPE —Å –¥—Ä—É–≥–∏–º score¬ª. –≠—Ç–æ **–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º**, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —è–∑—ã–∫–æ–≤–æ–º –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏. –û–Ω —Å—Ç—Ä–æ–∏—Ç —Å–ª–æ–≤–∞—Ä—å, **–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞**, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥–ª—è —Å–∂–∞—Ç–∏—è. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã `[UNK]`, `[CLS]`, `[SEP]`, `[MASK]` –∏–≥—Ä–∞—é—Ç –∫–ª—é—á–µ–≤—É—é —Ä–æ–ª—å –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ BERT –∏ –Ω–µ —É—á–∞—Å—Ç–≤—É—é—Ç –≤ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ —Å–ª–æ–≤–∞—Ä—è, –Ω–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."
      ],
      "metadata": {
        "id": "yjLOaDZmwd_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from tokenizers import Tokenizer, models, trainers\n",
        "from tokenizers import normalizers, pre_tokenizers, processors\n",
        "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
        "from tokenizers.pre_tokenizers import Whitespace, Punctuation, Digits\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ –°–û–ó–î–ê–ù–ò–ï –ö–û–†–ü–£–°–ê\n",
        "# -------------------------------\n",
        "def create_corpus(filename_txt=\"corpus.txt\", filename_jsonl=\"corpus.jsonl\"):\n",
        "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—ã–π –∫–æ—Ä–ø—É—Å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ JSONL –∏ TXT\"\"\"\n",
        "    data = [\n",
        "        {\"text\": \"–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\", \"label\": \"greeting\"},\n",
        "        {\"text\": \"–°–µ–≥–æ–¥–Ω—è —Ö–æ—Ä–æ—à–∞—è –ø–æ–≥–æ–¥–∞.\", \"label\": \"weather\"},\n",
        "        {\"text\": \"–Ø —É—á—É –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.\", \"label\": \"education\"},\n",
        "        {\"text\": \"–°–µ–≥–æ–¥–Ω—è —è –∏–∑—É—á–∞—é NLP –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã.\", \"label\": \"education\"},\n",
        "        {\"text\": \"–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ.\", \"label\": \"education\"},\n",
        "        {\"text\": \"–ü–æ–≥–æ–¥–∞ –Ω–∞ —É–ª–∏—Ü–µ –¥–æ–∂–¥–ª–∏–≤–∞—è –∏ —Ö–æ–ª–æ–¥–Ω–∞—è.\", \"label\": \"weather\"},\n",
        "        {\"text\": \"–ü—Ä–∏–≤–µ—Ç! –î–∞–≤–Ω–æ –Ω–µ –≤–∏–¥–µ–ª–∏—Å—å.\", \"label\": \"greeting\"},\n",
        "        {\"text\": \"BERT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç WordPiece —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é.\", \"label\": \"nlp\"},\n",
        "        {\"text\": \"–ß–∏—Å–ª–∞ 123 –∏ 4567 –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è.\", \"label\": \"example\"},\n",
        "        {\"text\": \"Hugging Face –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.\", \"label\": \"tools\"},\n",
        "        {\"text\": \"–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞.\", \"label\": \"nlp\"},\n",
        "        {\"text\": \"–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –æ–±—É—á–∞—é—Ç—Å—è –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\", \"label\": \"ai\"},\n",
        "        {\"text\": \"Python –∏ JavaScript –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —è–∑—ã–∫–∏.\", \"label\": \"programming\"},\n",
        "        {\"text\": \"–°–µ–≥–æ–¥–Ω—è —Å–æ–ª–Ω–µ—á–Ω–æ –∏ —Ç–µ–ø–ª–æ.\", \"label\": \"weather\"},\n",
        "        {\"text\": \"–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –º–µ–Ω—è–µ—Ç –º–∏—Ä.\", \"label\": \"ai\"},\n",
        "        {\"text\": \"–†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç—Ä–µ–±—É–µ—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω–æ—Å—Ç–∏.\", \"label\": \"data\"},\n",
        "        {\"text\": \"–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é –≤–∞—Å, –∫–æ–ª–ª–µ–≥–∏!\", \"label\": \"greeting\"},\n",
        "        {\"text\": \"–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ —Å–µ—Ç–∏.\", \"label\": \"ai\"},\n",
        "        {\"text\": \"JSON —Ñ–æ—Ä–º–∞—Ç —É–¥–æ–±–µ–Ω –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.\", \"label\": \"programming\"},\n",
        "        {\"text\": \"–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏.\", \"label\": \"nlp\"}\n",
        "    ]\n",
        "\n",
        "    with open(filename_jsonl, \"w\", encoding=\"utf-8\") as f_jsonl, \\\n",
        "         open(filename_txt, \"w\", encoding=\"utf-8\") as f_txt:\n",
        "        for item in data:\n",
        "            f_jsonl.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "            f_txt.write(item[\"text\"] + \"\\n\")\n",
        "\n",
        "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω –∫–æ—Ä–ø—É—Å –∏–∑ {len(data)} —Ç–µ–∫—Å—Ç–æ–≤\")\n",
        "    return data\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ –ì–ï–ù–ï–†–ê–¢–û–† –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø\n",
        "# -------------------------------\n",
        "def corpus_iterator(file_path=\"corpus.txt\"):\n",
        "    \"\"\"–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                yield line\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ –°–û–ó–î–ê–ù–ò–ï –ò –û–ë–£–ß–ï–ù–ò–ï –¢–û–ö–ï–ù–ò–ó–ê–¢–û–†–ê\n",
        "# -------------------------------\n",
        "def create_and_train_tokenizer(\n",
        "        corpus_file=\"corpus.txt\",\n",
        "        vocab_size=1000,\n",
        "        min_frequency=1,\n",
        "        tokenizer_file=\"wordpiece_tokenizer.json\"\n",
        "    ):\n",
        "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –∏ –æ–±—É—á–∞–µ—Ç WordPiece —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\"\"\"\n",
        "\n",
        "    tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
        "\n",
        "    # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–µ—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏\n",
        "    tokenizer.normalizer = normalizers.Sequence([\n",
        "        NFD(),\n",
        "        Lowercase(),\n",
        "        StripAccents()\n",
        "    ])\n",
        "\n",
        "    tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
        "        Whitespace(),\n",
        "        Punctuation(),\n",
        "        Digits(individual_digits=False)\n",
        "    ])\n",
        "\n",
        "    trainer = trainers.WordPieceTrainer(\n",
        "        vocab_size=vocab_size,\n",
        "        min_frequency=min_frequency,\n",
        "        special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"],\n",
        "        continuing_subword_prefix=\"##\",\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    print(\"üöÄ –û–±—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...\")\n",
        "    tokenizer.train_from_iterator(corpus_iterator(corpus_file), trainer)\n",
        "\n",
        "    tokenizer.post_processor = TemplateProcessing(\n",
        "        single=\"[CLS] $A [SEP]\",\n",
        "        pair=\"[CLS] $A [SEP] $B [SEP]\",\n",
        "        special_tokens=[\n",
        "            (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        "            (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    tokenizer.save(tokenizer_file)\n",
        "    print(f\"‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ '{tokenizer_file}'\")\n",
        "    return tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï\n",
        "# -------------------------------\n",
        "def test_tokenizer(tokenizer_path=\"wordpiece_tokenizer.json\"):\n",
        "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
        "\n",
        "    test_texts = [\n",
        "        \"–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\",\n",
        "        \"–°–µ–≥–æ–¥–Ω—è —è –∏–∑—É—á–∞—é NLP –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.\",\n",
        "        \"–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ!\",\n",
        "        \"–ß–∏—Å–ª–∞ 123 –∏ 4567 –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ.\",\n",
        "        \"BERT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç WordPiece –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.\",\n",
        "        \"Hugging Face - —ç—Ç–æ –æ—Ç–ª–∏—á–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è ML.\",\n",
        "        \"–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç\",\n",
        "        \"–†–∞–∑–ª–∏—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: !@#$%^&*()\",\n",
        "        \"–°–º–µ—à–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: Hello world –∏ –ü—Ä–∏–≤–µ—Ç –º–∏—Ä!\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –¢–û–ö–ï–ù–ò–ó–ê–¢–û–†–ê\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for i, text in enumerate(test_texts, 1):\n",
        "        output = tokenizer.encode(text)\n",
        "        decoded = tokenizer.decode(output.ids)\n",
        "\n",
        "        # –ì–∏–±–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–±–µ–ª—ã/—Ä–µ–≥–∏—Å—Ç—Ä)\n",
        "        clean = lambda s: re.sub(r\"\\s+\", \"\", s.lower())\n",
        "        match = clean(text) == clean(decoded)\n",
        "\n",
        "        print(f\"\\n{i}. –¢–µ–∫—Å—Ç: '{text}'\")\n",
        "        print(f\"   –¢–æ–∫–µ–Ω—ã: {output.tokens}\")\n",
        "        print(f\"   –ò–Ω–¥–µ–∫—Å—ã: {output.ids}\")\n",
        "        print(f\"   –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {'‚úÖ' if match else '‚ùå'}\")\n",
        "        print(f\"   –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ: '{decoded}'\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ –ê–ù–ê–õ–ò–ó –°–õ–û–í–ê–†–Ø\n",
        "# -------------------------------\n",
        "def analyze_vocabulary(tokenizer_path=\"wordpiece_tokenizer.json\"):\n",
        "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
        "    vocab = tokenizer.get_vocab()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä –ê–ù–ê–õ–ò–ó –°–õ–û–í–ê–†–Ø\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üìè –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(vocab)} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
        "\n",
        "    special_tokens = [t for t in vocab if t.startswith('[')]\n",
        "    subword_tokens = [t for t in vocab if t.startswith('##')]\n",
        "    word_tokens = [t for t in vocab if not t.startswith('[') and not t.startswith('##')]\n",
        "    punctuation_tokens = [t for t in word_tokens if len(t) == 1 and not t.isalnum()]\n",
        "\n",
        "    print(f\"\\nüéØ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã ({len(special_tokens)}): {special_tokens}\")\n",
        "    print(f\"\\nüî§ –¶–µ–ª—ã–µ —Å–ª–æ–≤–∞ ({len(word_tokens)}): {word_tokens[:15]}...\")\n",
        "    print(f\"\\nüß© –°—É–±—Ç–æ–∫–µ–Ω—ã ({len(subword_tokens)}): {subword_tokens[:10]}...\")\n",
        "    print(f\"\\nüî£ –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è ({len(punctuation_tokens)}): {punctuation_tokens}\")\n",
        "\n",
        "    lengths = [len(t) for t in vocab if not t.startswith('[')]\n",
        "    if lengths:\n",
        "        print(f\"\\nüìê –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–∞: {sum(lengths)/len(lengths):.2f}\")\n",
        "        print(f\"   –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: {max(lengths)}\")\n",
        "        print(f\"   –°–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–æ–∫–µ–Ω: {min(lengths)}\")\n",
        "\n",
        "# -------------------------------\n",
        "# üöÄ –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø\n",
        "# -------------------------------\n",
        "def main():\n",
        "    print(\"üöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø WORDPIECE –¢–û–ö–ï–ù–ò–ó–ê–¢–û–†–ê\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    create_corpus()\n",
        "    tokenizer = create_and_train_tokenizer(vocab_size=1000)\n",
        "    test_tokenizer()\n",
        "    analyze_vocabulary()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"‚úÖ –í–°–ï –ó–ê–î–ê–ß–ò –í–´–ü–û–õ–ù–ï–ù–´!\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1D1OG_TRxyqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}