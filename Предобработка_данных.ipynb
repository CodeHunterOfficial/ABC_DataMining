{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOxSqtHQYLtAjszJaxcxls5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/%D0%9F%D1%80%D0%B5%D0%B4%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ‚Äî —ç—Ç–æ –≤–∞–∂–Ω—ã–π —ç—Ç–∞–ø –≤ –∞–Ω–∞–ª–∏–∑–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á–∞—Ö. –û–Ω–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –±—ã–ª–∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–º–∏ –∏ –Ω–∞–¥–µ–∂–Ω—ã–º–∏."
      ],
      "metadata": {
        "id": "NFCXKWnsz7KM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. –ò–∑—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (Data Understanding)\n",
        "\n",
        "## –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "–ò–∑—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (Data Understanding) —è–≤–ª—è–µ—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º —ç—Ç–∞–ø–æ–º –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ù–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–≤–æ–¥–∏—Ç –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –≤—ã—è–≤–ª—è–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—ã –æ –≤–∑–∞–∏–º–æ—Å–≤—è–∑—è—Ö –º–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∏ –≥–æ—Ç–æ–≤–∏—Ç—Å—è –∫ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º—É —ç—Ç–∞–ø—É –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –¶–µ–ª—å—é –¥–∞–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —è–≤–ª—è–µ—Ç—Å—è –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –±–æ–ª–µ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –¥–∞–ª—å–Ω–µ–π—à–∏—Ö —ç—Ç–∞–ø–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞.\n",
        "\n",
        "\n",
        "\n",
        "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
        "\n",
        "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ‚Äî —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ —Ä–∞–±–æ—á—É—é —Å—Ä–µ–¥—É –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –î–∞–Ω–Ω—ã–π —à–∞–≥ —è–≤–ª—è–µ—Ç—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –æ—Å–Ω–æ–≤–æ–π –≤—Å–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.\n",
        "\n",
        "### –§–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤\n",
        "\n",
        "–ù–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
        "\n",
        "- **CSV** (Comma-Separated Values) ‚Äî —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏.\n",
        "- **Excel (.xlsx)** ‚Äî —Ñ–æ—Ä–º–∞—Ç —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü Microsoft Excel.\n",
        "- **JSON** ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.\n",
        "- **SQL –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö** ‚Äî —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.\n",
        "- **Parquet, HDF5, Pickle** ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ –æ–±—ä–µ–º–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ Python\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–∞\n",
        "# df = pd.read_excel('data.xlsx')\n",
        "```\n",
        "\n",
        "> –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—É—Ç—å –∫ –Ω–µ–º—É.\n",
        "\n",
        "\n",
        "\n",
        "## 2. –û—Å–º–æ—Ç—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–¶–µ–ª—å –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—ç—Ç–∞–ø–∞ ‚Äî –ø–æ–ª—É—á–∏—Ç—å –æ–±—â–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.\n",
        "\n",
        "### a) –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "\n",
        "–î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞—Ç—Ä–∏–±—É—Ç `.shape` –æ–±—ä–µ–∫—Ç–∞ DataFrame.\n",
        "\n",
        "```python\n",
        "print(df.shape)\n",
        "```\n",
        "\n",
        "–†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –±—É–¥–µ—Ç –∫–æ—Ä—Ç–µ–∂ `(–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Å—Ç—Ä–æ–∫, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Å—Ç–æ–ª–±—Ü–æ–≤)`.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä:\n",
        "```\n",
        "(1000, 10)\n",
        "```\n",
        "–æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç 1000 —Å—Ç—Ä–æ–∫ –∏ 10 —Å—Ç–æ–ª–±—Ü–æ–≤.\n",
        "\n",
        "### b) –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–ú–µ—Ç–æ–¥ `.info()` –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ DataFrame, –≤–∫–ª—é—á–∞—è:\n",
        "\n",
        "- –ò–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫;\n",
        "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π;\n",
        "- –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö (`int64`, `float64`, `object` –∏ –¥—Ä—É–≥–∏–µ).\n",
        "\n",
        "```python\n",
        "print(df.info())\n",
        "```\n",
        "\n",
        "–û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã —Ç–∏–ø–∞ `object`, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏–ª–∏ –æ—à–∏–±–∫–∞–º–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.\n",
        "\n",
        "### c) –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–§—É–Ω–∫—Ü–∏—è `.describe()` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ —á–∏—Å–ª–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–∞–º:\n",
        "\n",
        "```python\n",
        "print(df.describe())\n",
        "```\n",
        "\n",
        "–í—ã–≤–æ–¥–∏–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\n",
        "- Count ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π;\n",
        "- Mean ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ;\n",
        "- Std ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ;\n",
        "- Min/Max ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏—è;\n",
        "- –ü–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏: 25%, 50% (–º–µ–¥–∏–∞–Ω–∞), 75%.\n",
        "\n",
        "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—ã–∑–æ–≤ –º–µ—Ç–æ–¥–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `include=['O']`:\n",
        "\n",
        "```python\n",
        "print(df.describe(include=['O']))\n",
        "```\n",
        "\n",
        "\n",
        "## 3. –ü–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä –ø–µ—Ä–≤—ã—Ö N —Å—Ç—Ä–æ–∫\n",
        "\n",
        "–î–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫.\n",
        "\n",
        "```python\n",
        "print(df.head(5))  # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫\n",
        "```\n",
        "\n",
        "–≠—Ç–æ—Ç —à–∞–≥ –ø–æ–∑–≤–æ–ª—è–µ—Ç:\n",
        "\n",
        "- –ü–æ–Ω—è—Ç—å, –∫–∞–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ;\n",
        "- –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤–≤–æ–¥–∞, –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤;\n",
        "- –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Å–º—ã—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
        "\n",
        "### a) –ê–Ω–∞–ª–∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π –∏ –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –≤–∞–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–º—ã—Å–ª –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞. –ù–∞–ø—Ä–∏–º–µ—Ä:\n",
        "\n",
        "- –ö–æ–ª–æ–Ω–∫–∞ `Age` –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å –≤–æ–∑—Ä–∞—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞;\n",
        "- `X1`, `Var_2`, `feature_17` ‚Äî —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.\n",
        "\n",
        "–ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ª–æ–≤–∞—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –µ—ë –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É—Å–∫–æ—Ä—è–µ—Ç –∏ —É–≥–ª—É–±–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞.\n",
        "\n",
        "### b) –ù–∞–ª–∏—á–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
        "\n",
        "–ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, —Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å **—Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (label)**.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "- `Churn` (–∑–Ω–∞—á–µ–Ω–∏—è: \"Yes\"/\"No\") ‚Äî –∑–∞–¥–∞—á–∞ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏;\n",
        "- `Price` ‚Äî –∑–∞–¥–∞—á–∞ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.\n",
        "\n",
        "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—ã—á–Ω–æ –≤—ã–¥–µ–ª—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
        "\n",
        "```python\n",
        "y = df['Churn']  # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
        "X = df.drop('Churn', axis=1)  # –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## 5. –í—ã—è–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∏ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ —Ç–∏–ø–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è.\n",
        "\n",
        "### a) –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Numerical Features)\n",
        "\n",
        "–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–µ–ª—è—Ç—Å—è –Ω–∞ –¥–≤–∞ –ø–æ–¥—Ç–∏–ø–∞:\n",
        "\n",
        "- **–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ** ‚Äî –ø—Ä–∏–Ω–∏–º–∞—é—Ç —Ç–æ–ª—å–∫–æ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Number of Children`);\n",
        "- **–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ** ‚Äî –ø—Ä–∏–Ω–∏–º–∞—é—Ç –ª—é–±—ã–µ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Height`, `Weight`).\n",
        "\n",
        "–î–ª—è –∏—Ö –≤—ã–¥–µ–ª–µ–Ω–∏—è –≤ Pandas –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥:\n",
        "\n",
        "```python\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "print(numerical_cols)\n",
        "```\n",
        "\n",
        "### b) –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Categorical Features)\n",
        "\n",
        "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ —á–∞—Å—Ç–æ –∏–º–µ—é—Ç —Ç–∏–ø `object`.\n",
        "\n",
        "```python\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(categorical_cols)\n",
        "```\n",
        "\n",
        "> –í–∞–∂–Ω–æ! –ò–Ω–æ–≥–¥–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã —á–∏—Å–ª–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `0`, `1`). –¢–∞–∫–∏–µ —Å–ª—É—á–∞–∏ —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏.\n",
        "\n",
        "\n",
        "\n",
        "## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
        "\n",
        "- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –¥–∞–Ω–Ω—ã—Ö** ‚Äî –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω, –µ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—Å–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "- **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞** ‚Äî –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `pandas-profiling` –∏–ª–∏ `sweetviz`.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è `pandas-profiling`:\n",
        "\n",
        "```bash\n",
        "pip install pandas-profiling\n",
        "```\n",
        "\n",
        "```python\n",
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
        "profile.to_file(\"report.html\")\n",
        "```\n",
        "\n",
        "- **–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤** ‚Äî –∑–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã: ¬´–ß—Ç–æ –º—ã —Ö–æ—Ç–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å?¬ª, ¬´–ö–∞–∫ —Å–≤—è–∑–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–µ–∂–¥—É —Å–æ–±–æ–π?¬ª, ¬´–ö–∞–∫–∏–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –Ω–∞–±–ª—é–¥–∞—Ç—å?¬ª.\n",
        "\n",
        "\n",
        "\n",
        "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–≠—Ç–∞–ø –∏–∑—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —è–≤–ª—è–µ—Ç—Å—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π —á–∞—Å—Ç—å—é –ª—é–±–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–ª–∏ ML-–ø—Ä–æ–µ–∫—Ç–∞. –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å –∫—Ä–∞—Ç–∫–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞:\n",
        "\n",
        "| –≠—Ç–∞–ø | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|------|----------|\n",
        "| –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö | –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ |\n",
        "| –û—Å–º–æ—Ç—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ª–∏—á–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ |\n",
        "| –ü–µ—Ä–≤–∏—á–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä | –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ |\n",
        "| –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–º—ã—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –∏ –Ω–∞–ª–∏—á–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π |\n",
        "| –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –í—ã–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n",
        "\n",
        "\n",
        "\n",
        "## –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ—Ç–∫—Ä—ã—Ç—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Titanic](https://www.kaggle.com/c/titanic/data), [Iris](https://archive.ics.uci.edu/ml/datasets/Iris)).\n",
        "2. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ —ç—Ç–∞–ø—ã, —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –≤—ã—à–µ: –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ, –∏–∑—É—á–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ –∏—Ö –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ.\n",
        "3. –°–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–¥–Ω–æ–π –æ—Ç—á—ë—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `pandas-profiling`.\n"
      ],
      "metadata": {
        "id": "O4z54gcpOIXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 2. –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Data Cleaning)  \n",
        "## a. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "\n",
        "–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ‚Äî —ç—Ç–æ –æ–¥–∏–Ω –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —ç—Ç–∞–ø–æ–≤ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–≤—ã—Å–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è. –û–¥–Ω–∏–º –∏–∑ —Å–∞–º—ã—Ö —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –æ—á–∏—Å—Ç–∫–∏ —è–≤–ª—è–µ—Ç—Å—è **–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π** (missing data). –ü—Ä–æ–ø—É—Å–∫–∏ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–∞—Ç—å –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –ø—Ä–∏—á–∏–Ω–∞–º: –æ—à–∏–±–∫–∏ –≤–≤–æ–¥–∞, –Ω–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–±–æ–∏ –∏ —Ç.–¥.\n",
        "\n",
        "\n",
        "\n",
        "## üìå –¶–µ–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "\n",
        "1. –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –∏–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∑–∞–º–µ–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
        "2. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –æ–±—ä—ë–º–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
        "3. –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ (bias), –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –ø—Ä–∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
        "4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –∞–Ω–∞–ª–∏–∑—É –∏–ª–∏ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π.\n",
        "\n",
        "\n",
        "\n",
        "## 1. –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "\n",
        "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Ö **–æ–±–Ω–∞—Ä—É–∂–∏—Ç—å**. –í Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ `pandas` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç True —Ç–∞–º, –≥–¥–µ –µ—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫\n",
        "df.isnull()\n",
        "\n",
        "# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º\n",
        "df.isnull().sum()\n",
        "\n",
        "# –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º\n",
        "(df.isnull().sum() / len(df)) * 100\n",
        "```\n",
        "\n",
        "–¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, `missingno`, `seaborn`) –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–≥–ª—è–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è.\n",
        "\n",
        "\n",
        "## 2. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫/—Å—Ç–æ–ª–±—Ü–æ–≤ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
        "\n",
        "–ï—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –æ—á–µ–Ω—å –±–æ–ª—å—à—É—é –¥–æ–ª—é –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, >70%), —Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ —É–¥–∞–ª–∏—Ç—å —Ç–∞–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —Å—Ç–æ–ª–±—Ü—ã.\n",
        "\n",
        "### a) –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ (axis=0)\n",
        "\n",
        "```python\n",
        "# –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–æ–ø—É—Å–∫\n",
        "df_clean = df.dropna(axis=0)\n",
        "\n",
        "# –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ –±–æ–ª—å—à–µ N –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "df_clean = df.dropna(thresh=5)\n",
        "```\n",
        "\n",
        "> **–ü–ª—é—Å—ã**: –ø—Ä–æ—Å—Ç–æ—Ç–∞, —Å–∫–æ—Ä–æ—Å—Ç—å.  \n",
        "> **–ú–∏–Ω—É—Å—ã**: –ø–æ—Ç–µ—Ä—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –≤–æ–∑–º–æ–∂–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "### b) –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ (axis=1)\n",
        "\n",
        "```python\n",
        "# –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã, –≥–¥–µ –±–æ–ª—å—à–µ 70% –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
        "threshold = len(df) * 0.7\n",
        "df_clean = df.dropna(axis=1, thresh=threshold)\n",
        "```\n",
        "\n",
        "> –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–¥–∫–æ, –µ—Å–ª–∏ —Å—Ç–æ–ª–±–µ—Ü –Ω–µ –≤–∞–∂–µ–Ω –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –∏–∑ –¥—Ä—É–≥–∏—Ö.\n",
        "\n",
        "\n",
        "\n",
        "## 3. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "\n",
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è, –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –°—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤:\n",
        "\n",
        "### a) –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º (–¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –∫–æ–≥–¥–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ.\n",
        "\n",
        "```python\n",
        "mean_value = df['column_name'].mean()\n",
        "df['column_name'].fillna(mean_value, inplace=True)\n",
        "```\n",
        "\n",
        "> **–ü–ª—é—Å—ã**: –ø—Ä–æ—Å—Ç–æ—Ç–∞, —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º (–ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –º–µ–¥–∏–∞–Ω—ã).  \n",
        "> **–ú–∏–Ω—É—Å—ã**: –º–æ–∂–µ—Ç –∑–∞–Ω–∏–∂–∞—Ç—å –¥–∏—Å–ø–µ—Ä—Å–∏—é, –µ—Å–ª–∏ –º–Ω–æ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
        "\n",
        "### b) –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–µ–¥–∏–∞–Ω–æ–π (–¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
        "\n",
        "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –≤—ã–±—Ä–æ—Å–æ–≤.\n",
        "\n",
        "```python\n",
        "median_value = df['column_name'].median()\n",
        "df['column_name'].fillna(median_value, inplace=True)\n",
        "```\n",
        "\n",
        "### c) –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–æ–¥–æ–π (–¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
        "\n",
        "–î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–∞–∏–±–æ–ª–µ–µ –ª–æ–≥–∏—á–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **–º–æ–¥—ã** ‚Äî –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–µ–≥–æ—Å—è –∑–Ω–∞—á–µ–Ω–∏—è.\n",
        "\n",
        "```python\n",
        "mode_value = df['category_column'].mode()[0]\n",
        "df['category_column'].fillna(mode_value, inplace=True)\n",
        "```\n",
        "\n",
        "> –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å \"Unknown\" –∏–ª–∏ \"Missing\" –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é.\n",
        "\n",
        "#### üÜï –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä `'Unknown'`)\n",
        "\n",
        "–ï—Å–ª–∏ –º–æ–¥–∞ –º–æ–∂–µ—Ç –≤–Ω–æ—Å–∏—Ç—å —Å–º–µ—â–µ–Ω–∏–µ –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ —è–≤–ª—è—é—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏, –ª—É—á—à–µ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∏—Ö —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º:\n",
        "\n",
        "```python\n",
        "df['category_column'].fillna('Unknown', inplace=True)\n",
        "```\n",
        "\n",
        "–≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É—é—Ç –æ —Å–∫—Ä—ã—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –±—ã–ª–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ;\n",
        "- –ú–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω—ã.\n",
        "\n",
        "\n",
        "\n",
        "### d) –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã)\n",
        "\n",
        "–î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é.\n",
        "\n",
        "```python\n",
        "df['column_name'].interpolate(method='linear', inplace=True)\n",
        "```\n",
        "\n",
        "–ú–µ—Ç–æ–¥—ã: `linear`, `polynomial`, `spline`, `time`.\n",
        "\n",
        "\n",
        "\n",
        "### e) –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "\n",
        "–ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π, –Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –º–µ—Ç–æ–¥ ‚Äî –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "–ï—Å–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –≤ —á–∏—Å–ª–æ–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ `Age`, –º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, —á—Ç–æ–±—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è.\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ\n",
        "known = df[df['Age'].notnull()]\n",
        "unknown = df[df['Age'].isnull()]\n",
        "\n",
        "X_train = known.drop('Age', axis=1)\n",
        "y_train = known['Age']\n",
        "X_test = unknown.drop('Age', axis=1)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
        "df.loc[df['Age'].isnull(), 'Age'] = predicted\n",
        "```\n",
        "\n",
        "> **–ü–ª—é—Å—ã**: –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å.  \n",
        "> **–ú–∏–Ω—É—Å—ã**: —Ç—Ä–µ–±—É–µ—Ç –≤—Ä–µ–º–µ–Ω–∏, —Ä–µ—Å—É—Ä—Å–æ–≤, –∑–Ω–∞–Ω–∏–π, –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –§–ª–∞–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ (–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
        "\n",
        "–≠—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ –º—ã —Å–æ–∑–¥–∞—ë–º **–Ω–æ–≤—ã–π –±–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫**, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, –±—ã–ª–æ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "df['Age_missing'] = df['Age'].isnull().astype(int)\n",
        "```\n",
        "\n",
        "–ó–∞—Ç–µ–º –º–æ–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ–¥–∏–∞–Ω–æ–π:\n",
        "\n",
        "```python\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "```\n",
        "\n",
        "> **–ü–ª—é—Å—ã**: –º–æ–¥–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –±—ã–ª–∏ –ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–ø—É—â–µ–Ω—ã. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞–∂–Ω–æ, –µ—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ –Ω–µ —Å–ª—É—á–∞–π–Ω—ã.  \n",
        "> **–ú–∏–Ω—É—Å—ã**: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–µ—Ç–æ–¥–∞\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |\n",
        "|------|---------------------|---------------|-------------|\n",
        "| –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫/—Å—Ç–æ–ª–±—Ü–æ–≤ | –ï—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –æ—á–µ–Ω—å –º–Ω–æ–≥–æ (>70%) –∏–ª–∏ –æ–Ω–∏ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã | –ü—Ä–æ—Å—Ç–æ –∏ –±—ã—Å—Ç—Ä–æ | –ü–æ—Ç–µ—Ä—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ |\n",
        "| –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º/–º–µ–¥–∏–∞–Ω–æ–π | –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏–ª–∏ –Ω–∞–ª–∏—á–∏–µ–º –≤—ã–±—Ä–æ—Å–æ–≤ | –ë—ã—Å—Ç—Ä–æ, –ª–µ–≥–∫–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å | –ú–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å –¥–∏—Å–ø–µ—Ä—Å–∏—é |\n",
        "| –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–æ–¥–æ–π | –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –õ–æ–≥–∏—á–Ω–æ –∏ –ø—Ä–æ—Å—Ç–æ | –ú–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–º–µ—â–µ–Ω–∏–µ |\n",
        "| –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ `'Unknown'` | –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –µ—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω | –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–ø—É—Å–∫–µ | –¢—Ä–µ–±—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ |\n",
        "| –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è | –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ | –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ | –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–µ—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö |\n",
        "| –ú–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è | –ü—Ä–∏ –≤—ã—Å–æ–∫–æ–π —Ü–µ–Ω–µ –∑–∞ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö | –¢–æ—á–Ω–µ–µ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–æ–≤ | –°–ª–æ–∂–Ω–æ, –¥–æ–ª–≥–æ, —Ç—Ä–µ–±—É–µ—Ç –æ–ø—ã—Ç–∞ |\n",
        "| –§–ª–∞–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ | –ï—Å–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã | –î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é | –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å |\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –ò—Ç–æ–≥–∏\n",
        "\n",
        "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ‚Äî —ç—Ç–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, —Ç—Ä–µ–±—É—é—â–∏–π –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–¥–∞—á–∏. –ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –æ–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–π—Å—Ç–≤–∏–π:\n",
        "\n",
        "1. **–í—ã—è–≤–∏—Ç—å** –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
        "2. **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å** —Ö–∞—Ä–∞–∫—Ç–µ—Ä –ø—Ä–æ–ø—É—Å–∫–æ–≤: —Å–ª—É—á–∞–π–Ω—ã –æ–Ω–∏ –∏–ª–∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω—ã.\n",
        "3. **–í—ã–±—Ä–∞—Ç—å** –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏ –æ–±—ä—ë–º–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
        "4. **–ü—Ä–∏–º–µ–Ω–∏—Ç—å** –≤—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥.\n",
        "5. **–ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å** –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ñ–ª–∞–≥–∏).\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –í–æ–∑—å–º–∏—Ç–µ –ª—é–±–æ–π –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Titanic](https://www.kaggle.com/c/titanic/data)).\n",
        "2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
        "3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã:\n",
        "   - –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ –∏–ª–∏ —Å—Ç–æ–ª–±—Ü–æ–≤;\n",
        "   - –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º/–º–µ–¥–∏–∞–Ω–æ–π –∏ –º–æ–¥–æ–π;\n",
        "   - –°–æ–∑–¥–∞–π—Ç–µ —Ñ–ª–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏;\n",
        "   - –ü–æ –∂–µ–ª–∞–Ω–∏—é: –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –º–æ–¥–µ–ª—å—é.\n",
        "4. –°—Ä–∞–≤–Ω–∏—Ç–µ, –∫–∞–∫ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤–ª–∏—è—é—Ç –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n"
      ],
      "metadata": {
        "id": "OBqgotDdOWpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 2. –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Data Cleaning)  \n",
        "## b. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
        "\n",
        "–î—É–±–ª–∏–∫–∞—Ç—ã ‚Äî —ç—Ç–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–ø–∏—Å–∏ –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∏—Å–∫–∞–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –û–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å **–ø–æ–ª–Ω—ã–º–∏** (–ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç—Ä–æ–∫–µ) –∏–ª–∏ **—á–∞—Å—Ç–∏—á–Ω—ã–º–∏** (–ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è). –ò—Ö —É–¥–∞–ª–µ–Ω–∏–µ ‚Äî –≤–∞–∂–Ω—ã–π —ç—Ç–∞–ø –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "\n",
        "\n",
        "### üìå –¶–µ–ª–∏ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
        "\n",
        "1. **–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö**, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Å–º–µ—â–µ–Ω–∏—é —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ü–µ–Ω–æ–∫.\n",
        "2. **–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞** –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
        "3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∏—Å—Ç–æ—Ç—ã –∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö.**\n",
        "\n",
        "\n",
        "\n",
        "### 1. –ü–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã (—Å—Ç—Ä–æ–∫–∏)\n",
        "\n",
        "–≠—Ç–æ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö —Å–æ–≤–ø–∞–¥–∞—é—Ç. –¢–∞–∫–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –æ–±—ã—á–Ω–æ –ª–µ–≥–∫–æ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã (–∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ–π)\n",
        "df.duplicated()\n",
        "\n",
        "# –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–ª–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
        "df.duplicated().sum()\n",
        "\n",
        "# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
        "df_clean = df.drop_duplicates()\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é `drop_duplicates()` —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–µ—Ä–≤—É—é –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –∏ —É–¥–∞–ª—è–µ—Ç –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ. –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä:  \n",
        "> ```python\n",
        "> df.drop_duplicates(keep='last')\n",
        "> ```\n",
        "\n",
        "\n",
        "\n",
        "### 2. –ß–∞—Å—Ç–∏—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–ª—è–º)\n",
        "\n",
        "–ò–Ω–æ–≥–¥–∞ –≤–∞–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ ID –∫–ª–∏–µ–Ω—Ç–∞, –Ω–æ–º–µ—Ä—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏, –¥–∞—Ç–µ —Å–æ–±—ã—Ç–∏—è –∏ —Ç.–¥.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Ç–æ–ª—å–∫–æ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å—Ç–æ–ª–±—Ü—É 'customer_id'\n",
        "df_clean = df.drop_duplicates(subset=['customer_id'])\n",
        "\n",
        "# –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–µ–π:\n",
        "df_clean = df.drop_duplicates(subset=['customer_id', 'transaction_date'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏, –≥–¥–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ª—è–º–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
        "\n",
        "| –°–∏—Ç—É–∞—Ü–∏—è | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
        "|---------|------------|\n",
        "| –ü–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã | –£–¥–∞–ª–∏—Ç—å —Å –ø–æ–º–æ—â—å—é `drop_duplicates()` |\n",
        "| –ß–∞—Å—Ç–∏—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã | –£–∫–∞–∑–∞—Ç—å `subset` —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏ |\n",
        "| –ù—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –≤—Å–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ | –ù–µ —É–¥–∞–ª—è—Ç—å, –∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ |\n",
        "\n",
        "\n",
        "\n",
        "## c. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\n",
        "\n",
        "–û—à–∏–±–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö ‚Äî –µ—â—ë –æ–¥–∏–Ω —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–æ–±–ª–µ–º. –û–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–∏–ø), —Ç–∞–∫ –∏ —Å–º—ã—Å–ª–æ–≤—ã–º–∏ (–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è).\n",
        "\n",
        "\n",
        "\n",
        "### 1. –¢–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n",
        "\n",
        "–ß–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä:\n",
        "\n",
        "- `'Yees'`, `'No'` –≤–º–µ—Å—Ç–æ `'Yes'`;\n",
        "- `'Malee'`, `'M'` –≤–º–µ—Å—Ç–æ `'Male'`.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:\n",
        "\n",
        "```python\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º replace –¥–ª—è –∑–∞–º–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏–π\n",
        "df['Gender'] = df['Gender'].replace({'Malee': 'Male', 'M': 'Male', 'Femal': 'Female'})\n",
        "\n",
        "# –î–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –æ—à–∏–±–æ–∫ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è\n",
        "import pandas as pd\n",
        "\n",
        "df['Answer'] = df['Answer'].str.replace(r'(?i)y.*s', 'Yes', regex=True)\n",
        "df['Answer'] = df['Answer'].str.replace(r'(?i)n.*', 'No', regex=True)\n",
        "```\n",
        "\n",
        "> üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `fuzzywuzzy` –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç—å –∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ \"—Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞\".\n",
        "\n",
        "\n",
        "\n",
        "### 2. –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n",
        "\n",
        "–≠—Ç–∏ –æ—à–∏–±–∫–∏ —Å–≤—è–∑–∞–Ω—ã —Å –Ω–∞—Ä—É—à–µ–Ω–∏–µ–º –∑–¥—Ä–∞–≤–æ–≥–æ —Å–º—ã—Å–ª–∞ –∏–ª–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª. –ù–∞–ø—Ä–∏–º–µ—Ä:\n",
        "\n",
        "- –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç;\n",
        "- –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –≤ –±—É–¥—É—â–µ–º;\n",
        "- –ó–∞—Ä–ø–ª–∞—Ç–∞ –º–µ–Ω—å—à–µ –ø—Ä–æ–∂–∏—Ç–æ—á–Ω–æ–≥–æ –º–∏–Ω–∏–º—É–º–∞ (–ø—Ä–∏ —è–≤–Ω–æ–º –∑–∞–≤–µ–¥–æ–º–æ –Ω–µ–≤–µ—Ä–Ω–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏);\n",
        "- –í–æ–∑—Ä–∞—Å—Ç —Ä–µ–±—ë–Ω–∫–∞ —Å—Ç–∞—Ä—à–µ —Ä–æ–¥–∏—Ç–µ–ª—è –∏ —Ç.–¥.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
        "\n",
        "##### a) –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç\n",
        "\n",
        "```python\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç —Ä–∞–≤–Ω—ã–º 0\n",
        "df = df[df['Age'] >= 0]\n",
        "```\n",
        "\n",
        "–∏–ª–∏ –∑–∞–ø–æ–ª–Ω–∏–º –Ω–µ–≤–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–æ–π:\n",
        "\n",
        "```python\n",
        "median_age = df['Age'][df['Age'] > 0].median()\n",
        "df.loc[df['Age'] < 0, 'Age'] = median_age\n",
        "```\n",
        "\n",
        "##### b) –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –≤ –±—É–¥—É—â–µ–º\n",
        "\n",
        "```python\n",
        "from datetime import datetime\n",
        "\n",
        "current_year = datetime.now().year\n",
        "df = df[df['Birth_Date'].dt.year <= current_year]\n",
        "```\n",
        "\n",
        "##### c) –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É—Å–ª–æ–≤–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n",
        "\n",
        "```python\n",
        "# –ï—Å–ª–∏ –∑–∞—Ä–ø–ª–∞—Ç–∞ –º–µ–Ω—å—à–µ 1000 ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –æ—à–∏–±–∫–∞\n",
        "df = df[df['Salary'] >= 1000]\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è –í–∞–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç: –∏–Ω–æ–≥–¥–∞ —Ç–∞–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –¥–æ–ø—É—Å—Ç–∏–º—ã–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –¥–µ—Ç–∏ –∏ —Ç.–ø.).\n",
        "\n",
        "\n",
        "\n",
        "## d. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö ‚Äî –∫–ª—é—á–µ–≤–æ–π —à–∞–≥, –≤–ª–∏—è—é—â–∏–π –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è.\n",
        "\n",
        "\n",
        "\n",
        "### 1. –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
        "\n",
        "–ò–Ω–æ–≥–¥–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö Pandas –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–∏—Å–ª–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É—é—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏, –¥–∞—Ç—ã –∫–∞–∫ –æ–±—ä–µ–∫—Ç—ã –∏ —Ç.–¥.).\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "##### a) –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø\n",
        "\n",
        "```python\n",
        "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
        "```\n",
        "\n",
        "> `errors='coerce'` –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ `NaN`.\n",
        "\n",
        "##### b) –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –¥–∞—Ç—É\n",
        "\n",
        "```python\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "```\n",
        "\n",
        "##### c) –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø\n",
        "\n",
        "```python\n",
        "df['Category'] = df['Category'].astype('category')\n",
        "```\n",
        "\n",
        "> –≠—Ç–æ —É–º–µ–Ω—å—à–∞–µ—Ç –æ–±—ä—ë–º –ø–∞–º—è—Ç–∏ –∏ —É—Å–∫–æ—Ä—è–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏.\n",
        "\n",
        "##### d) –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ\n",
        "\n",
        "```python\n",
        "dtypes = {\n",
        "    'ID': 'int64',\n",
        "    'Name': 'object',\n",
        "    'Birth_Date': 'datetime64[ns]',\n",
        "    'Gender': 'category'\n",
        "}\n",
        "\n",
        "df = pd.read_csv('data.csv', dtype=dtypes)\n",
        "```\n",
        "\n",
        "\n",
        "### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤\n",
        "\n",
        "–ï—Å–ª–∏ —Ç–∏–ø—ã –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã, –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ñ—É–Ω–∫—Ü–∏–µ–π `infer_objects()`:\n",
        "\n",
        "```python\n",
        "df = df.infer_objects()\n",
        "```\n",
        "\n",
        "> –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—ã—Ç–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã –≤ –±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–∏–ø—ã.\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "1. **–ü–æ–∏—Å–∫ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤**:\n",
        "   - –ü–æ–ª–Ω—ã–µ –∏ —á–∞—Å—Ç–∏—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã.\n",
        "2. **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫**:\n",
        "   - –¢–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏.\n",
        "3. **–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö**:\n",
        "   - –ß–∏—Å–ª–æ–≤—ã–µ, –¥–∞—Ç—ã, –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Titanic](https://www.kaggle.com/c/titanic/data), [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult)).\n",
        "2. –í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ:\n",
        "   - –ù–∞–π–¥–∏—Ç–µ –∏ —É–¥–∞–ª–∏—Ç–µ –ø–æ–ª–Ω—ã–µ –∏ —á–∞—Å—Ç–∏—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã.\n",
        "   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ ‚Äî –∏—Å–ø—Ä–∞–≤—å—Ç–µ –∏—Ö.\n",
        "   - –ü—Ä–∏–≤–µ–¥–∏—Ç–µ –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã –∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö.\n",
        "3. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –æ—á–∏—â–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –µ–≥–æ —Å –∏—Å—Ö–æ–¥–Ω—ã–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ.\n",
        "\n"
      ],
      "metadata": {
        "id": "WxJHWS6-SZyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 3. –†–∞–±–æ—Ç–∞ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏ (Outliers)\n",
        "\n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**–í—ã–±—Ä–æ—Å—ã (outliers)** ‚Äî —ç—Ç–æ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. –û–Ω–∏ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–∞—Ç—å –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ –æ—à–∏–±–æ–∫ –∏–∑–º–µ—Ä–µ–Ω–∏—è, —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –±—ã—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ä–µ–¥–∫–∏—Ö, –Ω–æ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π.\n",
        "\n",
        "### –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –ø–æ—è–≤–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤:\n",
        "\n",
        "- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ –≤–≤–æ–¥–µ/—Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö;\n",
        "- –ê–Ω–æ–º–∞–ª–∏–∏ –≤ —Å–∏—Å—Ç–µ–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è);\n",
        "- –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—ã—Å–æ–∫–∏–π –¥–æ—Ö–æ–¥ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –≤—ã–±–æ—Ä–∫–µ —Å–æ —Å—Ä–µ–¥–Ω–∏–º —É—Ä–æ–≤–Ω–µ–º –¥–æ—Å—Ç–∞—Ç–∫–∞);\n",
        "- –°–±–æ–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ó–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å –≤—ã–±—Ä–æ—Å–∞–º–∏\n",
        "\n",
        "–£—á–µ—Ç –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –≤–∞–∂–Ω—ã –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –ø—Ä–∏—á–∏–Ω–∞–º:\n",
        "\n",
        "1. **–í–ª–∏—è–Ω–∏–µ –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏**: –≤—ã–±—Ä–æ—Å—ã –º–æ–≥—É—Ç —Å–∏–ª—å–Ω–æ –∏—Å–∫–∞–∑–∏—Ç—å —Ç–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏, –∫–∞–∫ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –¥–∏—Å–ø–µ—Ä—Å–∏—è, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ.\n",
        "2. **–°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è**, –æ—Å–æ–±–µ–Ω–Ω–æ —Ç–µ—Ö, –∫–æ—Ç–æ—Ä—ã–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏ (–ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, KNN, SVM).\n",
        "3. **–ò—Å–∫–∞–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π**, —á—Ç–æ –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏.\n",
        "4. **–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏**: –≤ –∑–∞–¥–∞—á–∞—Ö –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞, –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω–æ–º–∞–ª–∏–π, –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–∫–∞–∑–æ–≤ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –≤—ã–±—Ä–æ—Å—ã –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
        "\n",
        "\n",
        "\n",
        "## 1. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
        "\n",
        "–ü–µ—Ä–≤—ã–º —ç—Ç–∞–ø–æ–º –≤ —Ä–∞–±–æ—Ç–µ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏ —è–≤–ª—è–µ—Ç—Å—è –∏—Ö **–≤–∏–∑—É–∞–ª—å–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ**. –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π.\n",
        "\n",
        "### a) Boxplot (—è—â–∏–∫ —Å —É—Å–∞–º–∏)\n",
        "\n",
        "Boxplot ‚Äî –æ–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤. –û–Ω –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –º–µ–¥–∏–∞–Ω—É, –∫–≤–∞—Ä—Ç–∏–ª–∏, –∞ —Ç–∞–∫–∂–µ —Ç–æ—á–∫–∏, –≤—ã—Ö–æ–¥—è—â–∏–µ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã \"—É—Å–æ–≤\" –≥—Ä–∞—Ñ–∏–∫–∞.\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "sns.boxplot(x=df['Age'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –Ω–∞–≥–ª—è–¥–Ω–æ, –ø—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è.  \n",
        "> ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –ª–æ–∂–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–∏ –Ω–µ–Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "### b) Scatter plot (–¥–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è)\n",
        "\n",
        "–î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã –≤ –¥–≤—É–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df['Age'], df['Salary'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏.\n",
        "\n",
        "---\n",
        "\n",
        "### c) –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –∏ KDE (—è–¥–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏)\n",
        "\n",
        "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –∏ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –ø–æ–Ω—è—Ç—å —Ñ–æ—Ä–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –∑–∞–º–µ—Ç–∏—Ç—å —Ö–≤–æ—Å—Ç—ã, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤.\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "sns.histplot(df['Age'], kde=True)\n",
        "```\n",
        "\n",
        "> ‚úÖ –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ä–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –µ–≥–æ —Å–∏–º–º–µ—Ç—Ä–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "## 2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤\n",
        "\n",
        "–ö—Ä–æ–º–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã**, –ø–æ–∑–≤–æ–ª—è—é—â–∏–µ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–ª–µ–¥—É–µ—Ç —Å—á–∏—Ç–∞—Ç—å –≤—ã–±—Ä–æ—Å–∞–º–∏.\n",
        "\n",
        "### a) Z-score (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)\n",
        "\n",
        "Z-score –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "z = \\frac{x - \\mu}{\\sigma}\n",
        "$$\n",
        "–≥–¥–µ:\n",
        "- $ x $ ‚Äî —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ,\n",
        "- $ \\mu $ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ,\n",
        "- $ \\sigma $ ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "z_scores = np.abs(stats.zscore(df['Age']))\n",
        "threshold = 3\n",
        "df_clean = df[z_scores < threshold]\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.  \n",
        "> ‚ùå –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Å–∏–ª—å–Ω–æ–π –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "### b) IQR ‚Äî –ú–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö\n",
        "\n",
        "IQR (Interquartile Range) ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–∞–∂–µ –ø—Ä–∏ –Ω–µ–Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "IQR = Q3 - Q1\n",
        "$$\n",
        "–ó–Ω–∞—á–µ–Ω–∏—è —Å—á–∏—Ç–∞—é—Ç—Å—è –≤—ã–±—Ä–æ—Å–∞–º–∏, –µ—Å–ª–∏ –æ–Ω–∏:\n",
        "- –º–µ–Ω—å—à–µ $ Q1 - 1.5 \\cdot IQR $\n",
        "- –±–æ–ª—å—à–µ $ Q3 + 1.5 \\cdot IQR $\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "Q1 = df['Age'].quantile(0.25)\n",
        "Q3 = df['Age'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "df_clean = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
        "```\n",
        "\n",
        "> ‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥, —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º —Ç–∏–ø–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.  \n",
        "> ‚ö†Ô∏è –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–∞–∑–º–µ—Ä—É –≤—ã–±–æ—Ä–∫–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üìò –ß—Ç–æ —Ç–∞–∫–æ–µ —Å–∫–æ—à–µ–Ω–Ω–æ–µ (–∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–µ) —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ?\n",
        "\n",
        "**–°–∫–æ—à–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (skewed distribution)** ‚Äî —ç—Ç–æ –Ω–µ—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ö–≤–æ—Å—Ç –∑–Ω–∞—á–µ–Ω–∏–π —Å–º–µ—â—ë–Ω –ª–∏–±–æ –≤–ª–µ–≤–æ, –ª–∏–±–æ –≤–ø—Ä–∞–≤–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–∏.\n",
        "\n",
        "### –î–≤–∞ —Ç–∏–ø–∞ –∞—Å–∏–º–º–µ—Ç—Ä–∏–∏:\n",
        "\n",
        "- **–ü—Ä–∞–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è) –∞—Å–∏–º–º–µ—Ç—Ä–∏—è** ‚Äî –¥–ª–∏–Ω–Ω—ã–π –ø—Ä–∞–≤—ã–π —Ö–≤–æ—Å—Ç. –°—Ä–µ–¥–Ω–µ–µ > –º–µ–¥–∏–∞–Ω—ã.\n",
        "- **–õ–µ–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è) –∞—Å–∏–º–º–µ—Ç—Ä–∏—è** ‚Äî –¥–ª–∏–Ω–Ω—ã–π –ª–µ–≤—ã–π —Ö–≤–æ—Å—Ç. –°—Ä–µ–¥–Ω–µ–µ < –º–µ–¥–∏–∞–Ω—ã.\n",
        "\n",
        "#### –ü—Ä–∏—á–∏–Ω—ã —Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç–∏:\n",
        "- –ù–∞–ª–∏—á–∏–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞—Ä–ø–ª–∞—Ç—ã, —Å—Ç–æ–∏–º–æ—Å—Ç—å –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏).\n",
        "- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ/–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä —Å–∫–æ—à–µ–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:\n",
        "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º —Å—Ç–æ–ª–±–µ—Ü `Income` ‚Äî –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ª—é–¥–µ–π –∏–º–µ—é—Ç —Å—Ä–µ–¥–Ω–∏–π –¥–æ—Ö–æ–¥, –Ω–æ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–º –¥–æ—Ö–æ–¥–æ–º, —á—Ç–æ —Å–æ–∑–¥–∞—ë—Ç –¥–ª–∏–Ω–Ω—ã–π –ø—Ä–∞–≤—ã–π —Ö–≤–æ—Å—Ç.\n",
        "\n",
        "```python\n",
        "sns.histplot(df['Income'], kde=True)\n",
        "```\n",
        "\n",
        "#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å?\n",
        "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–∫–æ—à–µ–Ω–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è **–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è**, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
        "- –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ: `np.log(x)`\n",
        "- –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å: `np.sqrt(x)`\n",
        "- Box-Cox –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)\n",
        "\n",
        "\n",
        "\n",
        "## 3. –†–µ—à–µ–Ω–∏—è –ø–æ —Ä–∞–±–æ—Ç–µ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏\n",
        "\n",
        "–ü–æ—Å–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ, –∫–∞–∫ —Å –Ω–∏–º–∏ –ø–æ—Å—Ç—É–ø–∏—Ç—å. –ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "### a) –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π\n",
        "\n",
        "–ï—Å–ª–∏ –≤—ã–±—Ä–æ—Å—ã —è–≤–ª—è—é—Ç—Å—è —è–≤–Ω–æ–π –æ—à–∏–±–∫–æ–π –∏–ª–∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–≤–µ–ª–∏–∫–æ, –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏.\n",
        "\n",
        "```python\n",
        "df_clean = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∏ –±—ã—Å—Ç—Ä—ã–π —Å–ø–æ—Å–æ–±.  \n",
        "> ‚ùå –ú–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–æ—Ç–µ—Ä–µ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "### b) –ö–∞–ø–ø–∏–Ω–≥ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π)\n",
        "\n",
        "–ú–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –≤–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è.\n",
        "\n",
        "```python\n",
        "df['Age'] = np.where(df['Age'] > upper_bound, upper_bound, df['Age'])\n",
        "df['Age'] = np.where(df['Age'] < lower_bound, lower_bound, df['Age'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—ä—ë–º –≤—ã–±–æ—Ä–∫–∏.  \n",
        "> ‚ùå –ú–æ–∂–µ—Ç –∏—Å–∫–∞–∑–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ.\n",
        "\n",
        "\n",
        "\n",
        "### c) –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å—Ç–µ–ø–µ–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è)\n",
        "\n",
        "–î–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤–ª–∏—è–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Å–∫–æ—à–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.\n",
        "\n",
        "#### –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ:\n",
        "\n",
        "```python\n",
        "df['Log_Age'] = np.log(df['Age'] + 1)  # +1 —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å log(0)\n",
        "```\n",
        "\n",
        "#### Box-Cox –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ:\n",
        "\n",
        "```python\n",
        "from scipy.stats import boxcox\n",
        "df['Transformed_Age'], lambda_val = boxcox(df['Age'] + 1)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π, —Ç—Ä–µ–±—É—é—â–∏—Ö –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "\n",
        "\n",
        "### d) –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º\n",
        "\n",
        "–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–µ–Ω–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –∫ –≤—ã–±—Ä–æ—Å–∞–º:\n",
        "\n",
        "- **–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π**\n",
        "- **–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å**\n",
        "- **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ (XGBoost, LightGBM, CatBoost)**\n",
        "\n",
        "> ‚úÖ –ù–µ —Ç–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ, —ç–∫–æ–Ω–æ–º–∏–º –≤—Ä–µ–º—è.  \n",
        "> ‚ùå –í—ã–±—Ä–æ—Å—ã –≤—Å—ë –µ—â—ë –º–æ–≥—É—Ç –≤–ª–∏—è—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∞–Ω—Å–∞–º–±–ª—è—Ö.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ —Ä–∞–±–æ—Ç—ã —Å –≤—ã–±—Ä–æ—Å–∞–º–∏?\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |\n",
        "|------|---------------------|---------------|-------------|\n",
        "| –£–¥–∞–ª–µ–Ω–∏–µ | –ï—Å–ª–∏ –≤—ã–±—Ä–æ—Å—ã ‚Äî –æ—à–∏–±–∫–∏ –∏ –∏—Ö –º–∞–ª–æ | –ü—Ä–æ—Å—Ç–æ—Ç–∞ | –ü–æ—Ç–µ—Ä—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ |\n",
        "| –ö–∞–ø–ø–∏–Ω–≥ | –ï—Å–ª–∏ –≤—ã–±—Ä–æ—Å—ã –≤–æ–∑–º–æ–∂–Ω—ã, –Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã | –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å | –ò—Å–∫–∞–∂–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ |\n",
        "| –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ | –ü—Ä–∏ —Å–∫–æ—à–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ | –£–º–µ–Ω—å—à–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π | –¢—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ |\n",
        "| –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ | –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º | –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏ | –†–∏—Å–∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è |\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã —Å –≤—ã–±—Ä–æ—Å–∞–º–∏\n",
        "\n",
        "1. **–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ** –¥–∞–Ω–Ω—ã–µ (boxplot, –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞, scatter plot).\n",
        "2. **–û–±–Ω–∞—Ä—É–∂—å—Ç–µ** –≤—ã–±—Ä–æ—Å—ã —Å –ø–æ–º–æ—â—å—é —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤ (IQR, Z-score).\n",
        "3. **–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ** –∫–æ–Ω—Ç–µ–∫—Å—Ç: –æ—à–∏–±–∫–∞ –∏–ª–∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å?\n",
        "4. **–ü—Ä–∏–º–µ–Ω–∏—Ç–µ** –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–µ—Ç–æ–¥:\n",
        "   - –£–¥–∞–ª–µ–Ω–∏–µ,\n",
        "   - –ö–∞–ø–ø–∏–Ω–≥,\n",
        "   - –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è,\n",
        "   - –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ.\n",
        "5. **–û—Ü–µ–Ω–∏—Ç–µ** –≤–ª–∏—è–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ –º–æ–¥–µ–ª—å –∏–ª–∏ –∞–Ω–∞–ª–∏–∑.\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π —á–∏—Å–ª–æ–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Boston House Prices](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)).\n",
        "2. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (boxplot, –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞, scatter plot) –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤.\n",
        "3. –û–±–Ω–∞—Ä—É–∂—å—Ç–µ –≤—ã–±—Ä–æ—Å—ã —Å –ø–æ–º–æ—â—å—é IQR –∏ Z-score.\n",
        "4. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã:\n",
        "   - –£–¥–∞–ª–µ–Ω–∏–µ;\n",
        "   - –ö–∞–ø–ø–∏–Ω–≥;\n",
        "   - –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ.\n",
        "5. –°—Ä–∞–≤–Ω–∏—Ç–µ, –∫–∞–∫ —ç—Ç–∏ –º–µ—Ç–æ–¥—ã –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n"
      ],
      "metadata": {
        "id": "4ynBvxwMS-cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 4. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Categorical Encoding)\n",
        "\n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Äî —ç—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∏–º–∞—é—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: `['Male', 'Female']`, `['Red', 'Green', 'Blue']`).\n",
        "\n",
        "–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–µ –º–æ–≥—É—Ç –Ω–∞–ø—Ä—è–º—É—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ—ç—Ç–æ–º—É –∏—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **–∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å** –≤ —á–∏—Å–ª–æ–≤–æ–º –≤–∏–¥–µ.\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –¢–∏–ø—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "| –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä |\n",
        "|-----|----------|--------|\n",
        "| **–ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–µ (Nominal)** | –ù–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ | –ü–æ–ª (`Male`, `Female`), –¶–≤–µ—Ç (`Red`, `Blue`) |\n",
        "| **–û—Ä–¥–∏–Ω–∞–ª—å–Ω—ã–µ (Ordinal)** | –ï—Å—Ç—å —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ—Å—Ç—å | –£—Ä–æ–≤–µ–Ω—å —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏ (`Low`, `Medium`, `High`), –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (`High School`, `Bachelor`, `Master`, `PhD`) |\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ó–∞–¥–∞—á–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "–¶–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
        "- –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —á–∏—Å–ª–∞.\n",
        "- –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–ª–∏—á–∏—è—Ö –∏ –≤–∑–∞–∏–º–æ—Å–≤—è–∑—è—Ö –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏.\n",
        "- –ò–∑–±–µ–∂–∞—Ç—å –ª–æ–∂–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø–æ—Ä—è–¥–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ –¥—É–º–∞–ª–∞, —á—Ç–æ `1 < 2 < 3` –¥–ª—è –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö).\n",
        "\n",
        "\n",
        "\n",
        "## üî¢ –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "### 1. **One-Hot Encoding**\n",
        "\n",
        "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–∏–Ω–∞—Ä–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü (0 –∏–ª–∏ 1), —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞–ª–∏—á–∏–µ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "| Original | A | B | C |\n",
        "|----------|---|---|---|\n",
        "| A        | 1 | 0 | 0 |\n",
        "| B        | 0 | 1 | 0 |\n",
        "| C        | 0 | 0 | 1 |\n",
        "\n",
        "```python\n",
        "pd.get_dummies(df, columns=['Category'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ù–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫;\n",
        "- –ü—Ä–æ—Å—Ç–æ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –°–æ–∑–¥–∞—ë—Ç –º–Ω–æ–≥–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (curse of dimensionality);\n",
        "- –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –≤—ã—Å–æ–∫–æ–π –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Label Encoding**\n",
        "\n",
        "–ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –∫–∞–∂–¥–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ n_classes - 1.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "| Original | Encoded |\n",
        "|----------|---------|\n",
        "| Red      | 0       |\n",
        "| Green    | 1       |\n",
        "| Blue     | 2       |\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Encoded'] = le.fit_transform(df['Color'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏;\n",
        "- –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –æ—à–∏–±–æ—á–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —á–∏—Å–ª–∞ –∫–∞–∫ –ø–æ—Ä—è–¥–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è;\n",
        "- –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "\n",
        "\n",
        "### 3. **Ordinal Encoding**\n",
        "\n",
        "–ê–Ω–∞–ª–æ–≥–∏—á–µ–Ω Label Encoding, –Ω–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —è–≤–Ω–æ –∑–∞–¥–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "| Original | Encoded |\n",
        "|----------|---------|\n",
        "| Low      | 0       |\n",
        "| Medium   | 1       |\n",
        "| High     | 2       |\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
        "df['Encoded'] = encoder.fit_transform(df[['Rating']])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫;\n",
        "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ä–¥–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Target Encoding / Mean Encoding**\n",
        "\n",
        "–ó–∞–º–µ–Ω—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "–î–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π `Churn` (0/1):\n",
        "\n",
        "| City       | Churn_mean |\n",
        "|------------|------------|\n",
        "| Moscow     | 0.35       |\n",
        "| Saint-Petersburg | 0.28 |\n",
        "| Kazan      | 0.42       |\n",
        "\n",
        "```python\n",
        "from category_encoders import TargetEncoder\n",
        "te = TargetEncoder()\n",
        "df['City_encoded'] = te.fit_transform(df['City'], df['Churn'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –†–∞–±–æ—Ç–∞–µ—Ç —Å –≤—ã—Å–æ–∫–æ–π –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é;\n",
        "- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –ú–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (–æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö);\n",
        "- –¢—Ä–µ–±—É–µ—Ç –∑–∞—â–∏—Ç—ã –æ—Ç data leakage (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ).\n",
        "\n",
        "\n",
        "\n",
        "### 5. **Frequency Encoding**\n",
        "\n",
        "–ö–∞–∂–¥–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–º–µ–Ω—è–µ—Ç—Å—è —á–∞—Å—Ç–æ—Ç–æ–π –µ—ë –ø–æ—è–≤–ª–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "| City       | Frequency |\n",
        "|------------|-----------|\n",
        "| Moscow     | 0.4       |\n",
        "| Saint-Petersburg | 0.3 |\n",
        "| Kazan      | 0.3       |\n",
        "\n",
        "```python\n",
        "freq = df['City'].value_counts(normalize=True)\n",
        "df['City_freq'] = df['City'].map(freq)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ü—Ä–æ—Å—Ç–æ—Ç–∞;\n",
        "- –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∫–æ–≥–¥–∞ —á–∞—Å—Ç–æ—Ç–∞ —Å–≤—è–∑–∞–Ω–∞ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –ú–æ–∂–µ—Ç –±—ã—Ç—å —à—É–º–Ω—ã–º;\n",
        "- –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–≤—è–∑—å —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–∞–ø—Ä—è–º—É—é.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Binary Encoding**\n",
        "\n",
        "–°–Ω–∞—á–∞–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–¥–∏—Ä—É—é—Ç—Å—è —á–∏—Å–ª–∞–º–∏ (–∫–∞–∫ –≤ Label Encoding), –∑–∞—Ç–µ–º —ç—Ç–∏ —á–∏—Å–ª–∞ –ø–µ—Ä–µ–≤–æ–¥—è—Ç—Å—è –≤ –¥–≤–æ–∏—á–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∏ —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ –±–∏—Ç—ã.\n",
        "\n",
        "```python\n",
        "from category_encoders import BinaryEncoder\n",
        "be = BinaryEncoder()\n",
        "df_binary = be.fit_transform(df['City'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ú–µ–Ω—å—à–µ –∫–æ–ª–æ–Ω–æ–∫, —á–µ–º One-Hot;\n",
        "- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —á–∞—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –°–ª–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π;\n",
        "- –ú–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π, —á–µ–º Target Encoding.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Hashing Encoding (Feature Hashing)**\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ö—ç—à-—Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∏—Å–µ–ª (–æ–±—ã—á–Ω–æ –º–µ–Ω—å—à–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —á–∏—Å–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π).\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "hasher = FeatureHasher(n_features=4, input_type='string')\n",
        "hashed_features = hasher.transform(df['City'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π;\n",
        "- –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –í–æ–∑–º–æ–∂–Ω—ã –∫–æ–ª–ª–∏–∑–∏–∏ (—Ä–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–ª—É—á–∞—é—Ç –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ö—ç—à);\n",
        "- –ü–æ—Ç–µ—Ä—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Leave-One-Out Encoding**\n",
        "\n",
        "–ü–æ—Ö–æ–∂ –Ω–∞ Target Encoding, –Ω–æ –ø—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Å–∞–º–∞ —ç—Ç–∞ —Å—Ç—Ä–æ–∫–∞ (–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö).\n",
        "\n",
        "```python\n",
        "from category_encoders import LeaveOneOutEncoder\n",
        "looe = LeaveOneOutEncoder()\n",
        "df_loo = looe.fit_transform(df['City'], df['Churn'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ó–∞—â–∏—â–µ–Ω–æ –æ—Ç data leakage;\n",
        "- –í—ã—Å–æ–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **James-Stein Encoder**\n",
        "\n",
        "–û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ –®—Ç–µ–π–Ω–∞ ‚Äî —Å–≥–ª–∞–∂–∏–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ –≥—Ä—É–ø–ø–∞–º, \"—Å—Ö–ª–æ–ø—ã–≤–∞—è\" –∏—Ö –∫ –æ–±—â–µ–º—É —Å—Ä–µ–¥–Ω–µ–º—É.\n",
        "\n",
        "```python\n",
        "from category_encoders import JamesSteinEncoder\n",
        "jse = JamesSteinEncoder()\n",
        "df_jse = jse.fit_transform(df['City'], df['Churn'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –°–Ω–∏–∂–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ —à—É–º–∞ –≤ —Ä–µ–¥–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö;\n",
        "- –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞–ª—ã–º–∏ –≤—ã–±–æ—Ä–∫–∞–º–∏.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –°–ª–æ–∂–Ω–µ–µ –≤ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **M-Estimator Encoding**\n",
        "\n",
        "–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Target Encoding, –≥–¥–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π, —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å —É—á–µ—Ç–æ–º –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
        "\n",
        "```python\n",
        "from category_encoders import MEstimateEncoder\n",
        "mee = MEstimateEncoder(m=10)  # m ‚Äî –≤–µ—Å –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
        "df_mee = mee.fit_transform(df['City'], df['Churn'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –æ–±—â–µ–π —Å—Ä–µ–¥–Ω–µ–π –∏ —Å—Ä–µ–¥–Ω–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏;\n",
        "- –£—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `m`.\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **Helmert Encoding**\n",
        "\n",
        "–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —É—Ä–æ–≤–Ω–∏ —Ñ–∞–∫—Ç–æ—Ä–∞ —Å **—Å—Ä–µ–¥–Ω–∏–º –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —É—Ä–æ–≤–Ω–µ–π** (Reverse Helmert ‚Äî –Ω–∞–æ–±–æ—Ä–æ—Ç).\n",
        "\n",
        "```python\n",
        "from category_encoders import HelmertEncoder\n",
        "he = HelmertEncoder()\n",
        "df_he = he.fit_transform(df['Education'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ ANOVA –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –¢—Ä–µ–±—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π;\n",
        "- –†–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ ML.\n",
        "\n",
        "---\n",
        "\n",
        "### 12. **Polynomial Encoding**\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–º–µ–µ—Ç **–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Ä–∏—Ä–æ–¥—É** –∏ –º–æ–∂–Ω–æ –ø—Ä–∏–≤—è–∑–∞—Ç—å –µ—ë –∫ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏—è–º (–ª–∏–Ω–µ–π–Ω—ã–π, –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ã–π —Ç—Ä–µ–Ω–¥ –∏ —Ç.–¥.).\n",
        "\n",
        "```python\n",
        "from category_encoders import PolynomialEncoder\n",
        "pe = PolynomialEncoder()\n",
        "df_pe = pe.fit_transform(df['Education'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –£—á–∏—Ç—ã–≤–∞–µ—Ç —á–∏—Å–ª–æ–≤—É—é –ø—Ä–∏—Ä–æ–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏–π.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –†–µ–¥–∫–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤ –ø—Ä–∞–∫—Ç–∏–∫–µ ML.\n",
        "\n",
        "---\n",
        "\n",
        "### 13. **Sum (Deviation) Encoding**\n",
        "\n",
        "–ö–∞–∂–¥—ã–π —É—Ä–æ–≤–µ–Ω—å –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º –æ—Ç –æ–±—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.\n",
        "\n",
        "```python\n",
        "from category_encoders import SumEncoder\n",
        "se = SumEncoder()\n",
        "df_se = se.fit_transform(df['City'], df['Churn'])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –°–ª–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π;\n",
        "- –†–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.\n",
        "\n",
        "---\n",
        "\n",
        "### 14. **CatBoost Encoding**\n",
        "\n",
        "–†–µ–∞–ª–∏–∑–∞—Ü–∏—è Target Encoding —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Å–∞–º–æ–≥–æ CatBoost.\n",
        "\n",
        "```python\n",
        "from catboost import CatBoostClassifier\n",
        "model = CatBoostClassifier()\n",
        "model.fit(X_train, y_train, cat_features=[0, 1, 2])  # –ò–Ω–¥–µ–∫—Å—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É—Ç–µ—á–∫–∏;\n",
        "- –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å CatBoost.\n",
        "\n",
        "---\n",
        "\n",
        "### 15. **Entity Embeddings (–¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π)**\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏: –∫–∞–∂–¥–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–æ–º –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö —á–∏—Å–µ–ª (—ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º), –∫–æ—Ç–æ—Ä—ã–π –æ–±—É—á–∞–µ—Ç—Å—è –≤–º–µ—Å—Ç–µ —Å –º–æ–¥–µ–ª—å—é.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(1,))\n",
        "embedding = Embedding(input_dim=len(unique_categories), output_dim=embedding_dim)(inputs)\n",
        "flattened = Flatten()(embedding)\n",
        "output = Dense(1)(flattened)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–ª—é—Å—ã:\n",
        "- –õ–æ–≤–∏—Ç —Å–ª–æ–∂–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏;\n",
        "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π.\n",
        "\n",
        "> ‚ùå –ú–∏–Ω—É—Å—ã:\n",
        "- –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö;\n",
        "- –°–ª–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π;\n",
        "- –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç–æ–¥–æ–≤\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –î–ª—è –∫–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö | –ü–æ—Ä—è–¥–æ–∫ | –£—á–µ—Ç —Ü–µ–ª–µ–≤–æ–π | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |\n",
        "|-------|------------------|---------|--------------|---------------|-------------|\n",
        "| One-Hot | –ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–µ | ‚ùå | ‚ùå | –ü—Ä–æ—Å—Ç–æ—Ç–∞ | –ë–æ–ª—å—à–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å |\n",
        "| Label | –ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–µ | ‚ùå | ‚ùå | –ü—Ä–æ—Å—Ç–æ—Ç–∞ | –õ–æ–∂–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ |\n",
        "| Ordinal | –û—Ä–¥–∏–Ω–∞–ª—å–Ω—ã–µ | ‚úÖ | ‚ùå | –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ | –¢–æ–ª—å–∫–æ –¥–ª—è –æ—Ä–¥–∏–Ω–∞–ª—å–Ω—ã—Ö |\n",
        "| Target | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –í—ã—Å–æ–∫–∞—è –º–æ—â–Ω–æ—Å—Ç—å | Risk overfitting |\n",
        "| Frequency | –õ—é–±—ã–µ | ‚ùå | ‚ùå | –ü—Ä–æ—Å—Ç–æ—Ç–∞ | –°–ª–∞–±–∞—è —Å–≤—è–∑—å —Å —Ü–µ–ª–µ–≤–æ–π |\n",
        "| Binary | –õ—é–±—ã–µ | ‚ùå | ‚ùå | –ú–µ–Ω—å—à–µ –∫–æ–ª–æ–Ω–æ–∫ | –ú–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π |\n",
        "| Hashing | –õ—é–±—ã–µ | ‚ùå | ‚ùå | –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å | –ö–æ–ª–ª–∏–∑–∏–∏ |\n",
        "| Leave-One-Out | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –ë–µ–∑ —É—Ç–µ—á–∫–∏ | –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ç—Ä–∞—Ç–Ω–æ |\n",
        "| James-Stein | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ | –°–ª–æ–∂–Ω–æ—Å—Ç—å |\n",
        "| M-Estimator | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –ë–∞–ª–∞–Ω—Å | –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ |\n",
        "| Helmert | –û—Ä–¥–∏–Ω–∞–ª—å–Ω—ã–µ | ‚úÖ | ‚ùå | –î–ª—è ANOVA | –†–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è |\n",
        "| Polynomial | –û—Ä–¥–∏–Ω–∞–ª—å–Ω—ã–µ | ‚úÖ | ‚ùå | –£—á–∏—Ç—ã–≤–∞–µ—Ç —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å | –†–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è |\n",
        "| Sum | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è | –°–ª–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å |\n",
        "| CatBoost | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π | –¢–æ–ª—å–∫–æ –≤ CatBoost |\n",
        "| Entity Embedding | –õ—é–±—ã–µ | ‚ùå | ‚úÖ | –ì–ª—É–±–æ–∫–∏–µ —Å–≤—è–∑–∏ | –¢–æ–ª—å–∫–æ –≤ DL |\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–µ—Ç–æ–¥–∞\n",
        "\n",
        "\n",
        "\n",
        "## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å —Ñ–æ—Ä–º—É–ª–∞–º–∏ –∏ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –§–æ—Ä–º—É–ª–∞ | –û–±–æ–∑–Ω–∞—á–µ–Ω–∏—è |\n",
        "|-------|---------|-------------|\n",
        "| **One-Hot Encoding** | $ x_i^{(k)} = \\begin{cases} 1, & x_i = c_k \\\\ 0, & \\text{–∏–Ω–∞—á–µ} \\end{cases} $ | $ x_i $ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —É i-–≥–æ –æ–±—ä–µ–∫—Ç–∞; $ c_k $ ‚Äî k-—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è; $ x_i^{(k)} $ ‚Äî –Ω–æ–≤–æ–µ –±–∏–Ω–∞—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ |\n",
        "| **Label Encoding** | $ x_{\\text{encoded}} = \\text{rank}(x_i) $ | –ö–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä (—Ü–µ–ª–æ–µ —á–∏—Å–ª–æ) |\n",
        "| **Ordinal Encoding** | $ x_{\\text{encoded}} = f(c_1) < f(c_2) < \\dots < f(c_K) $ | $ f(\\cdot) $ ‚Äî –∑–∞–¥–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ–≤–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π |\n",
        "| **Target / Mean Encoding** | $ x_{\\text{encoded}}(c_k) = \\frac{\\sum y_i \\cdot \\mathbb{I}(x_i = c_k)}{\\sum \\mathbb{I}(x_i = c_k)} $ | $ y_i $ ‚Äî —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è; $ \\mathbb{I}(\\cdot) $ ‚Äî –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ |\n",
        "| **Frequency Encoding** | $ x_{\\text{encoded}}(c_k) = \\frac{\\#\\{x_i = c_k\\}}{n} $ | $ n $ ‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π |\n",
        "| **Binary Encoding** | $ x_{\\text{binary}} = \\text{binarize}(\\text{label\\_encode}(x_i)) $ | –°–Ω–∞—á–∞–ª–∞ Label Encoding, –∑–∞—Ç–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –±–∏–Ω–∞—Ä–Ω—É—é —Ñ–æ—Ä–º—É –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –±–∏—Ç—ã |\n",
        "| **Hashing Encoding** | $ x_{\\text{hashed}} = h(x_i) \\mod N $ | $ h(\\cdot) $ ‚Äî —Ö—ç—à-—Ñ—É–Ω–∫—Ü–∏—è; $ N $ ‚Äî —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ |\n",
        "| **Leave-One-Out Encoding** | $ x_{\\text{loo}}(c_k) = \\frac{\\sum_{j \\neq i} y_j \\cdot \\mathbb{I}(x_j = c_k)}{\\sum_{j \\neq i} \\mathbb{I}(x_j = c_k)} $ | –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —Å—Ä–µ–¥–Ω–µ–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –±–µ–∑ –Ω–µ–≥–æ |\n",
        "| **James-Stein Encoder** | $ x_{\\text{JS}}(c_k) = w_k \\cdot \\mu_k + (1 - w_k) \\cdot \\mu_{\\text{global}} $ | $ \\mu_k $ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ —Ç–∞—Ä–≥–µ—Ç–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏; $ \\mu_{\\text{global}} $ ‚Äî –æ–±—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ; $ w_k = \\frac{n_k}{n_k + m} $ |\n",
        "| **M-Estimator Encoding** | $ x_{\\text{ME}}(c_k) = \\frac{n_k \\cdot \\mu_k + m \\cdot \\mu_{\\text{global}}}{n_k + m} $ | $ n_k $ ‚Äî –∫–æ–ª-–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏; $ m $ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ |\n",
        "| **Helmert Encoding** | $ x_{\\text{helmert}}(c_k) = \\bar{y}_k - \\frac{1}{k - 1} \\sum_{j=1}^{k - 1} \\bar{y}_j $ | –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ —Å—Ä–µ–¥–Ω–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö |\n",
        "| **Polynomial Encoding** | $ x_{\\text{poly}} = [P_1(z_k), ..., P_d(z_k)] $ | $ z_k $ ‚Äî —á–∏—Å–ª–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–Ω–≥); $ P_d $ ‚Äî –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª–∏–Ω–æ–º—ã |\n",
        "| **Sum Encoding (Deviation)** | $ x_{\\text{sum}}(c_k) = \\mu_k - \\mu_{\\text{global}} $ | –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç –æ–±—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è |\n",
        "| **CatBoost Encoding** | $ x_{\\text{catboost}}(c_k) = \\frac{\\sum_{i \\in S_{<t}} y_i}{|S_{<t}|} $ | $ S_{<t} $ ‚Äî –¥–∞–Ω–Ω—ã–µ, –Ω–∞–±–ª—é–¥–∞–≤—à–∏–µ—Å—è –¥–æ —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è (–¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏) |\n",
        "| **Entity Embedding** | $ x_{\\text{embedding}}(c_k) = v_k \\in \\mathbb{R}^d $ | $ v_k $ ‚Äî –æ–±—É—á–∞–µ–º—ã–π d-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ $ c_k $ |\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–µ—Ç–æ–¥–∞\n",
        "\n",
        "| –ó–∞–¥–∞—á–∞ / –ö–æ–Ω—Ç–µ–∫—Å—Ç | –ü–æ–¥—Ö–æ–¥—è—â–∏–µ –º–µ—Ç–æ–¥—ã |\n",
        "|-------------------|------------------|\n",
        "| –ù–∞—É—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞ / —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ | M-Estimator, James-Stein, Target Encoding |\n",
        "| –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å –≤–∞–∂–Ω–∞ | One-Hot, Ordinal, Frequency Encoding |\n",
        "| –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ / –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ | Entity Embeddings |\n",
        "| –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ / –º–Ω–æ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π | Target Encoding, Hashing Encoding, CatBoost Encoding |\n",
        "| –î–µ—Ä–µ–≤—å—è / –∞–Ω—Å–∞–º–±–ª–∏ | Label/Ordinal Encoding, Target Encoding, CatBoost Encoding |\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Titanic](https://www.kaggle.com/c/titanic/data)).\n",
        "2. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
        "   - One-Hot Encoding\n",
        "   - Label Encoding\n",
        "   - Target Encoding\n",
        "   - CatBoost Encoding\n",
        "   - Binary Encoding\n",
        "3. –û–±—É—á–∏—Ç–µ –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, LogisticRegression –∏–ª–∏ RandomForest).\n",
        "4. –°—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–π.\n"
      ],
      "metadata": {
        "id": "l6fZAJ-HVfwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 5. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Scaling)\n",
        "\n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Scaling)** ‚Äî —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫ –æ–¥–Ω–æ–º—É –º–∞—Å—à—Ç–∞–±—É. –≠—Ç–æ –≤–∞–∂–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ **–º–Ω–æ–≥–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –∫ —Ä–∞–∑–Ω–∏—Ü–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏**, –æ—Å–æ–±–µ–Ω–Ω–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç **—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã**.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏?\n",
        "\n",
        "1. **–£—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ**: –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –º–µ—Ç–æ–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞.\n",
        "2. **–ü–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏**: –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º –º–∞—Å—à—Ç–∞–±–æ–º.\n",
        "3. **–£–ª—É—á—à–∞–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å**: –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö.\n",
        "4. **–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤**, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
        "   - KNN\n",
        "   - SVM\n",
        "   - –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π\n",
        "   - –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥ (—á–∞—Å—Ç–∏—á–Ω–æ)\n",
        "   - PCA\n",
        "   - –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n",
        "\n",
        "---\n",
        "\n",
        "## üìà –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º | –î–∏–∞–ø–∞–∑–æ–Ω | –§–æ—Ä–º—É–ª–∞ |\n",
        "|-------|--------------------------|----------|---------|\n",
        "| Standardization (Z-score) | ‚úÖ –î–∞ | $ (-\\infty, +\\infty) $ | $ z = \\frac{x - \\mu}{\\sigma} $ |\n",
        "| Min-Max Normalization | ‚úÖ –î–∞ | $ [0, 1] $ | $ x' = \\frac{x - x_{min}}{x_{max} - x_{min}} $ |\n",
        "| Robust Scaler | ‚ùå –ù–µ—Ç | $ [-1, 1] $ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) | $ x' = \\frac{x - Q_2}{Q_3 - Q_1} $ |\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤\n",
        "\n",
        "\n",
        "\n",
        "### 1. **Standardization (Z-score scaling)**\n",
        "\n",
        "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –∏–º–µ–ª–∏ **–Ω—É–ª–µ–≤–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏ –µ–¥–∏–Ω–∏—á–Ω–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ**.\n",
        "\n",
        "### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "z = \\frac{x - \\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "–ì–¥–µ:\n",
        "- $ x $ ‚Äî –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ;\n",
        "- $ \\mu $ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É:  \n",
        "  $$ \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n",
        "- $ \\sigma $ ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ:  \n",
        "  $$ \\sigma = \\sqrt{\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\mu)^2} $$\n",
        "\n",
        "> ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: —Å—Ä–µ–¥–Ω–µ–µ = 0, –¥–∏—Å–ø–µ—Ä—Å–∏—è = 1.\n",
        "\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n",
        "- –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã;\n",
        "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è).\n",
        "\n",
        "> ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:\n",
        "- –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º (–∏–∑-–∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏).\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Min-Max Normalization**\n",
        "\n",
        "–ü—Ä–∏–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É **[0, 1]**.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "x' = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
        "$$\n",
        "\n",
        "–ì–¥–µ:\n",
        "- $ x_{min} $ ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É;\n",
        "- $ x_{max} $ ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É.\n",
        "\n",
        "> ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –ª–µ–∂–∞—Ç –º–µ–∂–¥—É 0 –∏ 1.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n",
        "- –í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –ª–µ–≥–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É—é—Ç—Å—è;\n",
        "- –ü–æ–ª–µ–∑–Ω–æ, –∫–æ–≥–¥–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã –≥—Ä–∞–Ω–∏—Ü—ã –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑–º–µ—Ä–µ–Ω–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –æ—Ç 0 –¥–æ 100¬∞C).\n",
        "\n",
        "> ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:\n",
        "- –¢–∞–∫–∂–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º;\n",
        "- –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–æ—Ä–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Robust Scaling (—É—Å—Ç–æ–π—á–∏–≤—ã–π –∫ –≤—ã–±—Ä–æ—Å–∞–º)**\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–¥–∏–∞–Ω—É –∏ –º–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö (IQR), –ø–æ—ç—Ç–æ–º—É —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "x' = \\frac{x - Q_2}{Q_3 - Q_1}\n",
        "$$\n",
        "\n",
        "–ì–¥–µ:\n",
        "- $ Q_2 $ ‚Äî –º–µ–¥–∏–∞–Ω–∞ (50-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å);\n",
        "- $ Q_3 $ ‚Äî 75-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å;\n",
        "- $ Q_1 $ ‚Äî 25-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å;\n",
        "- $ IQR = Q_3 - Q_1 $\n",
        "\n",
        "> ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: –¥–∞–Ω–Ω—ã–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –æ–∫–æ–ª–æ –º–µ–¥–∏–∞–Ω—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –ø–æ IQR.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n",
        "- –£—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º;\n",
        "- –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ç—è–∂—ë–ª—ã–µ —Ö–≤–æ—Å—Ç—ã –∏–ª–∏ –∞–Ω–æ–º–∞–ª–∏–∏.\n",
        "\n",
        "> ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:\n",
        "- –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è;\n",
        "- –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—É–¥–æ–±–µ–Ω, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω, –Ω–∞–ø—Ä–∏–º–µ—Ä [0, 1].\n",
        "\n",
        "\n",
        "\n",
        "## üß© –î—Ä—É–≥–∏–µ –ø–æ–ª–µ–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã\n",
        "\n",
        "–•–æ—Ç—è –æ–Ω–∏ –Ω–µ –≤—Å–µ–≥–¥–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º—É \"–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é\", –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
        "\n",
        "### a) **Max Absolute Scaling**\n",
        "\n",
        "–ü—Ä–∏–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É **[-1, 1]**, –¥–µ–ª—è –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ –º–∞–∫—Å–∏–º—É–º –ø–æ –º–æ–¥—É–ª—é.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "x' = \\frac{x}{|x_{max}|}\n",
        "$$\n",
        "\n",
        "–ì–¥–µ:\n",
        "- $ x_{max} $ ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –º–æ–¥—É–ª—é:  \n",
        "  $$ |x_{max}| = \\max(|x_1|, |x_2|, ..., |x_n|) $$\n",
        "\n",
        "> ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –∑–Ω–∞–∫.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "scaler = MaxAbsScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### b) **Quantile Transformer / Rank Transformation**\n",
        "\n",
        "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ –∏–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Ä–∞–Ω–≥–∞—Ö.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞ (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ):\n",
        "$$\n",
        "x'_i = \\frac{\\text{rank}(x_i)}{n}\n",
        "$$\n",
        "\n",
        "–ì–¥–µ:\n",
        "- $ \\text{rank}(x_i) $ ‚Äî –ø–æ–∑–∏—Ü–∏—è $ x_i $ –≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Å–ø–∏—Å–∫–µ –∑–Ω–∞—á–µ–Ω–∏–π;\n",
        "- $ n $ ‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π.\n",
        "\n",
        "–ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å –ø–æ–º–æ—â—å—é –æ–±—Ä–∞—Ç–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–æ–∫:\n",
        "$$\n",
        "x'_i = \\Phi^{-1}\\left(\\frac{\\text{rank}(x_i)}{n + 1}\\right)\n",
        "$$\n",
        "\n",
        "–ì–¥–µ $ \\Phi^{-1} $ ‚Äî –æ–±—Ä–∞—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
        "\n",
        "> ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: –∑–Ω–∞—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—Ç –∑–∞–¥–∞–Ω–Ω–æ–º—É –∑–∞–∫–æ–Ω—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "scaler = QuantileTransformer(output_distribution='normal')\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –Ω–µ–≥–ª–∞–¥–∫–∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.\n",
        "\n",
        "\n",
        "\n",
        "### c) **Power Transformer (Yeo-Johnson, Box-Cox)**\n",
        "\n",
        "\n",
        "–ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–ª—è –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É.\n",
        "\n",
        "#### a) **Box-Cox Transformation** (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π):\n",
        "\n",
        "##### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "x' =\n",
        "\\begin{cases}\n",
        "\\frac{x^\\lambda - 1}{\\lambda}, & \\text{–µ—Å–ª–∏ } \\lambda \\neq 0 \\\\\n",
        "\\ln(x), & \\text{–µ—Å–ª–∏ } \\lambda = 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "#### b) **Yeo-Johnson Transformation** (—Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –ª—é–±—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –≤–∫–ª—é—á–∞—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ):\n",
        "\n",
        "##### –§–æ—Ä–º—É–ª–∞:\n",
        "\n",
        "$$\n",
        "x' =\n",
        "\\begin{cases}\n",
        "\\frac{(x + 1)^\\lambda - 1}{\\lambda}, & \\text{–µ—Å–ª–∏ } x \\geq 0, \\lambda \\neq 0 \\\\\n",
        "\\ln(x + 1), & \\text{–µ—Å–ª–∏ } x \\geq 0, \\lambda = 0 \\\\\n",
        "\\frac{(-x + 1)^{2 - \\lambda} - 1}{2 - \\lambda}, & \\text{–µ—Å–ª–∏ } x < 0, \\lambda \\neq 2 \\\\\n",
        "-\\ln(-x + 1), & \\text{–µ—Å–ª–∏ } x < 0, \\lambda = 2\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "> –ü–∞—Ä–∞–º–µ—Ç—Ä $ \\lambda $ –ø–æ–¥–±–∏—Ä–∞–µ—Ç—Å—è —Ç–∞–∫, —á—Ç–æ–±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞—Å–∏–º–º–µ—Ç—Ä–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ MLE).\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ 1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `PowerTransformer`\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "import numpy as np\n",
        "\n",
        "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
        "np.random.seed(42)\n",
        "data = np.random.exponential(scale=2.0, size=(1000, 1))\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä\n",
        "pt = PowerTransformer(method='yeo-johnson')  # –∏–ª–∏ 'box-cox'\n",
        "pt.fit(data)\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n",
        "transformed_data = pt.transform(data)\n",
        "\n",
        "print(\"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π Œª:\", pt.lambdas_)\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è `method='box-cox'` —Ç—Ä–µ–±—É–µ—Ç, —á—Ç–æ–±—ã –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ **—Å—Ç—Ä–æ–≥–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏**, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `scipy.stats.boxcox`\n",
        "\n",
        "–ï—Å–ª–∏ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –∏–º–µ–Ω–Ω–æ **Box-Cox** –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ:\n",
        "\n",
        "```python\n",
        "from scipy.stats import boxcox\n",
        "import numpy as np\n",
        "\n",
        "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
        "np.random.seed(42)\n",
        "data = np.random.exponential(scale=2.0, size=1000)\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º Box-Cox\n",
        "transformed_data, lambda_ = boxcox(data)\n",
        "\n",
        "print(\"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π Œª:\", lambda_)\n",
        "```\n",
        "\n",
        "> üìå –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å **–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏**.\n",
        "\n",
        "\n",
        "\n",
        "## üß™ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ/–ø–æ—Å–ª–µ\n",
        "\n",
        "–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ –∏ –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('–î–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(transformed_data, bins=30, color='salmon', edgecolor='black')\n",
        "plt.title('–ü–æ—Å–ª–µ Yeo-Johnson')\n",
        "\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n",
        "\n",
        "- Box-Cox —Ä–∞–±–æ—Ç–∞–µ—Ç **—Ç–æ–ª—å–∫–æ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏**.\n",
        "- Yeo-Johnson ‚Äî **—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ —á–∏—Å–ª–∞–º–∏**, –≤–∫–ª—é—á–∞—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –Ω–æ–ª—å.\n",
        "\n",
        "\n",
        "## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –î–∏–∞–ø–∞–∑–æ–Ω | –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
        "|------|----------|--------------------------|---------------------|\n",
        "| Standardization | $ (-\\infty, +\\infty) $ | ‚ùå –ù–µ—Ç | –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, PCA, –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ |\n",
        "| Min-Max | $ [0, 1] $ | ‚ùå –ù–µ—Ç | –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è |\n",
        "| Robust | $ [-1, 1] $ | ‚úÖ –î–∞ | –í—ã–±—Ä–æ—Å—ã, IQR |\n",
        "| Max Abs | $ [-1, 1] $ | ‚ùå –ù–µ—Ç | –†–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ |\n",
        "| Quantile | –ó–∞–¥–∞—ë—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º | ‚úÖ –î–∞ | –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |\n",
        "| Power Transformer | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –º–µ—Ç–æ–¥–∞ | ‚úÖ –î–∞ | –°–∫–æ—à–µ–Ω–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è |\n",
        "\n",
        "\n",
        "\n",
        "## ü§ñ –ö–∞–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Ç—Ä–µ–±—É—é—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è?\n",
        "\n",
        "| –ê–ª–≥–æ—Ä–∏—Ç–º | –¢—Ä–µ–±—É–µ—Ç—Å—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ? | –ü—Ä–∏—á–∏–Ω–∞ |\n",
        "|----------|-----------------------------|---------|\n",
        "| KNN | ‚úÖ | –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ |\n",
        "| SVM | ‚úÖ | –ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π |\n",
        "| Logistic Regression (—Å L1/L2) | ‚úÖ | –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–∞—Å—à—Ç–∞–±–∞ |\n",
        "| Linear Regression (OLS) | ‚ùå | –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∞–¥–∞–ø—Ç–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ |\n",
        "| Decision Trees | ‚ùå | –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è |\n",
        "| Random Forest | ‚ùå | –ù–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ä–µ–≤—å–µ–≤ |\n",
        "| Gradient Boosting | ‚ùå | –ù–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ä–µ–≤—å–µ–≤ |\n",
        "| Neural Networks | ‚úÖ | –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ |\n",
        "| PCA | ‚úÖ | –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ |\n",
        "| Clustering (K-means –∏ –¥—Ä.) | ‚úÖ | –ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π |\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "\n",
        "1. **–†–∞–∑–¥–µ–ª–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏.**\n",
        "2. **–û–±—É—á–∏—Ç–µ scaler —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ** (`fit_transform`).\n",
        "3. **–ü—Ä–∏–º–µ–Ω–∏—Ç–µ –µ–≥–æ –∫ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ** (`transform`).\n",
        "4. **–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –¥–µ–ª–∞–π—Ç–µ `fit_transform` –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ ‚Äî —ç—Ç–æ –≤—ã–∑–æ–≤–µ—Ç **—É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö**.\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π —á–∏—Å–ª–æ–≤–æ–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Boston`, `Iris`, `Wine`).\n",
        "2. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: Standardization, Min-Max, Robust Scaling.\n"
      ],
      "metadata": {
        "id": "WvYi6NJeX6MQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 7. –†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞–º–∏ –∏ –≤—Ä–µ–º–µ–Ω–µ–º (Date and Time Feature Engineering)\n",
        "\n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "–í —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è **–ø—Ä–∏–∑–Ω–∞–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º**. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å:\n",
        "- –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞;\n",
        "- –î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏;\n",
        "- –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—Å–µ—â–µ–Ω–∏—è;\n",
        "- –ú–æ–º–µ–Ω—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏ —Ç.–¥.\n",
        "\n",
        "–≠—Ç–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫ (`str`) –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤, –ø–æ—ç—Ç–æ–º—É –∏—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ `datetime`-–æ–±—ä–µ–∫—Ç**, –∞ –∑–∞—Ç–µ–º ‚Äî **–∏–∑–≤–ª–µ—á—å –ø–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å.\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –≠—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞–º–∏ –∏ –≤—Ä–µ–º–µ–Ω–µ–º\n",
        "\n",
        "1. **–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ datetime-–æ–±—ä–µ–∫—Ç**\n",
        "2. **–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**\n",
        "3. **–†–∞–±–æ—Ç–∞ —Å —Ä–∞–∑–Ω–∏—Ü–µ–π –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏**\n",
        "4. **–û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏: –≤—ã—Ö–æ–¥–Ω—ã–µ, –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –∏ —Ç.–¥.**\n",
        "\n",
        "\n",
        "\n",
        "## 1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ datetime-–æ–±—ä–µ–∫—Ç\n",
        "\n",
        "–ß–∞—Å—Ç–æ –¥–∞—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏ (`str`). –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏—Ö –≤ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ `datetime`.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'date_str': ['2025-01-01', '2025-01-02', '2025-01-03']})\n",
        "df['date'] = pd.to_datetime(df['date_str'])\n",
        "```\n",
        "\n",
        "–ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –æ–Ω –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n",
        "\n",
        "```python\n",
        "df['date'] = pd.to_datetime(df['date_str'], format='%Y-%m-%d')\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è –ï—Å–ª–∏ –¥–∞—Ç–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä `errors='coerce'`, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å `NaT` (Not a Time) –≤–º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏:\n",
        "```python\n",
        "df['date'] = pd.to_datetime(df['date_str'], errors='coerce')\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏\n",
        "\n",
        "–ü–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ `datetime` –º–æ–∂–Ω–æ **–∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**, —Ç–∞–∫–∏–µ –∫–∞–∫ –≥–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å, —á–∞—Å –∏ –¥—Ä—É–≥–∏–µ.\n",
        "\n",
        "### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏:\n",
        "\n",
        "| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ |\n",
        "|----------|-------------|\n",
        "| –ì–æ–¥      | `df['date'].dt.year` |\n",
        "| –ú–µ—Å—è—Ü    | `df['date'].dt.month` |\n",
        "| –î–µ–Ω—å     | `df['date'].dt.day` |\n",
        "| –ß–∞—Å      | `df['date'].dt.hour` |\n",
        "| –ú–∏–Ω—É—Ç–∞   | `df['date'].dt.minute` |\n",
        "| –°–µ–∫—É–Ω–¥–∞  | `df['date'].dt.second` |\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "```python\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day'] = df['date'].dt.day\n",
        "df['hour'] = df['date'].dt.hour\n",
        "df['weekday'] = df['date'].dt.weekday  # 0=–ü–Ω, ..., 4=–ü—Ç, 5=–°–±, 6=–í—Å\n",
        "```\n",
        "\n",
        "\n",
        "### –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –∏ –≤—ã—Ö–æ–¥–Ω—ã–µ\n",
        "\n",
        "–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞–∂–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –∑–∞–¥–∞—á –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ø—Ä–æ—Å–∞, –ø—Ä–æ–¥–∞–∂, –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ç.–¥.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä: —Ñ–ª–∞–≥ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –¥–Ω—è\n",
        "\n",
        "```python\n",
        "df['is_weekend'] = df['date'].dt.weekday >= 5  # True - –≤—ã—Ö–æ–¥–Ω–æ–π\n",
        "```\n",
        "\n",
        "–ï—Å–ª–∏ –Ω—É–∂–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏—è –¥–Ω–µ–π:\n",
        "\n",
        "```python\n",
        "df['day_name'] = df['date'].dt.strftime('%A')  # Monday, Tuesday...\n",
        "```\n",
        "\n",
        "\n",
        "### –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã\n",
        "\n",
        "–ú–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å:\n",
        "- –ö–≤–∞—Ä—Ç–∞–ª –≥–æ–¥–∞;\n",
        "- –ù–æ–º–µ—Ä –Ω–µ–¥–µ–ª–∏;\n",
        "- –£—Ç—Ä–æ/–¥–µ–Ω—å/–≤–µ—á–µ—Ä;\n",
        "- –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å (–≤–µ—Å–Ω–∞, –ª–µ—Ç–æ...).\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "```python\n",
        "df['quarter'] = df['date'].dt.quarter\n",
        "df['week_of_year'] = df['date'].dt.isocalendar().week\n",
        "```\n",
        "\n",
        "#### –£—Ç—Ä–æ/–¥–µ–Ω—å/–≤–µ—á–µ—Ä:\n",
        "\n",
        "```python\n",
        "def time_of_day(hour):\n",
        "    if 5 <= hour < 12:\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 17:\n",
        "        return 'Afternoon'\n",
        "    elif 17 <= hour < 21:\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Night'\n",
        "\n",
        "df['time_of_day'] = df['hour'].apply(time_of_day)\n",
        "```\n",
        "\n",
        "\n",
        "## 3. –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏ (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)\n",
        "\n",
        "–û–¥–Ω–∏–º –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø—Ä–∏—ë–º–æ–≤ —è–≤–ª—è–µ—Ç—Å—è **–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü—ã** –º–µ–∂–¥—É –¥–≤—É–º—è –¥–∞—Ç–∞–º–∏.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä 1: –í–æ–∑—Ä–∞—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞\n",
        "\n",
        "```python\n",
        "from datetime import datetime\n",
        "\n",
        "df['birthdate'] = pd.to_datetime(df['birthdate'])\n",
        "current_date = datetime.now()\n",
        "df['age_days'] = (current_date - df['birthdate']).dt.days\n",
        "df['age_years'] = df['age_days'] / 365.25\n",
        "```\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä 2: –í—Ä–µ–º—è —Å –º–æ–º–µ–Ω—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\n",
        "\n",
        "```python\n",
        "df['registration_date'] = pd.to_datetime(df['registration_date'])\n",
        "df['last_login'] = pd.to_datetime(df['last_login'])\n",
        "\n",
        "df['days_since_registration'] = (df['last_login'] - df['registration_date']).dt.days\n",
        "```\n",
        "\n",
        "> üí° –†–∞–∑–Ω–∏—Ü—É –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∞—Ç—å –≤ –¥–Ω—è—Ö, —á–∞—Å–∞—Ö, –º–∏–Ω—É—Ç–∞—Ö, —Å–µ–∫—É–Ω–¥–∞—Ö –∏ –¥–∞–∂–µ –≤ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥–∞—Ö.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏: –ø—Ä–∞–∑–¥–Ω–∏–∫–∏, —Å–æ–±—ã—Ç–∏—è –∏ —Ç.–ø.\n",
        "\n",
        "–î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∑–∞–¥–∞—á –ø–æ–ª–µ–∑–Ω–æ –∑–Ω–∞—Ç—å, –±—ã–ª–∞ –ª–∏ –¥–∞—Ç–∞:\n",
        "- –ü—Ä–∞–∑–¥–Ω–∏–∫–æ–º?\n",
        "- –í—ã—Ö–æ–¥–Ω—ã–º?\n",
        "- –î–Ω–µ–º –æ—Å–æ–±–æ–≥–æ —Å–æ–±—ã—Ç–∏—è?\n",
        "\n",
        "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ `holidays`:\n",
        "\n",
        "```bash\n",
        "pip install holidays\n",
        "```\n",
        "\n",
        "```python\n",
        "import holidays\n",
        "\n",
        "ru_holidays = holidays.RU(years=[2025])\n",
        "df['is_holiday'] = df['date'].isin(ru_holidays)\n",
        "```\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å —Å—Ç–æ–ª–±–µ—Ü `is_holiday` –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å `True`, –µ—Å–ª–∏ –¥–∞—Ç–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–º.\n",
        "\n",
        "\n",
        "## ‚úÖ –û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞–º–∏\n",
        "\n",
        "1. **–ü—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ** –∏—Å—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ `datetime`.\n",
        "2. **–ò–∑–≤–ª–µ–∫–∏—Ç–µ** –Ω—É–∂–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: –≥–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å, –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –≤—Ä–µ–º—è —Å—É—Ç–æ–∫.\n",
        "3. **–í—ã—á–∏—Å–ª–∏—Ç–µ** —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–æ–∑—Ä–∞—Å—Ç).\n",
        "4. **–î–æ–±–∞–≤—å—Ç–µ** –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏—á–∏: –≤—ã—Ö–æ–¥–Ω–æ–π, –ø—Ä–∞–∑–¥–Ω–∏–∫, –∫–≤–∞—Ä—Ç–∞–ª –∏ —Ç.–¥.\n",
        "5. **–£–¥–∞–ª–∏—Ç–µ** –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π, –µ—Å–ª–∏ –æ–Ω –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω.\n",
        "\n",
        "\n",
        "\n",
        "## üìä –ü—Ä–∏–º–µ—Ä –∫–æ–Ω–µ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞—Ç—ã\n",
        "\n",
        "| –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∞—Ç–∞ | year | month | day | weekday | is_weekend | time_of_day | days_since_registration | is_holiday |\n",
        "|---------------|------|-------|-----|----------|------------|--------------|------------------------|-------------|\n",
        "| 2025-01-01    | 2025 | 1     | 1   | 2        | False      | Morning      | 365                    | True        |\n",
        "| 2025-01-05    | 2025 | 1     | 5   | 6        | True       | Evening      | 369                    | False       |\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –¥–∞—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Air Passenger](https://www.kaggle.com/rakannimer/air-passengers), [Bike Sharing Dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)).\n",
        "2. –ü—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ –¥–∞—Ç—ã –≤ `datetime`-–æ–±—ä–µ–∫—Ç—ã.\n",
        "3. –ò–∑–≤–ª–µ–∫–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
        "   - –ì–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å, —á–∞—Å\n",
        "   - –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏\n",
        "   - –ü—Ä–∏–∑–Ω–∞–∫ \"–≤—ã—Ö–æ–¥–Ω–æ–π\"\n",
        "   - –í—Ä–µ–º—è —Å—É—Ç–æ–∫\n",
        "   - –ö–≤–∞—Ä—Ç–∞–ª\n",
        "4. –í—ã—á–∏—Å–ª–∏—Ç–µ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –¥–≤—É–º—è –¥–∞—Ç–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—à–ª–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏ –¥–æ —Ç–µ–∫—É—â–µ–π).\n",
        "5. –î–æ–±–∞–≤—å—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞—Ö (—á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É `holidays`).\n",
        "6. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –µ–≥–æ —Å –∏—Å—Ö–æ–¥–Ω—ã–º.\n"
      ],
      "metadata": {
        "id": "wblQAe86bGdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 8. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (Text Data Processing)\n",
        "\n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "–¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî —ç—Ç–æ –æ–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: –æ—Ç–∑—ã–≤—ã, —Å–æ–æ–±—â–µ–Ω–∏—è, —Å—Ç–∞—Ç—å–∏, —Ç–≤–∏—Ç—ã, –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏ —Ç.–¥.\n",
        "\n",
        "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ **–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –ø–æ–Ω—è—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏. –≠—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **—Ç–µ–∫—Å—Ç–æ–≤–æ–π –∏–Ω–∂–µ–Ω–µ—Ä–∏–µ–π (text feature engineering)**.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ü–æ—á–µ–º—É –≤–∞–∂–Ω–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞?\n",
        "\n",
        "1. **–ú–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç —Å–ª–æ–≤–∞** ‚Äî –∏–º –Ω—É–∂–Ω—ã —á–∏—Å–ª–∞.\n",
        "2. **–û–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø–∏—Å–∞–Ω—ã –ø–æ-—Ä–∞–∑–Ω–æ–º—É** (–Ω–∞–ø—Ä–∏–º–µ—Ä, `¬´–±–µ–≥–∞—Ç—å¬ª` –∏ `¬´–±–µ–∂–∞–ª¬ª`).\n",
        "3. **–®—É–º —Å–Ω–∏–∂–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π** (–º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è, —Å—Ç–æ–ø-—Å–ª–æ–≤–∞).\n",
        "4. **–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–µ–º–∞–Ω—Ç–∏–∫–∞ –≤–∞–∂–Ω—ã** ‚Äî —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —É—á–∏—Ç—ã–≤–∞—é—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤ (`Word2Vec`, `BERT`).\n",
        "\n",
        "\n",
        "\n",
        "## üî¢ –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "| –≠—Ç–∞–ø | –¶–µ–ª—å |\n",
        "|------|------|\n",
        "| –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è | –†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ —Ñ—Ä–∞–∑—ã |\n",
        "| –û—á–∏—Å—Ç–∫–∞ | –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, —Å—Ç–æ–ø-—Å–ª–æ–≤, –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è |\n",
        "| –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è | –ü—Ä–∏–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞ –∫ –±–∞–∑–æ–≤–æ–π —Ñ–æ—Ä–º–µ (–ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è / —Å—Ç–µ–º–º–∏–Ω–≥) |\n",
        "| –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è | –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞ –≤ —á–∏—Å–ª–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ |\n",
        "\n",
        "\n",
        "\n",
        "## 1. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "–†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ **—Ç–æ–∫–µ–Ω—ã** ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∞–Ω–∞–ª–∏–∑–∞: —Å–ª–æ–≤–∞, —Å–∏–º–≤–æ–ª—ã, n-–≥—Ä–∞–º–º—ã.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä:\n",
        "```\n",
        "\"–Ø –ª—é–±–ª—é –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\"\n",
        "‚Üí [\"–Ø\", \"–ª—é–±–ª—é\", \"–º–∞—à–∏–Ω–Ω–æ–µ\", \"–æ–±—É—á–µ–Ω–∏–µ\"]\n",
        "```\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"–Ø –ª—é–±–ª—é –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ!\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n",
        "# ['–Ø', '–ª—é–±–ª—é', '–º–∞—à–∏–Ω–Ω–æ–µ', '–æ–±—É—á–µ–Ω–∏–µ', '!']\n",
        "```\n",
        "\n",
        "> ‚úÖ –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `RegexpTokenizer`, `TweetTokenizer` (–¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π), `sent_tokenize` –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
        "\n",
        "\n",
        "## 2. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏ –º—É—Å–æ—Ä–∞\n",
        "\n",
        "–°—Ç–æ–ø-—Å–ª–æ–≤–∞ ‚Äî —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è, –Ω–æ –º–∞–ª–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞: `¬´–∏¬ª`, `¬´–≤¬ª`, `¬´–Ω–∞¬ª`, `¬´—è¬ª`.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('russian'))  # –∏–ª–∏ 'english'\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
        "```\n",
        "\n",
        "–¢–∞–∫–∂–µ —É–¥–∞–ª—è–µ–º:\n",
        "- –ó–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è\n",
        "- –ß–∏—Å–ª–∞\n",
        "- HTML-—Ç–µ–≥–∏\n",
        "- –°—Å—ã–ª–∫–∏\n",
        "- –≠–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã\n",
        "\n",
        "\n",
        "\n",
        "## 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Å—Ç–µ–º–º–∏–Ω–≥\n",
        "\n",
        "–¶–µ–ª—å ‚Äî –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞ –∫ –∏—Ö –±–∞–∑–æ–≤–æ–π —Ñ–æ—Ä–º–µ, —á—Ç–æ–±—ã –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ —Å–ª–æ–≤–∞.\n",
        "\n",
        "### a) **–°—Ç–µ–º–º–∏–Ω–≥ (Stemming)**  \n",
        "–û–±—Ä–µ–∑–∞–µ—Ç –æ–∫–æ–Ω—á–∞–Ω–∏—è, –æ—Å—Ç–∞–≤–ª—è—è –∫–æ—Ä–µ–Ω—å. –ë—ã—Å—Ç—Ä—ã–π, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π.\n",
        "\n",
        "```python\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "stems = [stemmer.stem(word) for word in filtered_tokens]\n",
        "```\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä:  \n",
        "`–º–∞—à–∏–Ω–Ω–æ–µ ‚Üí –º–∞—à–∏–Ω–Ω, –æ–±—É—á–µ–Ω–∏–µ ‚Üí –æ–±—É—á–µ–Ω`\n",
        "\n",
        "\n",
        "\n",
        "### b) **–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (Lemmatization)**  \n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ª–æ–≤–∞—Ä—å, —á—Ç–æ–±—ã –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–æ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ (–ª–µ–º–º–µ). –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π, —á–µ–º —Å—Ç–µ–º–º–∏–Ω–≥.\n",
        "\n",
        "```python\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")  # –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
        "doc = nlp(\"–ú–∞—à–∏–Ω–∞ –±—ã—Å—Ç—Ä–æ –±–µ–∂–∞–ª–∞\")\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "```\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä:  \n",
        "`–±–µ–∂–∞–ª–∞ ‚Üí –±–µ–∂–∞—Ç—å`\n",
        "\n",
        "> ‚úÖ –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á NLP, –æ—Å–æ–±–µ–Ω–Ω–æ –≥–¥–µ –≤–∞–∂–Ω–∞ —Å–µ–º–∞–Ω—Ç–∏–∫–∞.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞\n",
        "\n",
        "–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞ ‚Äî —ç—Ç–æ —ç—Ç–∞–ø **–≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏**. –ù–∏–∂–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã:\n",
        "\n",
        "---\n",
        "\n",
        "### a) **Bag of Words (BoW)**\n",
        "\n",
        "–°–æ–∑–¥–∞—ë—Ç –º–∞—Ç—Ä–∏—Ü—É, –≥–¥–µ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –¥–æ–∫—É–º–µ–Ω—Ç, —Å—Ç–æ–ª–±—Ü—ã ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî —á–∞—Å—Ç–æ—Ç–∞ –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∏ –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥.  \n",
        "> ‚ùå –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –∏ —Å–µ–º–∞–Ω—Ç–∏–∫—É.\n",
        "\n",
        "\n",
        "\n",
        "### b) **TF-IDF (Term Frequency - Inverse Document Frequency)**\n",
        "\n",
        "–£—á–∏—Ç—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ —Å–ª–æ–≤–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –∏ –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–æ —Ä–µ–¥–∫–æ –≤ –∫–æ—Ä–ø—É—Å–µ.\n",
        "\n",
        "#### –§–æ—Ä–º—É–ª–∞:\n",
        "$$\n",
        "\\text{TF-IDF}(t,d,D) = \\text{TF}(t,d) \\times \\text{IDF}(t,D)\n",
        "$$\n",
        "\n",
        "–ì–¥–µ:\n",
        "- $ \\text{TF}(t,d) = \\frac{\\text{–∫–æ–ª-–≤–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π } t \\text{ –≤ } d}{\\text{–æ–±—â–µ–µ –∫–æ–ª-–≤–æ —Å–ª–æ–≤ –≤ } d} $\n",
        "- $ \\text{IDF}(t,D) = \\log\\left(\\frac{|D|}{|\\{d \\in D : t \\in d\\}|}\\right) $\n",
        "\n",
        "#### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£–ª—É—á—à–∞–µ—Ç BoW –∑–∞ —Å—á—ë—Ç —É—á—ë—Ç–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏, –≤—Å—ë –µ—â—ë –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n",
        "\n",
        "\n",
        "\n",
        "### c) **Word Embeddings**\n",
        "\n",
        "–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ **–≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è —Å–ª–æ–≤ (word embeddings)** ‚Äî —ç—Ç–æ –ø–µ—Ä–µ—Ö–æ–¥ –æ—Ç –ø—Ä–æ—Å—Ç—ã—Ö —á–∞—Å—Ç–æ—Ç –∫ –ø–ª–æ—Ç–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ—Å—É—Ç –≤ —Å–µ–±–µ **—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é**.\n",
        "\n",
        "#### –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–µ—Ç–æ–¥—ã:\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ | –†–µ–∞–ª–∏–∑–∞—Ü–∏—è |\n",
        "|-------|------------------|------------|\n",
        "| **Word2Vec** | –û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –±–æ–ª—å—à–∏—Ö –∫–æ—Ä–ø—É—Å–∞—Ö, –∫–æ–¥–∏—Ä—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É —Å–ª–æ–≤ | Gensim, spaCy |\n",
        "| **GloVe** | –ì–ª–æ–±–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –∫–æ-–æ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–µ–π | Stanford NLP |\n",
        "| **FastText** | –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ–¥—Å–ª–æ–≤–∞, —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–¥–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ | Facebook AI |\n",
        "| **BERT, RoBERTa, RuBERT** | –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ | HuggingFace Transformers |\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä —Å Word2Vec (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º):\n",
        "\n",
        "```python\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)\n",
        "vector = model.wv['king']  # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä –¥–ª—è —Å–ª–æ–≤–∞ \"king\"\n",
        "```\n",
        "\n",
        "> ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å–º—ã—Å–ª —Å–ª–æ–≤.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "\n",
        "### d) **Sentence Embeddings**\n",
        "\n",
        "–ï—Å–ª–∏ –Ω—É–∂–µ–Ω –≤–µ–∫—Ç–æ—Ä –¥–ª—è —Ü–µ–ª–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n",
        "\n",
        "- **Sentence-BERT (SBERT)**\n",
        "- **Universal Sentence Encoder (USE)**\n",
        "- **LaBSE (—è–∑—ã–∫–æ–≤—ã–µ BERT-—ç–º–±–µ–¥–¥–∏–Ω–≥–∏)**\n",
        "- **MPNet, DistilBERT –∏ –¥—Ä.**\n",
        "\n",
        "```python\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM')\n",
        "embeddings = model.encode([\"–≠—Ç–æ –ø—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\", \"–ò –µ—â–µ –æ–¥–∏–Ω\"])\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –ø–æ–∏—Å–∫–∞ —Å—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.  \n",
        "> ‚ùå –í—ã—Å–æ–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–∞–º—è—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ | –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É | –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
        "|-------|------------------------|----------------------|-------------|--------------------|\n",
        "| Bag of Words | ‚ùå | ‚ùå | –í—ã—Å–æ–∫–∞—è | –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–¥–∞—á–∏, –Ω–µ–±–æ–ª—å—à–∏–µ –≤—ã–±–æ—Ä–∫–∏ |\n",
        "| TF-IDF | ‚ùå | ‚ùå | –í—ã—Å–æ–∫–∞—è | –¢–æ –∂–µ + –ª—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |\n",
        "| Word2Vec | ‚ùå | ‚úÖ | –ù–∏–∑–∫–∞—è‚Äì—Å—Ä–µ–¥–Ω—è—è | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –ø–æ–∏—Å–∫ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ |\n",
        "| FastText | ‚ùå | ‚úÖ | –ù–∏–∑–∫–∞—è‚Äì—Å—Ä–µ–¥–Ω—è—è | –†–∞–±–æ—Ç–∞ —Å —Ä–µ–¥–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ |\n",
        "| BERT / SBERT | ‚ùå / ‚úÖ | ‚úÖ | –°—Ä–µ–¥–Ω—è—è | –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏, –ø–µ—Ä–µ–≤–æ–¥, –≤–æ–ø—Ä–æ—Å—ã-–æ—Ç–≤–µ—Ç—ã |\n",
        "\n",
        "\n",
        "\n",
        "## üß™ –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
        "\n",
        "```python\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^–∞-—è–ê-–Ø—ë–Å ]', '', text.lower())\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('russian')]\n",
        "    stemmer = SnowballStemmer('russian')\n",
        "    return ' '.join([stemmer.stem(word) for word in tokens])\n",
        "\n",
        "cleaned_texts = [preprocess_text(text) for text in texts]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(cleaned_texts)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## ü§ñ –ì–ª—É–±–æ–∫–∏–µ –º–µ—Ç–æ–¥—ã (Deep Learning)\n",
        "\n",
        "–ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ **–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏**, —Ç–æ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å **—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ BPE –∏–ª–∏ WordPiece** –∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –º–æ–¥–µ–ª–∏ —Ç–∏–ø–∞:\n",
        "\n",
        "- **BERT**, **RoBERTa**, **DistilBERT**, **XLM-RoBERTa**\n",
        "- **CNN**, **RNN**, **LSTM**, **GRU**\n",
        "- **Transformer-based –º–æ–¥–µ–ª–∏**\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Hugging Face Transformers:\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "inputs = tokenizer(\"–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\", return_tensors=\"pt\", padding=True, truncation=True)\n",
        "outputs = model(**inputs)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–µ–º–∞–Ω—Ç–∏–∫—É.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç GPU –∏ –º–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏.\n",
        "\n",
        "\n",
        "\n",
        "## ‚úÖ –û–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "1. **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞ –∏–ª–∏ —Ñ—Ä–∞–∑—ã.\n",
        "2. **–û—á–∏—Å—Ç–∫–∞**: —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤, –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏, HTML-—Ç–µ–≥–æ–≤ –∏ —Ç.–¥.\n",
        "3. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: —Å—Ç–µ–º–º–∏–Ω–≥ –∏–ª–∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è.\n",
        "4. **–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è**:\n",
        "   - BoW / TF-IDF (–¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML),\n",
        "   - Word2Vec, FastText (–¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è),\n",
        "   - BERT –∏ –¥—Ä. (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á).\n",
        "5. **–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**:\n",
        "   - Logistic Regression, SVM, Random Forest,\n",
        "   - LSTM, GRU, Transformer (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏).\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –í–æ–∑—å–º–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [IMDB Movie Reviews](https://www.kaggle.com/lakshmi25n/tagline-dataset), [RuSentiment](https://github.com/text-machine-lab/rusentiment)).\n",
        "2. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –ø–æ–ª–Ω—É—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É:\n",
        "   - –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
        "   - –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
        "   - –°—Ç–µ–º–º–∏–Ω–≥ / –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
        "3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏:\n",
        "   - Bag of Words\n",
        "   - TF-IDF\n",
        "   - Word2Vec (–∏–ª–∏ FastText)\n",
        "   - BERT\n",
        "4. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, LogisticRegression) –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üìö –ü–æ–ª–µ–∑–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|------------|----------|\n",
        "| **NLTK** | –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ |\n",
        "| **spaCy** | –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ Python, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è |\n",
        "| **scikit-learn** | BoW, TF-IDF |\n",
        "| **Gensim** | Word2Vec, FastText, LDA |\n",
        "| **Transformers (HuggingFace)** | BERT, RoBERTa, XLM –∏ –¥—Ä—É–≥–∏–µ |\n",
        "| **Sentence Transformers** | –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π |\n",
        "| **langdetect**, **fasttext-langdetect** | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞ |\n",
        "\n"
      ],
      "metadata": {
        "id": "bqFo5Wd9j9aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 9. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Engineering)\n",
        "\n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Engineering)** ‚Äî —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å **–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–µ–∑–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö**, —á—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ –æ–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤ –≤ —Ä–∞–±–æ—Ç–µ —Å –¥–∞–Ω–Ω—ã–º–∏, –ø–æ—Å–∫–æ–ª—å–∫—É –¥–∞–∂–µ —Å–∞–º–∞—è –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–∂–µ—Ç —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –ø–ª–æ—Ö–∏—Ö –∏–ª–∏ –ø–ª–æ—Ö–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "> üí° –ü–æ —Å–ª–æ–≤–∞–º –≠–Ω–¥—Ä—é –ù–≥:  \n",
        "> *\"–§–∏—á–∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –¥–µ—Ç–∞–ª–∏.\"*\n",
        "\n",
        "\n",
        "## üß† –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏?\n",
        "\n",
        "1. **–£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö**.\n",
        "2. **–ü–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã—è–≤–ª—è—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏**.\n",
        "3. **–ü–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –æ–±–æ–±—â–∞—é—â—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏**.\n",
        "4. **–£–ø—Ä–æ—â–∞–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –º–æ–¥–µ–ª–∏**.\n",
        "5. **–ú–æ–∂–µ—Ç –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö**.\n",
        "\n",
        "\n",
        "\n",
        "## üß™ –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ —Å–æ–∑–¥–∞–Ω–∏—é –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|----------|----------|\n",
        "| –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –°–ª–æ–∂–µ–Ω–∏–µ, —É–º–Ω–æ–∂–µ–Ω–∏–µ, –¥–µ–ª–µ–Ω–∏–µ, —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ |\n",
        "| –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (—Ñ–ª–∞–≥–∏) | –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ—Ç–º–µ—á–∞—é—â–∏–µ –Ω–∞–ª–∏—á–∏–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É—Å–ª–æ–≤–∏—è |\n",
        "| –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | –°—Ä–µ–¥–Ω–µ–µ, –º–µ–¥–∏–∞–Ω–∞, —Å—É–º–º–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º |\n",
        "| –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | –ì–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ |\n",
        "| –î–æ–º–µ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ | –ü—Ä–∏–∑–Ω–∞–∫–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –∑–Ω–∞–Ω–∏–∏ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ |\n",
        "\n",
        "\n",
        "\n",
        "## 1. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–ß–∞—Å—Ç–æ –ø–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—ë–º –ø—Ä–æ—Å—Ç—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –Ω–∞–¥ —É–∂–µ –∏–º–µ—é—â–∏–º–∏—Å—è.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "- `Income / Expenses` ‚Üí –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–∞ –∫ —Ä–∞—Å—Ö–æ–¥–∞–º;\n",
        "- `TotalSpent = ProductA + ProductB + ProductC` ‚Üí –æ–±—â–∏–π –æ–±—ä–µ–º —Ç—Ä–∞—Ç;\n",
        "- `Price per Unit = TotalCost / Quantity` ‚Üí —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞;\n",
        "- `BMI = Weight / Height¬≤` ‚Üí –∏–Ω–¥–µ–∫—Å –º–∞—Å—Å—ã —Ç–µ–ª–∞.\n",
        "\n",
        "```python\n",
        "df['bmi'] = df['weight'] / (df['height'] ** 2)\n",
        "df['price_per_unit'] = df['total_cost'] / df['quantity']\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–º–µ—é—Ç \"–≤–∏–¥–µ—Ç—å\" —Ç–∞–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ.\n",
        "\n",
        "\n",
        "\n",
        "## 2. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (–±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–ª–∞–≥–∏)\n",
        "\n",
        "–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ‚Äî —ç—Ç–æ **–±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (0/1)**, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ —É—Å–ª–æ–≤–∏—è.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "- `IsSenior = Age >= 60`\n",
        "- `IsVIP = TotalPurchases > 10000`\n",
        "- `HasMissingValues = pd.isnull(df['Age'])`\n",
        "- `IsWeekend = df['date'].dt.weekday >= 5`\n",
        "\n",
        "```python\n",
        "df['is_senior'] = (df['age'] >= 60).astype(int)\n",
        "df['is_vip'] = (df['total_purchases'] > 10000).astype(int)\n",
        "```\n",
        "\n",
        "> ‚úÖ –¢–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "## 3. –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "\n",
        "–ê–≥—Ä–µ–≥–∞—Ü–∏—è ‚Äî —ç—Ç–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º. –ù–∞–ø—Ä–∏–º–µ—Ä, —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Ç.–¥.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "- `avg_salary_by_dept` ‚Äî —Å—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –æ—Ç–¥–µ–ª—É;\n",
        "- `user_activity_count` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞ –ø–µ—Ä–∏–æ–¥;\n",
        "- `avg_order_value_per_customer` ‚Äî —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫ –∫–ª–∏–µ–Ω—Ç–∞.\n",
        "\n",
        "```python\n",
        "# –ü—Ä–∏–º–µ—Ä –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é groupby\n",
        "df['avg_salary_by_dept'] = df.groupby('department')['salary'].transform('mean')\n",
        "df['total_orders_per_user'] = df.groupby('user_id')['order_id'].transform('count')\n",
        "```\n",
        "\n",
        "> ‚úÖ –û—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã –≤ –∑–∞–¥–∞—á–∞—Ö —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –≥—Ä—É–ø–ø–∞–º–∏ (–∫–ª–∏–µ–Ω—Ç—ã, –ø—Ä–æ–¥—É–∫—Ç—ã, —Ä–µ–≥–∏–æ–Ω—ã).\n",
        "> ‚ö†Ô∏è –ù–µ –∑–∞–±—ã–≤–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `.transform()` –≤–º–µ—Å—Ç–æ `.agg()`, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å DataFrame.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –æ–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)\n",
        "\n",
        "–î–ª—è –¥–∞—Ç –∏ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–∂–Ω–æ —Å—Ç—Ä–æ–∏—Ç—å **–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏** –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–æ–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏**, —á—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –∏ —Ç—Ä–µ–Ω–¥—ã.\n",
        "\n",
        "### a) –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "\n",
        "```python\n",
        "df['year'] = df['datetime'].dt.year\n",
        "df['month'] = df['datetime'].dt.month\n",
        "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['is_weekend'] = (df['datetime'].dt.dayofweek >= 5).astype(int)\n",
        "```\n",
        "\n",
        "### b) –û–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
        "\n",
        "–û–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –≤—ã—á–∏—Å–ª—è—Ç—å —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ, –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–µ —Å—É–º–º—ã –∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä: —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–ª–∏–µ–Ω—Ç—É\n",
        "\n",
        "```python\n",
        "df.sort_values(['customer_id', 'date'], inplace=True)\n",
        "df['rolling_avg_7d'] = df.groupby('customer_id')['amount'].transform(\n",
        "    lambda x: x.rolling(window=7).mean()\n",
        ")\n",
        "```\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä: –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞\n",
        "\n",
        "```python\n",
        "df['cumulative_spent'] = df.groupby('customer_id')['purchase_amount'].cumsum()\n",
        "```\n",
        "\n",
        "> ‚úÖ –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω—ã –≤ –∑–∞–¥–∞—á–∞—Ö –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n",
        "\n",
        "\n",
        "\n",
        "## 5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–æ–º–µ–Ω–Ω–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã\n",
        "\n",
        "**–î–æ–º–µ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ (domain knowledge)** ‚Äî —ç—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –æ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª–µ–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "\n",
        "| –ó–∞–¥–∞—á–∞ | –ü—Ä–∏–∑–Ω–∞–∫ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |\n",
        "|--------|---------|-------------|\n",
        "| –§–∏–Ω–∞–Ω—Å—ã | `Debt to Income Ratio = Debt / Income` | –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–ª–∞—Ç–µ–∂–µ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å |\n",
        "| –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ | `Customer Lifetime Value = AvgOrderValue * PurchaseFrequency` | –û—Ü–µ–Ω–∫–∞ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞ |\n",
        "| –†–∏—Ç–µ–π–ª | `Stockout Flag = Stock == 0` | –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ç–æ–≥–æ, —á—Ç–æ —Ç–æ–≤–∞—Ä –∑–∞–∫–æ–Ω—á–∏–ª—Å—è |\n",
        "| –ó–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ | `BMI = Weight / Height¬≤` | –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ä–∏—Å–∫–∞ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π |\n",
        "| E-commerce | `Days Since Last Purchase` | –ú–µ—Ä–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞ |\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "# –î–æ–ª—è –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π\n",
        "df['late_payment_ratio'] = df['num_late_payments'] / df['total_payments']\n",
        "\n",
        "# –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
        "df['distance_to_nearest_store_km'] = haversine_distance(lat1, lon1, lat2, lon2)\n",
        "```\n",
        "\n",
        "> ‚úÖ –≠—Ç–æ —Å–∞–º—ã–π —Ü–µ–Ω–Ω—ã–π —Ç–∏–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Äî –æ–Ω –º–æ–∂–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –≤—ã –ø–æ–Ω–∏–º–∞–µ—Ç–µ –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á—É.\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –¢–∏–ø—ã –∞–≥—Ä–µ–≥–∞—Ü–∏–π –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π\n",
        "\n",
        "| –¢–∏–ø | –ü—Ä–∏–º–µ—Ä | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
        "|-----|--------|---------------------|\n",
        "| –ê—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∏–µ | `x + y`, `x / y` | –ö–æ–≥–¥–∞ –µ—Å—Ç—å —Å–º—ã—Å–ª –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ |\n",
        "| –õ–æ–≥–∏—á–µ—Å–∫–∏–µ | `x > y`, `x.isin([...])` | –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ |\n",
        "| –£—Å–ª–æ–≤–Ω—ã–µ | `np.where(x > threshold, 1, 0)` | –î–ª—è –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Ñ–ª–∞–≥–æ–≤ |\n",
        "| –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º | `groupby().mean(), .std(), .nunique()` | –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –≥—Ä—É–ø–ø–∞–º–∏ |\n",
        "| –í—Ä–µ–º–µ–Ω–Ω—ã–µ | `diff()`, `shift()`, `rolling()` | –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ |\n",
        "| –°–ª–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã | `BMI`, `CLV`, `Churn Score` | –ù–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–µ–Ω–Ω–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã |\n",
        "\n",
        "\n",
        "\n",
        "## üìä –ü—Ä–∏–º–µ—Ä—ã Feature Engineering\n",
        "\n",
        "### a) **–ö–ª–∏–µ–Ω—Ç—Å–∫–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞**\n",
        "\n",
        "–î–æ–ø—É—Å—Ç–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–∫—É–ø–∫–∞—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤:\n",
        "\n",
        "| CustomerID | Date       | Amount |\n",
        "|------------|------------|--------|\n",
        "| 1          | 2024-01-01 | 100    |\n",
        "| 1          | 2024-01-15 | 200    |\n",
        "| 2          | 2024-01-05 | 50     |\n",
        "\n",
        "#### –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\n",
        "- `TotalSpentPerCustomer` ‚Äî –æ–±—â–∏–π –¥–æ—Ö–æ–¥ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞;\n",
        "- `AvgPurchaseValue` ‚Äî —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫;\n",
        "- `DaysSinceLastPurchase` ‚Äî —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –ø—Ä–æ—à–ª–æ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫—É–ø–∫–∏;\n",
        "- `IsHighSpender` ‚Äî —Ñ–ª–∞–≥, –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–æ—Ç—Ä–∞—Ç–∏–ª –±–æ–ª—å—à–µ X —Ä—É–±–ª–µ–π.\n",
        "\n",
        "```python\n",
        "# –û–±—â–∞—è —Å—É–º–º–∞ –ø–æ –∫–ª–∏–µ–Ω—Ç—É\n",
        "df['total_spent'] = df.groupby('CustomerID')['Amount'].transform('sum')\n",
        "\n",
        "# –°—Ä–µ–¥–Ω–∏–π —á–µ–∫\n",
        "df['avg_purchase'] = df.groupby('CustomerID')['Amount'].transform('mean')\n",
        "\n",
        "# –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –ø–æ–∫—É–ø–∫–∏\n",
        "last_purchase = df.groupby('CustomerID')['Date'].transform('max')\n",
        "df['days_since_last_purchase'] = (pd.to_datetime('today') - last_purchase).dt.days\n",
        "\n",
        "# –§–ª–∞–≥ VIP\n",
        "df['is_vip'] = (df['total_spent'] > 10000).astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### b) **–¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**\n",
        "\n",
        "–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞), –º–æ–∂–Ω–æ –∏–∑–≤–ª–µ–∫–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\n",
        "\n",
        "- `text_length = len(text)`\n",
        "- `word_count = text.split().len()`\n",
        "- `has_discount = '—Å–∫–∏–¥–∫–∞' in text`\n",
        "- `sentiment_score = sentiment_model.predict(text)`\n",
        "\n",
        "```python\n",
        "df['text_len'] = df['description'].str.len()\n",
        "df['word_count'] = df['description'].str.split().str.len()\n",
        "df['has_promo'] = df['description'].str.contains('—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞|—Å–∫–∏–¥–∫–∞|–∞–∫—Ü–∏—è', case=False).astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "## üìà –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–∫–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π\n",
        "\n",
        "### a) –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ (Moving Average)\n",
        "\n",
        "```python\n",
        "df['ma_7_days'] = df.groupby('product_id')['sales'].transform(lambda x: x.rolling(7).mean())\n",
        "```\n",
        "\n",
        "### b) –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞ (Cumulative Sum)\n",
        "\n",
        "```python\n",
        "df['cum_sales'] = df.groupby('product_id')['sales'].cumsum()\n",
        "```\n",
        "\n",
        "### c) –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º\n",
        "\n",
        "```python\n",
        "df['delta_prev_day'] = df.groupby('product_id')['sales'].diff()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üéØ –ö–∞–∫ –ø—Ä–∏–¥—É–º–∞—Ç—å —Ö–æ—Ä–æ—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏?\n",
        "\n",
        "1. **–ó–Ω–∞–π —Å–≤–æ—é –∑–∞–¥–∞—á—É**: —á–µ–º –ª—É—á—à–µ —Ç—ã –ø–æ–Ω–∏–º–∞–µ—à—å –±–∏–∑–Ω–µ—Å-–æ–±—ä–µ–∫—Ç, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–∂–µ—à—å —Å–æ–∑–¥–∞—Ç—å.\n",
        "2. **–ò–∑—É—á–∏ –¥–∞–Ω–Ω—ã–µ**: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –≤—ã–±—Ä–æ—Å—ã.\n",
        "3. **–ü—Ä–æ–≤–µ—Ä—è–π –≥–∏–ø–æ—Ç–µ–∑—ã**: –Ω–∞–ø—Ä–∏–º–µ—Ä, \"–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –≤—ã—Å–æ–∫–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –ø–æ–∫—É–ø–æ–∫ —á–∞—â–µ —É—Ö–æ–¥—è—Ç\".\n",
        "4. **–ò—Å–ø–æ–ª—å–∑—É–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏**: –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ–º–æ–≥–∞—é—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–∫—Ä—ã—Ç—ã–µ —Å–≤—è–∑–∏.\n",
        "5. **–¢–µ—Å—Ç–∏—Ä—É–π –ø—Ä–∏–∑–Ω–∞–∫–∏**: –¥–æ–±–∞–≤—å –∏—Ö –≤ –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ–≤–µ—Ä—å, —É–ª—É—á—à–∏–ª–æ—Å—å –ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ.\n",
        "\n",
        "\n",
        "\n",
        "## üß∞ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è Feature Engineering\n",
        "\n",
        "| –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç | –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ |\n",
        "|-----------|-------------|\n",
        "| **Pandas** | groupby, rolling, transform, apply |\n",
        "| **NumPy** | np.where, np.select, np.clip |\n",
        "| **Scikit-learn** | FunctionTransformer, ColumnTransformer |\n",
        "| **Feature-engine** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n",
        "| **tsfresh / featuretools** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –∏ –æ–±—â–∏—Ö –∑–∞–¥–∞—á) |\n",
        "| **Category Encoders** | –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —É—á–µ—Ç–æ–º —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π |\n",
        "\n",
        "\n",
        "\n",
        "## üì¶ –ü—Ä–∏–º–µ—Ä –Ω–∞–±–æ—Ä–∞ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "| –ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | –ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ |\n",
        "|------------------|----------------|\n",
        "| `income`, `expenses` | `savings = income - expenses` |\n",
        "| `latency`, `response_time` | `is_slow = latency > mean_latency` |\n",
        "| `start_date`, `end_date` | `duration_days = end_date - start_date` |\n",
        "| `clicks`, `views` | `CTR = clicks / views` |\n",
        "| `latitude`, `longitude` | `distance_from_home` (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–æ–º–∞) |\n",
        "| `order_date`, `delivery_date` | `delivery_delay_days = delivery_date - order_date` |\n",
        "| `temperature`, `humidity` | `heat_index = f(temperature, humidity)` |\n",
        "| `transaction_amount`, `time` | `rolling_avg_30d` ‚Äî —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ 30 –¥–Ω–µ–π |\n",
        "\n",
        "\n",
        "\n",
        "## üß™ –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è Feature Engineering\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "def engineer_features(df):\n",
        "    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
        "    df['income_expense_diff'] = df['income'] - df['expenses']\n",
        "    df['ratio_income_expenses'] = df['income'] / df['expenses']\n",
        "\n",
        "    # –§–ª–∞–≥–∏\n",
        "    df['is_high_risk'] = (df['debt_ratio'] > 0.8).astype(int)\n",
        "    df['is_new_customer'] = (df['first_purchase_date'] > '2024-01-01').astype(int)\n",
        "\n",
        "    # –ê–≥—Ä–µ–≥–∞—Ü–∏–∏\n",
        "    df['avg_purchase_by_city'] = df.groupby('city')['purchase_amount'].transform('mean')\n",
        "    df['total_purchases_by_user'] = df.groupby('user_id')['amount'].cumsum()\n",
        "\n",
        "    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "    df['signup_year'] = df['signup_date'].dt.year\n",
        "    df['is_weekend'] = df['visit_date'].dt.weekday >= 5\n",
        "\n",
        "    return df\n",
        "\n",
        "df = engineer_features(df)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
        "\n",
        "| –¢–∏–ø –ø—Ä–∏–∑–Ω–∞–∫–∞ | –ß—Ç–æ —ç—Ç–æ | –ü—Ä–∏–º–µ—Ä—ã | –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã |\n",
        "|--------------|---------|----------|-------------|\n",
        "| –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ | –ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç–∞—Ä—ã—Ö | `income / expenses`, `price per unit` | Pandas |\n",
        "| –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã | –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | `is_weekend`, `is_vip` | np.where, isin |\n",
        "| –ê–≥—Ä–µ–≥–∞—Ü–∏–∏ | –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º | `avg_salary_by_dept`, `total_orders_per_user` | groupby, transform |\n",
        "| –í—Ä–µ–º–µ–Ω–Ω—ã–µ | –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –¥–∞—Ç | `year`, `day_of_week`, `days_since_last_visit` | dt, diff, shift |\n",
        "| –î–æ–º–µ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ | –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ | `CLV`, `Churn Risk`, `LTV` | Pandas, NumPy, domain logic |\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –í–æ–∑—å–º–∏ –ª—é–±–æ–π –¥–∞—Ç–∞—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Titanic](https://www.kaggle.com/c/titanic/data), [Telco Churn](https://www.kaggle.com/blastchar/telco-customer-churn)).\n",
        "2. –í—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
        "   - –°–æ–∑–¥–∞–π 2‚Äì3 –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞ —á–µ—Ä–µ–∑ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç–Ω–æ—à–µ–Ω–∏–µ, —Ä–∞–∑–Ω–æ—Å—Ç—å, –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ);\n",
        "   - –î–æ–±–∞–≤—å 2‚Äì3 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `is_vip`, `has_missing`);\n",
        "   - –î–æ–±–∞–≤—å 1‚Äì2 –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≥—Ä—É–ø–ø–µ);\n",
        "   - –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞—Ç—ã ‚Äî —Å–¥–µ–ª–∞–π 2‚Äì3 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞;\n",
        "   - –ü–æ –∂–µ–ª–∞–Ω–∏—é: –∏—Å–ø–æ–ª—å–∑—É–π –¥–æ–º–µ–Ω–Ω—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –∏ —Å–æ–∑–¥–∞–π 1‚Äì2 –ø—Ä–∏–∑–Ω–∞–∫–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –ª–æ–≥–∏–∫–µ –∑–∞–¥–∞—á–∏.\n",
        "3. –û–±—É—á–∏ –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, LogisticRegression) –¥–æ –∏ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Äî —Å—Ä–∞–≤–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ.\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|-------------|----------|\n",
        "| **FeatureTools** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Feature Engineering |\n",
        "| **tsfresh** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ |\n",
        "| **AutoFeat** | –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏—á–µ–π |\n",
        "| **sklearn.preprocessing.FunctionTransformer** | –í—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤ –ø–∞–π–ø–ª–∞–π–Ω |\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "Feature Engineering ‚Äî —ç—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–æ –∏ –Ω–∞—É–∫–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ. –û–Ω —Ç—Ä–µ–±—É–µ—Ç –∫–∞–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≤—ã–∫–æ–≤, —Ç–∞–∫ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏. –•–æ—Ä–æ—à–æ —Å–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–≥—É—Ç:\n",
        "- **–°—ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø–æ–¥–±–æ—Ä –º–æ–¥–µ–ª–∏**;\n",
        "- **–°–Ω–∏–∑–∏—Ç—å —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è**;\n",
        "- **–£–≤–µ–ª–∏—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤**;\n",
        "- **–£—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∏ —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤—ã–º**.\n"
      ],
      "metadata": {
        "id": "JhyVfnWpnc8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 10. –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (Dimensionality Reduction)  \n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** ‚Äî —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å —É–ø—Ä–æ—â–µ–Ω–∏—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —Å—á—ë—Ç **—É–º–µ–Ω—å—à–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
        "\n",
        "–≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ, –∫–æ–≥–¥–∞:\n",
        "- –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ (curse of dimensionality).\n",
        "- –ï—Å—Ç—å –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏–µ –∏–ª–∏ —à—É–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.\n",
        "- –ù—É–∂–Ω–æ —É—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —É–ª—É—á—à–∏—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ü–æ—á–µ–º—É –Ω—É–∂–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å?\n",
        "\n",
        "| –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ—à–µ–Ω–∏–µ |\n",
        "|---------|---------|\n",
        "| –ú–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ | –û—Ç–±–æ—Ä –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n",
        "| –í—ã—Å–æ–∫–∞—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å | –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ |\n",
        "| –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ ‚Üí –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å | PCA, —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n",
        "| –®—É–º –≤ –¥–∞–Ω–Ω—ã—Ö ‚Üí —Å–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ | –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ |\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n",
        "\n",
        "| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ú–µ—Ç–æ–¥ | –¢–∏–ø | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
        "|-----------|-------|-----|---------------------|\n",
        "| –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö/–∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | –î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –æ—Ç–±–æ—Ä, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ | –§–∏–ª—å—Ç—Ä—ã | –ë—ã—Å—Ç—Ä–∞—è –æ—á–∏—Å—Ç–∫–∞ |\n",
        "| –õ–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏ | PCA, LDA | –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ | –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö |\n",
        "| –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | Filter, Wrapper, Embedded | –û—Ç–±–æ—Ä | –û–±—â–∏–µ –∑–∞–¥–∞—á–∏ ML |\n",
        "\n",
        "\n",
        "\n",
        "## 1. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "### a) –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π\n",
        "\n",
        "–ü—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—á—Ç–∏ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è, –Ω–µ –Ω–µ—Å—É—Ç –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
        "\n",
        "```python\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "X_reduced = selector.fit_transform(X)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–ª–µ–∑–µ–Ω –¥–ª—è —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –∏–ª–∏ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "\n",
        "\n",
        "\n",
        "### b) –£–¥–∞–ª–µ–Ω–∏–µ —Å–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç —É—Ö—É–¥—à–∏—Ç—å –º–æ–¥–µ–ª—å –∏ –µ—ë –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "corr_matrix = df.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
        "\n",
        "df.drop(to_drop, axis=1, inplace=True)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£–º–µ–Ω—å—à–∞–µ—Ç –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–≤—ã—à–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "\n",
        "\n",
        "## 2. –ú–µ—Ç–æ–¥ –≥–ª–∞–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (PCA)\n",
        "\n",
        "**Principal Component Analysis (PCA)** ‚Äî —ç—Ç–æ –ª–∏–Ω–µ–π–Ω—ã–π –º–µ—Ç–æ–¥ —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã), –æ–±—ä—è—Å–Ω—è—é—â–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "### –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã:\n",
        "1. –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (Standardization).\n",
        "2. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã.\n",
        "3. –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏–π.\n",
        "4. –ü—Ä–æ–µ–∫—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø–µ—Ä–≤—ã–µ `k` —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.\n",
        "\n",
        "#### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "pca = PCA(n_components=0.95)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º 95% –¥–∏—Å–ø–µ—Ä—Å–∏–∏\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ –±–æ–ª—å—à–æ–º —á–∏—Å–ª–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏.  \n",
        "> ‚ùå –ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç—Ä—É–¥–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å.\n",
        "\n",
        "\n",
        "\n",
        "## 3. –õ–∏–Ω–µ–π–Ω—ã–π –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (LDA)\n",
        "\n",
        "**LDA (Linear Discriminant Analysis)** ‚Äî –º–µ—Ç–æ–¥, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π PCA, –Ω–æ —É—á–∏—Ç—ã–≤–∞—é—â–∏–π **—Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é**. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –∑–∞–¥–∞—á–∞—Ö **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**.\n",
        "\n",
        "### –¶–µ–ª—å:\n",
        "–ù–∞–π—Ç–∏ –ø—Ä–æ–µ–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è **–º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤**.\n",
        "\n",
        "```python\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_lda = lda.fit_transform(X, y)\n",
        "```\n",
        "\n",
        "> ‚úÖ –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º—ã.  \n",
        "> ‚ùå –¢–æ–ª—å–∫–æ –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "–û—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: –º—ã **–≤—ã–±–∏—Ä–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**, –∞ –Ω–µ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ.\n",
        "\n",
        "### a) **Filter Methods (–§–∏–ª—å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã)**\n",
        "\n",
        "–í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –±–µ–∑ —É—á–∞—Å—Ç–∏—è –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞\n",
        "- –ú–µ—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ (Mutual Information)\n",
        "- ANOVA F-value\n",
        "\n",
        "```python\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–æ—Å—Ç–æ—Ç–∞, –±—ã—Å—Ç—Ä–æ–¥–µ–π—Å—Ç–≤–∏–µ.  \n",
        "> ‚ùå –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.\n",
        "\n",
        "\n",
        "\n",
        "### b) **Wrapper Methods (–û–±—ë—Ä—Ç–æ—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã)**\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É—é—Ç –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä: Recursive Feature Elimination (RFE)\n",
        "\n",
        "```python\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "rfe = RFE(estimator=model, n_features_to_select=10)\n",
        "X_rfe = rfe.fit_transform(X, y)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.  \n",
        "> ‚ùå –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ç—Ä–∞—Ç–Ω–æ.\n",
        "\n",
        "\n",
        "\n",
        "### c) **Embedded Methods (–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã)**\n",
        "\n",
        "–°–æ–≤–º–µ—â–∞—é—Ç –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä—ã:\n",
        "- **Lasso (L1-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)** ‚Äî –æ–±–Ω—É–ª—è–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–∞–ª–æ–∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "- **–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π, Random Forest, XGBoost** ‚Äî –∏—Å–ø–æ–ª—å–∑—É—é—Ç feature importance.\n",
        "\n",
        "##### Lasso (–ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å L1):\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "lasso = LassoCV(cv=5)\n",
        "lasso.fit(X_scaled, y)\n",
        "\n",
        "# –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω—É–ª–µ–≤—ã–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å\n",
        "mask = lasso.coef_ != 0\n",
        "X_lasso = X[:, mask]\n",
        "```\n",
        "\n",
        "##### Feature Importance —á–µ—Ä–µ–∑ –¥–µ—Ä–µ–≤—å—è:\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "top_k = indices[:10]  # —Ç–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "X_top = X[:, top_k]\n",
        "```\n",
        "\n",
        "> ‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤ –æ–±—É—á–µ–Ω–∏–µ.  \n",
        "> ‚ùå –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é | –¢—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å | –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è |\n",
        "|--------|------------------------------|--------------------------|--------------------|---------------|\n",
        "| –î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –æ—Ç–±–æ—Ä | ‚ùå | ‚ùå | ‚úÖ | –í—Å–µ –∑–∞–¥–∞—á–∏ |\n",
        "| –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç–±–æ—Ä | ‚úÖ | ‚ùå | ‚úÖ | –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ |\n",
        "| PCA | ‚ùå | ‚ùå | ‚ùå | –í—Å–µ –∑–∞–¥–∞—á–∏ |\n",
        "| LDA | ‚úÖ | ‚úÖ | ‚ùå | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è |\n",
        "| Filter Methods | ‚úÖ | ‚ùå | ‚úÖ | –í—Å–µ –∑–∞–¥–∞—á–∏ |\n",
        "| Wrapper Methods (RFE) | ‚úÖ | ‚úÖ | ‚úÖ | –í—Å–µ –∑–∞–¥–∞—á–∏ |\n",
        "| Embedded Methods (Lasso, Tree-based) | ‚úÖ | ‚úÖ | ‚úÖ | –í—Å–µ –∑–∞–¥–∞—á–∏ |\n",
        "\n",
        "\n",
        "\n",
        "## üìà –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç / –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?\n",
        "\n",
        "### a) PCA\n",
        "\n",
        "```python\n",
        "pca = PCA().fit(X_scaled)\n",
        "explained_variance = pca.explained_variance_ratio_.cumsum()\n",
        "n_components = np.argmax(explained_variance >= 0.95) + 1\n",
        "```\n",
        "\n",
        "### b) Feature Importance (–¥–µ—Ä–µ–≤—å—è)\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(range(len(importances)), importances[indices])\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### c) RFE\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'n_features_to_select': range(5, 20)}\n",
        "grid = GridSearchCV(rfe, param_grid, scoring='accuracy', cv=5)\n",
        "grid.fit(X, y)\n",
        "best_n = grid.best_params_['n_features_to_select']\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üß™ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –º–µ—Ç–æ–¥?\n",
        "\n",
        "| –ó–∞–¥–∞—á–∞ | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –º–µ—Ç–æ–¥ |\n",
        "|--------|----------------------|\n",
        "| –ú–Ω–æ–≥–æ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ—Ç —Ü–µ–ª–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ | PCA |\n",
        "| –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –µ—Å—Ç—å –º–µ—Ç–∫–∏ | LDA |\n",
        "| –ù—É–∂–Ω—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | Filter, Embedded |\n",
        "| –ï—Å—Ç—å –≤—Ä–µ–º—è –∏ —Ä–µ—Å—É—Ä—Å—ã, –Ω—É–∂–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å | Wrapper (RFE) |\n",
        "| –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –Ω—É–∂–Ω—ã –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | Embedded (Lasso, Random Forest) |\n",
        "\n",
        "\n",
        "\n",
        "## üìâ –ü—Ä–∏–º–µ—Ä –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
        "    ('dimensionality_reduction', PCA(n_components=5)),\n",
        "    ('clf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ –º–Ω–æ–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Breast Cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html), [Digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)).\n",
        "2. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã:\n",
        "   - –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π;\n",
        "   - –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤;\n",
        "   - PCA;\n",
        "   - LDA (–µ—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è);\n",
        "   - Filter / Embedded / Wrapper –º–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
        "3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–æ –∏ –ø–æ—Å–ª–µ —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ ‚Äî —Å—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ.\n",
        "4. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –¥–æ–ª–∏ –æ–±—ä—è—Å–Ω—ë–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|------------|----------|\n",
        "| **Scikit-learn** | PCA, LDA, RFE, SelectKBest |\n",
        "| **Feature-engine** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä |\n",
        "| **Boruta** | –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Random Forest –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n",
        "| **SHAP / LIME** | –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ |\n",
        "| **eli5** | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∏ –æ—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ |\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ ‚Äî –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç:\n",
        "- **–°–Ω–∏–∑–∏—Ç—å —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è**,\n",
        "- **–£—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**,\n",
        "- **–£–ø—Ä–æ—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é**,\n",
        "- **–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é**.\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –º–æ–∂–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—Å–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ —É—Å–ª–æ–≤–∏—è—Ö –≤—ã—Å–æ–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö.\n"
      ],
      "metadata": {
        "id": "RwgQsWKRoYJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 11. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏  \n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏** ‚Äî —ç—Ç–æ –∫–ª—é—á–µ–≤–æ–π —ç—Ç–∞–ø –≤ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–Ω–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç:\n",
        "- **–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å** –Ω–∞ —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö,\n",
        "- **–û—Ü–µ–Ω–∏—Ç—å –µ—ë –∫–∞—á–µ—Å—Ç–≤–æ** –Ω–∞ –Ω–µ–≤–∏–¥–∏–º—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö (–≤–∞–ª–∏–¥–∞—Ü–∏—è),\n",
        "- **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å** –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ.\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å **—É—Ç–µ—á–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏**, –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç **–æ–±—ä–µ–∫—Ç–∏–≤–Ω—É—é –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏** –∏ —Å–Ω–∏–∂–∞–µ—Ç —Ä–∏—Å–∫ **–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è**.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ü–æ—á–µ–º—É –≤–∞–∂–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ?\n",
        "\n",
        "| –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ—à–µ–Ω–∏–µ |\n",
        "|---------|----------|\n",
        "| –£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö | –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ |\n",
        "| –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ | –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è |\n",
        "| –°–º–µ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ | –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ |\n",
        "| –ù–∞—Ä—É—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ | TimeSeriesSplit |\n",
        "\n",
        "\n",
        "\n",
        "## üìä –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–∏–ø—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |\n",
        "|-------|---------------------|-------------|\n",
        "| `train_test_split()` | –ë—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test | –ü—Ä–æ—Å—Ç–æ, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ |\n",
        "| K-Fold | –î–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ | –ü–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ |\n",
        "| Stratified K-Fold | –î–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏ | –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π |\n",
        "| TimeSeriesSplit | –î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ | –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ |\n",
        "\n",
        "\n",
        "\n",
        "## 1. –û–±—ã—á–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: `train_test_split`\n",
        "\n",
        "–≠—Ç–æ —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —Å–ø–æ—Å–æ–± —Ä–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ **–æ–±—É—á–∞—é—â—É—é** –∏ **—Ç–µ—Å—Ç–æ–≤—É—é** –≤—ã–±–æ—Ä–∫–∏.\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "–ì–¥–µ:\n",
        "- `test_size` ‚Äî –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö, –≤—ã–¥–µ–ª—è–µ–º—ã—Ö –ø–æ–¥ —Ç–µ—Å—Ç;\n",
        "- `random_state` ‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏;\n",
        "- `stratify=y` ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤ (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏).\n",
        "\n",
        "#### –ü—Ä–∏–º–µ—Ä —Å `stratify`:\n",
        "\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–æ—Å—Ç–æ –∏ –±—ã—Å—Ç—Ä–æ.  \n",
        "> ‚ùå –ù–µ —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "\n",
        "\n",
        "## 2. K-Fold Cross Validation\n",
        "\n",
        "**K-Fold** ‚Äî –º–µ—Ç–æ–¥, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –¥–∞–Ω–Ω—ã–µ –¥–µ–ª—è—Ç—Å—è –Ω–∞ `k` —á–∞—Å—Ç–µ–π (—Ñ–æ–ª–¥–æ–≤), –∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è `k` —Ä–∞–∑, –∫–∞–∂–¥—ã–π —Ä–∞–∑ –Ω–∞ `k-1` —Ñ–æ–ª–¥–∞—Ö –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –æ—Å—Ç–∞–≤—à–µ–º—Å—è.\n",
        "\n",
        "### –≠—Ç–∞–ø—ã:\n",
        "1. –î–∞–Ω–Ω—ã–µ –¥–µ–ª—è—Ç—Å—è –Ω–∞ `k` —Ä–∞–≤–Ω—ã—Ö —á–∞—Å—Ç–µ–π.\n",
        "2. –ù–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –æ–¥–Ω–∞ —á–∞—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –∫–∞–∫ –æ–±—É—á–∞—é—â–∏–µ.\n",
        "3. –ò—Ç–æ–≥–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º `k` –∏—Ç–µ—Ä–∞—Ü–∏—è–º.\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
        "print(\"–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å:\", scores.mean())\n",
        "```\n",
        "\n",
        "> ‚úÖ –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ.\n",
        "\n",
        "\n",
        "\n",
        "## 3. Stratified K-Fold (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)\n",
        "\n",
        "–ê–Ω–∞–ª–æ–≥–∏—á–µ–Ω K-Fold, –Ω–æ **—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤** –≤ –∫–∞–∂–¥–æ–º —Ñ–æ–ª–¥–µ. –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ, –µ—Å–ª–∏ –∫–ª–∞—Å—Å—ã –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã.\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, val_index in skf.split(X, y):\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_val, y_val)\n",
        "    print(\"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:\", score)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏.  \n",
        "> ‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.\n",
        "\n",
        "\n",
        "\n",
        "## 4. TimeSeriesSplit (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)\n",
        "\n",
        "–î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ–ª—å–∑—è –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ ‚Äî —ç—Ç–æ –Ω–∞—Ä—É—à–∏—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å. –ü–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ **TimeSeriesSplit**, –≥–¥–µ –¥–∞–Ω–Ω—ã–µ –¥–µ–ª—è—Ç—Å—è –≤ –ø–æ—Ä—è–¥–∫–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏.\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "for train_index, val_index in tscv.split(X):\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_val, y_val)\n",
        "    print(\"–í—Ä–µ–º–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è ‚Äî —Ç–æ—á–Ω–æ—Å—Ç—å:\", score)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ—Ä—è–¥–æ–∫.  \n",
        "> ‚ùå –ù–µ–ª—å–∑—è –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.\n",
        "\n",
        "\n",
        "\n",
        "## 5. –û—Ç–ª–æ–∂–µ–Ω–Ω–∞—è —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ (Hold-out)\n",
        "\n",
        "–ò–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **—Ç—Ä–µ—Ö—á–∞—Å—Ç–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ**:  \n",
        "- `train` ‚Äî –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏,  \n",
        "- `validation` ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤,  \n",
        "- `test` ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞.\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "# –°–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∏–º –Ω–∞ train –∏ test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# –ó–∞—Ç–µ–º –¥–µ–ª–∏–º train –Ω–∞ train –∏ validation\n",
        "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=42)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –æ–±—ä—ë–º–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "\n",
        "\n",
        "## 6. –ì—Ä—É–ø–ø–æ–≤–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (Group-based Splitting)\n",
        "\n",
        "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç **–≥—Ä—É–ø–ø—ã** (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –ø–∞—Ü–∏–µ–Ω—Ç—ã, –∫–ª–∏–µ–Ω—Ç—ã), —Ç–æ –≤–∞–∂–Ω–æ **–Ω–µ –¥–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ–ø–∞–¥–∞–Ω–∏—è –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã –≤ train –∏ test**.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä: GroupKFold\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "for train_idx, val_idx in gkf.split(X, y, groups=groups):\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_val, y_val)\n",
        "    print(\"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\", score)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ò–∑–±–µ–≥–∞–µ–º —É—Ç–µ—á–∫–∏ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–Ω–∞—Ç—å –≥—Ä—É–ø–ø–æ–≤—ã–µ –º–µ—Ç–∫–∏.\n",
        "\n",
        "\n",
        "\n",
        "## 7. Leave-One-Out (LOO) ‚Äî —Ä–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è\n",
        "\n",
        "–ö–∞–∂–¥–∞—è —Ç–æ—á–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –æ–¥–∏–Ω —Ä–∞–∑, –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –æ–±—É—á–∞—é—â–∏–µ.\n",
        "\n",
        "### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "scores = cross_val_score(model, X, y, cv=loo)\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥.  \n",
        "> ‚ùå –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–¥–∫–æ –∏–∑-–∑–∞ –≤—ã—Å–æ–∫–∏—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞—Ç.\n",
        "\n",
        "\n",
        "\n",
        "## üßÆ –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤?\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —á–∏—Å–ª–æ —Ñ–æ–ª–¥–æ–≤ |\n",
        "|--------|-----------------------------|\n",
        "| K-Fold / Stratified K-Fold | 5 –∏–ª–∏ 10 |\n",
        "| TimeSeriesSplit | 3‚Äì5 |\n",
        "| Leave-One-Out | –í—Å–µ —Ç–æ—á–∫–∏ (–æ—á–µ–Ω—å –¥–æ–ª–≥–æ) |\n",
        "| Hold-out | 80% / 20% |\n",
        "\n",
        "–ß–µ–º –º–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö ‚Äî —Ç–µ–º –±–æ–ª—å—à–µ —Ñ–æ–ª–¥–æ–≤ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∫–∞ –±—ã–ª–∞ —É—Å—Ç–æ–π—á–∏–≤–æ–π.\n",
        "\n",
        "\n",
        "\n",
        "## üìà –ü—Ä–∏–º–µ—Ä: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –†–∞–∑–º–µ—Ä train | –†–∞–∑–º–µ—Ä test | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |\n",
        "|--------|--------------|-------------|-------------|\n",
        "| `train_test_split(0.2)` | 80% | 20% | –û–¥–Ω–æ —Ä–∞–∑–±–∏–µ–Ω–∏–µ |\n",
        "| K-Fold (n=5) | ~80% | ~20% | 5 —Ä–∞–∑–±–∏–µ–Ω–∏–π, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ |\n",
        "| Stratified K-Fold | ~80% | ~20% | –¢–æ –∂–µ + —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤ |\n",
        "| TimeSeriesSplit (n=5) | –ü–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é –≤—Ä–µ–º–µ–Ω–∏ | –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è | –£—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ |\n",
        "| GroupKFold (n=5) | –ë–µ–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –≥—Ä—É–ø–ø | –ë–µ–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –≥—Ä—É–ø–ø | –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —É—Ç–µ—á–∫–∏ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ |\n",
        "\n",
        "\n",
        "\n",
        "## üì¶ –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
        "df = pd.read_csv('data.csv')\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = []\n",
        "\n",
        "for train_idx, val_idx in skf.split(X_train, y_train):\n",
        "    pipeline.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
        "    score = pipeline.score(X_train.iloc[val_idx], y_train.iloc[val_idx])\n",
        "    scores.append(score)\n",
        "\n",
        "print(\"–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\", np.mean(scores))\n",
        "\n",
        "# –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö train –¥–∞–Ω–Ω—ã—Ö\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ\n",
        "final_score = pipeline.score(X_test, y_test)\n",
        "print(\"–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ:\", final_score)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üìä –°–æ–≤–µ—Ç—ã –ø–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "| –°–∏—Ç—É–∞—Ü–∏—è | –ß—Ç–æ –¥–µ–ª–∞—Ç—å |\n",
        "|----------|-------------|\n",
        "| –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å K-Fold (5 –∏–ª–∏ 10 —Ñ–æ–ª–¥–æ–≤) |\n",
        "| –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã | Stratified K-Fold |\n",
        "| –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã | TimeSeriesSplit |\n",
        "| –ì—Ä—É–ø–ø—ã –≤ –¥–∞–Ω–Ω—ã—Ö | GroupKFold |\n",
        "| –ö–æ–Ω—Ç—Ä–æ–ª—å —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö | –í—Å–µ–≥–¥–∞ –¥–µ–ª–∏—Ç—å –¥–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ñ–∏—á–µ-–∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ |\n",
        "| –í—ã–±–æ—Ä —á–∏—Å–ª–∞ —Ñ–æ–ª–¥–æ–≤ | 5 –∏–ª–∏ 10 ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é |\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ª—é–±–æ–π –¥–∞—Ç–∞—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Breast Cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)).\n",
        "2. –†–∞–∑–¥–µ–ª–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å–ª–µ–¥—É—é—â–∏–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
        "   - `train_test_split`\n",
        "   - `K-Fold`\n",
        "   - `StratifiedKFold`\n",
        "   - `TimeSeriesSplit` (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä)\n",
        "3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, `RandomForestClassifier`) –Ω–∞ –∫–∞–∂–¥–æ–º –∏–∑ –Ω–∏—Ö.\n",
        "4. –°—Ä–∞–≤–Ω–∏—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (accuracy, F1-score).\n",
        "5. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏ ‚Äî –æ—Å–Ω–æ–≤–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏. –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n",
        "\n",
        "- **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `train_test_split()`** –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.\n",
        "- **–ü—Ä–∏–º–µ–Ω—è–π—Ç–µ `K-Fold` –∏–ª–∏ `Stratified K-Fold`**, –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞.\n",
        "- **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `TimeSeriesSplit`**, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä.\n",
        "- **–£—á–∏—Ç—ã–≤–∞–π—Ç–µ –≥—Ä—É–ø–ø–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É**, –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –æ–±—ä–µ–∫—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏).\n",
        "- **–ù–µ –∑–∞–±—ã–≤–∞–π—Ç–µ –ø—Ä–æ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é**, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –∫–ª–∞—Å—Å—ã –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã.\n",
        "\n",
        "–•–æ—á–µ—à—å, —á—Ç–æ–±—ã —è –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏? –ù–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –∏–ª–∏ —Å —É—á—ë—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö ID ‚Äî –ø–∏—à–∏, —Å–¥–µ–ª–∞—é!"
      ],
      "metadata": {
        "id": "umXdXl51qGzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ 12. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (Class Imbalance Handling)  \n",
        "## üìå –í–≤–µ–¥–µ–Ω–∏–µ\n",
        "\n",
        "**–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤** ‚Äî —ç—Ç–æ –≤–∞–∂–Ω—ã–π —ç—Ç–∞–ø –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∑–∞–¥–∞—á–∞–º–∏ **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**, –≤ –∫–æ—Ç–æ—Ä—ã—Ö **–∫–ª–∞—Å—Å—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ**. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –∑–∞–¥–∞—á–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –º–æ–≥—É—Ç —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å 99.9% –¥–∞–Ω–Ω—ã—Ö, –∞ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ ‚Äî –ª–∏—à—å 0.1%. –¢–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è **–Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ (imbalanced)**.\n",
        "\n",
        "–ï—Å–ª–∏ –Ω–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç:\n",
        "- **–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–¥–∫–∏–π –∫–ª–∞—Å—Å**,\n",
        "- –¥–∞–≤–∞—Ç—å –≤—ã—Å–æ–∫—É—é –º–µ—Ç—Ä–∏–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, `accuracy`), –Ω–æ –±—ã—Ç—å –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ–π –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ,\n",
        "- **–ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ —á–∞—Å—Ç–æ–º –∫–ª–∞—Å—Å–µ** –∏ –ø–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ —Ä–µ–¥–∫–æ–º.\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ü–æ—á–µ–º—É –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–∞–∂–Ω–∞?\n",
        "\n",
        "| –ü—Ä–æ–±–ª–µ–º–∞ | –†–µ—à–µ–Ω–∏–µ |\n",
        "|---------|----------|\n",
        "| –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö | –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ |\n",
        "| –ó–∞–≤—ã—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (`accuracy`) | –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ |\n",
        "| –£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ train –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏ |\n",
        "| –°–º–µ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ | Oversampling / Undersampling |\n",
        "\n",
        "\n",
        "\n",
        "## üî¢ –¢–∏–ø—ã –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ –∫–ª–∞—Å—Å–æ–≤\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –û–ø–∏—Å–∞–Ω–∏–µ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
        "|--------|----------|---------------------|\n",
        "| **Undersampling** | –£–º–µ–Ω—å—à–µ–Ω–∏–µ —á–∏—Å–ª–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –±–æ–ª—å—à–æ–≥–æ –∫–ª–∞—Å—Å–∞ | –ú–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö, –º–∞–ª–∞—è —Ü–µ–Ω–∞ –ø–æ—Ç–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ |\n",
        "| **Oversampling** | –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –º–∞–ª–æ–≥–æ –∫–ª–∞—Å—Å–∞ | –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –≤–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã |\n",
        "| **–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã (SMOTE, ADASYN)** | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –º–∞–ª–æ–≥–æ –∫–ª–∞—Å—Å–∞ | –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, –Ω—É–∂–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ |\n",
        "| **–í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (`class_weight`)** | –£—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏ | –ö–æ–≥–¥–∞ –Ω–µ–ª—å–∑—è –º–µ–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ |\n",
        "| **–ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏** | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ F1, ROC AUC –≤–º–µ—Å—Ç–æ accuracy | –ü—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ |\n",
        "\n",
        "\n",
        "\n",
        "## 1. Oversampling: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "\n",
        "### a) **Random Oversampling**\n",
        "\n",
        "–ü—Ä–æ—Å—Ç–æ **–¥—É–±–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã** –∏–∑ —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞.\n",
        "\n",
        "```python\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler()\n",
        "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± —É—Ä–∞–≤–Ω—è—Ç—å –∫–ª–∞—Å—Å—ã.  \n",
        "> ‚ùå –ú–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ.\n",
        "\n",
        "\n",
        "\n",
        "### b) **SMOTE (Synthetic Minority Over-sampling Technique)**\n",
        "\n",
        "–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç **—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã** –º–µ–∂–¥—É —Å–æ—Å–µ–¥—è–º–∏ —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞.\n",
        "\n",
        "```python\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "#### –ü–ª—é—Å—ã:\n",
        "- –ù–µ –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ.\n",
        "- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞.\n",
        "\n",
        "#### –ú–∏–Ω—É—Å—ã:\n",
        "- –ú–æ–∂–µ—Ç —Å–æ–∑–¥–∞—Ç—å —à—É–º–æ–≤—ã–µ –æ–±—Ä–∞–∑—Ü—ã.\n",
        "- –¢—Ä–µ–±—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ—Å–µ–¥–µ–π.\n",
        "\n",
        "\n",
        "\n",
        "### c) **ADASYN (Adaptive Synthetic Sampling)**\n",
        "\n",
        "–ê–Ω–∞–ª–æ–≥ SMOTE, –Ω–æ –¥–µ–ª–∞–µ—Ç –±–æ–ª—å—à–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Å–ª–æ–∂–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö.\n",
        "\n",
        "```python\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "adasyn = ADASYN()\n",
        "X_res, y_res = adasyn.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ —Ä–µ–¥–∫–∏–π –∫–ª–∞—Å—Å —Å–ª–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "\n",
        "\n",
        "\n",
        "## 2. Undersampling: —É–º–µ–Ω—å—à–µ–Ω–∏–µ –±–æ–ª—å—à–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "\n",
        "### a) **Random Undersampling**\n",
        "\n",
        "–°–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º **—É–¥–∞–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç—ã –∏–∑ –±–æ–ª—å—à–æ–≥–æ –∫–ª–∞—Å—Å–∞**.\n",
        "\n",
        "```python\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler()\n",
        "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ.  \n",
        "> ‚ùå –ú–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–æ—Ç–µ—Ä–µ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "### b) **Tomek Links**\n",
        "\n",
        "–ù–∞—Ö–æ–¥–∏—Ç **\"–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ\" —Ç–æ—á–∫–∏** –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏ –∏ —É–¥–∞–ª—è–µ—Ç –∏—Ö.\n",
        "\n",
        "```python\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "tl = TomekLinks()\n",
        "X_res, y_res = tl.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –£–±–∏—Ä–∞–µ—Ç \"—à—É–º\" –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è.\n",
        "\n",
        "\n",
        "\n",
        "### c) **NearMiss**\n",
        "\n",
        "–í—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –∏–∑ –±–æ–ª—å—à–æ–≥–æ –∫–ª–∞—Å—Å–∞, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ –¥–æ –º–∞–ª–æ–≥–æ –∫–ª–∞—Å—Å–∞.\n",
        "\n",
        "```python\n",
        "from imblearn.under_sampling import NearMiss\n",
        "\n",
        "nm = NearMiss(version=1)\n",
        "X_res, y_res = nm.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "\n",
        "\n",
        "\n",
        "## 3. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥\n",
        "\n",
        "–ú–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å oversampling –∏ undersampling:\n",
        "\n",
        "```python\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "over = SMOTE(sampling_strategy=0.5)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 50% –æ—Ç –±–æ–ª—å—à–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "under = RandomUnderSampler(sampling_strategy=0.7)  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 70%\n",
        "\n",
        "pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
        "X_res, y_res = pipeline.fit_resample(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö.  \n",
        "> ‚ùå –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "\n",
        "\n",
        "## 4. –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (class_weight)\n",
        "\n",
        "–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∑–≤–æ–ª—è—é—Ç –∑–∞–¥–∞—Ç—å **–≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤**, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å —É–¥–µ–ª—è–ª–∞ –±–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è —Ä–µ–¥–∫–æ–º—É –∫–ª–∞—Å—Å—É.\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä: RandomForestClassifier\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä: XGBoost\n",
        "\n",
        "```python\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(scale_pos_weight=weight_for_positive_class)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "> ‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±.  \n",
        "> ‚ùå –ù–µ –≤—Å–µ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ.\n",
        "\n",
        "\n",
        "\n",
        "## 5. –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏\n",
        "\n",
        "Accuracy ‚Äî –ø–ª–æ—Ö–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n",
        "\n",
        "| –ú–µ—Ç—Ä–∏–∫–∞ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
        "|--------|---------------------|\n",
        "| **F1-score** | –ö–æ–≥–¥–∞ –≤–∞–∂–Ω—ã –∏ precision, –∏ recall |\n",
        "| **Precision / Recall** | –ï—Å–ª–∏ –≤–∞–∂–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –∏–ª–∏ –ø–æ–ª–Ω–æ—Ç–∞ |\n",
        "| **ROC AUC** | –î–ª—è –¥–≤–æ–∏—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ |\n",
        "| **PR AUC (Precision-Recall AUC)** | –ï—Å–ª–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å —Ä–µ–¥–∫–∏–π |\n",
        "| **Balanced Accuracy** | –ï—Å–ª–∏ –∫–ª–∞—Å—Å—ã —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã |\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä:\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç–æ–¥–æ–≤\n",
        "\n",
        "| –ú–µ—Ç–æ–¥ | –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |\n",
        "|--------|---------------|---------------|-------------|\n",
        "| Random Oversampling | –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö | –ü—Ä–æ—Å—Ç–æ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è | –ú–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ |\n",
        "| SMOTE | –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö | –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ –æ–±—Ä–∞–∑—Ü—ã | –ú–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —à—É–º |\n",
        "| ADASYN | –°–ª–æ–∂–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞ | –ê–¥–∞–ø—Ç–∏–≤–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç | –í—ã—Å–æ–∫–∏–µ –∑–∞—Ç—Ä–∞—Ç—ã |\n",
        "| Random Undersampling | –ú–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö | –£—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ | –ü–æ—Ç–µ—Ä—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ |\n",
        "| Tomek Links | –ß–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö | –£–±–∏—Ä–∞–µ—Ç —à—É–º –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏ | –£–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ |\n",
        "| NearMiss | –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ | –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã | –ú–æ–∂–µ—Ç –ø–æ—Ç–µ—Ä—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é |\n",
        "| Class Weight | –í—Å–µ —Å–ª—É—á–∞–∏ | –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö | –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ |\n",
        "| –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ | –í—Å–µ —Å–ª—É—á–∞–∏ | –û–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ | –ù–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ |\n",
        "\n",
        "\n",
        "\n",
        "## üìà –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏?\n",
        "\n",
        "| –ó–∞–¥–∞—á–∞ | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |\n",
        "|--------|---------------|\n",
        "| –û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–¥–∫–æ–º—É –∫–ª–∞—Å—Å—É | SMOTE / ADASYN |\n",
        "| –ï—Å—Ç—å –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö, –º–æ–∂–Ω–æ —Ç–µ—Ä—è—Ç—å —á–∞—Å—Ç—å | Undersampling |\n",
        "| –ù–µ–ª—å–∑—è –º–µ–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ | class_weight |\n",
        "| –ù—É–∂–Ω–æ —É—á–µ—Å—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–æ–Ω—ã —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞ | ADASYN |\n",
        "| –ù—É–∂–Ω–æ —É–±—Ä–∞—Ç—å —à—É–º –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏ | Tomek Links |\n",
        "| –ù—É–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –±–æ–ª—å—à–∏–π –∫–ª–∞—Å—Å | NearMiss / Random Under |\n",
        "| –ù—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –æ–±–æ–±—â–∞—é—â—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å | SMOTE + Tomek Links (–≥–∏–±—Ä–∏–¥) |\n",
        "\n",
        "\n",
        "\n",
        "## üß™ –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
        "pipeline = imbpipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üìâ –ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –∫–ª–∞—Å—Å—ã —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã?\n",
        "\n",
        "### a) –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `f1_weighted`, `precision_weighted`, `recall_weighted`.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "score = f1_score(y_test, y_pred, average='weighted')\n",
        "```\n",
        "\n",
        "### b) –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "for train_idx, val_idx in skf.split(X, y):\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    score = pipeline.score(X_val, y_val)\n",
        "    print(\"Validation Score:\", score)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## üì¶ –ü—Ä–∏–º–µ—Ä: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–æ –∏ –ø–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏\n",
        "\n",
        "| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ | –ü–æ—Å–ª–µ SMOTE |\n",
        "|--------|------------------|--------------|\n",
        "| Accuracy | 0.98 | 0.95 |\n",
        "| Precision (positive) | 0.35 | 0.72 |\n",
        "| Recall (positive) | 0.10 | 0.68 |\n",
        "| F1-score | 0.15 | 0.70 |\n",
        "\n",
        "> üí° –î–∞–∂–µ –µ—Å–ª–∏ accuracy —É–ø–∞–ª, –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–ª—É—á—à–µ–Ω–∏–µ!\n",
        "\n",
        "\n",
        "\n",
        "## üß∞ –ü–æ–ª–µ–∑–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ |\n",
        "|------------|-------------|\n",
        "| **scikit-learn** | class_weight, –º–µ—Ç—Ä–∏–∫–∏ |\n",
        "| **imbalanced-learn (imblearn)** | SMOTE, ADASYN, RandomOverSampler, TomekLinks –∏ –¥—Ä. |\n",
        "| **xgboost / lightgbm / catboost** | scale_pos_weight |\n",
        "| **sklearn.metrics** | weighted, macro, micro –º–µ—Ç—Ä–∏–∫–∏ |\n",
        "| **eli5 / shap** | –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —É—á—ë—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ |\n",
        "\n",
        "\n",
        "\n",
        "## üìö –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n",
        "\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)).\n",
        "2. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã:\n",
        "   - Random Oversampling\n",
        "   - SMOTE\n",
        "   - Random Undersampling\n",
        "   - Tomek Links\n",
        "   - ADASYN\n",
        "3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, `RandomForestClassifier`) –Ω–∞ –∫–∞–∂–¥–æ–º –∏–∑ –Ω–∏—Ö.\n",
        "4. –°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º:\n",
        "   - Accuracy\n",
        "   - F1-score\n",
        "   - ROC AUC\n",
        "   - Precision / Recall\n",
        "5. –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥: –∫–∞–∫–æ–π –º–µ—Ç–æ–¥ –¥–∞–ª –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø–æ—á–µ–º—É?\n",
        "\n",
        "\n",
        "\n",
        "## üß† –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ ‚Äî –æ–¥–∏–Ω –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —à–∞–≥–æ–≤ –≤ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç:\n",
        "- **—É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö**;\n",
        "- **–∏–∑–±–µ–∂–∞—Ç—å –∑–∞–≤—ã—à–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏** —á–µ—Ä–µ–∑ `accuracy`;\n",
        "- **—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é** –æ —Ä–µ–¥–∫–∏—Ö —Å–æ–±—ã—Ç–∏—è—Ö (–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ, –æ—Ç–∫–∞–∑ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –±–æ–ª–µ–∑–Ω–∏ –∏ —Ç.–¥.).\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–¥–æ–±—Ä–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –º–æ–∂–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–≤—ã—Å–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ —Ä–µ–¥–∫–∏–π –∫–ª–∞—Å—Å –∏–º–µ–µ—Ç –±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.\n"
      ],
      "metadata": {
        "id": "Z65e1QTByPSp"
      }
    }
  ]
}