{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYZvICYAY83bvAz0xy6iZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/DL/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D1%8B_Generative_Adversarial_Networks_(GANs).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Математические основы Generative Adversarial Networks (GANs)**\n",
        "\n",
        "Generative Adversarial Networks (GANs) представляют собой семейство генеративных моделей, предназначенных для восстановления неизвестного распределения, лежащего в основе процесса генерации данных. Это распределение восстанавливается посредством состязательного взаимодействия между двумя моделями: генератором и дискриминатором. Как уже обсуждалось в предыдущих вводных материалах по GANs, эти модели обучаются таким образом, что дискриминатор стремится корректно классифицировать реальные и сгенерированные данные, в то время как генератор пытается минимизировать способность дискриминатора к различию, создавая данные, максимально похожие на реальные.\n",
        "\n",
        "В данной лекции мы подробно рассмотрим математические основы GANs. Основным источником для анализа является работа *\"Generative Adversarial Nets\"* (Ian Goodfellow et al.), в которой впервые была предложена концепция GANs. Начнем с анализа этой статьи.\n",
        "\n",
        "### Мотивация функции потерь\n",
        "\n",
        "GANs можно рассматривать как систему, состоящую из двух взаимодействующих моделей: генератора и дискриминатора. Каждая из этих моделей имеет свою функцию потерь. В данном разделе мы попытаемся интуитивно обосновать вид функции потерь для каждой из моделей.\n",
        "\n",
        "#### Обозначения\n",
        "\n",
        "Для минимизации путаницы введем следующие обозначения, которые будут использоваться на протяжении всей лекции:\n",
        "\n",
        "- $x$: Реальные данные.\n",
        "- $z$: Латентный вектор (шум).\n",
        "- $G(z)$: Сгенерированные данные.\n",
        "- $D(x)$: Оценка дискриминатора для реальных данных.\n",
        "- $D(G(z))$: Оценка дискриминатора для сгенерированных данных.\n",
        "- $\\text{Error}(a, b)$: Функция ошибки, измеряющая различие между $a$ и $b$.\n",
        "\n",
        "#### Дискриминатор\n",
        "\n",
        "Цель дискриминатора заключается в корректной классификации реальных данных как истинных ($1$), а сгенерированных данных как ложных ($0$). Таким образом, функция потерь для дискриминатора может быть записана следующим образом:\n",
        "\n",
        "$$\n",
        "L_D = \\text{Error}(D(x), 1) + \\text{Error}(D(G(z)), 0) \\quad (1)\n",
        "$$\n",
        "\n",
        "Здесь $\\text{Error}$ обозначает функцию, измеряющую различие между двумя величинами. Если данная запись напоминает вам кросс-энтропию или расхождение Кульбака-Лейблера, это не случайно, так как эти метрики широко используются в задачах классификации.\n",
        "\n",
        "#### Генератор\n",
        "\n",
        "Аналогичным образом можно определить функцию потерь для генератора. Цель генератора заключается в том, чтобы \"обмануть\" дискриминатор, заставив его классифицировать сгенерированные данные как реальные. Таким образом, функция потерь генератора может быть записана как:\n",
        "\n",
        "$$\n",
        "L_G = \\text{Error}(D(G(z)), 1) \\quad (2)\n",
        "$$\n",
        "\n",
        "Важно отметить, что функция потерь — это величина, которую необходимо минимизировать. В случае генератора, минимизация $L_G$ достигается, когда $D(G(z))$ приближается к $1$, что соответствует ошибочной классификации сгенерированных данных как реальных.\n",
        "\n",
        "#### Бинарная кросс-энтропия\n",
        "\n",
        "Одной из наиболее распространенных функций потерь в задачах бинарной классификации является бинарная кросс-энтропия. Напомним, что формула для кросс-энтропии имеет вид:\n",
        "\n",
        "$$\n",
        "H(p, q) = \\mathbb{E}_{x \\sim p(x)}[-\\log q(x)] \\quad (3)\n",
        "$$\n",
        "\n",
        "В задачах классификации случайная величина является дискретной, поэтому математическое ожидание может быть выражено в виде суммы:\n",
        "\n",
        "$$\n",
        "H(p, q) = -\\sum_{x \\in \\chi} p(x) \\log q(x) \\quad (4)\n",
        "$$\n",
        "\n",
        "Для случая бинарной кросс-энтропии, где метки принимают значения $0$ или $1$, выражение упрощается:\n",
        "\n",
        "$$\n",
        "H(y, \\hat{y}) = -\\sum \\left( y \\log \\hat{y} + (1 - y) \\log (1 - \\hat{y}) \\right) \\quad (5)\n",
        "$$\n",
        "\n",
        "Именно эта функция $\\text{Error}$ использовалась в предыдущих разделах. Бинарная кросс-энтропия удовлетворяет нашим требованиям, так как она измеряет различие между двумя распределениями в контексте бинарной классификации. Применив эту функцию к выражениям (1) и (2), получим:\n",
        "\n",
        "$$\n",
        "L_D = -\\sum_{x \\in \\chi, z \\in \\zeta} \\left( \\log D(x) + \\log (1 - D(G(z))) \\right) \\quad (6)\n",
        "$$\n",
        "\n",
        "Аналогично для генератора:\n",
        "\n",
        "$$\n",
        "L_G = -\\sum_{z \\in \\zeta} \\log D(G(z)) \\quad (7)\n",
        "$$\n",
        "\n",
        "Теперь мы имеем две функции потерь, которые могут быть использованы для обучения генератора и дискриминатора. Заметим, что для функции потерь генератора $L_G$ значение потерь будет малым, если $D(G(z))$ близко к $1$, так как $\\log(1) = 0$. Это именно то поведение, которое мы ожидаем от функции потерь генератора. Аналогичная логика применима и к функции потерь дискриминатора $L_D$.\n",
        "\n",
        "\n",
        "**Дополнительные замечания и оптимизация модели**\n",
        "\n",
        "В оригинальной работе Goodfellow et al. представлен несколько иной вариант функций потерь по сравнению с теми, которые были выведены выше. Рассмотрим этот вариант:\n",
        "\n",
        "$$\n",
        "\\max_D \\left\\{ \\log(D(x)) + \\log(1 - D(G(z))) \\right\\} \\quad (8)\n",
        "$$\n",
        "\n",
        "Основное различие между выражениями (6) и (8) заключается в знаке и в том, минимизируется или максимизируется целевая функция. В (6) функция потерь была представлена как задача минимизации, тогда как в оригинальной формулировке она представлена как задача максимизации с обратным знаком.\n",
        "\n",
        "Goodfellow далее формулирует задачу как минимаксную игру, в которой дискриминатор стремится максимизировать целевую функцию, а генератор — минимизировать её. Математически это выражается следующим образом:\n",
        "\n",
        "$$\n",
        "\\min_G \\max_D \\left\\{ \\log(D(x)) + \\log(1 - D(G(z))) \\right\\} \\quad (9)\n",
        "$$\n",
        "\n",
        "Данная минимаксная формулировка компактно отражает состязательный характер взаимодействия между генератором и дискриминатором. Однако на практике используются отдельные функции потерь для генератора и дискриминатора, как было показано ранее. Это связано с тем, что градиент функции $y = \\log(x)$ вблизи $x = 0$ является более крутым по сравнению с градиентом функции $y = \\log(1 - x)$. Следовательно, максимизация $\\log(D(G(z)))$ (или эквивалентная минимизация $-\\log(D(G(z)))$) приводит к более быстрым и значительным улучшениям в работе генератора, чем минимизация $\\log(1 - D(G(z)))$.\n",
        "\n",
        "### Оптимизация модели\n",
        "\n",
        "Теперь, когда функции потерь для генератора и дискриминатора определены, можно перейти к решению задачи оптимизации, то есть к поиску параметров моделей, которые минимизируют (или максимизируют) соответствующие функции потерь. На практике это соответствует процессу обучения модели.\n",
        "\n",
        "\n",
        "## **Обучение дискриминатора**\n",
        "\n",
        "При обучении Generative Adversarial Networks (GANs) обычно обучают одну модель за раз. Это означает, что при обучении дискриминатора генератор считается фиксированным. Такой подход был продемонстрирован в предыдущих материалах, посвященных построению базовой GAN.\n",
        "\n",
        "Вернемся к минимаксной игре, описанной ранее. Целевая функция, которую мы рассматриваем, может быть выражена как функция от генератора $G$ и дискриминатора $D$. Назовем её функцией ценности (value function):\n",
        "\n",
        "$$\n",
        "V(G, D) = \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log(D(x))] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))] \\quad (10)\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "- $p_{\\text{data}}$ — распределение реальных данных,\n",
        "- $p_z$ — распределение латентного вектора $z$,\n",
        "- $D(x)$ — вероятность, присвоенная дискриминатором тому, что $x$ является реальным данным.\n",
        "\n",
        "### Что такое $\\mathbb{E}_{x \\sim p_{\\text{data}}}$?\n",
        "\n",
        "Обозначение $\\mathbb{E}_{x \\sim p_{\\text{data}}}$ означает **математическое ожидание** функции $\\log(D(x))$, вычисленное по распределению реальных данных $p_{\\text{data}}$. Математическое ожидание — это среднее значение функции по всем возможным значениям $x$, взятым из распределения $p_{\\text{data}}$.\n",
        "\n",
        "#### Подробнее:\n",
        "1. **Математическое ожидание**:\n",
        "   - Математическое ожидание $\\mathbb{E}$ — это оператор, который возвращает среднее значение функции случайной величины. В данном случае функция — это $\\log(D(x))$, а случайная величина — $x$, распределенная согласно $p_{\\text{data}}$.\n",
        "\n",
        "2. **Распределение $p_{\\text{data}}$**:\n",
        "   - $p_{\\text{data}}$ — это распределение, из которого берутся реальные данные. Например, если мы работаем с изображениями, $p_{\\text{data}}$ описывает вероятность появления каждого изображения в наборе данных.\n",
        "\n",
        "3. **Интегральная форма**:\n",
        "   - Математическое ожидание можно выразить через интеграл:\n",
        "     $$\n",
        "     \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log(D(x))] = \\int_{x \\in \\chi} p_{\\text{data}}(x) \\log(D(x)) \\, dx\n",
        "     $$\n",
        "     где $\\chi$ — это пространство всех возможных значений $x$.\n",
        "\n",
        "4. **Практическая аппроксимация**:\n",
        "   - На практике, когда у нас есть конечный набор данных, математическое ожидание аппроксимируется средним значением по всем доступным образцам:\n",
        "     $$\n",
        "     \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log(D(x))] \\approx \\frac{1}{N} \\sum_{i=1}^N \\log(D(x_i))\n",
        "     $$\n",
        "     где $x_i$ — это реальные данные из обучающего набора, а $N$ — количество образцов.\n",
        "\n",
        "### Продолжение о функции ценности:\n",
        "\n",
        "На практике нас больше интересует распределение, моделируемое генератором, чем $p_z$. Поэтому введем новую переменную $y = G(z)$, которая представляет сгенерированные данные. Используя эту подстановку, перепишем функцию ценности:\n",
        "\n",
        "$$\n",
        "V(G, D) = \\mathbb{E}_{x \\sim p_{\\text{data}}}[\\log(D(x))] + \\mathbb{E}_{y \\sim p_g}[\\log(1 - D(y))] \\quad (11)\n",
        "$$\n",
        "\n",
        "где $p_g$ — распределение сгенерированных данных. В интегральной форме это выражение принимает вид:\n",
        "\n",
        "$$\n",
        "V(G, D) = \\int_{x \\in \\chi} \\left( p_{\\text{data}}(x) \\log(D(x)) + p_g(x) \\log(1 - D(x)) \\right) dx \\quad (11)\n",
        "$$\n",
        "\n",
        "Цель дискриминатора заключается в максимизации этой функции ценности. Чтобы найти оптимальный дискриминатор $D^*(x)$, возьмем частную производную $V(G, D)$ по $D(x)$ и приравняем её к нулю:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial V(G, D)}{\\partial D(x)} = \\frac{p_{\\text{data}}(x)}{D(x)} - \\frac{p_g(x)}{1 - D(x)} = 0 \\quad (12)\n",
        "$$\n",
        "\n",
        "Решая это уравнение относительно $D(x)$, получаем оптимальный дискриминатор:\n",
        "\n",
        "$$\n",
        "D^*(x) = \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} \\quad (12)\n",
        "$$\n",
        "\n",
        "Это условие для оптимального дискриминатора. Данная формула интуитивно понятна:\n",
        "- Если образец $x$ является реальным, то $p_{\\text{data}}(x)$ близко к 1, а $p_g(x)$ близко к 0. В этом случае $D^*(x)$ стремится к 1, что соответствует корректной классификации.\n",
        "- Если образец $x = G(z)$ является сгенерированным, то $p_{\\text{data}}(G(z))$ близко к 0, и $D^*(x)$ стремится к 0, что также соответствует корректной классификации.\n",
        "\n",
        "\n",
        "##**Обучение генератора**\n",
        "\n",
        "Для обучения генератора предполагается, что дискриминатор фиксирован, и проводится анализ функции ценности $V(G, D^*)$. Подставим в функцию ценности оптимальный дискриминатор $D^*(x)$, найденный ранее (формула (12)):\n",
        "\n",
        "$$\n",
        "V(G, D^*) = \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[ \\log(D^*(x)) \\right] + \\mathbb{E}_{x \\sim p_g} \\left[ \\log(1 - D^*(x)) \\right]\n",
        "= \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[ \\log \\left( \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} \\right) \\right] + \\mathbb{E}_{x \\sim p_g} \\left[ \\log \\left( \\frac{p_g(x)}{p_{\\text{data}}(x) + p_g(x)} \\right) \\right] \\quad (13)\n",
        "$$\n",
        "\n",
        "Для дальнейшего анализа воспользуемся некоторыми математическими приемами. Преобразуем выражение (13), выделив константу $-\\log 4$:\n",
        "\n",
        "$$\n",
        "V(G, D^*) = \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[ \\log \\left( \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_g(x)} \\right) \\right] + \\mathbb{E}_{x \\sim p_g} \\left[ \\log \\left( \\frac{p_g(x)}{p_{\\text{data}}(x) + p_g(x)} \\right) \\right]\n",
        "= -\\log 4 + \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[ \\log \\left( \\frac{p_{\\text{data}}(x)}{\\frac{p_{\\text{data}}(x) + p_g(x)}{2}} \\right) \\right] + \\mathbb{E}_{x \\sim p_g} \\left[ \\log \\left( \\frac{p_g(x)}{\\frac{p_{\\text{data}}(x) + p_g(x)}{2}} \\right) \\right] \\quad (14)\n",
        "$$\n",
        "\n",
        "Это преобразование может показаться сложным, но его цель — выделить слагаемое $-\\log 4$ и представить оставшиеся члены в виде, удобном для интерпретации. В результате мы получаем выражение, которое можно связать с расхождением Кульбака-Лейблера (Kullback-Leibler divergence, KL):\n",
        "\n",
        "$$\n",
        "V(G, D^*) = -\\log 4 + D_{\\text{KL}} \\left( p_{\\text{data}} \\middle\\| \\frac{p_{\\text{data}} + p_g}{2} \\right) + D_{\\text{KL}} \\left( p_g \\middle\\| \\frac{p_{\\text{data}} + p_g}{2} \\right) \\quad (15)\n",
        "$$\n",
        "\n",
        "Здесь $D_{\\text{KL}}(P \\| Q)$ — расхождение Кульбака-Лейблера между распределениями $P$ и $Q$. Далее, используя определение дивергенции Йенсена-Шеннона (Jensen-Shannon divergence, JS):\n",
        "\n",
        "$$\n",
        "J(P, Q) = \\frac{1}{2} \\left( D_{\\text{KL}}(P \\| R) + D_{\\text{KL}}(Q \\| R) \\right), \\quad \\text{где } R = \\frac{P + Q}{2}, \\quad (16)\n",
        "$$\n",
        "\n",
        "мы можем переписать выражение (15) в терминах JS-дивергенции:\n",
        "\n",
        "$$\n",
        "V(G, D^*) = -\\log 4 + 2 \\cdot D_{\\text{JS}}(p_{\\text{data}} \\| p_g) \\quad (15)\n",
        "$$\n",
        "\n",
        "### Интерпретация результата\n",
        "\n",
        "Из этого анализа следует важный вывод: цель обучения генератора заключается в минимизации функции ценности $V(G, D^*)$, что эквивалентно минимизации JS-дивергенции между распределением реальных данных $p_{\\text{data}}$ и распределением сгенерированных данных $p_g$. Это полностью согласуется с интуицией: мы хотим, чтобы генератор научился воспроизводить распределение реальных данных как можно точнее. Иными словами, $p_g$ должно быть как можно ближе к $p_{\\text{data}}$.\n",
        "\n",
        "Оптимальный генератор $G$ — это такой генератор, который способен максимально точно аппроксимировать $p_{\\text{data}}$, создавая правдоподобные данные, неотличимые от реальных.\n",
        "\n",
        "### Практические аспекты обучения генератора\n",
        "\n",
        "На практике обучение генератора осуществляется с использованием метода градиентного спуска (поскольку цель — минимизация функции ценности). Обновление параметров генератора $\\theta_G$ происходит следующим образом:\n",
        "\n",
        "$$\n",
        "\\theta_G \\leftarrow \\theta_G - \\eta \\nabla_{\\theta_G} V(G, D^*)\n",
        "$$\n",
        "\n",
        "где $\\eta$ — скорость обучения, а $\\nabla_{\\theta_G} V(G, D^*)$ — градиент функции ценности по параметрам генератора.\n",
        "\n",
        "#### Проблемы обучения генератора\n",
        "\n",
        "1. **Исчезающие градиенты**: Если дискриминатор становится слишком сильным, градиенты функции потерь генератора могут стать очень малыми, что замедляет или останавливает обучение.\n",
        "2. **Модальный коллапс**: Генератор может начать производить ограниченное разнообразие данных, \"застревая\" в одной или нескольких модах распределения реальных данных.\n",
        "\n",
        "Для решения этих проблем используются следующие подходы:\n",
        "- **Регуляризация**: Добавление штрафных членов в функцию потерь генератора для стимулирования разнообразия генерируемых данных.\n",
        "- **Использование альтернативных функций потерь**: Например, в Wasserstein GANs (WGANs) используется метрика Вассерштейна, которая более устойчива к проблеме исчезающих градиентов.\n",
        "- **Методы балансировки**: Периодическое обновление параметров дискриминатора и генератора для поддержания баланса между их обучением.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YDgkpOOhmdhR"
      }
    }
  ]
}