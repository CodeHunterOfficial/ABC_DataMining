{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMC7RbBHa0m6aNfMaYWcRfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/DL/%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_(Convolutional_Neural_Networks).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Сверточные нейронные сети (Convolutional Neural Networks, CNN) с математической точки зрения\n",
        "\n",
        "В этой лекции мы разберем операцию свертки в CNN, используя символическое обозначение элементов матрицы в виде букв, таких как $ x_{00}, x_{01}, x_{02}, \\dots $. Это позволит наглядно показать, как выполняется умножение и суммирование.\n",
        "\n",
        "\n",
        "\n",
        "## 1. Исходные данные и ядро\n",
        "\n",
        "### 1.1. Исходное изображение\n",
        "Пусть входное изображение представлено матрицей $ I $ размером $ 5 \\times 5 $. Обозначим элементы матрицы через $ x_{ij} $, где $ i $ — номер строки, $ j $ — номер столбца:\n",
        "\n",
        "$$\n",
        "I =\n",
        "\\begin{bmatrix}\n",
        "x_{00} & x_{01} & x_{02} & x_{03} & x_{04} \\\\\n",
        "x_{10} & x_{11} & x_{12} & x_{13} & x_{14} \\\\\n",
        "x_{20} & x_{21} & x_{22} & x_{23} & x_{24} \\\\\n",
        "x_{30} & x_{31} & x_{32} & x_{33} & x_{34} \\\\\n",
        "x_{40} & x_{41} & x_{42} & x_{43} & x_{44}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "### 1.2. Ядро свертки\n",
        "Ядро (фильтр) $ K $ задано матрицей размером $ 3 \\times 3 $. Обозначим элементы ядра через $ k_{mn} $, где $ m $ — номер строки, $ n $ — номер столбца:\n",
        "\n",
        "$$\n",
        "K =\n",
        "\\begin{bmatrix}\n",
        "k_{00} & k_{01} & k_{02} \\\\\n",
        "k_{10} & k_{11} & k_{12} \\\\\n",
        "k_{20} & k_{21} & k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## 2. Операция свертки\n",
        "\n",
        "Операция свертки выполняется следующим образом:\n",
        "1. Ядро $ K $ накладывается на подматрицу входного изображения $ I $.\n",
        "2. Выполняется поэлементное умножение значений ядра и подматрицы.\n",
        "3. Результаты умножения суммируются, и получается одно значение выходной карты признаков.\n",
        "\n",
        "Размер выходной карты $ O $ зависит от параметров свертки:\n",
        "- **Шаг (stride)**: Шаг, с которым ядро перемещается по изображению. Пусть $ s = 1 $.\n",
        "- **Паддинг (padding)**: Дополнение границ изображения нулями. Пусть $ p = 0 $ (без паддинга).\n",
        "\n",
        "Для нашего случая размер выходной карты $ O $ будет $ 3 \\times 3 $.\n",
        "\n",
        "\n",
        "\n",
        "## 3. Пошаговое вычисление свертки\n",
        "\n",
        "### 3.1. Первый шаг\n",
        "Наложим ядро $ K $ на верхний левый угол изображения $ I $. Подматрица $ I_{1,1} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{1,1} =\n",
        "\\begin{bmatrix}\n",
        "x_{00} & x_{01} & x_{02} \\\\\n",
        "x_{10} & x_{11} & x_{12} \\\\\n",
        "x_{20} & x_{21} & x_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{1,1} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{1,1} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{00} \\cdot k_{00} & x_{01} \\cdot k_{01} & x_{02} \\cdot k_{02} \\\\\n",
        "x_{10} \\cdot k_{10} & x_{11} \\cdot k_{11} & x_{12} \\cdot k_{12} \\\\\n",
        "x_{20} \\cdot k_{20} & x_{21} \\cdot k_{21} & x_{22} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[1,1] =\n",
        "(x_{00} \\cdot k_{00}) + (x_{01} \\cdot k_{01}) + (x_{02} \\cdot k_{02}) +\n",
        "(x_{10} \\cdot k_{10}) + (x_{11} \\cdot k_{11}) + (x_{12} \\cdot k_{12}) +\n",
        "(x_{20} \\cdot k_{20}) + (x_{21} \\cdot k_{21}) + (x_{22} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "### 3.2. Второй шаг\n",
        "Переместим ядро на один шаг вправо ($ i = 1, j = 2 $). Подматрица $ I_{1,2} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{1,2} =\n",
        "\\begin{bmatrix}\n",
        "x_{01} & x_{02} & x_{03} \\\\\n",
        "x_{11} & x_{12} & x_{13} \\\\\n",
        "x_{21} & x_{22} & x_{23}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{1,2} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{1,2} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{01} \\cdot k_{00} & x_{02} \\cdot k_{01} & x_{03} \\cdot k_{02} \\\\\n",
        "x_{11} \\cdot k_{10} & x_{12} \\cdot k_{11} & x_{13} \\cdot k_{12} \\\\\n",
        "x_{21} \\cdot k_{20} & x_{22} \\cdot k_{21} & x_{23} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[1,2] =\n",
        "(x_{01} \\cdot k_{00}) + (x_{02} \\cdot k_{01}) + (x_{03} \\cdot k_{02}) +\n",
        "(x_{11} \\cdot k_{10}) + (x_{12} \\cdot k_{11}) + (x_{13} \\cdot k_{12}) +\n",
        "(x_{21} \\cdot k_{20}) + (x_{22} \\cdot k_{21}) + (x_{23} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "### 3.3. Третий шаг\n",
        "Переместим ядро еще на один шаг вправо ($ i = 1, j = 3 $). Подматрица $ I_{1,3} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{1,3} =\n",
        "\\begin{bmatrix}\n",
        "x_{02} & x_{03} & x_{04} \\\\\n",
        "x_{12} & x_{13} & x_{14} \\\\\n",
        "x_{22} & x_{23} & x_{24}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{1,3} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{1,3} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{02} \\cdot k_{00} & x_{03} \\cdot k_{01} & x_{04} \\cdot k_{02} \\\\\n",
        "x_{12} \\cdot k_{10} & x_{13} \\cdot k_{11} & x_{14} \\cdot k_{12} \\\\\n",
        "x_{22} \\cdot k_{20} & x_{23} \\cdot k_{21} & x_{24} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[1,3] =\n",
        "(x_{02} \\cdot k_{00}) + (x_{03} \\cdot k_{01}) + (x_{04} \\cdot k_{02}) +\n",
        "(x_{12} \\cdot k_{10}) + (x_{13} \\cdot k_{11}) + (x_{14} \\cdot k_{12}) +\n",
        "(x_{22} \\cdot k_{20}) + (x_{23} \\cdot k_{21}) + (x_{24} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 3.4. Четвертый шаг\n",
        "Переместим ядро на один шаг вниз ($ i = 2, j = 1 $). Подматрица $ I_{2,1} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{2,1} =\n",
        "\\begin{bmatrix}\n",
        "x_{10} & x_{11} & x_{12} \\\\\n",
        "x_{20} & x_{21} & x_{22} \\\\\n",
        "x_{30} & x_{31} & x_{32}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{2,1} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{2,1} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{10} \\cdot k_{00} & x_{11} \\cdot k_{01} & x_{12} \\cdot k_{02} \\\\\n",
        "x_{20} \\cdot k_{10} & x_{21} \\cdot k_{11} & x_{22} \\cdot k_{12} \\\\\n",
        "x_{30} \\cdot k_{20} & x_{31} \\cdot k_{21} & x_{32} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[2,1] =\n",
        "(x_{10} \\cdot k_{00}) + (x_{11} \\cdot k_{01}) + (x_{12} \\cdot k_{02}) +\n",
        "(x_{20} \\cdot k_{10}) + (x_{21} \\cdot k_{11}) + (x_{22} \\cdot k_{12}) +\n",
        "(x_{30} \\cdot k_{20}) + (x_{31} \\cdot k_{21}) + (x_{32} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 3.5. Пятый шаг\n",
        "Переместим ядро на один шаг вправо ($ i = 2, j = 2 $). Подматрица $ I_{2,2} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{2,2} =\n",
        "\\begin{bmatrix}\n",
        "x_{11} & x_{12} & x_{13} \\\\\n",
        "x_{21} & x_{22} & x_{23} \\\\\n",
        "x_{31} & x_{32} & x_{33}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{2,2} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{2,2} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{11} \\cdot k_{00} & x_{12} \\cdot k_{01} & x_{13} \\cdot k_{02} \\\\\n",
        "x_{21} \\cdot k_{10} & x_{22} \\cdot k_{11} & x_{23} \\cdot k_{12} \\\\\n",
        "x_{31} \\cdot k_{20} & x_{32} \\cdot k_{21} & x_{33} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[2,2] =\n",
        "(x_{11} \\cdot k_{00}) + (x_{12} \\cdot k_{01}) + (x_{13} \\cdot k_{02}) +\n",
        "(x_{21} \\cdot k_{10}) + (x_{22} \\cdot k_{11}) + (x_{23} \\cdot k_{12}) +\n",
        "(x_{31} \\cdot k_{20}) + (x_{32} \\cdot k_{21}) + (x_{33} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 3.6. Шестой шаг\n",
        "Переместим ядро еще на один шаг вправо ($ i = 2, j = 3 $). Подматрица $ I_{2,3} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{2,3} =\n",
        "\\begin{bmatrix}\n",
        "x_{12} & x_{13} & x_{14} \\\\\n",
        "x_{22} & x_{23} & x_{24} \\\\\n",
        "x_{32} & x_{33} & x_{34}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{2,3} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{2,3} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{12} \\cdot k_{00} & x_{13} \\cdot k_{01} & x_{14} \\cdot k_{02} \\\\\n",
        "x_{22} \\cdot k_{10} & x_{23} \\cdot k_{11} & x_{24} \\cdot k_{12} \\\\\n",
        "x_{32} \\cdot k_{20} & x_{33} \\cdot k_{21} & x_{34} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[2,3] =\n",
        "(x_{12} \\cdot k_{00}) + (x_{13} \\cdot k_{01}) + (x_{14} \\cdot k_{02}) +\n",
        "(x_{22} \\cdot k_{10}) + (x_{23} \\cdot k_{11}) + (x_{24} \\cdot k_{12}) +\n",
        "(x_{32} \\cdot k_{20}) + (x_{33} \\cdot k_{21}) + (x_{34} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 3.7. Седьмой шаг\n",
        "Переместим ядро на один шаг вниз ($ i = 3, j = 1 $). Подматрица $ I_{3,1} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{3,1} =\n",
        "\\begin{bmatrix}\n",
        "x_{20} & x_{21} & x_{22} \\\\\n",
        "x_{30} & x_{31} & x_{32} \\\\\n",
        "x_{40} & x_{41} & x_{42}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{3,1} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{3,1} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{20} \\cdot k_{00} & x_{21} \\cdot k_{01} & x_{22} \\cdot k_{02} \\\\\n",
        "x_{30} \\cdot k_{10} & x_{31} \\cdot k_{11} & x_{32} \\cdot k_{12} \\\\\n",
        "x_{40} \\cdot k_{20} & x_{41} \\cdot k_{21} & x_{42} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[3,1] =\n",
        "(x_{20} \\cdot k_{00}) + (x_{21} \\cdot k_{01}) + (x_{22} \\cdot k_{02}) +\n",
        "(x_{30} \\cdot k_{10}) + (x_{31} \\cdot k_{11}) + (x_{32} \\cdot k_{12}) +\n",
        "(x_{40} \\cdot k_{20}) + (x_{41} \\cdot k_{21}) + (x_{42} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 3.8. Восьмой шаг\n",
        "Переместим ядро на один шаг вправо ($ i = 3, j = 2 $). Подматрица $ I_{3,2} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{3,2} =\n",
        "\\begin{bmatrix}\n",
        "x_{21} & x_{22} & x_{23} \\\\\n",
        "x_{31} & x_{32} & x_{33} \\\\\n",
        "x_{41} & x_{42} & x_{43}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{3,2} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{3,2} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{21} \\cdot k_{00} & x_{22} \\cdot k_{01} & x_{23} \\cdot k_{02} \\\\\n",
        "x_{31} \\cdot k_{10} & x_{32} \\cdot k_{11} & x_{33} \\cdot k_{12} \\\\\n",
        "x_{41} \\cdot k_{20} & x_{42} \\cdot k_{21} & x_{43} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[3,2] =\n",
        "(x_{21} \\cdot k_{00}) + (x_{22} \\cdot k_{01}) + (x_{23} \\cdot k_{02}) +\n",
        "(x_{31} \\cdot k_{10}) + (x_{32} \\cdot k_{11}) + (x_{33} \\cdot k_{12}) +\n",
        "(x_{41} \\cdot k_{20}) + (x_{42} \\cdot k_{21}) + (x_{43} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 3.10. Девятый шаг\n",
        "Переместим ядро еще на один шаг вправо ($ i = 3, j = 3 $). Подматрица $ I_{3,3} $ имеет вид:\n",
        "\n",
        "$$\n",
        "I_{3,3} =\n",
        "\\begin{bmatrix}\n",
        "x_{22} & x_{23} & x_{24} \\\\\n",
        "x_{32} & x_{33} & x_{34} \\\\\n",
        "x_{42} & x_{43} & x_{44}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выполним поэлементное умножение $ I_{3,3} $ и $ K $:\n",
        "\n",
        "$$\n",
        "I_{3,3} \\odot K =\n",
        "\\begin{bmatrix}\n",
        "x_{22} \\cdot k_{00} & x_{23} \\cdot k_{01} & x_{24} \\cdot k_{02} \\\\\n",
        "x_{32} \\cdot k_{10} & x_{33} \\cdot k_{11} & x_{34} \\cdot k_{12} \\\\\n",
        "x_{42} \\cdot k_{20} & x_{43} \\cdot k_{21} & x_{44} \\cdot k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Суммируем все элементы:\n",
        "\n",
        "$$\n",
        "O[3,3] =\n",
        "(x_{22} \\cdot k_{00}) + (x_{23} \\cdot k_{01}) + (x_{24} \\cdot k_{02}) +\n",
        "(x_{32} \\cdot k_{10}) + (x_{33} \\cdot k_{11}) + (x_{34} \\cdot k_{12}) +\n",
        "(x_{42} \\cdot k_{20}) + (x_{43} \\cdot k_{21}) + (x_{44} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## 3.11. Итоговая матрица $ O $\n",
        "\n",
        "После выполнения всех вычислений получаем выходную матрицу $ O $ размером $ 3 \\times 3 $:\n",
        "\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "O[1,1] & O[1,2] & O[1,3] \\\\\n",
        "O[2,1] & O[2,2] & O[2,3] \\\\\n",
        "O[3,1] & O[3,2] & O[3,3]\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Каждый элемент $ O[i,j] $ вычисляется как сумма произведений элементов соответствующей подматрицы изображения $ I $ и ядра $ K $.\n",
        "\n",
        "\n",
        "\n",
        "##3.12 Общая формула\n",
        "\n",
        "Пусть:\n",
        "- $ I $ — входная матрица размером $ H \\times W $,\n",
        "- $ K $ — ядро свертки размером $ M \\times N $,\n",
        "- $ s $ — шаг (stride),\n",
        "- $ p $ — паддинг (padding).\n",
        "\n",
        "Тогда элемент $ O[i,j] $ выходной матрицы $ O $ вычисляется как:\n",
        "\n",
        "$$\n",
        "O[i,j] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} I[i \\cdot s + m, j \\cdot s + n] \\cdot K[m,n],\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $ i $ и $ j $ — индексы элемента в выходной матрице $ O $,\n",
        "- $ m $ и $ n $ — индексы элементов внутри ядра $ K $,\n",
        "- $ I[i \\cdot s + m, j \\cdot s + n] $ — соответствующий элемент входной матрицы $ I $, который участвует в операции.\n",
        "\n",
        "\n",
        "\n",
        "### Условия для границ\n",
        "\n",
        "Если используется **паддинг** ($ p > 0 $), то входная матрица $ I $ дополняется нулями по краям. Это означает, что при обращении к элементам $ I[i \\cdot s + m, j \\cdot s + n] $, которые выходят за пределы исходной матрицы, их значения считаются равными нулю.\n",
        "\n",
        "Размер выходной матрицы $ O $ определяется следующим образом:\n",
        "\n",
        "$$\n",
        "H_O = \\left\\lfloor \\frac{H + 2p - M}{s} \\right\\rfloor + 1,\n",
        "$$\n",
        "$$\n",
        "W_O = \\left\\lfloor \\frac{W + 2p - N}{s} \\right\\rfloor + 1,\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $ H_O $ и $ W_O $ — высота и ширина выходной матрицы,\n",
        "- $ \\lfloor \\cdot \\rfloor $ — операция взятия целой части числа.\n",
        "\n",
        "\n",
        "\n",
        "### Пример применения формулы\n",
        "\n",
        "Для нашей задачи:\n",
        "- $ H = W = 5 $ (размер входной матрицы),\n",
        "- $ M = N = 3 $ (размер ядра),\n",
        "- $ s = 1 $ (шаг),\n",
        "- $ p = 0 $ (без паддинга).\n",
        "\n",
        "Размер выходной матрицы:\n",
        "\n",
        "$$\n",
        "H_O = W_O = \\left\\lfloor \\frac{5 + 2 \\cdot 0 - 3}{1} \\right\\rfloor + 1 = 3.\n",
        "$$\n",
        "\n",
        "Таким образом, выходная матрица имеет размер $ 3 \\times 3 $.\n",
        "\n",
        "Элемент $ O[i,j] $ вычисляется как:\n",
        "\n",
        "$$\n",
        "O[i,j] = \\sum_{m=0}^{2} \\sum_{n=0}^{2} I[i + m, j + n] \\cdot K[m,n].\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## 4. Паддинг (padding)\n",
        "Паддинг (padding) — это важный параметр в операции свертки (convolution), который определяет, как обрабатываются границы входного изображения. Давайте разберем это понятие максимально подробно: что такое паддинг, зачем он нужен, какие виды существуют и когда его применяют.\n",
        "\n",
        "\n",
        "\n",
        "### **4.1. Что такое паддинг?**\n",
        "Паддинг — это добавление дополнительных \"краевых\" значений (обычно нулей) вокруг исходной матрицы входного изображения перед выполнением операции свертки. Эти дополнительные значения называются \"заполнением\" или \"рамкой\".\n",
        "\n",
        "Например, если у нас есть входная матрица $ I $ размером $ 5 \\times 5 $, а мы применяем паддинг $ p = 1 $, то к каждой стороне матрицы добавляется по одному ряду нулей. В результате размер матрицы увеличивается до $ 7 \\times 7 $:\n",
        "\n",
        "$$\n",
        "I_{\\text{с паддингом}} =\n",
        "\\begin{bmatrix}\n",
        "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
        "0 & x_{00} & x_{01} & x_{02} & x_{03} & x_{04} & 0 \\\\\n",
        "0 & x_{10} & x_{11} & x_{12} & x_{13} & x_{14} & 0 \\\\\n",
        "0 & x_{20} & x_{21} & x_{22} & x_{23} & x_{24} & 0 \\\\\n",
        "0 & x_{30} & x_{31} & x_{32} & x_{33} & x_{34} & 0 \\\\\n",
        "0 & x_{40} & x_{41} & x_{42} & x_{43} & x_{44} & 0 \\\\\n",
        "0 & 0 & 0 & 0 & 0 & 0 & 0\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Здесь нули (или другие значения, если используется нестандартный паддинг) добавлены по периметру исходной матрицы.\n",
        "\n",
        "\n",
        "\n",
        "### **4.2. Зачем нужен паддинг?**\n",
        "Паддинг решает несколько ключевых задач:\n",
        "\n",
        "#### **2.1. Сохранение размера выходной карты признаков**\n",
        "Без паддинга размер выходной карты признаков ($ O $) уменьшается после каждой операции свертки. Это происходит потому, что ядро ($ K $) не может полностью выйти за границы входной матрицы. Например:\n",
        "- Для входной матрицы $ I $ размером $ 5 \\times 5 $,\n",
        "- Ядра $ K $ размером $ 3 \\times 3 $,\n",
        "- Шага $ s = 1 $,\n",
        "размер выходной матрицы $ O $ будет $ 3 \\times 3 $ (как показано в примере из лекции).\n",
        "\n",
        "Если мы хотим сохранить размер входной матрицы ($ 5 \\times 5 $) для выходной карты, нужно использовать паддинг. Например, если добавить паддинг $ p = 1 $, то размер выходной матрицы останется $ 5 \\times 5 $.\n",
        "\n",
        "#### **4.2.2. Обработка граничных пикселей**\n",
        "При выполнении свертки центральные пиксели входного изображения участвуют в большем количестве вычислений, чем граничные пиксели. Это связано с тем, что ядро может быть полностью наложено только на центральные области изображения. Паддинг позволяет уравнять \"вклад\" всех пикселей, включая те, которые находятся на границах.\n",
        "\n",
        "#### **4.2.3. Увеличение глубины сети**\n",
        "В глубоких нейронных сетях часто требуется выполнять много последовательных операций свертки. Без паддинга размеры данных будут быстро уменьшаться, что может привести к потере важной информации. Паддинг помогает поддерживать размеры данных на протяжении всей сети.\n",
        "\n",
        "\n",
        "\n",
        "### **4.3. Типы паддинга**\n",
        "Существует несколько типов паддинга, которые различаются способом заполнения границ:\n",
        "\n",
        "#### **4.3.1. Zero Padding (нулевой паддинг)**\n",
        "Наиболее распространенный тип паддинга. Границы матрицы дополняются нулями. Это просто и эффективно, но может привести к появлению \"артефактов\" на границах выходной карты признаков.\n",
        "\n",
        "Пример:\n",
        "$$\n",
        "I_{\\text{с zero padding}} =\n",
        "\\begin{bmatrix}\n",
        "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
        "0 & x_{00} & x_{01} & x_{02} & x_{03} & x_{04} & 0 \\\\\n",
        "0 & x_{10} & x_{11} & x_{12} & x_{13} & x_{14} & 0 \\\\\n",
        "0 & x_{20} & x_{21} & x_{22} & x_{23} & x_{24} & 0 \\\\\n",
        "0 & x_{30} & x_{31} & x_{32} & x_{33} & x_{34} & 0 \\\\\n",
        "0 & x_{40} & x_{41} & x_{42} & x_{43} & x_{44} & 0 \\\\\n",
        "0 & 0 & 0 & 0 & 0 & 0 & 0\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "#### **4.3.2. Valid Padding**\n",
        "Это отсутствие паддинга. Ядро накладывается только на те области входной матрицы, где оно полностью помещается. Размер выходной матрицы всегда меньше входной.\n",
        "\n",
        "Пример:\n",
        "Для входной матрицы $ 5 \\times 5 $, ядра $ 3 \\times 3 $ и шага $ s = 1 $ размер выходной матрицы будет $ 3 \\times 3 $.\n",
        "\n",
        "#### **4.3.3. Same Padding**\n",
        "Паддинг подбирается таким образом, чтобы размер выходной матрицы был равен размеру входной матрицы. Это достигается за счет добавления необходимого количества строк и столбцов с нулями (или другими значениями).\n",
        "\n",
        "Формула для расчета паддинга:\n",
        "$$\n",
        "p = \\frac{M - 1}{2},\n",
        "$$\n",
        "где $ M $ — размер ядра.\n",
        "\n",
        "Пример:\n",
        "Для ядра $ 3 \\times 3 $ паддинг $ p = 1 $. Для ядра $ 5 \\times 5 $ паддинг $ p = 2 $.\n",
        "\n",
        "#### **4.3.4. Reflection Padding**\n",
        "Границы заполняются значениями, отраженными от ближайших пикселей входной матрицы. Этот метод помогает избежать появления \"нулевых\" областей на выходной карте признаков.\n",
        "\n",
        "Пример:\n",
        "$$\n",
        "I_{\\text{с reflection padding}} =\n",
        "\\begin{bmatrix}\n",
        "x_{11} & x_{10} & x_{11} & x_{12} & x_{13} & x_{14} & x_{13} \\\\\n",
        "x_{01} & x_{00} & x_{01} & x_{02} & x_{03} & x_{04} & x_{03} \\\\\n",
        "x_{11} & x_{10} & x_{11} & x_{12} & x_{13} & x_{14} & x_{13} \\\\\n",
        "x_{21} & x_{20} & x_{21} & x_{22} & x_{23} & x_{24} & x_{23} \\\\\n",
        "x_{31} & x_{30} & x_{31} & x_{32} & x_{33} & x_{34} & x_{33} \\\\\n",
        "x_{41} & x_{40} & x_{41} & x_{42} & x_{43} & x_{44} & x_{43} \\\\\n",
        "x_{31} & x_{30} & x_{31} & x_{32} & x_{33} & x_{34} & x_{33}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### **4.4. Когда используется паддинг?**\n",
        "\n",
        "#### **4.4.1. При сохранении размера данных**\n",
        "Если требуется, чтобы размер выходной карты признаков совпадал с размером входной матрицы, используется **same padding**.\n",
        "\n",
        "#### **4.4.2. В глубоких сетях**\n",
        "В глубоких архитектурах (например, ResNet) важно поддерживать размеры данных на каждом уровне сети. Паддинг помогает избежать быстрого уменьшения размеров после нескольких сверток.\n",
        "\n",
        "#### **4.4.3. При работе с маленькими изображениями**\n",
        "Для небольших входных данных (например, $ 8 \\times 8 $) использование паддинга позволяет избежать слишком быстрого уменьшения размеров выходной карты.\n",
        "\n",
        "#### **4.4.4. При обучении сегментации изображений**\n",
        "В задачах сегментации (например, U-Net) важно сохранять пространственные размеры данных, чтобы выходная карта могла быть сопоставлена с исходным изображением.\n",
        "\n",
        "\n",
        "\n",
        "### **4.5. Формулы с учетом паддинга**\n",
        "Размер выходной матрицы $ O $ зависит от паддинга $ p $, шага $ s $, размера входной матрицы $ H \\times W $ и размера ядра $ M \\times N $:\n",
        "\n",
        "$$\n",
        "H_O = \\left\\lfloor \\frac{H + 2p - M}{s} \\right\\rfloor + 1,\n",
        "$$\n",
        "$$\n",
        "W_O = \\left\\lfloor \\frac{W + 2p - N}{s} \\right\\rfloor + 1.\n",
        "$$\n",
        "\n",
        "- Если $ p = 0 $ (valid padding), размер выходной матрицы уменьшается.\n",
        "- Если $ p = \\frac{M - 1}{2} $ (same padding), размер выходной матрицы остается равным входной.\n",
        "\n",
        "\n",
        "\n",
        "### **4.6. Пример применения паддинга**\n",
        "#### **Исходные данные:**\n",
        "- Входная матрица $ I $: $ 5 \\times 5 $,\n",
        "- Ядро $ K $: $ 3 \\times 3 $,\n",
        "- Шаг $ s = 1 $,\n",
        "- Паддинг $ p = 1 $.\n",
        "\n",
        "#### **Расчет размера выходной матрицы:**\n",
        "$$\n",
        "H_O = \\left\\lfloor \\frac{5 + 2 \\cdot 1 - 3}{1} \\right\\rfloor + 1 = 5,\n",
        "$$\n",
        "$$\n",
        "W_O = \\left\\lfloor \\frac{5 + 2 \\cdot 1 - 3}{1} \\right\\rfloor + 1 = 5.\n",
        "$$\n",
        "\n",
        "Таким образом, размер выходной матрицы $ O $ остается $ 5 \\times 5 $.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 5. Активация (ReLU)\n",
        "\n",
        "После выполнения операции свертки, которая вычисляет линейные комбинации значений пикселей входного изображения и весов ядра, результаты передаются в **функцию активации**. Одной из наиболее популярных функций активации является **ReLU (Rectified Linear Unit)**.\n",
        "\n",
        "### 5.1. Что такое ReLU?\n",
        "\n",
        "Функция ReLU определяется следующим образом:\n",
        "\n",
        "$$\n",
        "f(x) = \\max(0, x),\n",
        "$$\n",
        "\n",
        "где $ x $ — это значение элемента матрицы, полученной после операции свертки.\n",
        "\n",
        "Это означает, что:\n",
        "- Если значение элемента положительное ($ x > 0 $), то оно остается без изменений.\n",
        "- Если значение элемента отрицательное ($ x \\leq 0 $), то оно обнуляется.\n",
        "\n",
        "Математически это можно записать как:\n",
        "$$\n",
        "f(x) =\n",
        "\\begin{cases}\n",
        "x, & \\text{если } x > 0, \\\\\n",
        "0, & \\text{если } x \\leq 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Графически функция ReLU выглядит так:\n",
        "\n",
        "- Для всех $ x > 0 $, график представляет собой прямую $ y = x $.\n",
        "- Для всех $ x \\leq 0 $, график представляет собой горизонтальную линию $ y = 0 $.\n",
        "\n",
        "### 5.2. Применение ReLU к выходу свертки\n",
        "\n",
        "После выполнения всех шагов свертки для входного изображения $ I $ и ядра $ K $ мы получили выходную матрицу $ O $ размером $ 3 \\times 3 $. Обозначим эту матрицу как:\n",
        "\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "O[1,1] & O[1,2] & O[1,3] \\\\\n",
        "O[2,1] & O[2,2] & O[2,3] \\\\\n",
        "O[3,1] & O[3,2] & O[3,3]\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Теперь применим функцию ReLU ко всем элементам этой матрицы. Это означает, что каждый элемент $ O[i,j] $ будет заменен на $ \\max(0, O[i,j]) $.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Предположим, что после выполнения свертки мы получили следующую матрицу $ O $:\n",
        "\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "-1.5 & 2.3 & -0.7 \\\\\n",
        "4.1 & -3.2 & 0.0 \\\\\n",
        "1.8 & -2.9 & 3.6\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Применим функцию ReLU к каждому элементу:\n",
        "\n",
        "1. $ O[1,1] = -1.5 $ → $ \\max(0, -1.5) = 0 $,\n",
        "2. $ O[1,2] = 2.3 $ → $ \\max(0, 2.3) = 2.3 $,\n",
        "3. $ O[1,3] = -0.7 $ → $ \\max(0, -0.7) = 0 $,\n",
        "4. $ O[2,1] = 4.1 $ → $ \\max(0, 4.1) = 4.1 $,\n",
        "5. $ O[2,2] = -3.2 $ → $ \\max(0, -3.2) = 0 $,\n",
        "6. $ O[2,3] = 0.0 $ → $ \\max(0, 0.0) = 0.0 $,\n",
        "7. $ O[3,1] = 1.8 $ → $ \\max(0, 1.8) = 1.8 $,\n",
        "8. $ O[3,2] = -2.9 $ → $ \\max(0, -2.9) = 0 $,\n",
        "9. $ O[3,3] = 3.6 $ → $ \\max(0, 3.6) = 3.6 $.\n",
        "\n",
        "В результате получаем новую матрицу $ O_{\\text{ReLU}} $:\n",
        "\n",
        "$$\n",
        "O_{\\text{ReLU}} =\n",
        "\\begin{bmatrix}\n",
        "0 & 2.3 & 0 \\\\\n",
        "4.1 & 0 & 0 \\\\\n",
        "1.8 & 0 & 3.6\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "### 5.3. Зачем нужна ReLU?\n",
        "\n",
        "ReLU выполняет несколько важных задач в обучении нейронных сетей:\n",
        "\n",
        "1. **Введение нелинейности**: Без функции активации все слои нейросети были бы линейными преобразованиями, и сеть в целом оставалась бы линейной системой. ReLU добавляет нелинейность, позволяя сети моделировать сложные зависимости в данных.\n",
        "\n",
        "2. **Ускорение обучения**: ReLU помогает ускорить процесс обучения по сравнению с другими функциями активации, такими как сигмоид или гиперболический тангенс (tanh). Это связано с тем, что ReLU не имеет проблемы затухающих градиентов (vanishing gradients) для положительных значений (градиент равен 1 для $ x > 0 $).\n",
        "\n",
        "3. **Разреженность активаций**: Благодаря тому, что ReLU обнуляет отрицательные значения, она способствует разреженности активаций. Это может помочь сети фокусироваться только на действительно важных признаках.\n",
        "\n",
        "### 5.4. Потенциальные проблемы с ReLU\n",
        "\n",
        "Несмотря на свои преимущества, ReLU также имеет некоторые недостатки:\n",
        "\n",
        "1. **\"Умершие\" нейроны**: Если входные данные часто отрицательны, ReLU может \"убивать\" нейроны, то есть их выход всегда будет равен нулю. В таких случаях градиент также будет равен нулю, и нейрон перестанет обучаться.\n",
        "\n",
        "2. **Неограниченный рост**: Для очень больших положительных значений ReLU может вызывать проблемы с численной стабильностью, так как ее значения могут расти бесконечно.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Для решения проблем, связанных с ReLU, таких как \"умершие\" нейроны и неограниченный рост, были предложены следующие модификации. Ниже приведены их математические формулы:\n",
        "\n",
        "\n",
        "\n",
        "### 1. **Leaky ReLU**\n",
        "\n",
        "Leaky ReLU позволяет небольшой градиент для отрицательных значений, что помогает избежать проблемы \"умерших\" нейронов. Формула выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "f(x) =\n",
        "\\begin{cases}\n",
        "x, & \\text{если } x > 0, \\\\\n",
        "\\alpha x, & \\text{если } x \\leq 0,\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $ \\alpha $ — малая положительная константа (обычно $ \\alpha \\ll 1 $, например, $ \\alpha = 0.01 $).\n",
        "\n",
        "Графически функция Leaky ReLU имеет наклон $ \\alpha $ для отрицательных значений.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Parametric ReLU (PReLU)**\n",
        "\n",
        "PReLU является обобщением Leaky ReLU, где параметр $ \\alpha $ обучается вместе с остальными параметрами сети. Это делает функцию более гибкой. Формула аналогична Leaky ReLU:\n",
        "\n",
        "$$\n",
        "f(x) =\n",
        "\\begin{cases}\n",
        "x, & \\text{если } x > 0, \\\\\n",
        "\\alpha x, & \\text{если } x \\leq 0,\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Однако в данном случае $ \\alpha $ — это обучаемый параметр, который определяется во время тренировки сети.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Exponential Linear Unit (ELU)**\n",
        "\n",
        "ELU обеспечивает более плавную аппроксимацию для отрицательных значений, что помогает улучшить численную стабильность и ускорить обучение. Формула ELU выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "f(x) =\n",
        "\\begin{cases}\n",
        "x, & \\text{если } x > 0, \\\\\n",
        "\\alpha (e^x - 1), & \\text{если } x \\leq 0,\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $ \\alpha $ — положительная константа, определяющая масштаб отрицательной части.\n",
        "\n",
        "Графически функция ELU стремится к $ -\\alpha $ при $ x \\to -\\infty $, что обеспечивает более плавное поведение по сравнению с ReLU и Leaky ReLU.\n",
        "\n",
        "\n",
        "\n",
        "### Сравнение формул\n",
        "\n",
        "| Функция        | Формула                                                                 |\n",
        "|----------------|-------------------------------------------------------------------------|\n",
        "| **ReLU**       | $ f(x) = \\max(0, x) $                                                 |\n",
        "| **Leaky ReLU** | $ f(x) = \\begin{cases} x, & x > 0 \\\\ \\alpha x, & x \\leq 0 \\end{cases} $ |\n",
        "| **PReLU**      | $ f(x) = \\begin{cases} x, & x > 0 \\\\ \\alpha x, & x \\leq 0 \\end{cases} $ |\n",
        "|                | ($ \\alpha $ — обучаемый параметр)                                       |\n",
        "| **ELU**        | $ f(x) = \\begin{cases} x, & x > 0 \\\\ \\alpha (e^x - 1), & x \\leq 0 \\end{cases} $ |\n",
        "\n",
        "\n",
        "\n",
        "### Пример применения\n",
        "\n",
        "Предположим, что на вход подается значение $ x = -2 $. Рассмотрим, как будут работать различные функции активации:\n",
        "\n",
        "1. **ReLU**:  \n",
        "   $$\n",
        "   f(-2) = \\max(0, -2) = 0.\n",
        "   $$\n",
        "\n",
        "2. **Leaky ReLU** ($ \\alpha = 0.01 $):  \n",
        "   $$\n",
        "   f(-2) = \\alpha \\cdot (-2) = 0.01 \\cdot (-2) = -0.02.\n",
        "   $$\n",
        "\n",
        "3. **PReLU** ($ \\alpha = 0.05 $):  \n",
        "   $$\n",
        "   f(-2) = \\alpha \\cdot (-2) = 0.05 \\cdot (-2) = -0.1.\n",
        "   $$\n",
        "\n",
        "4. **ELU** ($ \\alpha = 1 $):  \n",
        "   $$\n",
        "   f(-2) = \\alpha (e^{-2} - 1) = 1 \\cdot (e^{-2} - 1) \\approx 1 \\cdot (0.135 - 1) = -0.865.\n",
        "   $$\n",
        "\n",
        "\n",
        "\n",
        "### Преимущества и недостатки\n",
        "\n",
        "| Функция        | Преимущества                                                                 | Недостатки                                                              |\n",
        "|----------------|------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
        "| **ReLU**       | Простота вычислений, ускоряет обучение                                        | Может вызывать \"умершие\" нейроны, неограниченный рост для положительных значений |\n",
        "| **Leaky ReLU** | Устраняет проблему \"умерших\" нейронов благодаря ненулевому градиенту          | Необходимо выбрать параметр $ \\alpha $                                  |\n",
        "| **PReLU**      | Более гибкая версия Leaky ReLU                                               | Дополнительные вычисления для обучения $ \\alpha $                       |\n",
        "| **ELU**        | Плавное поведение для отрицательных значений, улучшает численную стабильность | Вычислительно дороже из-за экспоненты                                    |\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k-RluKzlKyn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Пулинг (Pooling)\n",
        "\n",
        "Пулинг (или субдискретизация) — это операция, которая обычно следует за сверткой в сверточных нейронных сетях (CNN). Основная цель пулинга заключается в уменьшении размерности карт признаков, что позволяет:\n",
        "\n",
        "1. **Снизить вычислительную сложность** последующих слоев сети.\n",
        "2. **Контролировать переобучение**, снижая чувствительность к малым изменениям входных данных.\n",
        "3. **Сохранять важные пространственные иерархии**, такие как относительное расположение объектов.\n",
        "\n",
        "### 6.1. Общее описание\n",
        "В процессе пулинга из подматриц входной карты признаков выбирается одно значение по определенному правилу. Размер выходной карты после пулинга уменьшается, так как каждая подматрица заменяется одним значением. Шаг (stride) и размер окна (pool size) являются ключевыми параметрами, которые определяют, как именно выполняется пулинг.\n",
        "\n",
        "Наиболее распространенные виды пулинга:\n",
        "- **Макс-пулинг (Max Pooling)**: Выбирается максимальное значение в пределах окна.\n",
        "- **Средне-пулинг (Average Pooling)**: Вычисляется среднее значение элементов в пределах окна.\n",
        "\n",
        "### 6.2. Математическое описание\n",
        "#### Исходные данные\n",
        "Пусть входная карта признаков представлена матрицей $ F $ размером $ H \\times W $. Размер окна пулинга обозначим как $ P_h \\times P_w $, где $ P_h $ — высота окна, а $ P_w $ — его ширина. Шаг (stride) обозначим через $ s $.\n",
        "\n",
        "Размер выходной карты $ O $ после пулинга будет зависеть от параметров $ P_h $, $ P_w $ и $ s $:\n",
        "$$\n",
        "O_{\\text{height}} = \\left\\lfloor \\frac{H - P_h}{s} \\right\\rfloor + 1,\n",
        "$$\n",
        "$$\n",
        "O_{\\text{width}} = \\left\\lfloor \\frac{W - P_w}{s} \\right\\rfloor + 1.\n",
        "$$\n",
        "\n",
        "#### Общая формула для пулинга\n",
        "Для каждого окна пулинга, заданного координатами $ (i, j) $, выходное значение $ O[i,j] $ вычисляется следующим образом:\n",
        "- Для **макс-пулинга**:\n",
        "$$\n",
        "O[i,j] = \\max_{m \\in [0, P_h-1], n \\in [0, P_w-1]} F[i \\cdot s + m, j \\cdot s + n].\n",
        "$$\n",
        "- Для **средне-пулинга**:\n",
        "$$\n",
        "O[i,j] = \\frac{1}{P_h \\cdot P_w} \\sum_{m=0}^{P_h-1} \\sum_{n=0}^{P_w-1} F[i \\cdot s + m, j \\cdot s + n].\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "- $ i, j $ — индексы выходной карты $ O $,\n",
        "- $ m, n $ — индексы внутри окна пулинга,\n",
        "- $ F[i \\cdot s + m, j \\cdot s + n] $ — значения входной карты $ F $, попадающие в текущее окно пулинга.\n",
        "\n",
        "\n",
        "\n",
        "### 6.3. Пример макс-пулинга\n",
        "#### Исходная карта признаков\n",
        "Пусть входная карта признаков $ F $ имеет размер $ 4 \\times 4 $:\n",
        "$$\n",
        "F =\n",
        "\\begin{bmatrix}\n",
        "x_{00} & x_{01} & x_{02} & x_{03} \\\\\n",
        "x_{10} & x_{11} & x_{12} & x_{13} \\\\\n",
        "x_{20} & x_{21} & x_{22} & x_{23} \\\\\n",
        "x_{30} & x_{31} & x_{32} & x_{33}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "#### Параметры пулинга\n",
        "- Размер окна: $ 2 \\times 2 $ ($ P_h = 2, P_w = 2 $),\n",
        "- Шаг: $ s = 2 $.\n",
        "\n",
        "#### Пошаговое вычисление\n",
        "1. **Первое окно** ($ i = 0, j = 0 $):\n",
        "   Подматрица:\n",
        "   $$\n",
        "   \\begin{bmatrix}\n",
        "   x_{00} & x_{01} \\\\\n",
        "   x_{10} & x_{11}\n",
        "   \\end{bmatrix}.\n",
        "   $$\n",
        "   Максимальное значение:\n",
        "   $$\n",
        "   O[0,0] = \\max(x_{00}, x_{01}, x_{10}, x_{11}).\n",
        "   $$\n",
        "\n",
        "2. **Второе окно** ($ i = 0, j = 1 $):\n",
        "   Подматрица:\n",
        "   $$\n",
        "   \\begin{bmatrix}\n",
        "   x_{02} & x_{03} \\\\\n",
        "   x_{12} & x_{13}\n",
        "   \\end{bmatrix}.\n",
        "   $$\n",
        "   Максимальное значение:\n",
        "   $$\n",
        "   O[0,1] = \\max(x_{02}, x_{03}, x_{12}, x_{13}).\n",
        "   $$\n",
        "\n",
        "3. **Третье окно** ($ i = 1, j = 0 $):\n",
        "   Подматрица:\n",
        "   $$\n",
        "   \\begin{bmatrix}\n",
        "   x_{20} & x_{21} \\\\\n",
        "   x_{30} & x_{31}\n",
        "   \\end{bmatrix}.\n",
        "   $$\n",
        "   Максимальное значение:\n",
        "   $$\n",
        "   O[1,0] = \\max(x_{20}, x_{21}, x_{30}, x_{31}).\n",
        "   $$\n",
        "\n",
        "4. **Четвертое окно** ($ i = 1, j = 1 $):\n",
        "   Подматрица:\n",
        "   $$\n",
        "   \\begin{bmatrix}\n",
        "   x_{22} & x_{23} \\\\\n",
        "   x_{32} & x_{33}\n",
        "   \\end{bmatrix}.\n",
        "   $$\n",
        "   Максимальное значение:\n",
        "   $$\n",
        "   O[1,1] = \\max(x_{22}, x_{23}, x_{32}, x_{33}).\n",
        "   $$\n",
        "\n",
        "#### Итоговая карта после макс-пулинга\n",
        "Выходная карта $ O $ имеет размер $ 2 \\times 2 $:\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "O[0,0] & O[0,1] \\\\\n",
        "O[1,0] & O[1,1]\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 6.4. Пример средне-пулинга\n",
        "Используем ту же входную карту $ F $ и параметры пулинга ($ 2 \\times 2 $, $ s = 2 $).\n",
        "\n",
        "1. **Первое окно** ($ i = 0, j = 0 $):\n",
        "   Подматрица:\n",
        "   $$\n",
        "   \\begin{bmatrix}\n",
        "   x_{00} & x_{01} \\\\\n",
        "   x_{10} & x_{11}\n",
        "   \\end{bmatrix}.\n",
        "   $$\n",
        "   Среднее значение:\n",
        "   $$\n",
        "   O[0,0] = \\frac{x_{00} + x_{01} + x_{10} + x_{11}}{4}.\n",
        "   $$\n",
        "\n",
        "2. **Второе окно** ($ i = 0, j = 1 $):\n",
        "   Подматрица:\n",
        "   $$\n",
        "   \\begin{bmatrix}\n",
        "   x_{02} & x_{03} \\\\\n",
        "   x_{12} & x_{13}\n",
        "   \\end{bmatrix}.\n",
        "   $$\n",
        "   Среднее значение:\n",
        "   $$\n",
        "   O[0,1] = \\frac{x_{02} + x_{03} + x_{12} + x_{13}}{4}.\n",
        "   $$\n",
        "\n",
        "Аналогично вычисляются значения для остальных окон.\n",
        "\n",
        "#### Итоговая карта после средне-пулинга\n",
        "Выходная карта $ O $ имеет размер $ 2 \\times 2 $:\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "O[0,0] & O[0,1] \\\\\n",
        "O[1,0] & O[1,1]\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 6.5. Преимущества пулинга\n",
        "1. **Устойчивость к изменениям**: Макс-пулинг сохраняет наиболее значимые признаки, игнорируя мелкие детали.\n",
        "2. **Снижение размерности**: Уменьшение количества параметров упрощает обучение модели.\n",
        "3. **Инвариантность к трансляции**: Пулинг делает модель менее чувствительной к сдвигам объектов на изображении.\n",
        "\n",
        "### 6.6. Недостатки пулинга\n",
        "1. **Потеря информации**: Особенно в случае средне-пулинга могут быть потеряны важные детали.\n",
        "2. **Ограниченная гибкость**: Фиксированный размер окна и шаг могут не подходить для всех задач.\n",
        "\n"
      ],
      "metadata": {
        "id": "pMusSodGKzmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Полносвязный слой\n",
        "\n",
        "Полносвязный слой (Fully Connected Layer, FC) — это ключевой компонент нейронных сетей, который обычно завершает архитектуру сверточных нейронных сетей (CNN). Этот слой выполняет преобразование данных из пространственного представления (например, карт признаков, полученных после сверток и пулинга) в векторное представление, чтобы выполнить классификацию или регрессию.\n",
        "\n",
        "### 7.1. Общее описание\n",
        "В полносвязном слое каждый нейрон соединен со всеми нейронами предыдущего слоя. Это означает, что выходные значения предыдущего слоя рассматриваются как входной вектор $ \\mathbf{x} $, и каждый элемент этого вектора участвует в вычислении значений для всех нейронов текущего слоя.\n",
        "\n",
        "Математически процесс можно описать следующим образом:\n",
        "- Пусть входной вектор имеет размерность $ n $: $ \\mathbf{x} = [x_1, x_2, \\dots, x_n] $.\n",
        "- Каждый нейрон в полносвязном слое вычисляет взвешенную сумму входных значений с добавлением смещения (bias):\n",
        "$$\n",
        "z_j = \\sum_{i=1}^{n} w_{ji} x_i + b_j,\n",
        "$$\n",
        "где:\n",
        "  - $ z_j $ — выходное значение $ j $-го нейрона до применения функции активации,\n",
        "  - $ w_{ji} $ — вес, связывающий $ i $-й вход с $ j $-м нейроном,\n",
        "  - $ b_j $ — смещение (bias) для $ j $-го нейрона.\n",
        "\n",
        "После вычисления взвешенной суммы применяется нелинейная функция активации $ f $ (например, ReLU, sigmoid или softmax), чтобы получить окончательное значение для нейрона:\n",
        "$$\n",
        "a_j = f(z_j).\n",
        "$$\n",
        "\n",
        "### 7.2. Матричная запись\n",
        "Если рассматривать полносвязный слой в матричной форме, то операцию можно записать как:\n",
        "$$\n",
        "\\mathbf{z} = \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{b},\n",
        "$$\n",
        "где:\n",
        "- $ \\mathbf{W} $ — матрица весов размером $ m \\times n $, где $ m $ — количество нейронов в текущем слое, $ n $ — количество входных значений,\n",
        "- $ \\mathbf{x} $ — входной вектор размером $ n $,\n",
        "- $ \\mathbf{b} $ — вектор смещений размером $ m $,\n",
        "- $ \\mathbf{z} $ — вектор выходных значений до применения функции активации.\n",
        "\n",
        "После применения функции активации:\n",
        "$$\n",
        "\\mathbf{a} = f(\\mathbf{z}),\n",
        "$$\n",
        "где $ \\mathbf{a} $ — вектор выходных значений текущего слоя.\n",
        "\n",
        "\n",
        "\n",
        "### 7.3. Пример вычислений\n",
        "#### Исходные данные\n",
        "Пусть входной вектор $ \\mathbf{x} $ имеет размерность $ 4 $:\n",
        "$$\n",
        "\\mathbf{x} = [x_1, x_2, x_3, x_4].\n",
        "$$\n",
        "\n",
        "Матрица весов $ \\mathbf{W} $ имеет размер $ 3 \\times 4 $ (3 нейрона в текущем слое):\n",
        "$$\n",
        "\\mathbf{W} =\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13} & w_{14} \\\\\n",
        "w_{21} & w_{22} & w_{23} & w_{24} \\\\\n",
        "w_{31} & w_{32} & w_{33} & w_{34}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Вектор смещений $ \\mathbf{b} $ имеет размер $ 3 $:\n",
        "$$\n",
        "\\mathbf{b} = [b_1, b_2, b_3].\n",
        "$$\n",
        "\n",
        "#### Вычисление выходного вектора\n",
        "Вычислим вектор $ \\mathbf{z} $:\n",
        "$$\n",
        "\\mathbf{z} = \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{b}.\n",
        "$$\n",
        "\n",
        "Каждый элемент $ z_j $ вычисляется как:\n",
        "$$\n",
        "z_1 = (w_{11} \\cdot x_1) + (w_{12} \\cdot x_2) + (w_{13} \\cdot x_3) + (w_{14} \\cdot x_4) + b_1,\n",
        "$$\n",
        "$$\n",
        "z_2 = (w_{21} \\cdot x_1) + (w_{22} \\cdot x_2) + (w_{23} \\cdot x_3) + (w_{24} \\cdot x_4) + b_2,\n",
        "$$\n",
        "$$\n",
        "z_3 = (w_{31} \\cdot x_1) + (w_{32} \\cdot x_2) + (w_{33} \\cdot x_3) + (w_{34} \\cdot x_4) + b_3.\n",
        "$$\n",
        "\n",
        "После применения функции активации (например, ReLU):\n",
        "$$\n",
        "a_1 = \\text{ReLU}(z_1), \\quad a_2 = \\text{ReLU}(z_2), \\quad a_3 = \\text{ReLU}(z_3).\n",
        "$$\n",
        "\n",
        "Итоговый выходной вектор:\n",
        "$$\n",
        "\\mathbf{a} = [a_1, a_2, a_3].\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 7.4. Преобразование карт признаков в вектор\n",
        "Перед подачей данных в полносвязный слой карты признаков, полученные после сверток и пулинга, необходимо преобразовать в одномерный вектор. Это делается с помощью операции **flatten** (выпрямления).\n",
        "\n",
        "#### Пример\n",
        "Пусть карта признаков $ F $ имеет размер $ 4 \\times 4 $:\n",
        "$$\n",
        "F =\n",
        "\\begin{bmatrix}\n",
        "f_{00} & f_{01} & f_{02} & f_{03} \\\\\n",
        "f_{10} & f_{11} & f_{12} & f_{13} \\\\\n",
        "f_{20} & f_{21} & f_{22} & f_{23} \\\\\n",
        "f_{30} & f_{31} & f_{32} & f_{33}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "После выпрямления получаем вектор $ \\mathbf{x} $ размером $ 16 $:\n",
        "$$\n",
        "\\mathbf{x} = [f_{00}, f_{01}, f_{02}, f_{03}, f_{10}, f_{11}, f_{12}, f_{13}, f_{20}, f_{21}, f_{22}, f_{23}, f_{30}, f_{31}, f_{32}, f_{33}].\n",
        "$$\n",
        "\n",
        "Этот вектор становится входом для полносвязного слоя.\n",
        "\n",
        "\n",
        "\n",
        "### 7.5. Роль полносвязного слоя в CNN\n",
        "1. **Классификация**: Полносвязный слой используется для классификации объектов на основе признаков, извлеченных сверточными слоями.\n",
        "2. **Регрессия**: В задачах регрессии полносвязный слой может предсказывать непрерывные значения (например, координаты объектов).\n",
        "3. **Абстрактное представление**: Свертки извлекают пространственные признаки, а полносвязный слой объединяет их в глобальное представление.\n",
        "\n",
        "\n",
        "\n",
        "### 7.6. Недостатки полносвязного слоя\n",
        "1. **Высокая вычислительная сложность**: Полносвязный слой содержит большое количество параметров, что увеличивает время обучения и требует больше памяти.\n",
        "2. **Склонность к переобучению**: Из-за большого числа параметров модель может чрезмерно подстраиваться под обучающую выборку.\n",
        "3. **Потеря пространственной информации**: Преобразование карт признаков в вектор приводит к потере пространственных взаимосвязей.\n"
      ],
      "metadata": {
        "id": "g7jYeUNLM3f-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Обучение CNN\n",
        "\n",
        "Обучение сверточных нейронных сетей (CNN) — это процесс настройки параметров сети (весов и смещений) для минимизации ошибки модели на обучающей выборке. Этот процесс включает несколько ключевых этапов: прямое распространение (forward propagation), вычисление функции потерь (loss function), обратное распространение ошибки (backpropagation) и обновление параметров с использованием методов оптимизации.\n",
        "\n",
        "\n",
        "\n",
        "### 8.1. Прямое распространение (Forward Propagation)\n",
        "Прямое распространение — это процесс, при котором входные данные последовательно проходят через все слои сети для получения предсказания. В CNN этот процесс состоит из следующих шагов:\n",
        "\n",
        "1. **Входные данные**: Изображение или другие данные подаются на вход сети.\n",
        "2. **Свертки и пулинг**:\n",
        "   - Сверточные слои применяют ядра фильтров к входным данным для извлечения признаков.\n",
        "   - Пулинговые слои уменьшают размерность карт признаков.\n",
        "3. **Выпрямление (Flatten)**: Карта признаков преобразуется в одномерный вектор.\n",
        "4. **Полносвязные слои**: Выполняется классификация или регрессия на основе извлеченных признаков.\n",
        "5. **Функция активации**: На каждом этапе применяются нелинейные функции активации (например, ReLU, softmax).\n",
        "\n",
        "Результатом прямого распространения является выходной вектор $ \\mathbf{y}_{\\text{pred}} $, представляющий предсказание модели.\n",
        "\n",
        "\n",
        "\n",
        "### 8.2. Функция потерь (Loss Function)\n",
        "\n",
        "Функция потерь измеряет, насколько предсказания модели отличаются от истинных значений. Выбор функции зависит от задачи:\n",
        "\n",
        "\n",
        "\n",
        "#### 1. **Классификация**\n",
        "\n",
        "- **Многоклассовая классификация**:\n",
        "  Используется **кросс-энтропийная потеря**:\n",
        "  $$\n",
        "  L = -\\sum_{i=1}^{C} y_i \\cdot \\log(\\hat{y}_i),\n",
        "  $$\n",
        "  где:\n",
        "  - $ C $ — количество классов,\n",
        "  - $ y_i $ — истинное значение (0 или 1),\n",
        "  - $ \\hat{y}_i $ — предсказанное значение (вероятность принадлежности к классу $ i $).\n",
        "\n",
        "- **Бинарная классификация**:\n",
        "  Используется **бинарная кросс-энтропия**:\n",
        "  $$\n",
        "  L = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i) \\right],\n",
        "  $$\n",
        "  где:\n",
        "  - $ N $ — количество примеров,\n",
        "  - $ y_i $ — истинное значение (0 или 1),\n",
        "  - $ \\hat{y}_i $ — предсказанное значение (вероятность принадлежности к классу 1).\n",
        "\n",
        "\n",
        "\n",
        "#### 2. **Регрессия**\n",
        "\n",
        "- **Среднеквадратичная ошибка (MSE)**:\n",
        "  $$\n",
        "  L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2,\n",
        "  $$\n",
        "  где:\n",
        "  - $ N $ — количество примеров,\n",
        "  - $ y_i $ — истинное значение,\n",
        "  - $ \\hat{y}_i $ — предсказанное значение.\n",
        "\n",
        "- **Средняя абсолютная ошибка (MAE)**:\n",
        "  $$\n",
        "  L = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|,\n",
        "  $$\n",
        "  где:\n",
        "  - $ N $ — количество примеров,\n",
        "  - $ y_i $ — истинное значение,\n",
        "  - $ \\hat{y}_i $ — предсказанное значение.\n",
        "\n",
        "\n",
        "\n",
        "#### 3. **Другие функции потерь**\n",
        "\n",
        "- **Huber Loss** (комбинация MSE и MAE):\n",
        "  $$\n",
        "  L =\n",
        "  \\begin{cases}\n",
        "  \\frac{1}{2}(y_i - \\hat{y}_i)^2, & \\text{если } |y_i - \\hat{y}_i| \\leq \\delta, \\\\\n",
        "  \\delta \\cdot |y_i - \\hat{y}_i| - \\frac{1}{2}\\delta^2, & \\text{если } |y_i - \\hat{y}_i| > \\delta,\n",
        "  \\end{cases}\n",
        "  $$\n",
        "  где:\n",
        "  - $ \\delta $ — пороговое значение, определяющее переход от MSE к MAE.\n",
        "\n",
        "- **Focal Loss** (для задач с несбалансированными классами):\n",
        "  $$\n",
        "  L = -\\sum_{i=1}^{C} \\alpha_i \\cdot (1 - \\hat{y}_i)^\\gamma \\cdot y_i \\cdot \\log(\\hat{y}_i),\n",
        "  $$\n",
        "  где:\n",
        "  - $ \\alpha_i $ — вес для класса $ i $,\n",
        "  - $ \\gamma $ — параметр, регулирующий фокусировку на сложных примерах.\n",
        "\n",
        "\n",
        "\n",
        "Цель обучения — минимизировать значение функции потерь.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uDolgvNBNUJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 8.3. Вычисление предсказанного значения $ \\hat{y}_i $\n",
        "\n",
        "\n",
        "В задачах классификации $ \\hat{y}_i $ представляет собой вероятность принадлежности входных данных к каждому из классов. Этот процесс включает следующие шаги:\n",
        "\n",
        "1. **Полносвязные слои (Fully Connected Layers)**:\n",
        "   - После сверток и пулинга данные преобразуются в одномерный вектор с помощью операции выпрямления (flatten).\n",
        "   - Этот вектор подается на вход полносвязных слоев, которые выполняют линейные преобразования:\n",
        "     $$\n",
        "     z = Wx + b,\n",
        "     $$\n",
        "     где:\n",
        "     - $ x $ — входной вектор (выпрямленная карта признаков),\n",
        "     - $ W $ — матрица весов,\n",
        "     - $ b $ — вектор смещений,\n",
        "     - $ z $ — выход полносвязного слоя до применения функции активации.\n",
        "\n",
        "2. **Функция активации**:\n",
        "   - Для многоклассовой классификации применяется функция softmax:\n",
        "     $$\n",
        "     \\hat{y}_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^{C} \\exp(z_j)},\n",
        "     $$\n",
        "     где:\n",
        "     - $ z_i $ — логит для класса $ i $,\n",
        "     - $ C $ — общее количество классов.\n",
        "   - Для бинарной классификации используется сигмоидная функция:\n",
        "     $$\n",
        "     \\hat{y}_i = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}.\n",
        "     $$\n",
        "\n",
        "3. **Интерпретация**:\n",
        "   - В случае softmax $ \\hat{y}_i $ интерпретируется как вероятность принадлежности входных данных к классу $ i $.\n",
        "   - В случае сигмоиды $ \\hat{y}_i $ — это вероятность принадлежности к положительному классу (классу 1).\n",
        "\n",
        "\n",
        "#### 2. **Регрессия**\n",
        "\n",
        "В задачах регрессии $ \\hat{y}_i $ представляет собой непрерывное числовое значение, которое модель пытается предсказать. Процесс вычисления аналогичен, но отличается последним этапом:\n",
        "\n",
        "1. **Полносвязные слои**:\n",
        "   - Как и в классификации, данные проходят через полносвязные слои:\n",
        "     $$\n",
        "     z = Wx + b.\n",
        "     $$\n",
        "\n",
        "2. **Отсутствие функции активации**:\n",
        "   - В задачах регрессии обычно не применяется нелинейная функция активации на выходном слое. Значение $ z $ напрямую интерпретируется как предсказание:\n",
        "     $$\n",
        "     \\hat{y}_i = z.\n",
        "     $$\n",
        "\n",
        "3. **Интерпретация**:\n",
        "   - $ \\hat{y}_i $ — это предсказанное значение целевой переменной.\n",
        "\n",
        "\n",
        "\n",
        "#### 3. **Общая схема вычисления**\n",
        "\n",
        "В общем случае предсказанное значение $ \\hat{y}_i $ вычисляется следующим образом:\n",
        "\n",
        "1. **Входные данные**: Изображение или другие данные подаются на вход сети.\n",
        "2. **Свертки и пулинг**: Извлекаются признаки с использованием сверточных и пулинговых слоев.\n",
        "3. **Выпрямление**: Карта признаков преобразуется в одномерный вектор.\n",
        "4. **Полносвязные слои**: Выполняются линейные преобразования и нелинейные преобразования (если требуется).\n",
        "5. **Функция активации**:\n",
        "   - Softmax для многоклассовой классификации.\n",
        "   - Сигмоида для бинарной классификации.\n",
        "   - Отсутствует для регрессии.\n",
        "\n",
        "\n",
        "\n",
        "### 8.3.1. Пример вычисления $ \\hat{y}_i $\n",
        "\n",
        "#### Пример 1: Многоклассовая классификация\n",
        "Предположим, что у нас есть три класса ($ C = 3 $), и выход полносвязного слоя равен:\n",
        "$$\n",
        "z = [2.0, 1.0, 0.1].\n",
        "$$\n",
        "Применяем функцию softmax:\n",
        "$$\n",
        "\\hat{y}_1 = \\frac{\\exp(2.0)}{\\exp(2.0) + \\exp(1.0) + \\exp(0.1)} \\approx 0.659,\n",
        "$$\n",
        "$$\n",
        "\\hat{y}_2 = \\frac{\\exp(1.0)}{\\exp(2.0) + \\exp(1.0) + \\exp(0.1)} \\approx 0.242,\n",
        "$$\n",
        "$$\n",
        "\\hat{y}_3 = \\frac{\\exp(0.1)}{\\exp(2.0) + \\exp(1.0) + \\exp(0.1)} \\approx 0.099.\n",
        "$$\n",
        "Таким образом, предсказанные вероятности:\n",
        "$$\n",
        "\\hat{y} = [0.659, 0.242, 0.099].\n",
        "$$\n",
        "\n",
        "#### Пример 2: Регрессия\n",
        "Пусть выход полносвязного слоя равен:\n",
        "$$\n",
        "z = 4.5.\n",
        "$$\n",
        "Тогда предсказанное значение:\n",
        "$$\n",
        "\\hat{y} = 4.5.\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "En2UalkhTUiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4. Обратное распространение ошибки (Backpropagation)\n",
        "\n",
        "Обратное распространение ошибки (backpropagation) — это ключевой механизм обучения нейронных сетей, который позволяет вычислить градиенты функции потерь относительно всех параметров сети. Эти градиенты используются для обновления параметров с целью минимизации ошибки.\n",
        "\n",
        "#### Основные принципы:\n",
        "1. **Цепное правило**:\n",
        "   Градиенты вычисляются поэтапно, начиная с выходного слоя и двигаясь к входному. Для каждого слоя используются частные производные функции потерь $ L $ относительно его параметров. Это делается с использованием цепного правила дифференцирования:\n",
        "$$\n",
        "   \\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial W},\n",
        "$$\n",
        "   где $ z $ — взвешенная сумма входов (до применения функции активации).\n",
        "\n",
        "\n",
        "\n",
        "### 2. Градиенты для полносвязных слоев\n",
        "\n",
        "Полносвязные слои (Fully Connected Layers, FC) являются ключевыми компонентами нейронных сетей, где каждый нейрон связан со всеми нейронами предыдущего слоя. Для обновления параметров полносвязного слоя необходимо вычислить градиенты функции потерь $ L $ относительно весов $ W $ и смещений $ b $. Рассмотрим этот процесс максимально подробно.\n",
        "\n",
        "\n",
        "\n",
        "#### 2.1. **Градиент функции потерь относительно весов $ W $**\n",
        "\n",
        "##### 2.1.1. Определение выхода полносвязного слоя\n",
        "Выход $ z $ полносвязного слоя вычисляется как:\n",
        "$$\n",
        "z = W \\cdot x + b,\n",
        "$$\n",
        "где:\n",
        "- $ W $ — матрица весов размером $ m \\times n $ ($ m $ — количество нейронов в текущем слое, $ n $ — количество входных значений),\n",
        "- $ x $ — входной вектор размером $ n $,\n",
        "- $ b $ — вектор смещений размером $ m $,\n",
        "- $ z $ — вектор выходных значений до применения функции активации.\n",
        "\n",
        "Функция потерь $ L $ зависит от выходных значений $ z $, которые, в свою очередь, зависят от весов $ W $. Чтобы обновить веса, необходимо вычислить градиент $ \\frac{\\partial L}{\\partial W} $. Это делается с использованием цепного правила дифференцирования:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial W}.\n",
        "$$\n",
        "\n",
        "##### 2.1.2. Вычисление $ \\frac{\\partial z}{\\partial W} $\n",
        "Выходное значение $ z $ для одного нейрона вычисляется как:\n",
        "$$\n",
        "z_j = \\sum_{i=1}^{n} w_{ji} x_i + b_j,\n",
        "$$\n",
        "где:\n",
        "- $ z_j $ — выходное значение $ j $-го нейрона,\n",
        "- $ w_{ji} $ — вес, связывающий $ i $-й вход с $ j $-м нейроном,\n",
        "- $ x_i $ — $ i $-й элемент входного вектора,\n",
        "- $ b_j $ — смещение для $ j $-го нейрона.\n",
        "\n",
        "Частная производная $ z_j $ по весу $ w_{ji} $ равна:\n",
        "$$\n",
        "\\frac{\\partial z_j}{\\partial w_{ji}} = x_i.\n",
        "$$\n",
        "\n",
        "Таким образом, матрица частных производных $ \\frac{\\partial z}{\\partial W} $ имеет вид:\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial W} = x,\n",
        "$$\n",
        "где $ x $ — входной вектор.\n",
        "\n",
        "##### 2.1.3. Итоговая формула для градиента по весам\n",
        "Подставляя $ \\frac{\\partial z}{\\partial W} = x $ в формулу цепного правила, получаем:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial z} \\cdot x.\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "- $ \\frac{\\partial L}{\\partial z} $ — градиент функции потерь относительно выходных значений $ z $ (вычисляется на предыдущем шаге обратного распространения),\n",
        "- $ x $ — входной вектор.\n",
        "\n",
        "Если записать это в матричной форме, то:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial z} \\cdot x^\\top,\n",
        "$$\n",
        "где $ x^\\top $ — транспонированный входной вектор.\n",
        "\n",
        "\n",
        "\n",
        "#### 2.2. **Градиент функции потерь относительно смещений $ b $**\n",
        "\n",
        "Смещения $ b $ добавляются к взвешенной сумме входов:\n",
        "$$\n",
        "z_j = \\sum_{i=1}^{n} w_{ji} x_i + b_j.\n",
        "$$\n",
        "\n",
        "Частная производная $ z_j $ по смещению $ b_j $ равна:\n",
        "$$\n",
        "\\frac{\\partial z_j}{\\partial b_j} = 1.\n",
        "$$\n",
        "\n",
        "Таким образом, градиент функции потерь $ L $ относительно смещений $ b $ равен:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial z}.\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "- $ \\frac{\\partial L}{\\partial z} $ — градиент функции потерь относительно выходных значений $ z $ (вычисляется на предыдущем шаге обратного распространения).\n",
        "\n",
        "\n",
        "\n",
        "#### 2.3. **Обновление параметров**\n",
        "\n",
        "После вычисления градиентов параметры обновляются с использованием метода оптимизации. Например, при использовании градиентного спуска обновление весов и смещений выполняется следующим образом:\n",
        "\n",
        "1. **Обновление весов**:\n",
        "$$\n",
        "   W = W - \\eta \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "   где $ \\eta $ — скорость обучения (learning rate).\n",
        "\n",
        "2. **Обновление смещений**:\n",
        "$$\n",
        "   b = b - \\eta \\cdot \\frac{\\partial L}{\\partial b}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### 2.4. **Пример вычислений**\n",
        "\n",
        "##### Исходные данные:\n",
        "- Входной вектор $ x $: $ [x_1, x_2, x_3] $,\n",
        "- Матрица весов $ W $:\n",
        "$$\n",
        "  W =\n",
        "  \\begin{bmatrix}\n",
        "  w_{11} & w_{12} & w_{13} \\\\\n",
        "  w_{21} & w_{22} & w_{23}\n",
        "  \\end{bmatrix},\n",
        "$$\n",
        "- Вектор смещений $ b $: $ [b_1, b_2] $,\n",
        "- Выходной вектор $ z $: $ [z_1, z_2] $,\n",
        "- Функция потерь $ L $ вычисляется на основе $ z $.\n",
        "\n",
        "##### Шаг 1: Прямое распространение\n",
        "Вычислим выходные значения $ z $:\n",
        "$$\n",
        "z_1 = w_{11} x_1 + w_{12} x_2 + w_{13} x_3 + b_1,\n",
        "$$\n",
        "$$\n",
        "z_2 = w_{21} x_1 + w_{22} x_2 + w_{23} x_3 + b_2.\n",
        "$$\n",
        "\n",
        "##### Шаг 2: Обратное распространение\n",
        "Пусть известен градиент $ \\frac{\\partial L}{\\partial z} = [\\delta_1, \\delta_2] $, где $ \\delta_1 = \\frac{\\partial L}{\\partial z_1} $, $ \\delta_2 = \\frac{\\partial L}{\\partial z_2} $.\n",
        "\n",
        "1. **Градиент по весам**:\n",
        "$$\n",
        "   \\frac{\\partial L}{\\partial W} =\n",
        "   \\begin{bmatrix}\n",
        "   \\delta_1 x_1 & \\delta_1 x_2 & \\delta_1 x_3 \\\\\n",
        "   \\delta_2 x_1 & \\delta_2 x_2 & \\delta_2 x_3\n",
        "   \\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "2. **Градиент по смещениям**:\n",
        "$$\n",
        "   \\frac{\\partial L}{\\partial b} = [\\delta_1, \\delta_2].\n",
        "$$\n",
        "\n",
        "##### Шаг 3: Обновление параметров\n",
        "Используем градиентный спуск:\n",
        "$$\n",
        "W = W - \\eta \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "$$\n",
        "b = b - \\eta \\cdot \\frac{\\partial L}{\\partial b}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### 2.5. **Важные замечания**\n",
        "1. **Размерность градиентов**:\n",
        "   - Градиент $ \\frac{\\partial L}{\\partial W} $ имеет ту же размерность, что и матрица весов $ W $.\n",
        "   - Градиент $ \\frac{\\partial L}{\\partial b} $ имеет ту же размерность, что и вектор смещений $ b $.\n",
        "\n",
        "2. **Цепное правило**:\n",
        "   Градиенты $ \\frac{\\partial L}{\\partial z} $ передаются от следующего слоя к предыдущему в процессе обратного распространения.\n",
        "\n",
        "3. **Нелинейности**:\n",
        "   Если используется нелинейная функция активации $ f(z) $, то градиент $ \\frac{\\partial L}{\\partial z} $ умножается на производную функции активации:\n",
        "$$\n",
        "   \\frac{\\partial L}{\\partial z} = \\frac{\\partial L}{\\partial a} \\cdot f'(z),\n",
        "$$\n",
        "   где $ a = f(z) $.\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3. Градиенты для сверточных слоев\n",
        "\n",
        "В сверточных слоях градиенты вычисляются для каждого элемента ядра свертки $ K $. Этот процесс является ключевым этапом обратного распространения ошибки (backpropagation) в сверточных нейронных сетях (CNN). Рассмотрим этот процесс максимально подробно.\n",
        "\n",
        "\n",
        "\n",
        "#### 3.1. **Общая формула для градиента по ядру свертки**\n",
        "\n",
        "Градиент функции потерь $ L $ относительно элемента $ K[m,n] $ ядра свертки вычисляется как:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial K[m,n]} = \\sum_{i,j} \\frac{\\partial L}{\\partial O[i,j]} \\cdot \\frac{\\partial O[i,j]}{\\partial K[m,n]},\n",
        "$$\n",
        "где:\n",
        "- $ \\frac{\\partial L}{\\partial O[i,j]} $ — градиент функции потерь относительно выходной карты признаков $ O[i,j] $ (передается из следующего слоя),\n",
        "- $ \\frac{\\partial O[i,j]}{\\partial K[m,n]} $ — производная выходной карты признаков $ O[i,j] $ по элементу ядра $ K[m,n] $.\n",
        "\n",
        "\n",
        "\n",
        "#### 3.2. **Вычисление $ \\frac{\\partial O[i,j]}{\\partial K[m,n]} $**\n",
        "\n",
        "Выходная карта признаков $ O[i,j] $ вычисляется как результат операции свертки:\n",
        "$$\n",
        "O[i,j] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} I[i \\cdot s + m, j \\cdot s + n] \\cdot K[m,n],\n",
        "$$\n",
        "где:\n",
        "- $ I $ — входная матрица,\n",
        "- $ K $ — ядро свертки,\n",
        "- $ s $ — шаг (stride).\n",
        "\n",
        "Частная производная $ O[i,j] $ по элементу ядра $ K[m,n] $ равна соответствующему элементу входной матрицы $ I $, который участвовал в операции свертки:\n",
        "$$\n",
        "\\frac{\\partial O[i,j]}{\\partial K[m,n]} = I[i \\cdot s + m, j \\cdot s + n].\n",
        "$$\n",
        "\n",
        "Таким образом, градиент функции потерь $ L $ относительно ядра свертки $ K[m,n] $ можно записать как:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial K[m,n]} = \\sum_{i,j} \\frac{\\partial L}{\\partial O[i,j]} \\cdot I[i \\cdot s + m, j \\cdot s + n].\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### 3.3. **Интерпретация формулы**\n",
        "\n",
        "Формула показывает, что градиент $ \\frac{\\partial L}{\\partial K[m,n]} $ вычисляется как взвешенная сумма элементов входной матрицы $ I $, где весами служат градиенты $ \\frac{\\partial L}{\\partial O[i,j]} $. Это означает, что каждый элемент ядра $ K[m,n] $ обновляется на основе всех позиций, где он участвовал в операции свертки.\n",
        "\n",
        "\n",
        "\n",
        "#### 3.4. **Пример вычислений**\n",
        "\n",
        "##### Исходные данные:\n",
        "- Входная матрица $ I $ размером $ 5 \\times 5 $:\n",
        "$$\n",
        "I =\n",
        "\\begin{bmatrix}\n",
        "x_{00} & x_{01} & x_{02} & x_{03} & x_{04} \\\\\n",
        "x_{10} & x_{11} & x_{12} & x_{13} & x_{14} \\\\\n",
        "x_{20} & x_{21} & x_{22} & x_{23} & x_{24} \\\\\n",
        "x_{30} & x_{31} & x_{32} & x_{33} & x_{34} \\\\\n",
        "x_{40} & x_{41} & x_{42} & x_{43} & x_{44}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "- Ядро свертки $ K $ размером $ 3 \\times 3 $:\n",
        "$$\n",
        "K =\n",
        "\\begin{bmatrix}\n",
        "k_{00} & k_{01} & k_{02} \\\\\n",
        "k_{10} & k_{11} & k_{12} \\\\\n",
        "k_{20} & k_{21} & k_{22}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "- Выходная карта признаков $ O $ размером $ 3 \\times 3 $:\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "O[1,1] & O[1,2] & O[1,3] \\\\\n",
        "O[2,1] & O[2,2] & O[2,3] \\\\\n",
        "O[3,1] & O[3,2] & O[3,3]\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "##### Шаг 1: Прямое распространение\n",
        "Каждый элемент $ O[i,j] $ вычисляется как:\n",
        "$$\n",
        "O[i,j] = \\sum_{m=0}^{2} \\sum_{n=0}^{2} I[i \\cdot s + m, j \\cdot s + n] \\cdot K[m,n].\n",
        "$$\n",
        "\n",
        "Например, для $ O[1,1] $:\n",
        "$$\n",
        "O[1,1] =\n",
        "(x_{00} \\cdot k_{00}) + (x_{01} \\cdot k_{01}) + (x_{02} \\cdot k_{02}) +\n",
        "(x_{10} \\cdot k_{10}) + (x_{11} \\cdot k_{11}) + (x_{12} \\cdot k_{12}) +\n",
        "(x_{20} \\cdot k_{20}) + (x_{21} \\cdot k_{21}) + (x_{22} \\cdot k_{22}).\n",
        "$$\n",
        "\n",
        "##### Шаг 2: Обратное распространение\n",
        "Пусть известен градиент $ \\frac{\\partial L}{\\partial O} $, где:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial O} =\n",
        "\\begin{bmatrix}\n",
        "\\delta_{1,1} & \\delta_{1,2} & \\delta_{1,3} \\\\\n",
        "\\delta_{2,1} & \\delta_{2,2} & \\delta_{2,3} \\\\\n",
        "\\delta_{3,1} & \\delta_{3,2} & \\delta_{3,3}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Для вычисления градиента по ядру $ K[m,n] $ используем формулу:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial K[m,n]} = \\sum_{i,j} \\delta_{i,j} \\cdot I[i \\cdot s + m, j \\cdot s + n].\n",
        "$$\n",
        "\n",
        "Например, для $ K[0,0] $:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial K[0,0]} =\n",
        "\\delta_{1,1} \\cdot x_{00} + \\delta_{1,2} \\cdot x_{01} + \\delta_{1,3} \\cdot x_{02} +\n",
        "\\delta_{2,1} \\cdot x_{10} + \\delta_{2,2} \\cdot x_{11} + \\delta_{2,3} \\cdot x_{12} +\n",
        "\\delta_{3,1} \\cdot x_{20} + \\delta_{3,2} \\cdot x_{21} + \\delta_{3,3} \\cdot x_{22}.\n",
        "$$\n",
        "\n",
        "Аналогично вычисляются градиенты для остальных элементов ядра $ K[m,n] $.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3.5. **Пример вычисления $ \\frac{\\partial L}{\\partial O} $**\n",
        "\n",
        "#### Исходные данные:\n",
        "- Выходная карта признаков $ O $ размером $ 3 \\times 3 $:\n",
        "$$\n",
        "O =\n",
        "\\begin{bmatrix}\n",
        "O[1,1] & O[1,2] & O[1,3] \\\\\n",
        "O[2,1] & O[2,2] & O[2,3] \\\\\n",
        "O[3,1] & O[3,2] & O[3,3]\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "- Градиент $ \\frac{\\partial L}{\\partial Z} $ (передается из следующего слоя):\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial Z} =\n",
        "\\begin{bmatrix}\n",
        "\\delta_{1,1} & \\delta_{1,2} & \\delta_{1,3} \\\\\n",
        "\\delta_{2,1} & \\delta_{2,2} & \\delta_{2,3} \\\\\n",
        "\\delta_{3,1} & \\delta_{3,2} & \\delta_{3,3}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "- Функция активации $ f(z) $ (например, ReLU):\n",
        "  - $ f(z) = \\max(0, z) $,\n",
        "  - $ f'(z) = 1 $, если $ z > 0 $, иначе $ f'(z) = 0 $.\n",
        "\n",
        "#### Шаг 1: Применение производной функции активации\n",
        "Для каждого элемента $ O[i,j] $ вычисляем:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial O[i,j]} = \\delta_{i,j} \\cdot f'(O[i,j]).\n",
        "$$\n",
        "\n",
        "Например, для $ O[1,1] $:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial O[1,1]} = \\delta_{1,1} \\cdot f'(O[1,1]).\n",
        "$$\n",
        "\n",
        "Аналогично вычисляются градиенты для остальных элементов.\n",
        "\n",
        "\n",
        "\n",
        "**Итоговая матрица $ \\frac{\\partial L}{\\partial O} $**\n",
        "После выполнения всех вычислений получаем матрицу градиентов:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial O} =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial L}{\\partial O[1,1]} & \\frac{\\partial L}{\\partial O[1,2]} & \\frac{\\partial L}{\\partial O[1,3]} \\\\\n",
        "\\frac{\\partial L}{\\partial O[2,1]} & \\frac{\\partial L}{\\partial O[2,2]} & \\frac{\\partial L}{\\partial O[2,3]} \\\\\n",
        "\\frac{\\partial L}{\\partial O[3,1]} & \\frac{\\partial L}{\\partial O[3,2]} & \\frac{\\partial L}{\\partial O[3,3]}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### 3.6. **Обновление параметров ядра**\n",
        "\n",
        "После вычисления градиентов ядро $ K $ обновляется с использованием метода оптимизации. Например, при использовании градиентного спуска:\n",
        "$$\n",
        "K[m,n] = K[m,n] - \\eta \\cdot \\frac{\\partial L}{\\partial K[m,n]},\n",
        "$$\n",
        "где $ \\eta $ — скорость обучения (learning rate).\n",
        "\n",
        "\n",
        "\n",
        "#### 3.7. **Важные замечания**\n",
        "\n",
        "1. **Размерность градиентов**:\n",
        "   - Градиент $ \\frac{\\partial L}{\\partial K} $ имеет ту же размерность, что и ядро $ K $.\n",
        "\n",
        "2. **Цепное правило**:\n",
        "   Градиенты $ \\frac{\\partial L}{\\partial O[i,j]} $ передаются от следующего слоя к предыдущему в процессе обратного распространения.\n",
        "\n",
        "3. **Связь с входной матрицей**:\n",
        "   Каждый элемент ядра $ K[m,n] $ обновляется на основе всех элементов входной матрицы $ I $, которые участвовали в операции свертки.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3.8. **Дополнительное объяснение шага свертки ($ s $)**\n",
        "\n",
        "Шаг свертки ($ s $) играет ключевую роль в определении того, как ядро перемещается по входной матрице $ I $. Если $ s > 1 $, ядро \"перепрыгивает\" через некоторые элементы $ I $, что влияет на плотность вычислений и размер выходной карты $ O $. Это также влияет на градиенты:\n",
        "\n",
        "- **Плотность участия элементов $ I $**: При $ s = 1 $ каждый элемент $ I $ участвует в большем количестве операций свертки, чем при $ s > 1 $. Это означает, что градиенты $ \\frac{\\partial L}{\\partial K[m,n]} $ будут более равномерно распределены по всем элементам $ I $.\n",
        "- **Разреженность градиентов**: При $ s > 1 $ некоторые элементы $ I $ могут вообще не участвовать в операции свертки, что приводит к разреженным градиентам.\n",
        "\n",
        "Пример:\n",
        "- Если $ s = 2 $, то ядро будет накладываться только на четные строки и столбцы $ I $, что уменьшает количество слагаемых в формуле:\n",
        "$$\n",
        "  \\frac{\\partial L}{\\partial K[m,n]} = \\sum_{i,j} \\frac{\\partial L}{\\partial O[i,j]} \\cdot I[i \\cdot s + m, j \\cdot s + n].\n",
        "$$\n",
        "\n",
        "\n",
        "### 3.8.1. **Объяснение паддинга**\n",
        "\n",
        "Паддинг ($ p $) добавляет нулевые значения вокруг границ входной матрицы $ I $, что увеличивает размер области, доступной для свертки. Это влияет на формулу для $ \\frac{\\partial O[i,j]}{\\partial K[m,n]} $:\n",
        "\n",
        "- **Индексы с учетом паддинга**:\n",
        "  Если используется паддинг $ p $, то индексы входной матрицы $ I $ изменяются:\n",
        "$$\n",
        "  O[i,j] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} I[(i \\cdot s + m) - p, (j \\cdot s + n) - p] \\cdot K[m,n].\n",
        "$$\n",
        "  Здесь $ p $ компенсирует смещение границ.\n",
        "\n",
        "- **Градиенты с учетом паддинга**:\n",
        "  Аналогично, градиенты $ \\frac{\\partial L}{\\partial K[m,n]} $ учитывают только те элементы $ I $, которые находятся внутри исходной области без паддинга.\n",
        "\n",
        "\n",
        "\n",
        "### 3.8.2. **Интерпретация градиентов**\n",
        "\n",
        "Градиенты $ \\frac{\\partial L}{\\partial K[m,n]} $ имеют физический смысл: они показывают, насколько сильно изменение конкретного веса $ K[m,n] $ влияет на общую ошибку $ L $. Это можно интерпретировать следующим образом:\n",
        "\n",
        "- **Сильная связь**: Если $ \\frac{\\partial L}{\\partial K[m,n]} $ велико, это означает, что вес $ K[m,n] $ сильно влияет на ошибку и требует корректировки.\n",
        "- **Слабая связь**: Если $ \\frac{\\partial L}{\\partial K[m,n]} $ близко к нулю, это означает, что вес $ K[m,n] $ слабо связан с ошибкой и может быть менее важным.\n",
        "\n",
        "\n",
        "### 3.8.3. **Роль градиентов $ \\frac{\\partial L}{\\partial O} $**\n",
        "\n",
        "Градиенты $ \\frac{\\partial L}{\\partial O} $ передаются от следующего слоя и зависят от его архитектуры. Например:\n",
        "\n",
        "- **Макс-пулинг**: Если следующий слой — это макс-пулинг, то градиент $ \\frac{\\partial L}{\\partial O[i,j]} $ передается только тому элементу $ O[i,j] $, который был максимальным в окне.\n",
        "- **Средне-пулинг**: Градиент равномерно распределяется между всеми элементами окна.\n",
        "- **Функция активации**: Градиенты $ \\frac{\\partial L}{\\partial O[i,j]} $ умножаются на производную функции активации $ f'(O[i,j]) $.\n",
        "\n",
        "Это важно учитывать при вычислении $ \\frac{\\partial L}{\\partial K[m,n]} $.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Градиенты для пулинга**\n",
        "\n",
        "Пулинговые слои (Pooling Layers) являются важной частью сверточных нейронных сетей (CNN), так как они уменьшают размерность карт признаков, сохраняя ключевую информацию. Однако при обучении сети необходимо вычислять градиенты функции потерь $ L $ относительно входных данных пулингового слоя. Рассмотрим подробно, как это делается для двух основных типов пулинга: макс-пулинга и средне-пулинга.\n",
        "\n",
        "\n",
        "\n",
        "#### **4.1. Напоминание о forward pass (прямом распространении)**\n",
        "\n",
        "Перед тем как перейти к вычислению градиентов (обратному распространению), напомним, как выполняется операция пулинга в прямом проходе:\n",
        "\n",
        "1. **Макс-пулинг**:\n",
        "   - Для каждого окна входной матрицы выбирается максимальное значение.\n",
        "   - Например, если окно имеет размер $ 2 \\times 2 $, то выходное значение равно:\n",
        "$$\n",
        "     z = \\max(x_{00}, x_{01}, x_{10}, x_{11}).\n",
        "$$\n",
        "\n",
        "2. **Средне-пулинг**:\n",
        "   - Для каждого окна входной матрицы вычисляется среднее значение.\n",
        "   - Например, если окно имеет размер $ 2 \\times 2 $, то выходное значение равно:\n",
        "$$\n",
        "     z = \\frac{x_{00} + x_{01} + x_{10} + x_{11}}{4}.\n",
        "$$\n",
        "\n",
        "Эти операции уменьшают размерность карт признаков, что помогает снизить вычислительные затраты и избежать переобучения.\n",
        "\n",
        "\n",
        "\n",
        "### 4.2. **Макс-пулинг**\n",
        "\n",
        "#### 4.2.1. Общая идея\n",
        "Макс-пулинг выбирает максимальное значение из окна входной матрицы. Это означает, что только один элемент в окне влияет на выходное значение. При обратном распространении ошибки градиент передается только тому элементу, который был максимальным в окне.\n",
        "\n",
        "#### 4.2.2. Математическая формулировка\n",
        "Пусть входное окно имеет размер $ P_h \\times P_w $ (например, $ 2 \\times 2 $), и его элементы обозначены как $ x_1, x_2, \\dots, x_n $. Выходное значение $ z $ для этого окна вычисляется как:\n",
        "$$\n",
        "z = \\max(x_1, x_2, \\dots, x_n).\n",
        "$$\n",
        "\n",
        "Если $ \\text{max}(x_1, x_2, \\dots, x_n) = x_k $, то градиент функции потерь $ L $ относительно входного элемента $ x_i $ равен:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_i} =\n",
        "\\begin{cases}\n",
        "  \\frac{\\partial L}{\\partial z}, & \\text{если } i = k, \\\\\n",
        "  0, & \\text{иначе}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "- $ \\frac{\\partial L}{\\partial z} $ — градиент функции потерь относительно выходного значения $ z $ (передается из следующего слоя),\n",
        "- $ k $ — индекс максимального элемента в окне.\n",
        "\n",
        "#### 4.2.3. Пример вычислений\n",
        "Пусть входное окно $ 2 \\times 2 $ имеет вид:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x_{00} & x_{01} \\\\\n",
        "x_{10} & x_{11}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выходное значение $ z $ вычисляется как:\n",
        "$$\n",
        "z = \\max(x_{00}, x_{01}, x_{10}, x_{11}).\n",
        "$$\n",
        "\n",
        "Предположим, что максимальным элементом является $ x_{01} $. Тогда градиенты относительно входных элементов будут:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_{00}} = 0, \\quad\n",
        "\\frac{\\partial L}{\\partial x_{01}} = \\frac{\\partial L}{\\partial z}, \\quad\n",
        "\\frac{\\partial L}{\\partial x_{10}} = 0, \\quad\n",
        "\\frac{\\partial L}{\\partial x_{11}} = 0.\n",
        "$$\n",
        "\n",
        "#### 4.2.4. Интерпретация\n",
        "Градиент $ \\frac{\\partial L}{\\partial x_i} $ равен нулю для всех элементов окна, кроме максимального. Это связано с тем, что только максимальный элемент влияет на выходное значение $ z $, а остальные элементы не участвуют в операции.\n",
        "\n",
        "\n",
        "\n",
        "### 4.3. **Средне-пулинг**\n",
        "\n",
        "#### 4.3.1. Общая идея\n",
        "Средне-пулинг вычисляет среднее значение элементов в окне. В отличие от макс-пулинга, здесь все элементы окна вносят вклад в выходное значение. При обратном распространении ошибки градиент равномерно распределяется между всеми элементами окна.\n",
        "\n",
        "#### 4.3.2. Математическая формулировка\n",
        "Пусть входное окно имеет размер $ P_h \\times P_w $, и его элементы обозначены как $ x_1, x_2, \\dots, x_n $. Выходное значение $ z $ для этого окна вычисляется как:\n",
        "$$\n",
        "z = \\frac{1}{P_h \\cdot P_w} \\sum_{i=1}^{n} x_i.\n",
        "$$\n",
        "\n",
        "Градиент функции потерь $ L $ относительно входного элемента $ x_i $ равен:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_i} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{1}{P_h \\cdot P_w}.\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "- $ \\frac{\\partial L}{\\partial z} $ — градиент функции потерь относительно выходного значения $ z $,\n",
        "- $ P_h \\cdot P_w $ — общее количество элементов в окне.\n",
        "\n",
        "#### 4.3.3. Пример вычислений\n",
        "Пусть входное окно $ 2 \\times 2 $ имеет вид:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x_{00} & x_{01} \\\\\n",
        "x_{10} & x_{11}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Выходное значение $ z $ вычисляется как:\n",
        "$$\n",
        "z = \\frac{x_{00} + x_{01} + x_{10} + x_{11}}{4}.\n",
        "$$\n",
        "\n",
        "Градиенты относительно входных элементов будут:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_{00}} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{1}{4}, \\quad\n",
        "\\frac{\\partial L}{\\partial x_{01}} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{1}{4}, \\quad\n",
        "\\frac{\\partial L}{\\partial x_{10}} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{1}{4}, \\quad\n",
        "\\frac{\\partial L}{\\partial x_{11}} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{1}{4}.\n",
        "$$\n",
        "\n",
        "#### 4.3.4. Интерпретация\n",
        "Градиент $ \\frac{\\partial L}{\\partial x_i} $ равномерно распределяется между всеми элементами окна, так как каждый элемент вносит равный вклад в выходное значение $ z $.\n",
        "\n",
        "\n",
        "\n",
        "### 4.4. **Влияние пулинга на обучение**\n",
        "\n",
        "1. **Макс-пулинг**:\n",
        "   - Преимущества:\n",
        "     - Сохраняет наиболее значимые признаки.\n",
        "     - Устойчив к шуму за счет выбора максимальных значений.\n",
        "   - Недостатки:\n",
        "     - Может привести к потере информации о положении признаков, так как игнорирует все элементы окна, кроме максимального.\n",
        "\n",
        "2. **Средне-пулинг**:\n",
        "   - Преимущества:\n",
        "     - Учитывает все элементы окна, что делает его более устойчивым к шуму.\n",
        "   - Недостатки:\n",
        "     - Может размывать данные, так как среднее значение может быть менее информативным, чем максимальное.\n",
        "\n",
        "\n",
        "\n",
        "### 4.5. **Общие замечания**\n",
        "\n",
        "1. **Размер окна**:\n",
        "   Размер окна $ P_h \\times P_w $ определяет, сколько элементов участвует в операции пулинга. Например:\n",
        "   - Для $ 2 \\times 2 $ окна $ P_h = 2 $, $ P_w = 2 $, и $ P_h \\cdot P_w = 4 $.\n",
        "   - Для $ 3 \\times 3 $ окна $ P_h = 3 $, $ P_w = 3 $, и $ P_h \\cdot P_w = 9 $.\n",
        "\n",
        "2. **Связь с предыдущими слоями**:\n",
        "   Градиенты $ \\frac{\\partial L}{\\partial x_i} $ передаются обратно на предыдущий слой (например, сверточный слой) через цепное правило дифференцирования. Это позволяет обновлять параметры ядра свертки $ K $.\n",
        "\n",
        "3. **Эффективность**:\n",
        "   - **Макс-пулинг**: Более эффективен для выделения наиболее значимых признаков, так как сохраняет только максимальные значения.\n",
        "   - **Средне-пулинг**: Более устойчив к шуму, так как учитывает все элементы окна.\n",
        "\n",
        "\n",
        "\n",
        "### 4.6. **Заключение**\n",
        "\n",
        "Вычисление градиентов для пулинговых слоев зависит от типа пулинга:\n",
        "- Для **макс-пулинга** градиент передается только максимальному элементу в окне.\n",
        "- Для **средне-пулинга** градиент равномерно распределяется между всеми элементами окна.\n",
        "\n",
        "Эти градиенты играют ключевую роль в обратном распространении ошибки, позволяя обновлять параметры сети для минимизации функции потерь.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 8.5. Методы оптимизации\n",
        "\n",
        "После вычисления градиентов функции потерь $ L $ относительно параметров модели (например, весов $ W $) необходимо обновить эти параметры для минимизации ошибки. Для этого используются методы оптимизации, которые определяют, как именно параметры будут корректироваться на каждом шаге обучения. Рассмотрим наиболее популярные методы оптимизации.\n",
        "\n",
        "\n",
        "\n",
        "### 1. **Градиентный спуск (Gradient Descent)**\n",
        "\n",
        "#### 1.1. Основная идея\n",
        "Градиентный спуск — это базовый метод оптимизации, который использует градиент функции потерь для обновления параметров модели. Параметры изменяются в направлении, противоположном градиенту, чтобы минимизировать значение функции потерь.\n",
        "\n",
        "#### 1.2. Формула обновления\n",
        "Обновление параметров выполняется по формуле:\n",
        "$$\n",
        "W = W - \\eta \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "где:\n",
        "- $ W $ — параметры модели (например, веса),\n",
        "- $ \\eta $ — скорость обучения (learning rate), которая контролирует размер шага,\n",
        "- $ \\frac{\\partial L}{\\partial W} $ — градиент функции потерь относительно параметров.\n",
        "\n",
        "#### 1.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Простота реализации.\n",
        "  - Хорошо работает для небольших датасетов.\n",
        "- **Недостатки**:\n",
        "  - Может быть медленным для больших датасетов, так как градиенты вычисляются на всем наборе данных.\n",
        "  - Чувствителен к выбору скорости обучения $ \\eta $.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Стохастический градиентный спуск (SGD)**\n",
        "\n",
        "#### 2.1. Основная идея\n",
        "В стохастическом градиентном спуске (SGD) градиенты вычисляются не на всем наборе данных, а на случайных мини-батчах (подмножествах данных). Это ускоряет обучение и делает его более устойчивым к шуму.\n",
        "\n",
        "#### 2.2. Формула обновления\n",
        "Обновление параметров выполняется по формуле:\n",
        "$$\n",
        "W = W - \\eta \\cdot \\frac{1}{B} \\sum_{i=1}^{B} \\frac{\\partial L_i}{\\partial W},\n",
        "$$\n",
        "где:\n",
        "- $ B $ — размер мини-батча,\n",
        "- $ L_i $ — функция потерь для $ i $-го примера в мини-батче.\n",
        "\n",
        "#### 2.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Быстрее, чем классический градиентный спуск, особенно для больших датасетов.\n",
        "  - Устойчивость к шуму благодаря использованию мини-батчей.\n",
        "- **Недостатки**:\n",
        "  - Шумные обновления из-за использования малых подмножеств данных.\n",
        "  - Требует тщательного подбора скорости обучения $ \\eta $.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Momentum**\n",
        "\n",
        "#### 3.1. Основная идея\n",
        "Momentum — это метод оптимизации, который добавляет \"импульс\" (ускорение) к обновлению параметров. Он помогает преодолевать локальные минимумы и сглаживает колебания при обучении.\n",
        "\n",
        "Идея заключается в том, чтобы не только учитывать текущий градиент, но и добавлять часть предыдущего изменения параметров. Это позволяет модели двигаться быстрее в направлении общего тренда и замедляться в областях с высокой кривизной.\n",
        "\n",
        "#### 3.2. Формула обновления\n",
        "Обновление параметров выполняется по следующим формулам:\n",
        "1. Вычисление скорости изменения (momentum):\n",
        "$$\n",
        "   v_t = \\beta \\cdot v_{t-1} + \\eta \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "   где:\n",
        "   - $ v_t $ — скорость изменения на шаге $ t $,\n",
        "   - $ \\beta $ — коэффициент затухания (обычно $ \\beta = 0.9 $),\n",
        "   - $ \\eta $ — скорость обучения (learning rate),\n",
        "   - $ \\frac{\\partial L}{\\partial W} $ — градиент функции потерь относительно параметров.\n",
        "\n",
        "2. Обновление параметров:\n",
        "$$\n",
        "   W = W - v_t.\n",
        "$$\n",
        "\n",
        "#### 3.3. Преимущества\n",
        "- Ускоряет обучение в областях с малыми градиентами.\n",
        "- Снижает колебания в областях с высокой кривизной.\n",
        "- Помогает преодолевать локальные минимумы.\n",
        "\n",
        "#### 3.4. Недостатки\n",
        "- Может быть менее эффективным для задач с разреженными данными.\n",
        "- Требует тщательного подбора параметра $ \\beta $.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **RMSProp**\n",
        "\n",
        "#### 4.1. Основная идея\n",
        "RMSProp (Root Mean Square Propagation) — это метод оптимизации, который адаптирует скорость обучения для каждого параметра на основе экспоненциально затухающей средней величины квадратов градиентов. Это помогает избежать взрывов градиентов и обеспечивает более стабильное обучение.\n",
        "\n",
        "#### 4.2. Формула обновления\n",
        "Обновление параметров выполняется по следующим формулам:\n",
        "1. Вычисление экспоненциально затухающей средней величины квадратов градиентов:\n",
        "$$\n",
        "   v_t = \\beta \\cdot v_{t-1} + (1 - \\beta) \\cdot (\\frac{\\partial L}{\\partial W})^2,\n",
        "$$\n",
        "   где:\n",
        "   - $ v_t $ — экспоненциально затухающая средняя величина квадратов градиентов,\n",
        "   - $ \\beta $ — коэффициент затухания (обычно $ \\beta = 0.9 $).\n",
        "\n",
        "2. Обновление параметров:\n",
        "$$\n",
        "   W = W - \\frac{\\eta}{\\sqrt{v_t} + \\epsilon} \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "   где:\n",
        "   - $ \\eta $ — скорость обучения,\n",
        "   - $ \\epsilon $ — малая константа для численной стабильности (обычно $ \\epsilon = 10^{-8} $).\n",
        "\n",
        "#### 4.3. Преимущества\n",
        "- Адаптивная скорость обучения для каждого параметра.\n",
        "- Эффективен для задач с разреженными данными.\n",
        "- Устойчив к взрывам градиентов.\n",
        "\n",
        "#### 4.4. Недостатки\n",
        "- Может быть менее стабильным без дополнительных механизмов (например, Momentum).\n",
        "- Требует тщательного подбора параметра $ \\beta $.\n",
        "\n",
        "\n",
        "\n",
        "### 5. **Adam (Adaptive Moment Estimation)**\n",
        "\n",
        "#### 5.1. Основная идея\n",
        "Adam комбинирует преимущества методов RMSProp и Momentum. Он использует экспоненциально затухающие средние величины градиентов ($ \\hat{m} $) и квадратов градиентов ($ \\hat{v} $) для адаптивного изменения скорости обучения.\n",
        "\n",
        "#### 5.2. Формулы обновления\n",
        "1. Вычисление экспоненциально затухающих средних:\n",
        "$$\n",
        "   m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "$$\n",
        "   v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot (\\frac{\\partial L}{\\partial W})^2,\n",
        "$$\n",
        "   где:\n",
        "   - $ m_t $ — экспоненциально затухающая средняя величина градиентов,\n",
        "   - $ v_t $ — экспоненциально затухающая средняя величина квадратов градиентов,\n",
        "   - $ \\beta_1 $ и $ \\beta_2 $ — коэффициенты затухания (обычно $ \\beta_1 = 0.9 $, $ \\beta_2 = 0.999 $).\n",
        "\n",
        "2. Коррекция смещения:\n",
        "$$\n",
        "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}.\n",
        "$$\n",
        "\n",
        "3. Обновление параметров:\n",
        "$$\n",
        "   W = W - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\cdot \\hat{m}_t,\n",
        "$$\n",
        "   где:\n",
        "   - $ \\epsilon $ — малая константа для численной стабильности (обычно $ \\epsilon = 10^{-8} $).\n",
        "\n",
        "#### 5.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Адаптивная скорость обучения для каждого параметра.\n",
        "  - Хорошо работает для задач с разреженными данными.\n",
        "  - Устойчив к шуму.\n",
        "- **Недостатки**:\n",
        "  - Может быть менее эффективным для простых задач.\n",
        "\n",
        "\n",
        "\n",
        "### 6. **AdamW**\n",
        "\n",
        "#### 6.1. Основная идея\n",
        "AdamW — это улучшенная версия Adam, которая решает проблему регуляризации весов. В классическом Adam регуляризация L2 добавляется к функции потерь, что может привести к нежелательным эффектам при использовании адаптивной скорости обучения. AdamW отделяет регуляризацию от обновления параметров, что делает его более стабильным и эффективным.\n",
        "\n",
        "#### 6.2. Формулы обновления\n",
        "1. Вычисление экспоненциально затухающих средних:\n",
        "$$\n",
        "   m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "$$\n",
        "   v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot (\\frac{\\partial L}{\\partial W})^2.\n",
        "$$\n",
        "\n",
        "2. Коррекция смещения:\n",
        "$$\n",
        "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}.\n",
        "$$\n",
        "\n",
        "3. Обновление параметров:\n",
        "$$\n",
        "   W = W - \\eta \\cdot (\\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\cdot W),\n",
        "$$\n",
        "   где:\n",
        "   - $ \\lambda $ — коэффициент регуляризации L2,\n",
        "   - $ \\epsilon $ — малая константа для численной стабильности.\n",
        "\n",
        "#### 6.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Более точная регуляризация весов.\n",
        "  - Устойчивость к взрывам градиентов.\n",
        "  - Хорошо работает для задач глубокого обучения.\n",
        "- **Недостатки**:\n",
        "  - Требует тщательного подбора гиперпараметров ($ \\eta, \\beta_1, \\beta_2, \\lambda $).\n",
        "\n",
        "\n",
        "\n",
        "### 7. **AdaGrad**\n",
        "\n",
        "#### 7.1. Основная идея\n",
        "AdaGrad (Adaptive Gradient Algorithm) — это метод оптимизации, который адаптирует скорость обучения для каждого параметра на основе кумулятивной суммы квадратов градиентов. Это особенно полезно для задач с разреженными данными, где некоторые параметры обновляются реже других.\n",
        "\n",
        "#### 7.2. Формулы обновления\n",
        "1. Вычисление кумулятивной суммы квадратов градиентов:\n",
        "$$\n",
        "   G_t = G_{t-1} + (\\frac{\\partial L}{\\partial W})^2.\n",
        "$$\n",
        "\n",
        "2. Обновление параметров:\n",
        "$$\n",
        "   W = W - \\frac{\\eta}{\\sqrt{G_t} + \\epsilon} \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "   где:\n",
        "   - $ \\epsilon $ — малая константа для численной стабильности.\n",
        "\n",
        "#### 7.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Адаптивная скорость обучения для каждого параметра.\n",
        "  - Эффективен для задач с разреженными данными.\n",
        "- **Недостатки**:\n",
        "  - Скорость обучения может слишком быстро уменьшаться, что замедляет обучение в долгосрочной перспективе.\n",
        "\n",
        "\n",
        "\n",
        "### 8. **Adadelta**\n",
        "\n",
        "#### 8.1. Основная идея\n",
        "Adadelta — это улучшенная версия AdaGrad, которая решает проблему монотонного уменьшения скорости обучения. Вместо кумулятивной суммы квадратов градиентов Adadelta использует скользящее среднее.\n",
        "\n",
        "#### 8.2. Формулы обновления\n",
        "1. Вычисление скользящего среднего квадратов градиентов:\n",
        "$$\n",
        "   E[g^2]_t = \\rho \\cdot E[g^2]_{t-1} + (1 - \\rho) \\cdot (\\frac{\\partial L}{\\partial W})^2,\n",
        "$$\n",
        "   где $ \\rho $ — коэффициент затухания (обычно $ \\rho = 0.9 $).\n",
        "\n",
        "2. Вычисление изменения параметров:\n",
        "$$\n",
        "   \\Delta W_t = -\\frac{\\sqrt{E[\\Delta W^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} \\cdot \\frac{\\partial L}{\\partial W}.\n",
        "$$\n",
        "\n",
        "3. Обновление параметров:\n",
        "$$\n",
        "   W = W + \\Delta W_t.\n",
        "$$\n",
        "\n",
        "4. Обновление скользящего среднего изменений параметров:\n",
        "$$\n",
        "   E[\\Delta W^2]_t = \\rho \\cdot E[\\Delta W^2]_{t-1} + (1 - \\rho) \\cdot (\\Delta W_t)^2.\n",
        "$$\n",
        "\n",
        "#### 8.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Не требует установки скорости обучения $ \\eta $.\n",
        "  - Устойчив к взрывам градиентов.\n",
        "- **Недостатки**:\n",
        "  - Может быть менее эффективным для простых задач.\n",
        "\n",
        "\n",
        "\n",
        "### 9. **Nadam**\n",
        "\n",
        "#### 9.1. Основная идея\n",
        "Nadam (Nesterov-accelerated Adaptive Moment Estimation) — это комбинация Adam и Nesterov Accelerated Gradient (NAG). Он использует принцип \"предварительного просмотра\" градиента, что позволяет более эффективно преодолевать локальные минимумы.\n",
        "\n",
        "#### 9.2. Формулы обновления\n",
        "1. Вычисление экспоненциально затухающих средних:\n",
        "$$\n",
        "   m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot \\frac{\\partial L}{\\partial W},\n",
        "$$\n",
        "$$\n",
        "   v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot (\\frac{\\partial L}{\\partial W})^2.\n",
        "$$\n",
        "\n",
        "2. Коррекция смещения:\n",
        "$$\n",
        "   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}.\n",
        "$$\n",
        "\n",
        "3. Обновление параметров:\n",
        "$$\n",
        "   W = W - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\cdot (\\beta_1 \\cdot \\hat{m}_t + \\frac{(1 - \\beta_1) \\cdot \\frac{\\partial L}{\\partial W}}{1 - \\beta_1^t}).\n",
        "$$\n",
        "\n",
        "#### 9.3. Преимущества и недостатки\n",
        "- **Преимущества**:\n",
        "  - Комбинирует преимущества Adam и NAG.\n",
        "  - Ускоряет обучение в областях с высокой кривизной.\n",
        "- **Недостатки**:\n",
        "  - Требует тщательного подбора гиперпараметров.\n",
        "\n",
        "\n",
        "\n",
        "### 10. **Практические рекомендации**\n",
        "\n",
        "1. **Выбор метода оптимизации**:\n",
        "   - Для простых задач: SGD или Momentum.\n",
        "   - Для сложных задач: Adam, AdamW или Nadam.\n",
        "   - Для задач с разреженными данными: AdaGrad или RMSProp.\n",
        "\n",
        "2. **Подбор скорости обучения**:\n",
        "   - Начните с небольших значений ($ \\eta = 0.001 $) и постепенно увеличивайте.\n",
        "   - Используйте learning rate scheduling для уменьшения скорости обучения в процессе обучения.\n",
        "\n",
        "3. **Инициализация параметров**:\n",
        "   - Используйте методы инициализации, такие как Xavier или He, чтобы избежать проблем с исчезающими или взрывающимися градиентами.\n",
        "\n",
        "4. **Регуляризация**:\n",
        "   - Добавьте L2-регуляризацию или dropout для предотвращения переобучения.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 8.6. Регуляризация (подробное описание)\n",
        "\n",
        "Регуляризация — это ключевой инструмент в машинном обучении, который помогает предотвратить переобучение модели. Переобучение возникает, когда модель становится слишком сложной и начинает \"запоминать\" обучающую выборку вместо того, чтобы обобщать закономерности. Регуляризация добавляет ограничения или штрафы к процессу обучения, чтобы уменьшить сложность модели и повысить ее способность работать с новыми данными. Рассмотрим основные методы регуляризации более подробно.\n",
        "\n",
        "\n",
        "\n",
        "### 1. **L2-регуляризация (Weight Decay)**\n",
        "\n",
        "#### 1.1. Основная идея\n",
        "L2-регуляризация, также известная как Weight Decay (декремент весов), добавляет штраф за большие значения весов в функцию потерь. Это ограничивает рост весов модели, что делает её менее чувствительной к выбросам и шуму в данных. В результате модель становится более гладкой и обобщающей.\n",
        "\n",
        "#### 1.2. Формула\n",
        "Функция потерь с L2-регуляризацией выглядит следующим образом:\n",
        "$$\n",
        "L_{\\text{reg}} = L + \\lambda \\cdot \\sum_{i} W_i^2,\n",
        "$$\n",
        "где:\n",
        "- $ L $ — исходная функция потерь (например, среднеквадратичная ошибка или кросс-энтропия),\n",
        "- $ \\lambda $ — коэффициент регуляризации, который контролирует силу штрафа,\n",
        "- $ W_i $ — веса модели.\n",
        "\n",
        "Чем больше значение $ \\lambda $, тем сильнее штраф за большие веса, и тем проще становится модель.\n",
        "\n",
        "#### 1.3. Преимущества\n",
        "- Уменьшает переобучение.\n",
        "- Делает модель более устойчивой к шуму в данных.\n",
        "- Простота реализации и применения.\n",
        "\n",
        "#### 1.4. Недостатки\n",
        "- Может привести к недообучению при слишком большом значении $ \\lambda $.\n",
        "- Требует тщательного подбора параметра $ \\lambda $.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **L1-регуляризация**\n",
        "\n",
        "#### 2.1. Основная идея\n",
        "L1-регуляризация добавляет штраф за абсолютные значения весов в функцию потерь. В отличие от L2-регуляризации, L1-регуляризация может привести к разреженности весов, то есть некоторые веса могут стать равными нулю. Это полезно для задач, где требуется отбор признаков.\n",
        "\n",
        "#### 2.2. Формула\n",
        "Функция потерь с L1-регуляризацией выглядит так:\n",
        "$$\n",
        "L_{\\text{reg}} = L + \\lambda \\cdot \\sum_{i} |W_i|,\n",
        "$$\n",
        "где:\n",
        "- $ |W_i| $ — абсолютное значение веса.\n",
        "\n",
        "#### 2.3. Преимущества\n",
        "- Способствует разреженности весов, что позволяет отбирать важные признаки.\n",
        "- Уменьшает размер модели за счет игнорирования незначимых весов.\n",
        "\n",
        "#### 2.4. Недостатки\n",
        "- Может быть менее эффективным для моделей с большим количеством малозначимых весов.\n",
        "- Более сложный процесс оптимизации из-за не дифференцируемости функции $ |W_i| $ в точке ноль.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Dropout**\n",
        "\n",
        "#### 3.1. Основная идея\n",
        "Dropout — это техника регуляризации, которая случайным образом \"выключает\" (обнуляет) некоторые нейроны в нейронной сети во время обучения. Это снижает зависимость модели от конкретных связей между нейронами и заставляет её учиться более надежным и обобщающим представлениям.\n",
        "\n",
        "#### 3.2. Механизм работы\n",
        "- На каждом шаге обучения каждый нейрон сети с вероятностью $ p $ \"выключается\", то есть его выход устанавливается в ноль.\n",
        "- Вероятность $ p $ обычно выбирается в диапазоне от 0.2 до 0.5.\n",
        "- Во время тестирования все нейроны активны, но их выходы умножаются на $ 1-p $, чтобы компенсировать эффект Dropout.\n",
        "\n",
        "#### 3.3. Преимущества\n",
        "- Эффективно предотвращает переобучение.\n",
        "- Позволяет модели использовать различные комбинации нейронов, что улучшает обобщающую способность.\n",
        "- Простота реализации.\n",
        "\n",
        "#### 3.4. Недостатки\n",
        "- Замедляет обучение, так как часть нейронов временно \"выключена\".\n",
        "- Требует тщательного подбора вероятности $ p $.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Data Augmentation**\n",
        "\n",
        "#### 4.1. Основная идея\n",
        "Data Augmentation (расширение данных) — это метод увеличения размера обучающей выборки путем искусственного преобразования исходных данных. Это особенно полезно для задач компьютерного зрения, где данные часто ограничены.\n",
        "\n",
        "#### 4.2. Примеры преобразований\n",
        "- Для изображений:\n",
        "  - Повороты, отражения, изменение масштаба.\n",
        "  - Изменение яркости, контрастности, цветового баланса.\n",
        "  - Добавление шума.\n",
        "- Для текстовых данных:\n",
        "  - Перестановка слов.\n",
        "  - Использование синонимов.\n",
        "  - Генерация новых предложений с помощью моделей языкового моделирования.\n",
        "- Для временных рядов:\n",
        "  - Сдвиги по времени.\n",
        "  - Добавление случайного шума.\n",
        "\n",
        "#### 4.3. Преимущества\n",
        "- Увеличивает объем данных, что улучшает обобщающую способность модели.\n",
        "- Помогает модели лучше справляться с вариациями входных данных.\n",
        "- Не требует дополнительных затрат на сбор реальных данных.\n",
        "\n",
        "#### 4.4. Недостатки\n",
        "- Может быть трудоемким для реализации, особенно для сложных типов данных.\n",
        "- Неправильно подобранные преобразования могут ввести в данные артефакты, которые не соответствуют реальности.\n",
        "\n",
        "\n",
        "\n",
        "### 5. **Early Stopping**\n",
        "\n",
        "#### 5.1. Основная идея\n",
        "Early Stopping — это метод регуляризации, который заключается в прекращении обучения модели, если качество на валидационной выборке перестает улучшаться. Это предотвращает переобучение, так как модель не продолжает обучаться после достижения оптимального уровня обобщающей способности.\n",
        "\n",
        "#### 5.2. Механизм работы\n",
        "- Обучение модели проводится в несколько эпох.\n",
        "- После каждой эпохи проверяется значение функции потерь на валидационной выборке.\n",
        "- Если значение функции потерь не улучшается в течение заданного числа эпох (патиентности), обучение прекращается.\n",
        "\n",
        "#### 5.3. Преимущества\n",
        "- Простота реализации.\n",
        "- Эффективно предотвращает переобучение.\n",
        "- Экономит вычислительные ресурсы, так как обучение завершается раньше.\n",
        "\n",
        "#### 5.4. Недостатки\n",
        "- Требует наличия валидационной выборки.\n",
        "- Может привести к преждевременной остановке, если патиентность выбрана слишком маленькой.\n",
        "\n",
        "\n",
        "\n",
        "### 6. **Batch Normalization**\n",
        "\n",
        "#### 6.1. Основная идея\n",
        "Batch Normalization — это метод, который нормализует выходы нейронов внутри каждого мини-батча. Это стабилизирует процесс обучения, уменьшает влияние внутренних ковариационных сдвигов и действует как форма регуляризации.\n",
        "\n",
        "#### 6.2. Механизм работы\n",
        "Для каждого мини-батча выполняются следующие шаги:\n",
        "1. Вычисление среднего и стандартного отклонения выходов нейронов.\n",
        "2. Нормализация выходов:\n",
        "$$\n",
        "   \\hat{x} = \\frac{x - \\mu}{\\sigma},\n",
        "$$\n",
        "   где $ \\mu $ — среднее, $ \\sigma $ — стандартное отклонение.\n",
        "3. Масштабирование и сдвиг нормализованных значений:\n",
        "$$\n",
        "   y = \\gamma \\cdot \\hat{x} + \\beta,\n",
        "$$\n",
        "   где $ \\gamma $ и $ \\beta $ — обучаемые параметры.\n",
        "\n",
        "#### 6.3. Преимущества\n",
        "- Ускоряет обучение.\n",
        "- Уменьшает чувствительность модели к инициализации весов.\n",
        "- Действует как регуляризатор, снижая необходимость в Dropout.\n",
        "\n",
        "#### 6.4. Недостатки\n",
        "- Может замедлить обучение при очень маленьких размерах мини-батчей.\n",
        "- Требует дополнительных вычислений.\n",
        "\n"
      ],
      "metadata": {
        "id": "zdZOlnsGTVj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Исходное изображение (матрица 5x5)\n",
        "I = np.array([\n",
        "    [1, 2, 3, 4, 5],\n",
        "    [6, 7, 8, 9, 10],\n",
        "    [11, 12, 13, 14, 15],\n",
        "    [16, 17, 18, 19, 20],\n",
        "    [21, 22, 23, 24, 25]\n",
        "])\n",
        "\n",
        "# 2. Ядро свертки (матрица 3x3)\n",
        "K = np.array([\n",
        "    [1, 0, -1],\n",
        "    [0, 1, 0],\n",
        "    [-1, 0, 1]\n",
        "])\n",
        "\n",
        "# 3. Функция для выполнения свертки\n",
        "def convolution(image, kernel, stride=1, padding=0):\n",
        "    # Добавляем паддинг к изображению\n",
        "    if padding > 0:\n",
        "        image = np.pad(image, pad_width=padding, mode='constant', constant_values=0)\n",
        "\n",
        "    # Размеры входного изображения и ядра\n",
        "    H, W = image.shape\n",
        "    M, N = kernel.shape\n",
        "\n",
        "    # Размеры выходной карты признаков\n",
        "    output_height = (H - M) // stride + 1\n",
        "    output_width = (W - N) // stride + 1\n",
        "\n",
        "    # Создаем выходную матрицу\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    # Выполняем свертку\n",
        "    for i in range(0, output_height):\n",
        "        for j in range(0, output_width):\n",
        "            # Извлекаем подматрицу изображения\n",
        "            submatrix = image[i * stride:i * stride + M, j * stride:j * stride + N]\n",
        "\n",
        "            # Вычисляем значение для текущего элемента выходной матрицы\n",
        "            output[i, j] = np.sum(submatrix * kernel)\n",
        "\n",
        "    return output\n",
        "\n",
        "# 4. Визуализация\n",
        "def visualize_convolution(image, kernel, output):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Исходное изображение\n",
        "    axes[0].imshow(image, cmap='gray')\n",
        "    axes[0].set_title(\"Input Image\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Ядро свертки\n",
        "    axes[1].imshow(kernel, cmap='gray')\n",
        "    axes[1].set_title(\"Kernel\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Выходная карта признаков\n",
        "    axes[2].imshow(output, cmap='gray')\n",
        "    axes[2].set_title(\"Output Feature Map\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 5. Выполнение свертки\n",
        "output = convolution(I, K, stride=1, padding=0)\n",
        "\n",
        "# 6. Вывод результатов\n",
        "print(\"Input Image:\")\n",
        "print(I)\n",
        "print(\"\\nKernel:\")\n",
        "print(K)\n",
        "print(\"\\nOutput Feature Map:\")\n",
        "print(output)\n",
        "\n",
        "# 7. Визуализация\n",
        "visualize_convolution(I, K, output)"
      ],
      "metadata": {
        "id": "m2IGLJKOnkcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 8.7. Этапы обучения\n",
        "\n",
        "Обучение модели машинного или глубокого обучения состоит из нескольких ключевых этапов, каждый из которых играет важную роль в успешности процесса. Рассмотрим эти этапы подробнее.\n",
        "\n",
        "\n",
        "\n",
        "### 1. **Инициализация параметров**\n",
        "\n",
        "#### 1.1. Основная идея\n",
        "Инициализация параметров модели — это первый шаг перед началом обучения. Правильная инициализация весов и смещений помогает избежать проблем с исчезающими или взрывающимися градиентами, что особенно важно для глубоких нейронных сетей.\n",
        "\n",
        "#### 1.2. Методы инициализации\n",
        "- **Случайная инициализация**:\n",
        "  Веса инициализируются небольшими случайными значениями, обычно из нормального или равномерного распределения:\n",
        "$$\n",
        "  W \\sim \\mathcal{N}(0, \\sigma^2),\n",
        "$$\n",
        "  где $ \\sigma $ — стандартное отклонение.\n",
        "  \n",
        "  Например, для слоев с активацией ReLU часто используется метод инициализации He:\n",
        "$$\n",
        "  W \\sim \\mathcal{N}(0, \\sqrt{\\frac{2}{n_{\\text{in}}}}),\n",
        "$$\n",
        "  где $ n_{\\text{in}} $ — количество входных нейронов.\n",
        "\n",
        "- **Инициализация смещений**:\n",
        "  Смещения обычно инициализируются нулями:\n",
        "$$\n",
        "  b = 0.\n",
        "$$\n",
        "\n",
        "#### 1.3. Преимущества правильной инициализации\n",
        "- Уменьшает вероятность исчезающих или взрывающихся градиентов.\n",
        "- Ускоряет сходимость модели.\n",
        "\n",
        "#### 1.4. Недостатки неправильной инициализации\n",
        "- Может привести к медленному обучению или полной неспособности модели обучаться.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Эпохи и мини-батчи**\n",
        "\n",
        "#### 2.1. Основная идея\n",
        "Обучающая выборка разбивается на мини-батчи, чтобы ускорить обучение и сделать его более устойчивым к шуму. Процесс обучения организован в эпохи, каждая из которых представляет собой полный проход по всей обучающей выборке.\n",
        "\n",
        "#### 2.2. Мини-батчи\n",
        "- Размер мини-батча ($ B $) определяется пользователем. Типичные значения: 32, 64, 128.\n",
        "- Каждый мини-батч используется для вычисления градиентов и обновления параметров модели.\n",
        "\n",
        "#### 2.3. Эпохи\n",
        "- Одна эпоха — это проход по всей обучающей выборке.\n",
        "- Обучение может состоять из множества эпох, пока модель не достигнет желаемого уровня качества.\n",
        "\n",
        "#### 2.4. Преимущества использования мини-батчей\n",
        "- Более быстрое обучение по сравнению с использованием всего датасета.\n",
        "- Устойчивость к шуму в данных благодаря стохастическому характеру обновлений.\n",
        "\n",
        "#### 2.5. Недостатки\n",
        "- При слишком маленьком размере мини-батча обновления могут быть слишком шумными.\n",
        "- При слишком большом размере мини-батча обучение становится похожим на классический градиентный спуск, что может замедлить процесс.\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Оценка модели**\n",
        "\n",
        "#### 3.1. Основная идея\n",
        "После каждой эпохи модель оценивается на валидационной выборке для контроля качества обучения. Это помогает определить, насколько хорошо модель обобщает данные, и предотвратить переобучение.\n",
        "\n",
        "#### 3.2. Метрики качества\n",
        "- **Accuracy** (точность):\n",
        "$$\n",
        "  \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}.\n",
        "$$\n",
        "- **Loss** (функция потерь):\n",
        "  Значение функции потерь на валидационной выборке:\n",
        "$$\n",
        "  \\text{Validation Loss} = L_{\\text{val}}.\n",
        "$$\n",
        "- Другие метрики (Precision, Recall, F1-score и т.д.) используются в зависимости от задачи.\n",
        "\n",
        "#### 3.3. Преимущества регулярной оценки\n",
        "- Позволяет контролировать качество модели в процессе обучения.\n",
        "- Помогает своевременно выявить переобучение или недообучение.\n",
        "\n",
        "#### 3.4. Недостатки\n",
        "- Требует наличия отдельной валидационной выборки.\n",
        "- Оценка может быть затратной по времени для больших моделей.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Остановка обучения (Early Stopping)**\n",
        "\n",
        "#### 4.1. Основная идея\n",
        "Early Stopping — это метод регуляризации, который заключается в прекращении обучения модели, если качество на валидационной выборке перестает улучшаться. Это предотвращает переобучение и экономит вычислительные ресурсы.\n",
        "\n",
        "#### 4.2. Механизм работы\n",
        "- После каждой эпохи проверяется значение функции потерь или другой метрики качества на валидационной выборке.\n",
        "- Если значение не улучшается в течение заданного числа эпох (патиентности), обучение прекращается:\n",
        "$$\n",
        "  \\text{Stop if } \\text{Validation Loss}[t] > \\text{Validation Loss}[t-1].\n",
        "$$\n",
        "\n",
        "#### 4.3. Преимущества\n",
        "- Простота реализации.\n",
        "- Эффективно предотвращает переобучение.\n",
        "- Экономит вычислительные ресурсы.\n",
        "\n",
        "#### 4.4. Недостатки\n",
        "- Может привести к преждевременной остановке, если патиентность выбрана слишком маленькой.\n",
        "- Требует наличия валидационной выборки.\n",
        "\n",
        "\n",
        "\n",
        "### 5. **Финальная оценка и тестирование**\n",
        "\n",
        "#### 5.1. Основная идея\n",
        "После завершения обучения модель тестируется на отдельной тестовой выборке, которая не использовалась ни для обучения, ни для валидации. Это позволяет получить объективную оценку обобщающей способности модели.\n",
        "\n",
        "#### 5.2. Метрики тестирования\n",
        "- Те же метрики, что и при валидации (Accuracy, Loss, Precision, Recall и т.д.).\n",
        "\n",
        "#### 5.3. Преимущества\n",
        "- Обеспечивает объективную оценку качества модели.\n",
        "- Помогает понять, насколько хорошо модель работает на новых данных.\n",
        "\n",
        "#### 5.4. Недостатки\n",
        "- Требует наличия отдельной тестовой выборки.\n",
        "- Необходимо соблюдать строгую изоляцию тестовой выборки от процесса обучения.\n",
        "\n"
      ],
      "metadata": {
        "id": "HkkwN5l0nkpl"
      }
    }
  ]
}