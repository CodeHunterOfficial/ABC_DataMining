{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOmsMYJOHNW8dKyy93vKhaV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/DL/MLP/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%962_%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD_(MLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Практическая работа №2. Многослойный перцептрон (MLP)**\n",
        "\n",
        "## **Введение**\n",
        "Цель данной работы заключается в систематическом изучении архитектуры, процесса обучения и применения многослойных перцептронов (MLP) для решения задач регрессии и классификации. Особое внимание уделяется практическим аспектам реализации моделей, анализу их поведения и оптимизации производительности. Работа структурирована таким образом, чтобы охватить ключевые этапы разработки нейронных сетей: от подготовки данных до анализа результатов и интерпретации моделей.\n",
        "\n",
        "\n",
        "\n",
        "## **Структура работы**\n",
        "\n",
        "### **Задача 1: Подготовка данных**\n",
        "1. **Цель**: Подготовить данные для анализа и обучения моделей.\n",
        "2. **Описание**:\n",
        "   - Выберите датасет из надежных источников:\n",
        "     - Kaggle, Yahoo Finance, Hugging Face, UCI Machine Learning Repository, Google Dataset Search, Data.gov, World Bank Open Data, Eurostat, FiveThirtyEight, AWS Open Data Registry, Quandl, OpenML, Figshare, KDD Cup Archives, StatLib Datasets Archive, Reddit Datasets.\n",
        "   - Загрузите данные из файла (например, CSV) или API.\n",
        "   - Проведите предварительный анализ данных:\n",
        "     - Проверьте наличие пропущенных значений. При необходимости заполните их (средним, медианой, KNN).\n",
        "     - Определите выбросы и аномалии с помощью статистических методов (например, межквартильного размаха) или методов машинного обучения (например, Isolation Forest или DBSCAN).\n",
        "   - Преобразуйте категориальные признаки в числовые форматы:\n",
        "     - Примените One-Hot Encoding для номинальных переменных.\n",
        "     - Используйте Label Encoding для порядковых переменных.\n",
        "   - Масштабируйте числовые признаки (например, стандартизация или нормализация) для улучшения работы моделей.\n",
        "   - Разделите данные на обучающую и тестовую выборки (например, в соотношении 80/20). Для временных данных используйте временную кросс-валидацию.\n",
        "3. **Входные данные**:\n",
        "   - Набор данных с признаками и целевой переменной.\n",
        "4. **Выходные данные**:\n",
        "   - Обучающая и тестовая выборки, готовые для обучения моделей.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 2: Feature Engineering**\n",
        "1. **Цель**: Создать новые признаки для улучшения качества модели.\n",
        "2. **Описание**:\n",
        "   - Создайте взаимодействия между признаками (например, произведение двух числовых признаков).\n",
        "   - Генерируйте полиномиальные признаки (например, квадраты или кубы числовых переменных).\n",
        "   - Преобразуйте признаки с помощью логарифмов, экспонент или других функций для снижения асимметрии распределения.\n",
        "   - Для временных рядов:\n",
        "     - Добавьте оконные признаки (lag features).\n",
        "     - Проведите проверку стационарности (тест Дики-Фуллера).\n",
        "   - Примените метод главных компонент (PCA) для снижения размерности.\n",
        "   - Проверьте мультиколлинеарность между новыми признаками (например, через корреляционную матрицу или VIF).\n",
        "3. **Входные данные**:\n",
        "   - Исходные признаки.\n",
        "4. **Выходные данные**:\n",
        "   - Новый набор признаков.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 3: Анализ корреляции и проверка гипотез**\n",
        "1. **Цель**: Проанализировать взаимосвязи между признаками и целевой переменной, а также сгенерировать и проверить гипотезы.\n",
        "2. **Описание**:\n",
        "   - Постройте корреляционную матрицу для числовых признаков и визуализируйте её с помощью тепловой карты.\n",
        "   - Проверьте статистические гипотезы:\n",
        "     - Например, проверьте гипотезу о равенстве средних значений целевой переменной для различных групп (t-тест или ANOVA).\n",
        "     - Проверьте гипотезу о нормальности распределения признаков (тест Шапиро-Уилка или Колмогорова-Смирнова).\n",
        "   - Оцените зависимость между категориальными и числовыми признаками (например, тест Краскела-Уоллиса).\n",
        "3. **Входные данные**:\n",
        "   - Набор данных с признаками и целевой переменной.\n",
        "4. **Выходные данные**:\n",
        "   - Корреляционная матрица, результаты статистических тестов.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 4: Подготовка данных для MLP**\n",
        "1. **Цель**: Обеспечить корректную предобработку данных для повышения эффективности обучения нейронной сети.\n",
        "2. **Описание**:\n",
        "   - **Обработка несбалансированных данных**:\n",
        "     - Внедрение весовых коэффициентов (`class_weight`) в функцию потерь для коррекции дисбаланса классов.\n",
        "     - Применение методов ресемплинга, таких как SMOTE (Synthetic Minority Over-sampling Technique) и ADASYN (Adaptive Synthetic Sampling), для генерации синтетических примеров миноритарного класса.\n",
        "   - **Обработка временных рядов**:\n",
        "     - Создание оконных признаков (lag features) для учета временных зависимостей.\n",
        "     - Проверка стационарности временных рядов с использованием теста Дики-Фуллера (ADF-test).\n",
        "   - **Нормализация данных**:\n",
        "     - Применение `MinMaxScaler` для нормализации данных изображений в диапазоне [0, 1].\n",
        "     - Использование `StandardScaler` для центрирования и масштабирования табличных данных.\n",
        "     - Разработка кастомных методов нормализации для временных рядов с учетом их специфики.\n",
        "3. **Входные данные**:\n",
        "   - Обучающая и тестовая выборки.\n",
        "4. **Выходные данные**:\n",
        "   - Предобработанные данные, готовые для обучения MLP.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 5: Построение и анализ архитектуры MLP**\n",
        "1. **Цель**: Исследовать влияние структурных параметров сети на её производительность.\n",
        "2. **Описание**:\n",
        "   - **Сравнительный анализ функций активации**:\n",
        "     | Функция        | Область применения                  | Преимущества                              | Недостатки                                |\n",
        "     |-|-|-|-|\n",
        "     | ReLU           | Скрытые слои                       | Быстрая сходимость, простота вычислений    | Проблема \"умирающих\" нейронов             |\n",
        "     | LeakyReLU      | При проблемах с ReLU               | Устраняет проблему \"умирания\"             | Требует настройки дополнительного параметра |\n",
        "     | Sigmoid        | Выходной слой (бинарная классификация) | Интерпретируемый вывод                     | Проблемы с градиентами (vanishing gradient) |\n",
        "   - **Практическое задание**: Сравнение производительности сетей с различной глубиной (3 vs 5 слоёв) на основе метрик точности и скорости обучения.\n",
        "3. **Входные данные**:\n",
        "   - Предобработанные данные.\n",
        "4. **Выходные данные**:\n",
        "   - Обученные модели MLP с различной архитектурой.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 6: Методы оптимизации и анализ градиентов**\n",
        "1. **Цель**: Изучить различные подходы к оптимизации MLP и их влияние на сходимость модели.\n",
        "2. **Описание**:\n",
        "   - **Сравнение оптимизаторов**:\n",
        "     ```python\n",
        "     optimizers = {\n",
        "         'SGD': {'lr': 0.01, 'momentum': 0.9},\n",
        "         'Adam': {'lr': 0.001},\n",
        "         'RMSprop': {'lr': 0.001, 'rho': 0.9}\n",
        "     }\n",
        "     ```\n",
        "   - **Практикум по вычислению градиентов**:\n",
        "     - Аналитический расчёт градиентов для функции потерь MSE.\n",
        "     - Численные методы (конечные разности) для проверки корректности аналитического расчёта.\n",
        "     - Автоматическое дифференцирование с использованием PyTorch Autograd.\n",
        "   - **Визуализация**:\n",
        "     - 3D-график поверхности функции потерь для анализа ландшафта ошибок.\n",
        "     - Визуализация траекторий оптимизаторов в пространстве параметров для сравнения их поведения.\n",
        "3. **Входные данные**:\n",
        "   - Обучающая выборка.\n",
        "4. **Выходные данные**:\n",
        "   - Реализованные алгоритмы вычисления градиента, графики сходимости.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 7: Регуляризация и борьба с переобучением**\n",
        "1. **Цель**: Освоить современные методы улучшения обобщающей способности модели.\n",
        "2. **Описание**:\n",
        "   - **Сравнительная таблица методов регуляризации**:\n",
        "     | Метод          | Параметры          | Эффективность | Влияние на скорость обучения |\n",
        "     |-|--||--|\n",
        "     | L2             | λ=0.01             | +++           | +                           |\n",
        "     | Dropout        | p=0.5              | ++++          | ++                          |\n",
        "     | Early Stopping | patience=5         | +++           | -                           |\n",
        "   - **Практическое задание**: Реализация комбинированной регуляризации:\n",
        "     ```python\n",
        "     model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "     model.add(Dropout(0.3))\n",
        "     model.add(BatchNormalization())\n",
        "     ```\n",
        "3. **Входные данные**:\n",
        "   - Переобучающаяся модель.\n",
        "4. **Выходные данные**:\n",
        "   - Улучшенная модель с применением регуляризации.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 8: Оценка качества и интерпретация**\n",
        "1. **Цель**: Комплексно оценить результаты моделирования и интерпретировать поведение модели.\n",
        "2. **Описание**:\n",
        "   - **Детализированные метрики**:\n",
        "     - Для задач классификации: построение Precision-Recall кривых и ROC-кривых.\n",
        "     - Для задач регрессии: анализ Q-Q plots остатков для проверки нормальности распределения ошибок.\n",
        "   - **Интерпретация моделей**:\n",
        "     - Использование SHAP-значений для анализа важности признаков.\n",
        "     - Применение метода LIME для локальной интерпретации предсказаний.\n",
        "     - Визуализация градиентов для анализа чувствительности модели к входным данным.\n",
        "3. **Входные данные**:\n",
        "   - Обученная модель, тестовые данные.\n",
        "4. **Выходные данные**:\n",
        "   - Графики и метрики интерпретации.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 9: Продвинутые техники и оптимизация**\n",
        "1. **Цель**: Изучить профессиональные подходы к работе с MLP.\n",
        "2. **Описание**:\n",
        "   - **Автоматизация ML-пайплайнов**:\n",
        "     - Использование TensorBoard для мониторинга процесса обучения.\n",
        "     - Применение MLflow для управления экспериментами и версионирования моделей.\n",
        "   - **Оптимизация гиперпараметров**:\n",
        "     ```python\n",
        "     param_grid = {\n",
        "         'hidden_layers': [2, 3],\n",
        "         'units': [32, 64, 128],\n",
        "         'dropout_rate': [0.2, 0.3]\n",
        "     }\n",
        "     ```\n",
        "   - **Этический анализ**:\n",
        "     - Выявление предвзятости (bias) в предсказаниях модели.\n",
        "     - Методы обеспечения fairness, такие как адаптивная коррекция весов классов.\n",
        "3. **Входные данные**:\n",
        "   - Данные и параметры модели.\n",
        "4. **Выходные данные**:\n",
        "   - Автоматизированный пайплайн, логи экспериментов.\n",
        "\n",
        "\n",
        "\n",
        "### **Задача 10: Анализ результатов и выбор модели**\n",
        "1. **Цель**: Выбрать лучшую модель на основе проведенного анализа.\n",
        "2. **Описание**:\n",
        "   - Сравните метрики качества всех моделей (MAE, MSE, RMSE, R²).\n",
        "   - Проанализируйте результаты диагностики остатков (случайность, нормальность).\n",
        "   - Предложите дальнейшие шаги для улучшения моделей:\n",
        "     - Добавление новых признаков.\n",
        "     - Использование более сложных алгоритмов (например, градиентный бустинг).\n",
        "     - Устранение мультиколлинеарности и переобучения.\n",
        "   - Проверьте модель на внешних данных для оценки обобщающей способности.\n",
        "3. **Входные данные**:\n",
        "   - Результаты всех предыдущих задач.\n",
        "4. **Выходные данные**:\n",
        "   - Рекомендации по выбору модели и улучшению её производительности.\n",
        "\n",
        "\n",
        "\n",
        "## **Рекомендации по отчету**\n",
        "1. **Раздел данных**:\n",
        "   - Описание датасета: краткая информация о данных, их источнике и признаках.\n",
        "   - Визуализация результатов EDA (Exploratory Data Analysis):\n",
        "     - Распределение целевой переменной и основных признаков.\n",
        "     - Корреляционная матрица или тепловая карта.\n",
        "     - Выбросы, пропущенные значения и аномалии (с визуализацией, например, boxplot или scatter plot).\n",
        "2. **Методология**:\n",
        "   - Схема preprocessing pipeline:\n",
        "     - Этапы предобработки данных (например, заполнение пропусков, масштабирование, кодирование категориальных признаков).\n",
        "     - Использованные инструменты (например, `Pipeline` из `sklearn`).\n",
        "   - Обоснование выбора моделей:\n",
        "     - Почему выбраны конкретные модели (например, линейная регрессия, Lasso, Ridge, нелинейные модели).\n",
        "     - Какие гиперпараметры были оптимизированы.\n",
        "3. **Результаты**:\n",
        "   - Сравнительная таблица метрик:\n",
        "     - MAE, MSE, RMSE, R², sMAPE, MASE (или другие метрики, если применимо).\n",
        "     - Укажите лучшую модель на основе метрик.\n",
        "   - Интерпретация лучшей модели:\n",
        "     - Важность признаков (например, коэффициенты регрессии для линейных моделей, SHAP-значения для сложных моделей).\n",
        "     - Анализ ошибок модели (например, случаи завышения/занижения прогнозов).\n",
        "\n",
        "\n",
        "\n",
        "## **Критерии оценки**\n",
        "1. **Полнота реализации** (30%):\n",
        "   - Все запланированные эксперименты проведены.\n",
        "   - Использованы различные архитектуры и методы.\n",
        "2. **Глубина анализа** (25%):\n",
        "   - Качественное сравнение методов.\n",
        "   - Обоснованные выводы.\n",
        "3. **Техническая корректность** (20%):\n",
        "   - Правильное применение методов.\n",
        "   - Отсутствие методологических ошибок.\n",
        "4. **Визуализация** (15%):\n",
        "   - Читаемые графики.\n",
        "   - Информативные таблицы.\n",
        "5. **Оформление** (10%):\n",
        "   - Структурированный отчёт.\n",
        "   - Формальное представление результатов.\n",
        "\n",
        "\n",
        "\n",
        "## **Рекомендуемые инструменты**\n",
        "- **Фреймворки**: PyTorch, TensorFlow/Keras.\n",
        "- **Визуализация**: Matplotlib, Seaborn, Plotly.\n",
        "- **Оптимизация**: Optuna, Hyperopt.\n",
        "- **Логирование**: MLflow, TensorBoard.\n",
        "\n",
        "**Примечание**: В процессе выполнения работы рекомендуется уделять особое внимание документированию каждого этапа и сохранению промежуточных результатов для последующего анализа."
      ],
      "metadata": {
        "id": "Jiib7OIhhnYw"
      }
    }
  ]
}