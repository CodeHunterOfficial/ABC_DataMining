{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMnpX6fdaK42PUecthJ9w8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/DL/datasets/%D0%94%D0%B0%D1%82%D0%B0%D1%81%D0%B5%D1%82%D0%B8%D0%BA%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1. **Beijing Multi-Site Air-Quality Data**\n",
        "Этот датасет содержит данные о качестве воздуха в Пекине с разбивкой по времени и местоположению. В нем много признаков, таких как уровень PM2.5, PM10, SO2 и другие.\n",
        "\n",
        "- **Описание**: Качество воздуха в Пекине.\n",
        "- **Ссылка**: [Beijing Air Quality](https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data)\n",
        "- **Код для загрузки**:\n"
      ],
      "metadata": {
        "id": "0VATASwCOfR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# URL архива\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00501/PRSA2017_Data_20130301-20170228.zip\"\n",
        "\n",
        "# Скачиваем архив\n",
        "response = requests.get(url)\n",
        "with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "    # Список всех файлов в архиве\n",
        "    file_list = zip_file.namelist()\n",
        "\n",
        "    # Выбираем первый CSV-файл (например, данные для района Aotizhongxin)\n",
        "    csv_file_name = [f for f in file_list if f.endswith('.csv')][0]\n",
        "\n",
        "    # Читаем CSV-файл напрямую из архива\n",
        "    with zip_file.open(csv_file_name) as csv_file:\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "# Просмотр первых строк\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mtpKqFTgOoH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 2. **Metro Interstate Traffic Volume**\n",
        "Этот датасет содержит данные о трафике на межштатной автомагистрали в Миннесоте. Признаки включают время суток, погодные условия, праздники и другие факторы.\n",
        "\n",
        "- **Описание**: Трафик на межштатной автомагистрали.\n",
        "- **Ссылка**: [Metro Interstate Traffic Volume](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume)\n",
        "- **Код для загрузки**:\n"
      ],
      "metadata": {
        "id": "mFzf-38EOoPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tRwjQ3YnO6uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка датасета\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\"\n",
        "df = pd.read_csv(url, compression='gzip', parse_dates=True)\n",
        "\n",
        "# Просмотр первых строк\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FBtN6OzHO61x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3. **Household Power Consumption**\n",
        "Этот датасет содержит данные о потреблении электроэнергии в домохозяйстве. Признаки включают активную и реактивную мощность, напряжение и ток.\n",
        "\n",
        "- **Описание**: Потребление электроэнергии в домохозяйстве.\n",
        "- **Ссылка**: [Household Power Consumption](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption)\n",
        "- **Код для загрузки**:\n"
      ],
      "metadata": {
        "id": "_Nx0OerSO7nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка датасета\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\"\n",
        "df = pd.read_csv(url, sep=\";\", decimal=\",\", parse_dates=True)\n",
        "\n",
        "# Просмотр первых строк\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FFhG4q7kPGWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 4. **Energy Efficiency Dataset**\n",
        "Этот датасет содержит данные о энергоэффективности зданий. Признаки включают геометрические параметры зданий, материалы и другие характеристики.\n",
        "\n",
        "- **Описание**: Энергоэффективность зданий.\n",
        "- **Ссылка**: [Energy Efficiency Dataset](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency)\n",
        "- **Код для загрузки**:\n",
        "\n"
      ],
      "metadata": {
        "id": "G-_7OOFLPGxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка датасета\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\"\n",
        "df = pd.read_excel(url)\n",
        "\n",
        "# Просмотр первых строк\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gncSvhbMPPS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 5. **Appliances Energy Prediction**\n",
        "Этот датасет содержит данные о потреблении энергии бытовыми приборами. Признаки включают температуру, влажность, давление и другие факторы.\n",
        "\n",
        "- **Описание**: Потребление энергии бытовыми приборами.\n",
        "- **Ссылка**: [Appliances Energy Prediction](https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction)\n",
        "- **Код для загрузки**:\n"
      ],
      "metadata": {
        "id": "_NxmevTpPPal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка датасета\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Просмотр первых строк\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7qeAT9TBPXjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. **Сбор принципиально нового датасета**"
      ],
      "metadata": {
        "id": "-MejMY7QNN8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "def generate_date_range(start_date, end_date):\n",
        "    \"\"\"Генерирует список дат в формате 'dd.mm.yyyy'.\"\"\"\n",
        "    date_list = []\n",
        "    current_date = start_date\n",
        "    while current_date <= end_date:\n",
        "        date_list.append(current_date.strftime('%d.%m.%Y'))\n",
        "        current_date += timedelta(days=1)\n",
        "    return date_list\n",
        "\n",
        "def parse_currency_rates_for_dates(dates):\n",
        "    \"\"\"Парсит курсы валют для списка дат и сохраняет их в DataFrame.\"\"\"\n",
        "    base_url = \"https://cbr.ru/currency_base/daily/\"\n",
        "    currency_codes = {\"USD\": \"Доллар США\", \"EUR\": \"Евро\", \"CNY\": \"Юань\"}\n",
        "\n",
        "    # Создаем пустой DataFrame\n",
        "    columns = ['Дата', 'Юань', 'Евро', 'Доллар США']\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    for date in dates:\n",
        "        print(f\"Парсинг данных за {date}...\")\n",
        "        params = {'date_req': date}\n",
        "        response = requests.get(base_url, params=params)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Ошибка при получении данных за {date}: {response.status_code}\")\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        table = soup.find('table', class_='data')\n",
        "        if not table:\n",
        "            print(f\"Таблица с курсами валют не найдена за {date}.\")\n",
        "            continue\n",
        "\n",
        "        rates = {'Дата': date}\n",
        "        for row in table.find_all('tr')[1:]:\n",
        "            columns = row.find_all('td')\n",
        "            if len(columns) == 5:\n",
        "                code = columns[1].text.strip()\n",
        "                rate = float(columns[4].text.replace(',', '.'))\n",
        "                if code in currency_codes:\n",
        "                    currency_name = currency_codes[code]\n",
        "                    rates[currency_name] = rate\n",
        "\n",
        "        # Добавляем строку в DataFrame с помощью concat\n",
        "        new_row = pd.DataFrame([rates])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # Задаем диапазон дат\n",
        "    start_date = datetime(2025, 1, 1)  # Начальная дата\n",
        "    end_date = datetime(2025, 2, 1)   # Конечная дата\n",
        "\n",
        "    # Генерируем список дат\n",
        "    dates = generate_date_range(start_date, end_date)\n",
        "\n",
        "    # Парсим курсы валют для каждой даты\n",
        "    df = parse_currency_rates_for_dates(dates)\n",
        "\n",
        "    # Выводим DataFrame\n",
        "    print(df)\n",
        "\n",
        "    # Сохраняем DataFrame в CSV-файл\n",
        "    df.to_csv('currency_rates.csv', index=False, encoding='utf-8')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "mhGJeNKRNOQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}