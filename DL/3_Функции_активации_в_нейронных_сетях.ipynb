{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPERJQ23EeBc8S5v4fO6pss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/ABC_DataMining/blob/main/DL/3_%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8_%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D1%8F%D1%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Функции активации в нейронных сетях  \n",
        "## 1. Сигмоида  \n",
        "\n",
        "Сигмоида является одной из классических функций активации, широко используемых в нейронных сетях. Однако её применение в глубоких нейронных сетях требует осторожности из-за ряда присущих ей ограничений. В данном разделе рассматриваются основные свойства сигмоиды, её математические характеристики и особенности использования.  \n",
        "\n",
        "Сигмоидой называют любую S-образную функцию. Наиболее известной из них является логистическая функция, определяемая следующим образом:  \n",
        "\n",
        "$$\n",
        "\\sigma(t) = \\frac{e^t}{1 + e^t} = \\frac{1}{1 + e^{-t}}.\n",
        "$$  \n",
        "\n",
        "Данная функция имеет важное значение в задачах классификации, так как позволяет преобразовать выход нейронной сети в интервал $[0; 1]$, что интерпретируется как вероятность принадлежности к одному из классов.  \n",
        "\n",
        "### а) Асимптотическое поведение сигмоиды  \n",
        "\n",
        "Рассмотрим поведение функции $\\sigma(t)$ при $t \\to +\\infty$ и $t \\to -\\infty$.  \n",
        "\n",
        "1. При $t \\to +\\infty$:  \n",
        "$$\n",
        "   e^{-t} \\to 0 \\implies \\sigma(t) \\to 1.\n",
        "$$  \n",
        "\n",
        "2. При $t \\to -\\infty$:  \n",
        "$$\n",
        "   e^{-t} \\to +\\infty \\implies \\sigma(t) \\to 0.\n",
        "$$  \n",
        "\n",
        "Таким образом, сигмоида имеет горизонтальные асимптоты при $y = 0$ и $y = 1$.  \n",
        "\n",
        "### б) Связь между $\\sigma(t)$ и $\\sigma(-t)$  \n",
        "\n",
        "Исследуем связь между значениями функции $\\sigma(t)$ и $\\sigma(-t)$:  \n",
        "\n",
        "$$\n",
        "\\sigma(-t) = \\frac{1}{1 + e^{t}} = \\frac{1 + e^{t} - e^{t}}{1 + e^{t}} = 1 - \\sigma(t).\n",
        "$$  \n",
        "\n",
        "Следовательно, $\\sigma(-t) = 1 - \\sigma(t)$.  \n",
        "\n",
        "### в) Связь между $\\sigma(t)$ и её производной $\\sigma'(t)$  \n",
        "\n",
        "Производная сигмоиды может быть выражена через саму функцию:  \n",
        "\n",
        "$$\n",
        "\\sigma'(t) = \\frac{d}{dt} \\left( \\frac{e^t}{1 + e^t} \\right) = \\frac{e^t (1 + e^t) - e^t \\cdot e^t}{(1 + e^t)^2} = \\frac{e^t}{(1 + e^t)^2} = \\sigma(t) \\cdot (1 - \\sigma(t)).\n",
        "$$  \n",
        "\n",
        "Таким образом, $\\sigma'(t) = \\sigma(t) \\cdot (1 - \\sigma(t))$.  \n",
        "\n",
        "### г) Значения $\\sigma(0)$ и $\\sigma'(0)$  \n",
        "\n",
        "Вычислим значения функции и её производной в точке $t = 0$:  \n",
        "\n",
        "1. $\\sigma(0)$:  \n",
        "$$\n",
        "   \\sigma(0) = \\frac{1}{1 + e^{-0}} = 0.5.\n",
        "$$  \n",
        "\n",
        "2. $\\sigma'(0)$:  \n",
        "$$\n",
        "   \\sigma'(0) = \\sigma(0) \\cdot (1 - \\sigma(0)) = 0.5 \\cdot 0.5 = 0.25.\n",
        "$$  \n",
        "\n",
        "### д) Обратная функция $\\sigma^{-1}(t)$  \n",
        "\n",
        "Найдём обратную функцию для сигмоиды:  \n",
        "\n",
        "$$\n",
        "y = \\frac{1}{1 + e^{-t}} \\implies e^{-t} = \\frac{1 - y}{y} \\implies t = \\ln \\left( \\frac{y}{1 - y} \\right).\n",
        "$$  \n",
        "\n",
        "Таким образом, обратная функция имеет вид:  \n",
        "\n",
        "$$\n",
        "\\sigma^{-1}(t) = \\ln \\left( \\frac{t}{1 - t} \\right).\n",
        "$$  \n",
        "\n",
        "Эта величина, известная как логит, часто используется в задачах классификации для прогнозирования вероятностей.  \n",
        "\n",
        "### е) Связь между $[ \\ln \\sigma(t) ]'$ и $\\sigma(-t)$  \n",
        "\n",
        "Рассмотрим производную логарифма сигмоиды:  \n",
        "\n",
        "$$\n",
        "[ \\ln \\sigma(t) ]' = \\frac{1}{\\sigma(t)} \\cdot \\sigma'(t) = \\frac{1}{\\sigma(t)} \\cdot \\sigma(t) \\cdot (1 - \\sigma(t)) = 1 - \\sigma(t) = \\sigma(-t).\n",
        "$$  \n",
        "\n",
        "Таким образом, $[ \\ln \\sigma(t) ]' = \\sigma(-t)$.  \n",
        "\n",
        "### ё) Графики функций $\\sigma(t)$ и $\\sigma'(t)$  \n",
        "\n",
        "График сигмоиды имеет S-образную форму с асимптотами при $y = 0$ и $y = 1$. Производная сигмоиды $\\sigma'(t)$ представляет собой симметричный \"холмик\" с максимумом в точке $t = 0$ (Рис. 1).  \n",
        "\n",
        "### ж) Сигмоида как гладкий аналог единичной ступеньки  \n",
        "\n",
        "При увеличении коэффициента перед $t$ в функции $\\sigma(k \\cdot t)$ график сигмоиды становится более крутым, приближаясь к форме единичной ступеньки. При $k \\to +\\infty$ сигмоида практически совпадает с ступенчатой функцией, оставаясь при этом дифференцируемой (Рис. 2).  \n",
        "\n",
        "Таким образом, сигмоида является гладким аналогом единичной ступеньки, что делает её полезной в задачах, где требуется дифференцируемость функции активации.  \n",
        "\n",
        "### з) Формулы для forward pass и backward pass через слой с сигмоидой  \n",
        "\n",
        "Сигмоида является элементом нейронной сети, не имеющим обучаемых параметров. Поэтому прямой (forward pass) и обратный (backward pass) проходы через слой с сигмоидой выполняются следующим образом.  \n",
        "\n",
        "1. **Прямой проход (forward pass):**  \n",
        "   Выход слоя вычисляется по формуле:  \n",
        "$$\n",
        "   o = \\sigma(h),\n",
        "$$  \n",
        "   где $h$ — входной сигнал слоя, а $\\sigma(h)$ — значение сигмоиды.  \n",
        "\n",
        "2. **Обратный проход (backward pass):**  \n",
        "   Градиент по входному сигналу $h$ вычисляется с использованием производной сигмоиды:  \n",
        "$$\n",
        "   \\frac{\\partial L}{\\partial h} = \\sigma(h) \\cdot (1 - \\sigma(h)) \\cdot \\frac{\\partial L}{\\partial o},\n",
        "$$  \n",
        "   где $\\frac{\\partial L}{\\partial o}$ — градиент по выходу слоя, полученный от последующих слоёв.  \n",
        "\n",
        "Таким образом, обратный проход через слой с сигмоидой учитывает как градиент от последующих слоёв, так и производную самой сигмоиды.  \n",
        "\n",
        "### и) Максимальное значение производной сигмоиды и проблема затухания градиента  \n",
        "\n",
        "Производная сигмоиды $\\sigma'(t)$ выражается как:  \n",
        "$$\n",
        "\\sigma'(t) = \\sigma(t) \\cdot (1 - \\sigma(t)).\n",
        "$$  \n",
        "Рассмотрим функцию $f(\\sigma) = \\sigma \\cdot (1 - \\sigma)$. Это парабола, ветви которой направлены вниз. Её экстремум находится в точке:  \n",
        "$$\n",
        "f'(\\sigma) = 1 - 2\\sigma = 0 \\implies \\sigma = 0.5.\n",
        "$$  \n",
        "Максимальное значение функции $f(\\sigma)$ равно:  \n",
        "$$\n",
        "f(0.5) = 0.5 \\cdot (1 - 0.5) = 0.25.\n",
        "$$  \n",
        "Таким образом, производная сигмоиды принимает значения на интервале $[0; 0.25]$.  \n",
        "\n",
        "#### Проблема затухания градиента  \n",
        "При обратном распространении ошибки градиент умножается на производную сигмоиды. Поскольку производная сигмоиды ограничена сверху значением $0.25$, градиент на каждом слое уменьшается. В глубоких нейронных сетях это приводит к тому, что градиенты, доходящие до начальных слоёв, становятся крайне малыми. В результате веса начальных слоёв практически не обновляются, что замедляет или полностью останавливает обучение. Это явление известно как **проблема затухания градиента** (vanishing gradient problem).  \n",
        "\n",
        "#### Паралич нейронной сети  \n",
        "По мере обучения нейроны начинают выдавать значения, близкие к $0$ или $1$, где производная сигмоиды стремится к нулю. Это усугубляет проблему затухания градиента, так как градиенты на этих участках становятся ещё меньше. В результате функция потерь стабилизируется, создавая иллюзию сходимости, хотя на самом деле обучение останавливается.  \n",
        "\n",
        "Для борьбы с этой проблемой в глубоких нейронных сетях вместо сигмоиды используют другие функции активации, такие как ReLU (Rectified Linear Unit), которые не подвержены затуханию градиента.  \n",
        "\n",
        "\n",
        "\n",
        "### к) Нецентрированность сигмоиды и её влияние на градиентный спуск  \n",
        "\n",
        "Сигмоида не является центрированной относительно нуля, так как её выход всегда лежит в интервале $[0; 1]$. Это приводит к следующим проблемам при оптимизации:  \n",
        "\n",
        "1. **Однонаправленность градиентов:**  \n",
        "   Поскольку выход сигмоиды $o = \\sigma(h)$ всегда положителен, градиенты по весам линейного слоя, предшествующего сигмоиде, будут либо все положительными, либо все отрицательными. Это ограничивает направление обновления весов, что замедляет сходимость градиентного спуска.  \n",
        "\n",
        "2. **Зигзагообразное движение к оптимуму:**  \n",
        "   Если для разных параметров требуется движение в противоположных направлениях (например, один параметр должен увеличиваться, а другой — уменьшаться), градиенты не смогут одновременно принимать разные знаки. В результате процесс оптимизации будет двигаться зигзагообразно, что увеличивает время достижения оптимума (Рис. 4).  \n",
        "\n",
        "#### Решение проблемы  \n",
        "Для ускорения сходимости градиентного спуска рекомендуется использовать функции активации, центрированные относительно нуля (например, гиперболический тангенс $\\tanh$). Такие функции позволяют градиентам принимать как положительные, так и отрицательные значения, что улучшает направленность обновления весов и ускоряет обучение.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jtUF4z8ie8AP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KpcCDQqEe8qB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Логистические потери и Softmax  \n",
        "\n",
        "### а) Логистические потери и их визуализация  \n",
        "\n",
        "Логистическая функция потерь (logloss) для одного наблюдения в задаче бинарной классификации определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{logloss} = -\\left( y_i \\cdot \\ln p_i + (1 - y_i) \\cdot \\ln (1 - p_i) \\right),\n",
        "$$  \n",
        "\n",
        "где $y_i$ — истинная метка класса (0 или 1), а $p_i = P(y_i = 1 \\mid x)$ — предсказанная вероятность принадлежности к классу 1.  \n",
        "\n",
        "#### Визуализация логистических потерь  \n",
        "Для $y_i = 1$ функция потерь сводится к $-\\ln p_i$, а для $y_i = 0$ — к $-\\ln (1 - p_i)$. Графики этих функций представлены на Рис. 1.  \n",
        "\n",
        "1. **Для $y_i = 1$:**  \n",
        "   - Если $p_i$ близко к 1, штраф минимален.  \n",
        "   - Если $p_i$ близко к 0, штраф стремится к бесконечности.  \n",
        "\n",
        "2. **Для $y_i = 0$:**  \n",
        "   - Если $p_i$ близко к 0, штраф минимален.  \n",
        "   - Если $p_i$ близко к 1, штраф стремится к бесконечности.  \n",
        "\n",
        "#### Роль логарифма  \n",
        "Логарифм в функции потерь обеспечивает нелинейный штраф за ошибки:  \n",
        "- Небольшие отклонения $p_i$ от истинного значения штрафуются слабо.  \n",
        "- Крупные отклонения штрафуются значительно сильнее.  \n",
        "\n",
        "Если заменить логарифм на линейную функцию, например, $-(y_i \\cdot p_i + (1 - y_i) \\cdot (1 - p_i))$, возникнут следующие проблемы:  \n",
        "1. **Отсутствие нелинейности:** Штраф за ошибки будет одинаковым на всём диапазоне $p_i$.  \n",
        "2. **Сложность оптимизации:** Линейная функция потерь менее чувствительна к малым изменениям $p_i$.  \n",
        "3. **Потеря интерпретации:** Выход модели нельзя будет интерпретировать как вероятность $P(y = 1 \\mid x)$.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Функция потерь для задачи классификации  \n",
        "\n",
        "Рассмотрим задачу классификации с тремя наблюдениями:  \n",
        "- Первое наблюдение: кит ($y_1 = 1$).  \n",
        "- Второе и третье наблюдения: муравьи ($y_2 = 0$, $y_3 = 0$).  \n",
        "\n",
        "Модель логистической регрессии задаётся следующим образом:  \n",
        "$$\n",
        "z_i = w_0 + w_1 x_i, \\quad p_i = P(y_i = 1 \\mid x) = \\sigma(z_i) = \\frac{1}{1 + e^{-(w_0 + w_1 x_i)}},\n",
        "$$  \n",
        "где $x_i$ — номер наблюдения.  \n",
        "\n",
        "Функция потерь (logloss) для данной задачи:  \n",
        "$$\n",
        "\\text{logloss} = -\\frac{1}{3} \\left( \\ln p_1 + \\ln (1 - p_2) + \\ln (1 - p_3) \\right).\n",
        "$$  \n",
        "\n",
        "Подставляя выражения для $p_i$, получаем:  \n",
        "$$\n",
        "\\text{logloss} = -\\frac{1}{3} \\left( \\ln \\sigma(w_0 + w_1) + \\ln \\sigma(-(w_0 + 2w_1)) + \\ln \\sigma(-(w_0 + 3w_1)) \\right).\n",
        "$$  \n",
        "\n",
        "Здесь использовано свойство сигмоиды: $\\sigma(-t) = 1 - \\sigma(t)$.  \n",
        "\n",
        "\n",
        "\n",
        "### в) Минимизация функции потерь  \n",
        "\n",
        "Данная выборка является линейно-разделимой. Минимум функции потерь достигается, когда:  \n",
        "- Для кита ($y_1 = 1$): $p_1 \\to 1$.  \n",
        "- Для муравьёв ($y_2 = 0$, $y_3 = 0$): $p_2 \\to 0$, $p_3 \\to 0$.  \n",
        "\n",
        "Это соответствует случаю, когда сигмоида идеально разделяет классы.  \n",
        "\n",
        "\n",
        "\n",
        "### г) Многоклассовая классификация с Softmax  \n",
        "\n",
        "Если добавляется третий класс (бобёр), задача становится многоклассовой. В этом случае выход нейронной сети специфицируется следующим образом:  \n",
        "\n",
        "1. **Выходной слой:**  \n",
        "   - Количество нейронов равно количеству классов $K$.  \n",
        "   - На выходе получается вектор $(z_1, z_2, \\dots, z_K)$, где $z_k = w_k^T x$.  \n",
        "\n",
        "2. **Функция Softmax:**  \n",
        "$$\n",
        "   \\text{Softmax}(z_k) = \\frac{e^{z_k}}{\\sum_{j=1}^K e^{z_j}}.\n",
        "$$  \n",
        "   Эта функция преобразует выходы нейронной сети в вероятности, принадлежащие интервалу $[0; 1]$ и суммирующиеся в единицу (Рис. 2).  \n",
        "\n",
        "3. **Функция потерь:**  \n",
        "   Для многоклассовой классификации используется обобщённая логистическая функция потерь:  \n",
        "$$\n",
        "   \\text{logloss} = -\\frac{1}{n} \\sum_{i=1}^n \\sum_{k=1}^K [y_i = k] \\cdot \\ln \\left( \\frac{e^{w_k^T x_i}}{\\sum_{j=1}^K e^{w_j^T x_i}} \\right),\n",
        "$$  \n",
        "   где $[y_i = k]$ — индикаторная функция, равная 1, если $y_i = k$, и 0 в противном случае.  \n",
        "\n",
        "#### Калибровка вероятностей  \n",
        "Выход Softmax можно интерпретировать как вероятность, если модель откалибрована. Калиброванная модель удовлетворяет условию:  \n",
        "$$\n",
        "P(y = k \\mid p_k \\approx p) = p,\n",
        "$$  \n",
        "где $p$ — предсказанная вероятность, а $P(y = k \\mid p_k \\approx p)$ — доля объектов с истинной меткой $k$ среди объектов, для которых предсказанная вероятность близка к $p$.  \n",
        "\n",
        "### д) Прогнозирование вероятностей с использованием Softmax  \n",
        "\n",
        "После обучения нейронной сети для задачи классификации на три класса (кит, муравей, бобёр) выходы слоя, предшествующего Softmax, для двух наблюдений составили:  \n",
        "1. Первое наблюдение: $(1, -2, 0)$.  \n",
        "2. Второе наблюдение: $(0.5, -1, 0)$.  \n",
        "\n",
        "Применим функцию Softmax для вычисления вероятностей каждого класса:  \n",
        "\n",
        "1. **Для первого наблюдения:**  \n",
        "$$\n",
        "   \\text{Softmax}(1, -2, 0) = \\left( \\frac{e^1}{e^1 + e^{-2} + e^0}, \\frac{e^{-2}}{e^1 + e^{-2} + e^0}, \\frac{e^0}{e^1 + e^{-2} + e^0} \\right) \\approx (0.7, 0.03, 0.27).\n",
        "$$  \n",
        "\n",
        "2. **Для второго наблюдения:**  \n",
        "$$\n",
        "   \\text{Softmax}(0.5, -1, 0) = \\left( \\frac{e^{0.5}}{e^{0.5} + e^{-1} + e^0}, \\frac{e^{-1}}{e^{0.5} + e^{-1} + e^0}, \\frac{e^0}{e^{0.5} + e^{-1} + e^0} \\right) \\approx (0.55, 0.12, 0.33).\n",
        "$$  \n",
        "\n",
        "Таким образом, вероятности для каждого класса:  \n",
        "- Первое наблюдение: кит — 70%, муравей — 3%, бобёр — 27%.  \n",
        "- Второе наблюдение: кит — 55%, муравей — 12%, бобёр — 33%.  \n",
        "\n",
        "\n",
        "\n",
        "### е) Вычисление logloss-ошибки  \n",
        "\n",
        "Предположим, что первое наблюдение соответствует киту ($y_1 = (1, 0, 0)$), а второе — бобру ($y_2 = (0, 0, 1)$). Логистическая функция потерь (logloss) для этих наблюдений вычисляется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{logloss} = -\\frac{1}{2} \\left( \\ln 0.7 + \\ln 0.33 \\right).\n",
        "$$  \n",
        "\n",
        "\n",
        "\n",
        "### ё) Softmax как сглаженный аналог arg max  \n",
        "\n",
        "Функция Softmax является сглаженной версией arg max, так как она преобразует входные значения в вероятности, сохраняя их относительные различия. В отличие от arg max, которая возвращает строгое максимальное значение (единицу для максимального элемента и нули для остальных), Softmax:  \n",
        "1. **Усиливает различия:** Значения, значительно меньшие максимального, приближаются к нулю.  \n",
        "2. **Сохраняет дифференцируемость:** В отличие от arg max, Softmax является гладкой функцией, что позволяет использовать её в градиентных методах оптимизации.  \n",
        "\n",
        "\n",
        "\n",
        "### ж) Связь между сигмоидой и Softmax для двух классов  \n",
        "\n",
        "Рассмотрим два подхода к задаче бинарной классификации:  \n",
        "1. **Один выход с сигмоидой:**  \n",
        "$$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^z}.\n",
        "$$  \n",
        "   В этом случае вероятность класса 1 равна $\\sigma(z)$, а класса 0 — $1 - \\sigma(z)$.  \n",
        "\n",
        "2. **Два выхода с Softmax:**  \n",
        "$$\n",
        "   \\text{Softmax}(z_1, z_2) = \\left( \\frac{e^{z_1}}{e^{z_1} + e^{z_2}}, \\frac{e^{z_2}}{e^{z_1} + e^{z_2}} \\right).\n",
        "$$  \n",
        "   Если положить $z_1 = 0$ и $z_2 = z$, то:  \n",
        "$$\n",
        "   \\text{Softmax}(0, z) = \\left( \\frac{1}{1 + e^z}, \\frac{e^z}{1 + e^z} \\right) = \\left( 1 - \\sigma(z), \\sigma(z) \\right).\n",
        "$$  \n",
        "   Таким образом, Softmax для двух классов эквивалентен использованию сигмоиды, где первый выход соответствует вероятности класса 0, а второй — класса 1.  \n",
        "\n",
        "\n",
        "\n",
        "### з) Инвариантность Softmax относительно сдвига  \n",
        "\n",
        "Функция Softmax инвариантна относительно добавления константы ко всем её аргументам:  \n",
        "$$\n",
        "\\text{Softmax}(z_1 + c, z_2 + c, \\dots, z_K + c) = \\text{Softmax}(z_1, z_2, \\dots, z_K).\n",
        "$$  \n",
        "Это свойство следует из того, что:  \n",
        "$$\n",
        "\\frac{e^{z_i + c}}{\\sum_{k=1}^K e^{z_k + c}} = \\frac{e^c \\cdot e^{z_i}}{e^c \\cdot \\sum_{k=1}^K e^{z_k}} = \\frac{e^{z_i}}{\\sum_{k=1}^K e^{z_k}}.\n",
        "$$  \n",
        "\n",
        "#### Численная устойчивость  \n",
        "Для предотвращения переполнения при вычислении экспонент используется устойчивая версия Softmax:  \n",
        "$$\n",
        "\\text{Softmax}(z_1, z_2, \\dots, z_K) = \\text{Softmax}(z_1 - \\max(z), z_2 - \\max(z), \\dots, z_K - \\max(z)).\n",
        "$$  \n",
        "Это упрощает вычисления и повышает устойчивость алгоритма.  \n",
        "\n",
        "\n",
        "\n",
        "### и) Производная logloss по входам Softmax  \n",
        "\n",
        "Рассмотрим производную функции потерь logloss по входам Softmax. Для одного наблюдения:  \n",
        "$$\n",
        "\\text{logloss} = -\\sum_{k=1}^K y_k \\ln p_k,\n",
        "$$  \n",
        "где $p_k = \\text{Softmax}(z_k)$.  \n",
        "\n",
        "Производная Softmax:  \n",
        "$$\n",
        "\\frac{\\partial p_i}{\\partial z_j} =\n",
        "\\begin{cases}\n",
        "p_i (1 - p_j), & i = j, \\\\\n",
        "-p_i p_j, & i \\neq j.\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "Производная logloss по $z_j$:  \n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z_j} = -\\sum_{k=1}^K y_k \\frac{\\partial \\ln p_k}{\\partial z_j} = -\\sum_{k=1}^K y_k \\frac{1}{p_k} \\frac{\\partial p_k}{\\partial z_j}.\n",
        "$$  \n",
        "\n",
        "Подставляя производную Softmax, получаем:  \n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z_j} = -y_j (1 - p_j) + \\sum_{k \\neq j} y_k p_j = -y_j + p_j \\sum_{k=1}^K y_k = p_j - y_j.\n",
        "$$  \n",
        "\n",
        "Таким образом, производная logloss по входам Softmax равна разности между предсказанными вероятностями и истинными метками:  \n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z} = p - y.\n",
        "$$  \n",
        "\n",
        "Для множества наблюдений производная вычисляется как сумма производных для каждого наблюдения.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "waIw2P8ye8tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fpTm_6AZfCgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Разные выходы нейросети и правдоподобие  \n",
        "\n",
        "### а) Бинарная классификация  \n",
        "\n",
        "Для решения задачи бинарной классификации, где требуется предсказать вероятность принадлежности объекта к одному из двух классов, последний слой нейронной сети должен состоять из одного нейрона. К выходу этого нейрона применяется сигмоидная функция активации:  \n",
        "\n",
        "$$\n",
        "p = \\sigma(z) = \\frac{1}{1 + e^{-z}},\n",
        "$$  \n",
        "\n",
        "где $p$ — вероятность принадлежности к первому классу. Вероятность принадлежности ко второму классу вычисляется как $1 - p$.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Многоклассовая классификация  \n",
        "\n",
        "Для задачи классификации на $K$ классов последний слой нейронной сети должен содержать $K$ нейронов. К выходам этих нейронов применяется функция Softmax:  \n",
        "\n",
        "$$\n",
        "p_k = \\frac{e^{z_k}}{\\sum_{j=1}^K e^{z_j}},\n",
        "$$  \n",
        "\n",
        "где $p_k$ — вероятность принадлежности объекта к классу $k$. Таким образом, выходы нейронной сети интерпретируются как вероятности для каждого из $K$ классов.  \n",
        "\n",
        "\n",
        "\n",
        "### в) Регрессия для прогнозирования рейтинга фильма  \n",
        "\n",
        "Для задачи прогнозирования непрерывного значения, такого как рейтинг фильма на шкале от 0 до 10, последний слой нейронной сети должен состоять из одного нейрона. В этом случае можно использовать линейную функцию активации (т.е. отсутствие функции активации) или ограничить выход нейрона на интервале $[0; 10]$ с помощью подходящей функции активации.  \n",
        "\n",
        "Например, можно использовать масштабированную сигмоиду:  \n",
        "\n",
        "$$\n",
        "f(z) = 10 \\cdot \\sigma(z) = \\frac{10}{1 + e^{-z}}.\n",
        "$$  \n",
        "\n",
        "Однако сигмоида может быть неоптимальной, если данные распределены неравномерно (например, большинство рейтингов сосредоточено в диапазоне 6–10). В таком случае можно использовать другие функции активации, такие как гиперболический тангенс с масштабированием:  \n",
        "\n",
        "$$\n",
        "f(z) = 5 \\cdot (\\tanh(z) + 1).\n",
        "$$  \n",
        "\n",
        "\n",
        "\n",
        "### г) Мультиклассификация с пересекающимися классами  \n",
        "\n",
        "Если каждая новость может принадлежать к нескольким категориям (спортивная, политическая, экономическая), задача называется мультиклассификацией с пересекающимися классами. Для решения такой задачи можно использовать следующие подходы:  \n",
        "\n",
        "1. **Отдельные нейронные сети для каждого класса:**  \n",
        "   Для каждого класса обучается отдельная нейронная сеть, которая предсказывает вероятность принадлежности новости к данному классу. Однако этот подход неэффективен, так как нейронные сети могут дублировать вычисления на начальных слоях.  \n",
        "\n",
        "2. **Общая архитектура с несколькими выходами:**  \n",
        "   Нейронная сеть имеет $K$ выходов, где $K$ — количество классов. К каждому выходу применяется сигмоидная функция активации:  \n",
        "\n",
        "$$\n",
        "   p_k = \\sigma(z_k),\n",
        "$$  \n",
        "\n",
        "   где $p_k$ — вероятность принадлежности новости к классу $k$.  \n",
        "\n",
        "   Функция потерь представляет собой сумму логистических потерь для каждого класса:  \n",
        "\n",
        "$$\n",
        "   \\text{loss} = \\lambda_1 \\cdot \\text{logloss}_1 + \\lambda_2 \\cdot \\text{logloss}_2 + \\lambda_3 \\cdot \\text{logloss}_3,\n",
        "$$  \n",
        "\n",
        "   где $\\lambda_i$ — весовые коэффициенты, позволяющие учитывать важность ошибок для каждого класса.  \n",
        "\n",
        "3. **Использование предобученных моделей (тушек и голов):**  \n",
        "   Для текстовых данных часто используют предобученные модели (например, BERT), которые извлекают векторные представления (эмбеддинги) текста. Затем эти эмбеддинги передаются в простые модели (головы), которые дообучаются для конкретной задачи.  \n",
        "\n",
        "\n",
        "\n",
        "### д) Задача обнаружения и классификации объектов  \n",
        "\n",
        "Для задачи обнаружения и классификации объектов на изображении (например, уток и чаек) выход нейронной сети должен содержать информацию о местоположении объекта (bounding box) и его классе.  \n",
        "\n",
        "1. **Спецификация выхода:**  \n",
        "   - **Координаты bounding box:** Четыре числа, описывающие координаты угла прямоугольника, его ширину и высоту.  \n",
        "   - **Класс объекта:** Вектор вероятностей для каждого класса (например, утка или чайка).  \n",
        "\n",
        "2. **Функция потерь:**  \n",
        "   - **Для bounding box:** Используется среднеквадратичная ошибка (MSE) для штрафования отклонений предсказанных координат от истинных.  \n",
        "   - **Для классификации:** Используется логистическая функция потерь (logloss) для штрафования ошибок классификации.  \n",
        "\n",
        "   Общая функция потерь представляет собой взвешенную сумму потерь для bounding box и классификации:  \n",
        "\n",
        "$$\n",
        "   \\text{loss} = \\lambda_{\\text{bbox}} \\cdot \\text{MSE} + \\lambda_{\\text{class}} \\cdot \\text{logloss}.\n",
        "$$  \n",
        "\n",
        "   Весовые коэффициенты $\\lambda_{\\text{bbox}}$ и $\\lambda_{\\text{class}}$ позволяют балансировать важность ошибок локализации и классификации.  \n",
        "\n",
        "### е) Прогнозирование количества лайков с использованием нейронных сетей  \n",
        "\n",
        "Для задачи прогнозирования количества лайков под фотографиями в Instagram, где количество лайков является целым числом, можно использовать два подхода: инженерный и вероятностный.  \n",
        "\n",
        "#### 1. Инженерный подход  \n",
        "Первый подход заключается в округлении выхода нейронной сети и использовании стандартных функций потерь, таких как среднеквадратичная ошибка (MSE) или средняя абсолютная ошибка (MAE). Однако этот метод имеет недостатки:  \n",
        "- Округление может привести к потере информации.  \n",
        "- Функции потерь, такие как MSE и MAE, не учитывают дискретную природу целевой переменной.  \n",
        "\n",
        "Для улучшения качества прогнозирования можно анализировать ошибки модели и модифицировать функцию потерь, чтобы минимизировать отклонения предсказанных значений от истинных.  \n",
        "\n",
        "#### 2. Вероятностный подход  \n",
        "Вероятностный подход основан на предположении о распределении целевой переменной. В данном случае количество лайков можно рассматривать как случайную величину, следующую распределению Пуассона. Это распределение подходит для моделирования событий, происходящих с низкой вероятностью в большом количестве испытаний (например, лайки под фотографиями).  \n",
        "\n",
        "##### Модель Пуассоновской регрессии  \n",
        "Пуассоновская регрессия предполагает, что интенсивность $\\lambda$ (среднее количество лайков) зависит от характеристик фотографии $x_i$:  \n",
        "\n",
        "$$\n",
        "\\lambda(x_i) = \\langle w, x_i \\rangle,\n",
        "$$  \n",
        "\n",
        "где $w$ — вектор весов модели. В качестве $\\lambda(x_i)$ можно использовать нейронную сеть или градиентный бустинг над деревьями (например, в библиотеке CatBoost).  \n",
        "\n",
        "##### Функция правдоподобия и потерь  \n",
        "Для распределения Пуассона вероятность наблюдения $y_i$ лайков под фотографией $x_i$ равна:  \n",
        "\n",
        "$$\n",
        "P(y_i = k) = \\frac{e^{-\\lambda(x_i)} \\cdot (\\lambda(x_i))^k}{k!}.\n",
        "$$  \n",
        "\n",
        "Функция правдоподобия для всей выборки:  \n",
        "\n",
        "$$\n",
        "L(w) = \\prod_{i=1}^n \\frac{e^{-\\lambda(x_i)} \\cdot (\\lambda(x_i))^{y_i}}{y_i!}.\n",
        "$$  \n",
        "\n",
        "Логарифмируя и упрощая, получаем логарифмическую функцию правдоподобия:  \n",
        "\n",
        "$$\n",
        "\\ln L(w) = \\sum_{i=1}^n \\left( y_i \\ln \\lambda(x_i) - \\lambda(x_i) - \\ln(y_i!) \\right).\n",
        "$$  \n",
        "\n",
        "Исключая константные слагаемые и меняя знак, получаем функцию потерь для минимизации:  \n",
        "\n",
        "$$\n",
        "\\text{loss}(w) = \\sum_{i=1}^n \\left( \\lambda(x_i) - y_i \\ln \\lambda(x_i) \\right).\n",
        "$$  \n",
        "\n",
        "##### Прогнозирование  \n",
        "Прогноз модели можно получить как значение $k$, максимизирующее вероятность $P(y = k)$:  \n",
        "\n",
        "$$\n",
        "\\hat{y} = \\arg\\max_{k \\in \\mathbb{N}} P(y = k).\n",
        "$$  \n",
        "\n",
        "На практике перебор значений $k$ ограничивается разумными пределами, так как распределение Пуассона имеет бесконечный носитель.  \n",
        "\n",
        "#### 3. Байесовский подход  \n",
        "Вероятностный подход можно расширить до байесовских методов, где априорные распределения на параметры модели позволяют учитывать дополнительные знания о данных. Например, регуляризация в байесовских моделях естественным образом возникает из априорных распределений.  \n",
        "\n"
      ],
      "metadata": {
        "id": "e8xawXAlfCjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9meWwiG9fIbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Гиперболический тангенс  \n",
        "\n",
        "Функция гиперболического тангенса определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "f(t) = \\tanh(t) = \\frac{2}{1 + e^{-2t}} - 1.\n",
        "$$  \n",
        "\n",
        "Эта функция широко используется в нейронных сетях в качестве функции активации. В данном разделе рассматриваются её свойства, производная, а также особенности использования в нейронных сетях.  \n",
        "\n",
        "\n",
        "\n",
        "### а) Асимптотическое поведение гиперболического тангенса  \n",
        "\n",
        "Исследуем поведение функции $\\tanh(t)$ при $t \\to +\\infty$ и $t \\to -\\infty$:  \n",
        "\n",
        "1. **При $t \\to +\\infty$:**  \n",
        "$$\n",
        "   e^{-2t} \\to 0 \\implies \\tanh(t) \\to 1.\n",
        "$$  \n",
        "\n",
        "2. **При $t \\to -\\infty$:**  \n",
        "$$\n",
        "   e^{-2t} \\to +\\infty \\implies \\tanh(t) \\to -1.\n",
        "$$  \n",
        "\n",
        "Таким образом, гиперболический тангенс имеет горизонтальные асимптоты при $y = 1$ и $y = -1$.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Связь между $\\tanh(t)$ и его производной  \n",
        "\n",
        "Производная гиперболического тангенса выражается через саму функцию:  \n",
        "\n",
        "$$\n",
        "f'(t) = 1 - \\tanh^2(t).\n",
        "$$  \n",
        "\n",
        "Графики функции $\\tanh(t)$ и её производной $f'(t)$ представлены на Рис. 1.  \n",
        "\n",
        "\n",
        "\n",
        "### в) Формулы для forward pass и backward pass через слой с гиперболическим тангенсом  \n",
        "\n",
        "Гиперболический тангенс не имеет обучаемых параметров, поэтому прямой и обратный проходы через слой с этой функцией активации выполняются следующим образом:  \n",
        "\n",
        "1. **Прямой проход (forward pass):**  \n",
        "$$\n",
        "   o = \\tanh(h),\n",
        "$$  \n",
        "   где $h$ — входной сигнал слоя.  \n",
        "\n",
        "2. **Обратный проход (backward pass):**  \n",
        "   Градиент по входному сигналу $h$ вычисляется с использованием производной гиперболического тангенса:  \n",
        "$$\n",
        "   \\frac{\\partial L}{\\partial h} = (1 - \\tanh^2(h)) \\cdot \\frac{\\partial L}{\\partial o},\n",
        "$$  \n",
        "   где $\\frac{\\partial L}{\\partial o}$ — градиент по выходу слоя, полученный от последующих слоёв.  \n",
        "\n",
        "\n",
        "\n",
        "### г) Проблема затухания градиента  \n",
        "\n",
        "Производная гиперболического тангенса $f'(t) = 1 - \\tanh^2(t)$ принимает значения на интервале $[0; 1]$. Максимальное значение производной равно $1$ (достигается при $t = 0$).  \n",
        "\n",
        "Как и в случае с сигмоидой, гиперболический тангенс способствует затуханию градиента, особенно при больших по модулю значениях $t$, где производная близка к нулю. Это может привести к замедлению или остановке обучения глубоких нейронных сетей (проблема затухания градиента).  \n",
        "\n",
        "\n",
        "\n",
        "### д) Центрированность относительно нуля  \n",
        "\n",
        "В отличие от сигмоиды, гиперболический тангенс центрирован относительно нуля, так как его выход лежит в интервале $[-1; 1]$. Это свойство улучшает сходимость градиентного спуска, так как градиенты могут принимать как положительные, так и отрицательные значения.  \n",
        "\n",
        "\n",
        "\n",
        "### е) Практическое использование гиперболического тангенса  \n",
        "\n",
        "Гиперболический тангенс редко используется в качестве функции активации в скрытых слоях нейронных сетей из-за проблемы затухания градиента. Однако он находит применение в следующих случаях:  \n",
        "\n",
        "1. **Генерация данных на интервале $[-1; 1]$:**  \n",
        "   Например, при работе с изображениями, нормализованными на интервал $[-1; 1]$, гиперболический тангенс может использоваться на выходном слое генеративной модели.  \n",
        "\n",
        "2. **Специфические архитектуры нейронных сетей:**  \n",
        "   В некоторых архитектурах, таких как LSTM (Long Short-Term Memory), гиперболический тангенс используется для управления потоком информации, так как его выход лежит в ограниченном диапазоне.  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wBagY9_XfIeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mSH4FS6pfLt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ReLU и её вариации  \n",
        "\n",
        "### а) Функция ReLU и её свойства  \n",
        "\n",
        "Функция активации ReLU (Rectified Linear Unit) определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{ReLU}(t) = \\max(t, 0).\n",
        "$$  \n",
        "\n",
        "#### Производная ReLU  \n",
        "Производная функции ReLU имеет вид:  \n",
        "\n",
        "$$\n",
        "\\text{ReLU}'(t) =\n",
        "\\begin{cases}\n",
        "1, & t \\geq 0, \\\\\n",
        "0, & t < 0.\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "График функции ReLU и её производной представлен на Рис. 1.  \n",
        "\n",
        "#### Обратное распространение ошибки  \n",
        "При обратном распространении ошибки градиент умножается на производную ReLU:  \n",
        "- Если $t \\geq 0$, градиент передаётся без изменений.  \n",
        "- Если $t < 0$, градиент обнуляется.  \n",
        "\n",
        "#### Проблема \"мёртвых нейронов\"  \n",
        "Если все входы нейрона отрицательны, его выход становится нулевым, и градиент также обнуляется. Это явление называется \"мёртвым нейроном\" (dying ReLU problem). Для предотвращения этой проблемы рекомендуется инициализировать смещение $b$ положительными значениями.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Центрированность ReLU относительно нуля  \n",
        "\n",
        "ReLU не является центрированной относительно нуля, так как её выход лежит в интервале $[0, +\\infty)$. Это может замедлять сходимость обучения в глубоких нейронных сетях.  \n",
        "\n",
        "\n",
        "\n",
        "### в) Функция Leaky ReLU  \n",
        "\n",
        "Функция Leaky ReLU (LReLU) определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{LReLU}(t) =\n",
        "\\begin{cases}\n",
        "t, & t \\geq 0, \\\\\n",
        "\\alpha \\cdot t, & t < 0,\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "где $\\alpha$ — небольшой положительный параметр (обычно $\\alpha = 0.01$).  \n",
        "\n",
        "#### Производная Leaky ReLU  \n",
        "Производная функции LReLU имеет вид:  \n",
        "\n",
        "$$\n",
        "\\text{LReLU}'(t) =\n",
        "\\begin{cases}\n",
        "1, & t \\geq 0, \\\\\n",
        "\\alpha, & t < 0.\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "График функции LReLU и её производной представлен на Рис. 2.  \n",
        "\n",
        "#### Преимущества LReLU  \n",
        "- Предотвращает проблему \"мёртвых нейронов\", так как градиент на отрицательных значениях не обнуляется.  \n",
        "- Сохраняет вычислительную эффективность ReLU.  \n",
        "\n",
        "\n",
        "\n",
        "### г) Функция ELU  \n",
        "\n",
        "Функция ELU (Exponential Linear Unit) определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{ELU}(t) =\n",
        "\\begin{cases}\n",
        "t, & t \\geq 0, \\\\\n",
        "\\alpha \\cdot (e^t - 1), & t < 0,\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "где $\\alpha$ — параметр, обычно равный 1.  \n",
        "\n",
        "#### Производная ELU  \n",
        "Производная функции ELU имеет вид:  \n",
        "\n",
        "$$\n",
        "\\text{ELU}'(t) =\n",
        "\\begin{cases}\n",
        "1, & t \\geq 0, \\\\\n",
        "\\alpha \\cdot e^t, & t < 0.\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "Для $t < 0$ производную можно переписать как $\\text{ELU}(t) + \\alpha$, что упрощает вычисления.  \n",
        "\n",
        "График функции ELU и её производной представлен на Рис. 3.  \n",
        "\n",
        "#### Преимущества ELU  \n",
        "- На отрицательных значениях функция экспоненциально насыщается, что помогает сохранить разреженность активаций.  \n",
        "- ELU приблизительно центрирована относительно нуля, что ускоряет сходимость глубоких нейронных сетей.  \n",
        "\n",
        "\n",
        "\n",
        "### д) Функция SELU  \n",
        "\n",
        "Функция SELU (Scaled Exponential Linear Unit) определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{SELU}(t) = \\lambda \\cdot\n",
        "\\begin{cases}\n",
        "t, & t \\geq 0, \\\\\n",
        "\\alpha \\cdot (e^t - 1), & t < 0,\n",
        "\\end{cases}\n",
        "$$  \n",
        "\n",
        "где $\\alpha = 1.67733$ и $\\lambda = 1.0507$ — фиксированные параметры, предложенные авторами функции.  \n",
        "\n",
        "#### Преимущества SELU  \n",
        "- SELU обладает свойством самонормализации, что позволяет глубоким нейронным сетям сохранять стабильность градиентов без необходимости использования техник, таких как Batch Normalization.  \n",
        "\n",
        "\n",
        "## 5. ReLU и её вариации (продолжение)  \n",
        "\n",
        "### д) Нормализация данных и функция SELU  \n",
        "\n",
        "#### Нормализация данных в машинном обучении  \n",
        "При обучении линейных моделей градиентным спуском данные часто нормализуются путём вычитания среднего значения и деления на стандартное отклонение. Это улучшает сходимость алгоритма, так как градиентный спуск работает эффективнее, когда признаки имеют одинаковый масштаб.  \n",
        "\n",
        "#### Нормализация в нейронных сетях  \n",
        "В нейронных сетях желательно, чтобы выходы каждого слоя также были нормализованы. Это достигается с помощью техник, таких как **нормализация по батчам** (Batch Normalization), которая стабилизирует распределение активаций внутри сети.  \n",
        "\n",
        "#### Самонормализация SELU  \n",
        "Функция активации SELU (Scaled Exponential Linear Unit) обладает свойством **самонормализации**. Это означает, что при использовании SELU выходы всех слоёв нейронной сети автоматически распределены со средним значением 0 и дисперсией 1. Это свойство позволяет избежать необходимости использования Batch Normalization.  \n",
        "\n",
        "Авторы SELU доказали, что эта функция предотвращает взрыв и затухание градиентов, что делает её особенно полезной для глубоких нейронных сетей. Однако для корректной работы SELU необходимо:  \n",
        "- Использовать инициализацию весов по Лякуну (LeCun initialization).  \n",
        "- Применять **AlphaDropout** вместо стандартного Dropout, чтобы сохранить нулевое среднее и единичную дисперсию.  \n",
        "\n",
        "\n",
        "\n",
        "### е) Функция активации Swish  \n",
        "\n",
        "Функция Swish была предложена в 2017 году исследователями из Google Brain с использованием автоматического поиска на основе RNN. Она определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{Swish}(t) = t \\cdot \\sigma(\\beta \\cdot t),\n",
        "$$  \n",
        "\n",
        "где $\\sigma$ — сигмоидная функция, а $\\beta$ — обучаемый параметр.  \n",
        "\n",
        "#### Интерпретация Swish  \n",
        "Swish можно рассматривать как гладкий аналог ReLU с \"гейтом\" (gate), который регулирует поток информации. Параметр $\\beta$ управляет формой функции:  \n",
        "- При $\\beta \\to 0$: Swish приближается к линейной функции $\\frac{t}{2}$.  \n",
        "- При $\\beta \\to \\infty$: Swish становится похожей на ReLU, так как сигмоида превращается в ступеньку.  \n",
        "\n",
        "График функции Swish для различных значений $\\beta$ представлен на Рис. 4.  \n",
        "\n",
        "#### Практическое использование Swish  \n",
        "Swish демонстрирует улучшенную производительность по сравнению с ReLU в некоторых задачах, особенно в глубоких нейронных сетях. Однако её использование требует дополнительных вычислительных ресурсов из-за наличия сигмоиды.  \n",
        "\n",
        "\n",
        "\n",
        "### ж) Современные функции активации  \n",
        "\n",
        "#### Mish (2019)  \n",
        "Функция Mish была предложена как альтернатива Swish:  \n",
        "\n",
        "$$\n",
        "\\text{Mish}(t) = t \\cdot \\tanh(\\ln(1 + e^t)).\n",
        "$$  \n",
        "\n",
        "Mish сочетает в себе преимущества Swish и ELU, обеспечивая высокую производительность в различных задачах.  \n",
        "\n",
        "#### ACON (2021)  \n",
        "В 2021 году было предложено семейство саморегулирующихся функций активации ACON (Activate or Not). Эти функции автоматически адаптируются к данным, выбирая между активацией и её отсутствием.  \n",
        "\n",
        "\n",
        "\n",
        "### Рекомендации по выбору функции активации  \n",
        "\n",
        "1. **Начните с ReLU:** ReLU является стандартным выбором для большинства задач благодаря своей простоте и эффективности.  \n",
        "2. **Используйте ELU/SELU:** Эти функции могут улучшить сходимость и производительность в глубоких сетях.  \n",
        "3. **Экспериментируйте с Swish и Mish:** Если вы готовы к дополнительным вычислениям, попробуйте Swish или Mish для потенциального улучшения качества модели.  \n",
        "4. **Избегайте сигмоиды и тангенса:** Эти функции устарели и могут вызывать проблемы с затуханием градиентов.  \n",
        "\n"
      ],
      "metadata": {
        "id": "zLMBnH8JfLxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pa97b-MAfTrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Температура генерации  \n",
        "\n",
        "В задачах генерации данных с использованием нейронных сетей в функцию Softmax часто добавляется параметр $T$, называемый **температурой сэмплирования**. Модифицированная функция Softmax принимает вид:  \n",
        "\n",
        "$$\n",
        "p_i = \\frac{e^{\\frac{z_i}{T}}}{\\sum_{k=1}^K e^{\\frac{z_k}{T}}},\n",
        "$$  \n",
        "\n",
        "где $z_i$ — выходы нейронной сети, а $T$ — параметр температуры.  \n",
        "\n",
        "\n",
        "\n",
        "### а) Влияние температуры на распределение вероятностей  \n",
        "\n",
        "Рассмотрим пример, где нейронная сеть выдала на последнем слое значения $z = (1, 2, 5)$. Вычислим распределение вероятностей для различных значений температуры $T$:  \n",
        "\n",
        "1. **При $T = 10$:**  \n",
        "$$\n",
        "   p \\approx (0.39, 0.36, 0.25).\n",
        "$$  \n",
        "   Распределение близко к равномерному.  \n",
        "\n",
        "2. **При $T = 1$:**  \n",
        "$$\n",
        "   p \\approx (0.72, 0.27, 0.01).\n",
        "$$  \n",
        "   Распределение становится более выраженным, с преобладанием класса с максимальным значением.  \n",
        "\n",
        "3. **При $T = 0.1$:**  \n",
        "$$\n",
        "   p \\approx (0.9999, 4 \\cdot 10^{-5}, 4 \\cdot 10^{-18}).\n",
        "$$  \n",
        "   Распределение почти полностью сосредоточено на классе с максимальным значением.  \n",
        "\n",
        "**Вывод:**  \n",
        "- Чем меньше $T$, тем более выраженным становится максимум в распределении.  \n",
        "- Чем больше $T$, тем ближе распределение к равномерному.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Предельные случаи температуры  \n",
        "\n",
        "1. **При $T \\to \\infty$:**  \n",
        "$$\n",
        "   e^{\\frac{z_i}{T}} \\to 1 \\quad \\text{для всех } i.\n",
        "$$  \n",
        "   Следовательно,  \n",
        "$$\n",
        "   p_i \\to \\frac{1}{K},\n",
        "$$  \n",
        "   где $K$ — количество классов. Распределение становится равномерным.  \n",
        "\n",
        "2. **При $T \\to 0$:**  \n",
        "$$\n",
        "   e^{\\frac{z_i}{T}} \\to \\begin{cases}\n",
        "   +\\infty, & \\text{если } z_i = \\max(z), \\\\\n",
        "   0, & \\text{иначе}.\n",
        "   \\end{cases}\n",
        "$$  \n",
        "   Следовательно,  \n",
        "$$\n",
        "   p_i \\to \\begin{cases}\n",
        "   1, & \\text{если } z_i = \\max(z), \\\\\n",
        "   0, & \\text{иначе}.\n",
        "   \\end{cases}\n",
        "$$  \n",
        "   Распределение становится детерминированным, сосредоточенным на классе с максимальным значением.  \n",
        "\n",
        "### в) Применение температуры в задачах генерации текста  \n",
        "\n",
        "Рассмотрим задачу генерации текста, например, ответов виртуального помощника (Алисы). В этом случае:  \n",
        "\n",
        "1. **Маленькие значения $T$:**  \n",
        "   - Делают ответы более предсказуемыми и однотипными.  \n",
        "   - Подходят для задач, где требуется высокая точность и повторяемость.  \n",
        "\n",
        "2. **Большие значения $T$:**  \n",
        "   - Делают ответы более разнообразными, но менее предсказуемыми.  \n",
        "   - Могут приводить к генерации случайных или несвязных ответов.  \n",
        "\n",
        "**Практическое использование:**  \n",
        "- Параметр $T$ подбирается экспериментально после обучения модели.  \n",
        "- Оптимальное значение $T$ зависит от задачи:  \n",
        "  - Для задач, требующих точности, выбирают маленькие $T$.  \n",
        "  - Для задач, требующих разнообразия, выбирают большие $T$.  \n",
        "\n"
      ],
      "metadata": {
        "id": "MMi6SxezfTxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t9pYvd_LfZR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7. Модернизация функции потерь  \n",
        "\n",
        "### а) Учёт дисбаланса классов в logloss  \n",
        "\n",
        "Рассмотрим задачу бинарной классификации, где распределение целевой переменной $y$ является несбалансированным (Рис. 1). В таких случаях стандартная логистическая функция потерь (logloss) может быть модифицирована для учёта дисбаланса классов.  \n",
        "\n",
        "#### Стандартная logloss  \n",
        "Стандартная функция потерь logloss имеет вид:  \n",
        "\n",
        "$$\n",
        "\\text{logloss} = -\\frac{1}{n} \\sum_{i=1}^n \\left( y_i \\cdot \\ln p_i + (1 - y_i) \\cdot \\ln (1 - p_i) \\right),\n",
        "$$  \n",
        "\n",
        "где $y_i$ — истинная метка класса, а $p_i$ — предсказанная вероятность принадлежности к классу 1.  \n",
        "\n",
        "#### Модифицированная logloss  \n",
        "Для учёта дисбаланса классов можно ввести весовые коэффициенты:  \n",
        "\n",
        "$$\n",
        "\\text{logloss}_{\\text{weighted}} = -\\frac{1}{n} \\sum_{i=1}^n \\left( w_1 \\cdot y_i \\cdot \\ln p_i + w_0 \\cdot (1 - y_i) \\cdot \\ln (1 - p_i) \\right),\n",
        "$$  \n",
        "\n",
        "где $w_1$ и $w_0$ — веса для классов 1 и 0 соответственно. В примере Маши $w_1 = 3$ и $w_0 = 1$, что позволяет увеличить вклад редкого класса в функцию потерь.  \n",
        "\n",
        "#### Практическое применение  \n",
        "В библиотеке scikit-learn подобная модификация может быть реализована с помощью параметра `class_weight='balanced'` в модели `LogisticRegression`. Это автоматически учитывает дисбаланс классов и назначает веса пропорционально частоте классов в обучающей выборке.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Функция потерь Focal Loss  \n",
        "\n",
        "Focal Loss была предложена для решения задачи детекции объектов на изображениях, где часто возникает сильный дисбаланс между классами (например, фон и объекты).  \n",
        "\n",
        "#### Проблема дисбаланса классов  \n",
        "В задачах детекции изображений большинство участков (патчей) содержат фон, который легко классифицируется. Это приводит к тому, что модель сосредотачивается на \"лёгких\" примерах (фоне) и игнорирует \"сложные\" примеры (объекты).  \n",
        "\n",
        "#### Определение Focal Loss  \n",
        "Focal Loss модифицирует стандартную logloss, добавляя два параметра: $\\alpha$ и $\\gamma$. Функция потерь определяется следующим образом:  \n",
        "\n",
        "$$\n",
        "\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\ln(p_t),\n",
        "$$  \n",
        "\n",
        "где:  \n",
        "- $p_t$ — вероятность правильной классификации:  \n",
        "  $$\n",
        "  p_t =\n",
        "  \\begin{cases}\n",
        "  p, & \\text{если } y = 1, \\\\\n",
        "  1 - p, & \\text{если } y = 0.\n",
        "  \\end{cases}\n",
        "  $$  \n",
        "- $\\alpha_t$ — весовой коэффициент для баланса классов:  \n",
        "  $$\n",
        "  \\alpha_t =\n",
        "  \\begin{cases}\n",
        "  \\alpha, & \\text{если } y = 1, \\\\\n",
        "  1 - \\alpha, & \\text{если } y = 0.\n",
        "  \\end{cases}\n",
        "  $$  \n",
        "- $\\gamma$ — параметр, управляющий фокусировкой на \"сложных\" примерах.  \n",
        "\n",
        "#### Роль параметров $\\alpha$ и $\\gamma$  \n",
        "1. **Параметр $\\alpha$:**  \n",
        "   - Управляет балансом между классами.  \n",
        "   - Увеличивает вклад редкого класса в функцию потерь.  \n",
        "\n",
        "2. **Параметр $\\gamma$:**  \n",
        "   - Уменьшает вклад \"лёгких\" примеров (где $p_t$ близко к 1).  \n",
        "   - Увеличивает вклад \"сложных\" примеров (где $p_t$ близко к 0).  \n",
        "\n",
        "#### График Focal Loss  \n",
        "На Рис. 2 представлен график Focal Loss для различных значений $\\gamma$. Видно, что при увеличении $\\gamma$ штраф за \"лёгкие\" примеры уменьшается, что позволяет модели сосредоточиться на \"сложных\" примерах.  \n",
        "\n",
        "\n",
        "\n",
        "### в) Преимущества Focal Loss  \n",
        "\n",
        "1. **Учёт дисбаланса классов:**  \n",
        "   - Параметр $\\alpha$ позволяет балансировать вклад классов в функцию потерь.  \n",
        "\n",
        "2. **Фокусировка на сложных примерах:**  \n",
        "   - Параметр $\\gamma$ уменьшает вклад \"лёгких\" примеров, что особенно полезно в задачах с большим количеством фона.  \n",
        "\n",
        "3. **Улучшение качества модели:**  \n",
        "   - Focal Loss помогает модели лучше классифицировать редкие классы и сложные примеры, что повышает её общую производительность.  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tf1lx749fZXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YqDA1pYwfda4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Предсказание вероятностей  \n",
        "\n",
        "### Постановка задачи  \n",
        "\n",
        "Рассмотрим задачу бинарной классификации, где необходимо определить, является ли пиво \"правильным\" ($y = 1$) или \"неправильным\" ($y = 0$). Для этого используется выборка данных $(y_i, x_i)$, где $y_i$ — метка класса, а $x_i$ — признаки. Цель — построить модель, которая на выходе будет выдавать оценку вероятности принадлежности пива к классу \"правильное\".  \n",
        "\n",
        "Для достижения этой цели необходимо выбрать подходящую функцию потерь. Рассмотрим несколько вариантов и проанализируем их свойства.  \n",
        "\n",
        "\n",
        "\n",
        "### а) Квадратичная функция потерь  \n",
        "\n",
        "Функция потерь:  \n",
        "\n",
        "$$\n",
        "L(y, a(x)) = (y - a(x))^2.\n",
        "$$  \n",
        "\n",
        "#### Математическое ожидание потерь  \n",
        "Математическое ожидание потерь при фиксированном $x$ выражается как:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = P(y = 1 \\mid x) \\cdot (a - 1)^2 + (1 - P(y = 1 \\mid x)) \\cdot a^2.\n",
        "$$  \n",
        "\n",
        "Обозначим $p = P(y = 1 \\mid x)$. Тогда:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = p(a - 1)^2 + (1 - p)a^2.\n",
        "$$  \n",
        "\n",
        "#### Оптимизация  \n",
        "Продифференцируем по $a$:  \n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial a} E[L(y, a) \\mid x] = 2p(a - 1) + 2(1 - p)a = 2a - 2p.\n",
        "$$  \n",
        "\n",
        "Приравнивая производную к нулю, получаем:  \n",
        "\n",
        "$$\n",
        "a = p.\n",
        "$$  \n",
        "\n",
        "Таким образом, минимизация квадратичной функции потерь приводит к тому, что модель предсказывает вероятность $P(y = 1 \\mid x)$.  \n",
        "\n",
        "\n",
        "\n",
        "### б) Абсолютная функция потерь  \n",
        "\n",
        "Функция потерь:  \n",
        "\n",
        "$$\n",
        "L(y, a(x)) = |y - a(x)|.\n",
        "$$  \n",
        "\n",
        "#### Математическое ожидание потерь  \n",
        "Математическое ожидание потерь при фиксированном $x$:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = p \\cdot |1 - a| + (1 - p) \\cdot |a|.\n",
        "$$  \n",
        "\n",
        "Упростим выражение:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = p + (1 - 2p)a.\n",
        "$$  \n",
        "\n",
        "#### Оптимизация  \n",
        "Поскольку функция линейна по $a$, её минимум достигается на границах интервала $[0, 1]$:  \n",
        "- Если $1 - 2p > 0$ ($p < 0.5$), минимум достигается при $a = 0$.  \n",
        "- Если $1 - 2p < 0$ ($p > 0.5$), минимум достигается при $a = 1$.  \n",
        "- Если $p = 0.5$, значение $a$ не влияет на потери.  \n",
        "\n",
        "Таким образом, абсолютная функция потерь не позволяет модели предсказывать вероятности, так как оптимальные прогнозы всегда равны 0 или 1.  \n",
        "\n",
        "\n",
        "\n",
        "### в) Логистическая функция потерь (logloss)  \n",
        "\n",
        "Функция потерь:  \n",
        "\n",
        "$$\n",
        "L(y, a(x)) = y \\cdot \\ln a(x) + (1 - y) \\cdot \\ln (1 - a(x)).\n",
        "$$  \n",
        "\n",
        "#### Математическое ожидание потерь  \n",
        "Математическое ожидание потерь при фиксированном $x$:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = p \\cdot \\ln a + (1 - p) \\cdot \\ln (1 - a).\n",
        "$$  \n",
        "\n",
        "#### Оптимизация  \n",
        "Продифференцируем по $a$:  \n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial a} E[L(y, a) \\mid x] = \\frac{p}{a} - \\frac{1 - p}{1 - a}.\n",
        "$$  \n",
        "\n",
        "Приравнивая производную к нулю, получаем:  \n",
        "\n",
        "$$\n",
        "a = p.\n",
        "$$  \n",
        "\n",
        "Таким образом, минимизация логистической функции потерь также приводит к тому, что модель предсказывает вероятность $P(y = 1 \\mid x)$.  \n",
        "\n",
        "\n",
        "\n",
        "### г) Линейная функция потерь  \n",
        "\n",
        "Функция потерь:  \n",
        "\n",
        "$$\n",
        "L(y, a(x)) = y \\cdot a(x) + (1 - y) \\cdot (1 - a(x)).\n",
        "$$  \n",
        "\n",
        "#### Математическое ожидание потерь  \n",
        "Математическое ожидание потерь при фиксированном $x$:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = p \\cdot a + (1 - p) \\cdot (1 - a).\n",
        "$$  \n",
        "\n",
        "Упростим выражение:  \n",
        "\n",
        "$$\n",
        "E[L(y, a) \\mid x] = a(2p - 1) + (1 - p).\n",
        "$$  \n",
        "\n",
        "#### Оптимизация  \n",
        "Поскольку функция линейна по $a$, её минимум достигается на границах интервала $[0, 1]$:  \n",
        "- Если $2p - 1 > 0$ ($p > 0.5$), минимум достигается при $a = 1$.  \n",
        "- Если $2p - 1 < 0$ ($p < 0.5$), минимум достигается при $a = 0$.  \n",
        "- Если $p = 0.5$, значение $a$ не влияет на потери.  \n",
        "\n",
        "Таким образом, линейная функция потерь также не позволяет модели предсказывать вероятности.  \n",
        "\n",
        "\n",
        "\n",
        "### Вывод  \n",
        "\n",
        "Для задачи предсказания вероятностей наиболее подходящими являются:  \n",
        "1. **Квадратичная функция потерь** — минимизация приводит к предсказанию вероятности $P(y = 1 \\mid x)$.  \n",
        "2. **Логистическая функция потерь (logloss)** — также приводит к предсказанию вероятности $P(y = 1 \\mid x)$.  \n",
        "\n",
        "Абсолютная и линейная функции потерь не подходят для предсказания вероятностей, так как их минимизация приводит к детерминированным прогнозам (0 или 1).  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "meqAdDJufde-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Таблица сравнения функций активации и их свойств:\n",
        "\n",
        "| **Функция активации** | **Формула**                                                                 | **Диапазон значений** | **Производная**                                                                 | **Преимущества**                                                                 | **Недостатки**                                                                 |\n",
        "|------------------------|-----------------------------------------------------------------------------|-----------------------|--------------------------------------------------------------------------------|---------------------------------------------------------------------------------|--------------------------------------------------------------------------------|\n",
        "| **Сигмоида**          | $\\sigma(t) = \\frac{1}{1 + e^{-t}}$                                          | $[0, 1]$              | $\\sigma'(t) = \\sigma(t) \\cdot (1 - \\sigma(t))$                                 | - Интерпретируемость как вероятность.<br>- Гладкая и дифференцируемая.          | - Проблема затухания градиента.<br>- Нецентрированность относительно нуля.<br>- Медленные вычисления. |\n",
        "| **Гиперболический тангенс** | $\\tanh(t) = \\frac{2}{1 + e^{-2t}} - 1$                                | $[-1, 1]$             | $\\tanh'(t) = 1 - \\tanh^2(t)$                                                   | - Центрированность относительно нуля.<br>- Улучшает сходимость градиентного спуска. | - Проблема затухания градиента.<br>- Медленные вычисления.                     |\n",
        "| **ReLU**              | $\\text{ReLU}(t) = \\max(t, 0)$                                               | $[0, +\\infty)$        | $\\text{ReLU}'(t) = \\begin{cases} 1, & t \\geq 0, \\\\ 0, & t < 0. \\end{cases}$     | - Простота вычислений.<br>- Устранение проблемы затухания градиента.<br>- Быстрые вычисления. | - Проблема \"мёртвых нейронов\".<br>- Нецентрированность относительно нуля.      |\n",
        "| **Leaky ReLU**        | $\\text{LReLU}(t) = \\begin{cases} t, & t \\geq 0, \\\\ \\alpha \\cdot t, & t < 0. \\end{cases}$ | $(-\\infty, +\\infty)$  | $\\text{LReLU}'(t) = \\begin{cases} 1, & t \\geq 0, \\\\ \\alpha, & t < 0. \\end{cases}$ | - Решает проблему \"мёртвых нейронов\".<br>- Сохраняет вычислительную эффективность. | - Требует подбора параметра $\\alpha$.                                          |\n",
        "| **ELU**               | $\\text{ELU}(t) = \\begin{cases} t, & t \\geq 0, \\\\ \\alpha \\cdot (e^t - 1), & t < 0. \\end{cases}$ | $[-\\alpha, +\\infty)$  | $\\text{ELU}'(t) = \\begin{cases} 1, & t \\geq 0, \\\\ \\alpha \\cdot e^t, & t < 0. \\end{cases}$ | - Улучшает сходимость.<br>- Решает проблему \"мёртвых нейронов\".                | - Требует больше вычислений из-за экспоненты.<br>- Требует подбора параметра $\\alpha$. |\n",
        "| **SELU**              | $\\text{SELU}(t) = \\lambda \\cdot \\begin{cases} t, & t \\geq 0, \\\\ \\alpha \\cdot (e^t - 1), & t < 0. \\end{cases}$ | $[-\\lambda \\alpha, +\\infty)$ | $\\text{SELU}'(t) = \\lambda \\cdot \\begin{cases} 1, & t \\geq 0, \\\\ \\alpha \\cdot e^t, & t < 0. \\end{cases}$ | - Самонормализация.<br>- Улучшает стабильность глубоких сетей.                 | - Требует специфической инициализации весов.<br>- Требует больше вычислений.    |\n",
        "| **Swish**             | $\\text{Swish}(t) = t \\cdot \\sigma(\\beta \\cdot t)$                           | $(-\\infty, +\\infty)$  | $\\text{Swish}'(t) = \\sigma(\\beta t) + \\beta t \\cdot \\sigma(\\beta t) \\cdot (1 - \\sigma(\\beta t))$ | - Гладкая и эффективная.<br>- Лучше ReLU в некоторых задачах.                   | - Требует больше вычислений из-за сигмоиды.<br>- Требует подбора параметра $\\beta$. |\n",
        "| **Mish**              | $\\text{Mish}(t) = t \\cdot \\tanh(\\ln(1 + e^t))$                              | $(-\\infty, +\\infty)$  | $\\text{Mish}'(t) = \\frac{e^t \\cdot (4e^{2t} + e^{3t} + 4(1 + t) + e^t(6 + 4t))}{(2 + 2e^t + e^{2t})^2}$ | - Сочетает преимущества Swish и ELU.<br>- Высокая производительность.           | - Требует больше вычислений.<br>- Сложность вычисления производной.            |\n",
        "\n",
        "\n",
        "\n",
        "### Таблица сравнения функций потерь:\n",
        "\n",
        "\n",
        "\n",
        "| **Функция потерь**       | **Формула**                                                                 | **Оптимизация**                                                                 | **Преимущества**                                                                 | **Недостатки**                                                                 |\n",
        "|--------------------------|-----------------------------------------------------------------------------|--------------------------------------------------------------------------------|---------------------------------------------------------------------------------|--------------------------------------------------------------------------------|\n",
        "| **Квадратичная**         | $L(y, a) = (y - a)^2$                                                       | $a = P(y = 1 \\mid x)$                                                          | - Простота.<br>- Подходит для предсказания вероятностей.                        | - Чувствительность к выбросам.<br>- Не подходит для задач классификации.        |\n",
        "| **Абсолютная**           | $L(y, a) = |y - a|$                                                         | $a = 0$ или $a = 1$ (детерминированный прогноз)                                 | - Устойчивость к выбросам.                                                      | - Не подходит для предсказания вероятностей.<br>- Недифференцируема в нуле.     |\n",
        "| **Логистическая (logloss)** | $L(y, a) = y \\cdot \\ln a + (1 - y) \\cdot \\ln (1 - a)$                       | $a = P(y = 1 \\mid x)$                                                          | - Подходит для предсказания вероятностей.<br>- Широко используется в классификации. | - Чувствительность к дисбалансу классов.<br>- Медленная сходимость при больших ошибках. |\n",
        "| **Focal Loss**           | $\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\ln(p_t)$                      | Учитывает дисбаланс классов и сложные примеры.                                 | - Эффективна при дисбалансе классов.<br>- Фокусируется на сложных примерах.      | - Требует подбора параметров $\\alpha$ и $\\gamma$.<br>- Сложность интерпретации. |\n",
        "| **Hinge Loss**           | $L(y, a) = \\max(0, 1 - y \\cdot a)$                                          | Используется в SVM.                                                            | - Эффективна для задач классификации.<br>- Устойчивость к выбросам.             | - Не подходит для предсказания вероятностей.<br>- Недифференцируема в некоторых точках. |\n",
        "| **Cross-Entropy**        | $L(y, a) = -\\sum_{i} y_i \\log(a_i)$                                         | $a_i = P(y_i = 1 \\mid x)$                                                      | - Подходит для многоклассовой классификации.<br>- Широко используется в нейронных сетях. | - Чувствительность к дисбалансу классов.<br>- Требует нормализации вероятностей. |\n",
        "\n",
        "\n",
        "\n",
        "### Основные выводы:\n",
        "\n",
        "1. **Функции активации:**\n",
        "   - **ReLU** и её вариации (Leaky ReLU, ELU, SELU) остаются наиболее популярными благодаря их простоте, эффективности и быстрым вычислениям.\n",
        "   - **Сигмоида** и **гиперболический тангенс** устарели из-за проблем с затуханием градиентов и медленными вычислениями.\n",
        "   - **Swish** и **Mish** показывают улучшенную производительность в сложных задачах, но требуют больше вычислительных ресурсов.\n",
        "   - Выбор функции активации зависит от задачи: для глубоких сетей предпочтительны ReLU и её модификации, а для задач, требующих гладких функций, — Swish или Mish.\n",
        "\n",
        "2. **Функции потерь:**\n",
        "   - **Logloss** и **квадратичная функция потерь** подходят для задач регрессии и бинарной классификации.\n",
        "   - **Focal Loss** эффективна в задачах с дисбалансом классов, таких как детекция объектов.\n",
        "   - **Cross-Entropy** является стандартом для многоклассовой классификации.\n",
        "   - **Абсолютная** и **Hinge Loss** используются в специфических задачах, где важна устойчивость к выбросам или требуется максимальная точность классификации.\n",
        "\n",
        "3. **Рекомендации:**\n",
        "   - Для глубоких нейронных сетей начните с **ReLU** или **Leaky ReLU**.\n",
        "   - Для задач классификации используйте **Cross-Entropy** или **Logloss**.\n",
        "   - Для задач с дисбалансом классов рассмотрите **Focal Loss**.\n",
        "   - Экспериментируйте с **Swish** и **Mish**, если вычислительные ресурсы позволяют.\n",
        "\n"
      ],
      "metadata": {
        "id": "jIVJwTL4hK05"
      }
    }
  ]
}